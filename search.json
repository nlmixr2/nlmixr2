[{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"id_17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"adding-covariances-between-random-effects","dir":"Articles","previous_headings":"","what":"Adding Covariances between random effects","title":"Random Effect Covariances","text":"can simply add co-variances two random effects adding effects together model specification block, eta.cl+eta.v ~. statement, specify lower triangular matrix fit c(). example phenobarbitol data:","code":"## Load phenobarbitol data library(nlmixr2)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"model-specification","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Model Specification","title":"Random Effect Covariances","text":"","code":"pheno <- function() {   ini({     tcl <- log(0.008) # typical value of clearance     tv <-  log(0.6)   # typical value of volume     ## var(eta.cl)     eta.cl + eta.v ~ c(1,                         0.01, 1) ## cov(eta.cl, eta.v), var(eta.v)                       # interindividual variability on clearance and volume     add.err <- 0.1    # residual variability   })   model({     cl <- exp(tcl + eta.cl) # individual value of clearance     v <- exp(tv + eta.v)    # individual value of volume     ke <- cl / v            # elimination rate constant     d/dt(A1) = - ke * A1    # model differential equation     cp = A1 / v             # concentration in plasma     cp ~ add(add.err)       # define error model   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"fit-with-saem","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Fit with SAEM","title":"Random Effect Covariances","text":"","code":"fit <- nlmixr(pheno, pheno_sd, \"saem\",               control=list(print=0),                table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 print(fit) #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 688.6792 985.5502 1003.811      -486.7751        7.570439        6.604927 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance   saem table compress #> elapsed 0.002518    4e-06   0.017006 11.413 2.932    0.024 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>                          Parameter  Est.     SE %RSE    Back-transformed(95%CI) #> tcl     typical value of clearance -4.99 0.0743 1.49 0.00677 (0.00586, 0.00784) #> tv         typical value of volume 0.346 0.0538 15.5          1.41 (1.27, 1.57) #> add.err       residual variability  2.83                                   2.83 #>         BSV(CV%) Shrink(SD)% #> tcl         52.4      1.50%  #> tv          41.0      1.09%  #> add.err                      #>   #>   Covariance Type ($covMethod): linFim #>   Correlations in between subject variability (BSV) matrix: #>     cor:eta.v,eta.cl  #>           0.989   #>   #>  #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 155 × 26 #>   ID     TIME    DV EPRED  ERES   NPDE     NPD   PDE    PD  PRED    RES    WRES #>   <fct> <dbl> <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl> <dbl>  <dbl>   <dbl> #> 1 1        2   17.3  18.9 -1.62 -0.350 -0.0837 0.363 0.467  17.5 -0.222 -0.0297 #> 2 1      112.  31    29.7  1.33  0.279  0.279  0.61  0.61   27.9  3.11   0.254  #> 3 2        2    9.7  11.4 -1.71 -0.706 -0.253  0.24  0.4    10.5 -0.813 -0.162  #> # ℹ 152 more rows #> # ℹ 14 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.cl <dbl>, eta.v <dbl>, A1 <dbl>, cl <dbl>, #> #   v <dbl>, ke <dbl>, tad <dbl>, dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"basic-goodness-of-fit-plots","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Basic Goodness of Fit Plots","title":"Random Effect Covariances","text":"individual plots great, better see actual curves; can augPred","code":"plot(fit) plot(augPred(fit))"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"two-types-of-vpcs","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Two types of VPCs","title":"Random Effect Covariances","text":"","code":"library(ggplot2) p1 <- vpcPlot(fit, show=list(obs_dv=TRUE)); #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 p1 <- p1 + ylab(\"Concentrations\")  ## A prediction-corrected VPC p2 <- vpcPlot(fit, pred_corr = TRUE, show=list(obs_dv=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 p2 <- p2 + ylab(\"Prediction-Corrected Concentrations\")  library(patchwork) p1 / p2"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"the-broom-and-broom-mixed-packages","dir":"Articles","previous_headings":"","what":"The broom and broom.mixed packages","title":"Using broom with nlmixr2","text":"broom broom.mixed packages attempt put standard model outputs data frames. nlmixr supports tidy glance methods support augment time. Using model covariance term, Phenobarbital model, can explore different types output used tidy functions. explore , first run model:","code":"library(nlmixr2) library(broom.mixed)  pheno <- function() {   # Pheno with covariance   ini({     tcl <- log(0.008) # typical value of clearance     tv <-  log(0.6)   # typical value of volume     ## var(eta.cl)     eta.cl + eta.v ~ c(1,                        0.01, 1) ## cov(eta.cl, eta.v), var(eta.v)     # interindividual variability on clearance and volume     add.err <- 0.1    # residual variability   })   model({     cl <- exp(tcl + eta.cl) # individual value of clearance     v <- exp(tv + eta.v)    # individual value of volume     ke <- cl / v            # elimination rate constant     d/dt(A1) = - ke * A1    # model differential equation     cp = A1 / v             # concentration in plasma     cp ~ add(add.err)       # define error model   }) }  ## We will run it two ways to allow comparisons fit.s <- nlmixr(pheno, pheno_sd, \"saem\", control=list(logLik=TRUE, print=0),                 table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 fit.f <- nlmixr(pheno, pheno_sd, \"focei\",                 control=list(print=0),                 table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done #> [====|====|====|====|====|====|====|====|====|====] 0:00:00"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"glancing-at-the-goodness-of-fit-metrics","dir":"Articles","previous_headings":"","what":"Glancing at the goodness of fit metrics","title":"Using broom with nlmixr2","text":"Often fitting data, want glance fit see well fits. broom, glance give summary fit metrics goodness fit: Note nlmixr possible one fit metric (based different quadratures, FOCEi approximation etc). However, glance returns fit metrics current. wish can set objective function focei objective function (already calculated CWRES). Now glance gives gauss3_1.6 values. course can always change type objective function nlmixr uses: setting back SAEM default objective function FOCEi, glance(fit.s) values : convenience, can glance objects:","code":"glance(fit.s) #> # A tibble: 2 × 6 #>    OBJF   AIC   BIC logLik `Condition#(Cov)` `Condition#(Cor)` #>   <dbl> <dbl> <dbl>  <dbl>             <dbl>             <dbl> #> 1  689.  986. 1004.  -487.              7.57              6.60 #> 2  729. 1026. 1044.  -507.              7.57              6.60 setOfv(fit.s,\"gauss3_1.6\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 glance(fit.s) #> # A tibble: 3 × 6 #>    OBJF   AIC   BIC logLik `Condition#(Cov)` `Condition#(Cor)` #>   <dbl> <dbl> <dbl>  <dbl>             <dbl>             <dbl> #> 1  689.  986. 1004.  -487.              7.57              6.60 #> 2  729. 1026. 1044.  -507.              7.57              6.60 #> 3  729. 1026. 1044.  -507.              7.57              6.60 setOfv(fit.s,\"FOCEi\") # Setting objective function to focei glance(fit.s) #> # A tibble: 3 × 6 #>    OBJF   AIC   BIC logLik `Condition#(Cov)` `Condition#(Cor)` #>   <dbl> <dbl> <dbl>  <dbl>             <dbl>             <dbl> #> 1  689.  986. 1004.  -487.              7.57              6.60 #> 2  729. 1026. 1044.  -507.              7.57              6.60 #> 3  729. 1026. 1044.  -507.              7.57              6.60 glance(fit.s, type=\"FOCEi\") #> # A tibble: 3 × 6 #>    OBJF   AIC   BIC logLik `Condition#(Cov)` `Condition#(Cor)` #>   <dbl> <dbl> <dbl>  <dbl>             <dbl>             <dbl> #> 1  689.  986. 1004.  -487.              7.57              6.60 #> 2  729. 1026. 1044.  -507.              7.57              6.60 #> 3  729. 1026. 1044.  -507.              7.57              6.60"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"tidying-of-overall-fit-parameters","dir":"Articles","previous_headings":"Tidying the model parameters","what":"Tidying of overall fit parameters","title":"Using broom with nlmixr2","text":"can also tidy model estimates data frame broom processing. can useful integrating 3rd parting modeling packages. consistent parameter format, tasks multiple types models can automated applied. default function tidy, applied fit object provides overall parameter information tidy dataset: Note default parameters actually estimated nlmixr, back-transformed values table printout. course, mu-referenced models, may want exponentiate terms. broom package allows apply exponentiation parameters, : Note:, accordance rest broom package, parameters exponentiated, standard errors transformed approximate standard error formula: \\(\\textrm{se}(\\exp(x)) \\approx \\exp(\\textrm{model estimate}_x)\\times \\textrm{se}_x\\). can confusing confidence intervals (described later) using actual standard error back-transforming exponentiated scale. reason default nlmixr’s broom interface exponentiate=FALSE, : want, can also use parsed back-transformation used nlmixr tables (ie fit$parFixedDf). Please note uses approximate back-transformation standard errors log-scaled back-transformed values. done : Also note, time writing default separator variables ., doesn’t work well model giving cor__eta.v.eta.cl. can easily change : gives easier way parse value: cor__eta.v..eta.cl","code":"tidy(fit.s) #> # A tibble: 6 × 7 #>   effect   group         term             estimate std.error statistic   p.value #>   <chr>    <chr>         <chr>               <dbl>     <dbl>     <dbl>     <dbl> #> 1 fixed    NA            tcl                -4.99     0.0743    -67.2   1   e+ 0 #> 2 fixed    NA            tv                  0.346    0.0538      6.43  8.09e-10 #> 3 ran_pars ID            sd__eta.cl          0.492   NA          NA    NA        #> 4 ran_pars ID            sd__eta.v           0.394   NA          NA    NA        #> 5 ran_pars ID            cor__eta.v.eta.…    0.989   NA          NA    NA        #> 6 ran_pars Residual(add) add.err             2.83    NA          NA    NA ## Transformation applied on every parameter tidy(fit.s, exponentiate=TRUE) #> # A tibble: 6 × 7 #>   effect   group         term             estimate std.error statistic   p.value #>   <chr>    <chr>         <chr>               <dbl>     <dbl>     <dbl>     <dbl> #> 1 fixed    NA            tcl               0.00677  0.000503      13.5  7.75e-28 #> 2 fixed    NA            tv                1.41     0.0760        18.6  5.66e-41 #> 3 ran_pars ID            sd__eta.cl        0.492   NA             NA   NA        #> 4 ran_pars ID            sd__eta.v         0.394   NA             NA   NA        #> 5 ran_pars ID            cor__eta.v.eta.…  0.989   NA             NA   NA        #> 6 ran_pars Residual(add) add.err           2.83    NA             NA   NA tidy(fit.s, exponentiate=FALSE) ## No transformation applied #> # A tibble: 6 × 7 #>   effect   group         term             estimate std.error statistic   p.value #>   <chr>    <chr>         <chr>               <dbl>     <dbl>     <dbl>     <dbl> #> 1 fixed    NA            tcl                -4.99     0.0743    -67.2   1   e+ 0 #> 2 fixed    NA            tv                  0.346    0.0538      6.43  8.09e-10 #> 3 ran_pars ID            sd__eta.cl          0.492   NA          NA    NA        #> 4 ran_pars ID            sd__eta.v           0.394   NA          NA    NA        #> 5 ran_pars ID            cor__eta.v.eta.…    0.989   NA          NA    NA        #> 6 ran_pars Residual(add) add.err             2.83    NA          NA    NA ## Transformation applied to log-scaled population parameters tidy(fit.s, exponentiate=NA) #> # A tibble: 6 × 7 #>   effect   group         term             estimate std.error statistic   p.value #>   <chr>    <chr>         <chr>               <dbl>     <dbl>     <dbl>     <dbl> #> 1 fixed    NA            tcl               0.00677  0.000503      13.5  7.75e-28 #> 2 fixed    NA            tv                1.41     0.0760        18.6  5.66e-41 #> 3 ran_pars ID            sd__eta.cl        0.492   NA             NA   NA        #> 4 ran_pars ID            sd__eta.v         0.394   NA             NA   NA        #> 5 ran_pars ID            cor__eta.v.eta.…  0.989   NA             NA   NA        #> 6 ran_pars Residual(add) add.err           2.83    NA             NA   NA options(broom.mixed.sep2=\"..\") tidy(fit.s) #> # A tibble: 6 × 7 #>   effect   group         term             estimate std.error statistic   p.value #>   <chr>    <chr>         <chr>               <dbl>     <dbl>     <dbl>     <dbl> #> 1 fixed    NA            tcl                -4.99     0.0743    -67.2   1   e+ 0 #> 2 fixed    NA            tv                  0.346    0.0538      6.43  8.09e-10 #> 3 ran_pars ID            sd__eta.cl          0.492   NA          NA    NA        #> 4 ran_pars ID            sd__eta.v           0.394   NA          NA    NA        #> 5 ran_pars ID            cor__eta.v..eta…    0.989   NA          NA    NA        #> 6 ran_pars Residual(add) add.err             2.83    NA          NA    NA"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"adding-a-confidence-interval-to-the-parameters","dir":"Articles","previous_headings":"Tidying the model parameters","what":"Adding a confidence interval to the parameters","title":"Using broom with nlmixr2","text":"default R method confint works nlmixr fit objects: transforms variables described . can still use exponentiate parameter control display confidence interval: However, broom also implemented way make data tidy dataset. easiest way get values nlmixr dataset use: confidence interval scale specified exponentiate, default estimated scale. want confidence adaptive back-transformed scale, simply use following:","code":"confint(fit.s) #>          model.est    estimate      2.5 %     97.5 % #> tcl     -4.9946697 0.006773958 -5.1402489 -4.8490905 #> tv       0.3458435 1.413181420  0.2404558  0.4512312 #> add.err  2.8342748 2.834274766         NA         NA confint(fit.s, exponentiate=FALSE) #>          model.est    estimate      2.5 %     97.5 % #> tcl     -4.9946697 0.006773958 -5.1402489 -4.8490905 #> tv       0.3458435 1.413181420  0.2404558  0.4512312 #> add.err  2.8342748 2.834274766         NA         NA tidy(fit.s, conf.level=0.9) #> # A tibble: 6 × 9 #>   effect   group term  estimate std.error statistic   p.value conf.low conf.high #>   <chr>    <chr> <chr>    <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl> #> 1 fixed    NA    tcl     -4.99     0.0743    -67.2   1   e+ 0   -5.12     -4.87  #> 2 fixed    NA    tv       0.346    0.0538      6.43  8.09e-10    0.257     0.434 #> 3 ran_pars ID    sd__…    0.492   NA          NA    NA          NA        NA     #> 4 ran_pars ID    sd__…    0.394   NA          NA    NA          NA        NA     #> 5 ran_pars ID    cor_…    0.989   NA          NA    NA          NA        NA     #> 6 ran_pars Resi… add.…    2.83    NA          NA    NA          NA        NA tidy(fit.s, conf.level=0.9, exponentiate=NA) #> # A tibble: 6 × 9 #>   effect   group term  estimate std.error statistic   p.value conf.low conf.high #>   <chr>    <chr> <chr>    <dbl>     <dbl>     <dbl>     <dbl>    <dbl>     <dbl> #> 1 fixed    NA    tcl    0.00677  0.000503      13.5  7.75e-28  0.00599   0.00765 #> 2 fixed    NA    tv     1.41     0.0760        18.6  5.66e-41  1.29      1.54    #> 3 ran_pars ID    sd__…  0.492   NA             NA   NA        NA        NA       #> 4 ran_pars ID    sd__…  0.394   NA             NA   NA        NA        NA       #> 5 ran_pars ID    cor_…  0.989   NA             NA   NA        NA        NA       #> 6 ran_pars Resi… add.…  2.83    NA             NA   NA        NA        NA"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-other-model-information-with-tidy","dir":"Articles","previous_headings":"","what":"Extracting other model information with tidy","title":"Using broom with nlmixr2","text":"type information extracted can controlled effects argument.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-only-fixed-effect-parameters","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting only fixed effect parameters","title":"Using broom with nlmixr2","text":"fixed effect parameters can extracted effects=\"fixed\"","code":"tidy(fit.s, effects=\"fixed\") #> # A tibble: 2 × 6 #>   effect term  estimate std.error statistic  p.value #>   <chr>  <chr>    <dbl>     <dbl>     <dbl>    <dbl> #> 1 fixed  tcl     -4.99     0.0743    -67.2  1   e+ 0 #> 2 fixed  tv       0.346    0.0538      6.43 8.09e-10"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-only-random-parameters","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting only random parameters","title":"Using broom with nlmixr2","text":"random standard deviations can extracted effects=\"ran_pars\":","code":"tidy(fit.s, effects=\"ran_pars\") #> # A tibble: 4 × 4 #>   effect   group         term               estimate #>   <chr>    <chr>         <chr>                 <dbl> #> 1 ran_pars ID            sd__eta.cl            0.492 #> 2 ran_pars ID            sd__eta.v             0.394 #> 3 ran_pars ID            cor__eta.v..eta.cl    0.989 #> 4 ran_pars Residual(add) add.err               2.83"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-random-values-also-called-etas","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting random values (also called ETAs)","title":"Using broom with nlmixr2","text":"random values, NONMEM ETAs, can extracted effects=\"ran_vals\" effects=\"random\" duplicate method running effects broom package supports effects=\"random\" broom.mixed package supports effects=\"ran_vals\".","code":"head(tidy(fit.s, effects=\"ran_vals\")) #> # A tibble: 6 × 5 #>   effect   group level term   estimate #>   <chr>    <chr> <fct> <fct>     <dbl> #> 1 ran_vals ID    1     eta.cl  -0.0743 #> 2 ran_vals ID    2     eta.cl  -0.212  #> 3 ran_vals ID    3     eta.cl   0.261  #> 4 ran_vals ID    4     eta.cl  -0.537  #> 5 ran_vals ID    5     eta.cl   0.316  #> 6 ran_vals ID    6     eta.cl  -0.125"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-random-coefficients","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting random coefficients","title":"Using broom with nlmixr2","text":"Random coefficients population fixed effect parameter + random effect parameter, possibly transformed correct scale. case can extract information nlmixr fit object : can also changed exponentiate argument:","code":"head(tidy(fit.s, effects=\"ran_coef\")) #> # A tibble: 6 × 5 #>   effect   group level term  estimate #>   <chr>    <chr> <fct> <fct>    <dbl> #> 1 ran_coef ID    1     tcl      -5.07 #> 2 ran_coef ID    2     tcl      -5.21 #> 3 ran_coef ID    3     tcl      -4.73 #> 4 ran_coef ID    4     tcl      -5.53 #> 5 ran_coef ID    5     tcl      -4.68 #> 6 ran_coef ID    6     tcl      -5.12 head(tidy(fit.s, effects=\"ran_coef\", exponentiate=NA)) #> # A tibble: 6 × 5 #>   effect   group level term  estimate #>   <chr>    <chr> <fct> <fct>    <dbl> #> 1 ran_coef ID    1     tcl    0.00629 #> 2 ran_coef ID    2     tcl    0.00548 #> 3 ran_coef ID    3     tcl    0.00879 #> 4 ran_coef ID    4     tcl    0.00396 #> 5 ran_coef ID    5     tcl    0.00929 #> 6 ran_coef ID    6     tcl    0.00598 head(tidy(fit.s, effects=\"ran_coef\", exponentiate=TRUE)) #> # A tibble: 6 × 5 #>   effect   group level term  estimate #>   <chr>    <chr> <fct> <fct>    <dbl> #> 1 ran_coef ID    1     tcl    0.00629 #> 2 ran_coef ID    2     tcl    0.00548 #> 3 ran_coef ID    3     tcl    0.00879 #> 4 ran_coef ID    4     tcl    0.00396 #> 5 ran_coef ID    5     tcl    0.00929 #> 6 ran_coef ID    6     tcl    0.00598"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/censoring.html","id":"censoring-support-in-nlmixr","dir":"Articles","previous_headings":"","what":"Censoring support in nlmixr","title":"Censoring in nlmixr","text":"general, censoring observation measured researcher knows something certain number. 2001, Beal introduced censoring pharmacometric community described common ways deal missing data. methods , data structure used nlmixr support : Estimate Likelihood observation censored limit. concentrations limit quantitation (left censored), can specify nlmixr two columns: DV, CENS. value censored, DV limit quantification, CENS 1. rest non-censored values, DV keeps normal value CENS 0. censored value limit quantitation (right censored), DV remains limit quantification CENS -1. expansion M3 method. cases, like PK, can also assume observations actually positive. Therefore, may want adjust likelihood take consideration fact. can accomplished nlmixr well adding LIMIT column. case left censored problem, can specify concentration LIMIT DV. works right left censored values. data columns LIMIT CENS, based Monolix method handling censored data.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/censoring.html","id":"data-output-for-censored-data-in-nlmixr","dir":"Articles","previous_headings":"","what":"Data output for censored data in nlmixr","title":"Censoring in nlmixr","text":"censored data output, often useful see predictions perform censored area. accomplish , simulated value used show prediction noise. used calculate standard residual values nlmixr. default, value simulated truncated normal distribution model assumptions censoring information specified data (though can use CDF method used npde package instead calculating npdes well). simulated value replaces original DV used calculate residuals requested. original limit information output lowerLim upperLim.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"citations","dir":"Articles","previous_headings":"","what":"Citations","title":"nlmixr2 Citations","text":"document, attempt keep list published scientific work reported using nlmixr fashion. used nlmixr nlmixr2 (mixrverse package) work, please let us know can add list.","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section","dir":"Articles","previous_headings":"Citations > Publications","what":"2019","title":"nlmixr2 Citations","text":"Helmlinger G, Sokolov V, Peskov K, Hallow KM, Kosinsky Y, Voronova V, et al. Quantitative Systems Pharmacology: Exemplar Model-Building Workflow Applications Cardiovascular, Metabolic, Oncology Drug Development. CPT: Pharmacometrics & Systems Pharmacology. 2019;8(6):380–95. 10.1002/psp4.12426 Fidler M, Wilkins JJ, Hooijmaijers R, Post TM, Schoemaker R, Trame MN, et al. Nonlinear Mixed-Effects Model Development Simulation Using nlmixr Related R Open-Source Packages. CPT: Pharmacometrics & Systems Pharmacology. 2019;8(9):621–33. 10.1002/psp4.12445 Schoemaker R, Fidler M, Laveille C, Wilkins JJ, Hooijmaijers R, Post TM, et al. Performance SAEM FOCEI Algorithms Open-Source, Nonlinear Mixed Effect Modeling Tool nlmixr. CPT: Pharmacometrics & Systems Pharmacology. 2019;8(12):923–30. 10.1002/psp4.12471","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-1","dir":"Articles","previous_headings":"Citations > Publications","what":"2020","title":"nlmixr2 Citations","text":"Mwandigha LM, Fraser KJ, Racine-Poon , Mouksassi MS, Ghani AC. Power calculations cluster randomized trials (CRTs) right-truncated Poisson-distributed outcomes: motivating example malaria vector control trial. International Journal Epidemiology. 2020 Jun 1;49(3):954–62. 10.1093/ije/dyz277","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-2","dir":"Articles","previous_headings":"Citations > Publications","what":"2021","title":"nlmixr2 Citations","text":"Fidler M, Hooijmaijers R, Schoemaker R, Wilkins JJ, Xiong Y, Wang W. R nlmixr gateway statistics pharmacometrics. CPT: Pharmacometrics & Systems Pharmacology. 2021;10(4):283–5. 10.1002/psp4.12618 Lombard , Mistry H, Aarons L, Ogungbenro K. Dose individualisation oncology using chemotherapy-induced neutropenia: Example docetaxel non-small cell lung cancer patients. British Journal Clinical Pharmacology. 2021;87(4):2053–63. 10.1111/bcp.14614 Lu J, Deng K, Zhang X, Liu G, Guan Y. Neural-ODE pharmacokinetics modeling advantage alternative machine learning models predicting new dosing regimens. iScience. 2021 Jul 23;24(7). 10.1016/j.isci.2021.102804 Välitalo PAJ. Pharmacometric estimation methods aggregate data, including data simulated pharmacometric models. J Pharmacokinet Pharmacodyn. 2021 Oct 1;48(5):623–38. 10.1007/s10928-021-09760-1 Goers R, Coman Schmid D, Jäggi VF, Paioni P, Okoniewski MJ, Parker , et al. SwissPKcdw – clinical data warehouse optimization pediatric dosing regimens. CPT: Pharmacometrics & Systems Pharmacology. 2021;10(12):1578–87. 10.1002/psp4.12723 Jaisser F, Tan X, Chi S, Liu J, Wang P, Bush M, et al. Non-Steroidal Mineralocorticoid Receptor Antagonist KBP-5074 Limits Albuminuria Improved Therapeutic Index Compared Eplerenone Rat Model Mineralocorticoid-Induced Renal Injury. Frontiers Pharmacology. 2021;12. 10.3389/fphar.2021.604928 Medhora M, Phadnis P, Narayanan J, Gasperetti T, Zielonka J, Moulder JE, et al. Radiation Increases Bioavailability Lisinopril, Mitigator Radiation-Induced Toxicities. Frontiers Pharmacology. 2021;12. 10.3389/fphar.2021.646076","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-3","dir":"Articles","previous_headings":"Citations > Publications","what":"2022","title":"nlmixr2 Citations","text":"Lee SY. Bayesian Nonlinear Models Repeated Measurement Data: Overview, Implementation, Applications. Mathematics. 2022 Jan;10(6):898. 10.3390/math10060898 Aghamiri SS, Amin R, Helikar T. Recent applications quantitative systems pharmacology machine learning models across diseases. J Pharmacokinet Pharmacodyn. 2022 Feb 1;49(1):19–37. 10.1007/s10928-021-09790-9 Soeorg H, Sverrisdóttir E, Andersen M, Lund TM, Sessa M. PHARMACOM-EPI Framework Integrating Pharmacometric Modelling Pharmacoepidemiological Research Using Real-World Data: Application Assess Death Associated Valproate. Clinical Pharmacology & Therapeutics. 2022;111(4):840–56. 10.1002/cpt.2502 Liakopoulos , Aulin LBS, Buffoni M, Fragkiskou E, Coen van Hasselt JG, Rozen DE. Allele-specific collateral fitness effects determine dynamics fluoroquinolone resistance evolution. Proceedings National Academy Sciences. 2022 May 3;119(18):e2121768119. 10.1073/pnas.2121768119 Mehta K, Guo T, Wallis RS, van der Graaf PH, van Hasselt JGC. Quantitative Systems Pharmacology Modeling Framework Autophagy Tuberculosis: Application Adjunctive Metformin Host-Directed Therapy. Antimicrobial Agents Chemotherapy. 2022 Jul 14;66(8):e00366-22. 10.1128/aac.00366-22 Agyeman AA, T, Chan PLS, Lonsdale , Hadjichrysanthou C, Mahungu T, et al. Comparative assessment viral dynamic models SARS-CoV-2 pharmacodynamic assessment early treatment trials. British Journal Clinical Pharmacology. 2022;88(12):5428–33. 10.1111/bcp.15518 Aulin LBS, Tandar ST, van Zijp T, van Ballegooie E, van der Graaf PH, Saleh MAA, et al. Physiologically Based Modelling Framework Prediction Pulmonary Pharmacokinetics Antimicrobial Target Site Concentrations. Clin Pharmacokinet. 2022 Dec 1;61(12):1735–48. 10.1007/s40262-022-01186-3 Kloprogge F, Ortiz Canseco J, Phee L, Sadouki Z, Kipper K, Witney AA, et al. Emergence phenotypic genotypic antimicrobial resistance Mycobacterium tuberculosis. Sci Rep. 2022 Dec 11;12(1):21429. 10.1038/s41598-022-25827-6 Voulgarelis D, Bulusu KC, Yates JWT. Comparison classical tumour growth models patient derived cell-line derived xenografts using nonlinear mixed-effects framework. Journal Biological Dynamics. 2022 Dec 31;16(1):160–85. 10.1080/17513758.2022.2061615","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-4","dir":"Articles","previous_headings":"Citations > Publications","what":"2023","title":"nlmixr2 Citations","text":"Mak WY, Ooi QX, Cruz CV, Looi , Yuen KH, Standing JF. Assessment nlmixr R package population pharmacokinetic modeling: metformin case study. British Journal Clinical Pharmacology. 2023;89(1):330–9. 10.1111/bcp.15496 Mehta K, Guo T, van der Graaf PH, van Hasselt JGC. Predictions Bedaquiline Pretomanid Target Attainment Lung Lesions Tuberculosis Patients using Translational Minimal Physiologically Based Pharmacokinetic Modeling. Clin Pharmacokinet. 2023 Mar 1;62(3):519–32. 10.1007/s40262-023-01217-7 Yang W, Mak W, Gwee , Gu M, Wu Y, Shi Y, et al. Establishment Evaluation Parametric Population Pharmacokinetic Model Repository Ganciclovir Valganciclovir. Pharmaceutics. 2023 Jul;15(7):1801. 10.3390/pharmaceutics15071801 Ibrahim EIK, Karlsson MO, Friberg LE. Assessment ibrutinib scheduling leukocyte, lymph node size blood pressure dynamics chronic lymphocytic leukemia pharmacokinetic-pharmacodynamic models. CPT: Pharmacometrics & Systems Pharmacology. 2023;12(9):1305–18. 10.1002/psp4.13010 Zhang S, Agyeman AA, Hadjichrysanthou C, Standing JF. SARS-CoV-2 viral dynamic modeling inform model selection timing efficacy antiviral therapy. CPT: Pharmacometrics & Systems Pharmacology. 2023;12(10):1450–60. 10.1002/psp4.13022 Barrett JS, Betourne , Walls RL, Lasater K, Russell S, Borens , et al. future rare disease drug development: rare disease cures accelerator data analytics platform (RDCA-DAP). J Pharmacokinet Pharmacodyn. 2023 Dec 1;50(6):507–19. 10.1007/s10928-023-09859-7","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-5","dir":"Articles","previous_headings":"Citations > Publications","what":"2024","title":"nlmixr2 Citations","text":"Kovács L, Ferenci T, Gombos B, Füredi , Rudas , Szakács G, et al. Positive Impulsive Control Tumor Therapy—Cyber-Medical Approach. IEEE Transactions Systems, Man, Cybernetics: Systems. 2024 Jan;54(1):597–608. 10.1109/TSMC.2023.3315637 Lepak AJ, VanScoy B, Rubino C, Ambrose PG, Andes DR. vivo pharmacodynamic characterization next-generation polyene, SF001, invasive pulmonary aspergillosis mouse model. Antimicrobial Agents Chemotherapy. 2024 Feb 6;0(0):e01631-23. 10.1128/aac.01631-23 Standing JF, Buggiotti L, Guerra-Assuncao JA, Woodall M, Ellis S, Agyeman AA, et al. Randomized controlled trial molnupiravir SARS-CoV-2 viral antibody response -risk adult outpatients. Nat Commun. 2024 Feb 23;15(1):1652. 10.1038/s41467-024-45641-0","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-6","dir":"Articles","previous_headings":"Citations > Conference Proceedings","what":"2016","title":"nlmixr2 Citations","text":"Fidler M, Schoemaker R, Xiong Y, Wilkins J, Laveille C, Wang W. W-66. nlmixr: open-source package pharmacometric modelling R. Abstracts accepted American Conference Pharmacometrics 2016 (ACoP7). J Pharmacokinet Pharmacodyn. 2016 43(S1):S115. 10.1007/s10928-016-9485-x","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-7","dir":"Articles","previous_headings":"Citations > Conference Proceedings","what":"2017","title":"nlmixr2 Citations","text":"Erhardt E, Jacobs T, Gasparini M. Comparison pharmacokinetic parameters estimated experimental R package ‘nlmixr’ MONOLIX. PAGE 2017 (Budapest, Hungary): Abstr 7247 Schoemaker R, Fidler M, Xiong Y, Wilkins J, Trame MN, Laveille C, Wang W. T-012. nlmixr: open-source package pharmacometric modelling R. Abstracts American Conference Pharmacometrics 2017 (ACoP8). J Pharmacokinet Pharmacodyn. 2017 44(S1):S60. 10.1007/s10928-017-9536-y Schoemaker R, Fidler M, Xiong Y, Wilkins J, Trame M, Laveille C, Wang W. nlmixr: open-source package pharmacometric modelling R. PAGE 2017 (Budapest, Hungary): Abstr 7102","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-8","dir":"Articles","previous_headings":"Citations > Conference Proceedings","what":"2018","title":"nlmixr2 Citations","text":"Bartels C, Bieth B, Dumortier T, Baltcheva , Bhattacharya S, Ludwig , Demin , Gassem , Renard D. ggPMX: toolbox easily generate comprehensive set model diagnostic plots population models. PAGE 2018 (Montreux, Switzerland): Abstr 8423 Fidler M, Xiong Y, Schoemaker R, Wilkins J, Trame MN, Post T, Hooijmaijers R, Wang W. W-058. Exploring inductive linearization population pharmacokinetic pharmacodynamic models. Abstracts Ninth American Conference Pharmacometrics (ACoP9). J Pharmacokinet Pharmacodyn. 2018 45(S1):S116. 10.1007/s10928-018-9606-9 Hooijmaijers R, Fidler M, Schoemaker R, Trame MN, Wang W, Wilkins J, Xiong Y, Post T. ShinyMixR: project-centric R/Shiny run management tool nlmixr. PAGE 2018 (Montreux, Switzerland): Abstr 8452 Erhardt EM, Ursino M, Jacobs T, Biewenga J, Gasparini M. Bayesian knowledge integration vitro–vivo correlation (IVIVC) model. PAGE 2018 (Montreux, Switzerland): Abstr 8689","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-9","dir":"Articles","previous_headings":"Citations > Conference Proceedings","what":"2019","title":"nlmixr2 Citations","text":"Baltcheva , Bartels C, Dumortier T, Bhattacharya S, Paule , Ludwig , Demin , Gassem , Renard D, Bieth B. ggPMX: open-source R package pharmacometric model diagnostic plots. PAGE 2019 (Stockholm, Sweden): Abstr 9013 Schoemaker S, Fidler M, Laveille C, Wilkins JJ, Hooijmaijers R, Post TM, Trame MN, Xiong Y, Wang W. Performance SAEM FOCEI algorithms open-source non-linear mixed effect modelling tool nlmixr. PAGE 2019 (Stockholm, Sweden): Abstr 8978","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-10","dir":"Articles","previous_headings":"Citations > Conference Proceedings","what":"2021","title":"nlmixr2 Citations","text":"Aulin LBS, Liakopoulos , Rozen DE, van Hasselt JGC. Model-based design innovative treatment strategies suppress antimicrobial resistance using collateral sensitivity. PAGE 2021 (Virtual): Abstr 9792 Ibrahim E, Karlsson MO, Friberg LE. Pharmacokinetic-pharmacodynamic (PK-PD) modeling leukocyte dynamics lymph node size chronic lymphocytic leukaemia patients treated ibrutinib. PAGE 2021 (Virtual): Abstr 9682 Jung WJ, Hwang T, Jung S, Savic RM, Chae JW, Yun HY. Web based platform clinical pharmacokinetic consultation service (CPCS) Non-linear Mixed Effect Model. PAGE 2021 (Virtual): Abstr 9727 Pham AD, van Hasselt JGC. Modelling rate extent resistance development colistin Klebsiella pneumoniae. PAGE 2021 (Virtual): Abstr 9774 Tran QT, Lee CH, Kim MG, Kim M, Kim H, Chae JW, Yun HY. Overview Korean Pharmacometrics Modeling Library web-based pharmacometrics platform. PAGE 2021 (Virtual): Abstr 9865 Vavilov S, Sokolov V, Zhudenkov K, Stolbov L, Peskov K. Parameter estimation nonlinear fixed-effects QSP models: benchmark optimization methods. PAGE 2021 (Virtual): Abstr 9755","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-11","dir":"Articles","previous_headings":"Citations > Conference Proceedings","what":"2022","title":"nlmixr2 Citations","text":"Bieth B, Fidler M, Baltcheva . ggPMX: re-imagine diagnostics plots. PAGE 2022 (Ljubljana, Slovenia): Abstr 9998 Liu C, Cojutti PG, Bussini L, Rosselli Del Turco E, Bartoletti M, Pea F. Comparison performances open-source R package “nlmixr” vs. Monolix population pharmacokinetics continuous infusion meropenem patients onco-hematological malignancies. PAGE 2022 (Ljubljana, Slovenia): Abstr 10210 Nordgren R, Belin S, Yngman G, Huang Z, Carter SJ, Chen X, Qutishat O, Hamdan , Wang S, Yang T, Assawasuwannakit P, Buatois S, Abrantes JA, Hooker AC, Karlsson MO. Pharmpy: versatile open-source library pharmacometrics. PAGE 2022 (Ljubljana, Slovenia): Abstr 10096","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/citations.html","id":"section-12","dir":"Articles","previous_headings":"Citations > Conference Proceedings","what":"2023","title":"nlmixr2 Citations","text":"Cheng , Solas C, Howley E, McGarrity O, Rajani K, Breuer J, Standing J, Kreins . Favipiravir pharmacokinetics immunocompromised infants children chronic RNA viral infections. PAGE 2023 (Coruña, Spain): Abstr 10570 Codina MS, Pham AD, van Os W, al Jalali V, Matzneller P, Wölfl-Duchek M, Vychytil , Reiter B, Stimpfl T, van Hasselt JG, Zeitlinger M. Evaluating ceftazidime-avibactam exposure patients undergoing automated peritoneal dialysis using population pharmacokinetic modelling. PAGE 2023 (Coruña, Spain): Abstr 10707 Combes FP, Fidler M, Ochsenbein D, Illis W, Subrahmanyam K, Ho Y-Y. Benchmarking Industrial Computing Environments - Pharmacometrics Study (BICEPS). PAGE 2023 (Coruña, Spain): Abstr 10604 Duong , Marsot . NONMEM versus nlmixr2 : example external evaluation gentamicin Pop-PK models. PAGE 2023 (Coruña, Spain): Abstr 10602 Fidler M, Denney WS, Harrold J, Hooijmaijers R, Schoemaker R, Taubert M, Trame M, Papathanasiou T, Wilkins J. nlmixr2, rxode2 NONMEM: interchangeable models using babelmixr2 nonmem2rx. PAGE 2023 (Coruña, Spain): Abstr 10313 Huang Z, Standing JF, Kloprogge F. Development exploration exhaustive, stepwise, heuristic algorithms automated population pharmacokinetic modelling. PAGE 2023 (Coruña, Spain): Abstr 10704. Jeon H, Sung T, Jung W, Chae J-W, Yun H-Y. Construction model-based PK-PD software platform using R package considering compatibility nlme structured model. PAGE 2023 (Coruña, Spain): Abstr 10432 Nordgren R, Belin S, Chen X, Borg J, Huang Z, Qutishat O, Shi K, Liu X, Wang S, Mohamed S, Mirasbekov S, Hooker AC, Karlsson MO. Pharmpy: versatile open-source library pharmacometrics. PAGE 2023 (Coruña, Spain): Abstr 10508 Xu C, Yu J, Cao W, Lu H, Yao Z, Sun X, Zhang K, Luo J, Zheng Q, Zheng H. PyMaS: population pharmacometric modeling Python. PAGE 2023 (Coruña, Spain): Abstr 10676","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"nlmixr-model","dir":"Articles","previous_headings":"","what":"nlmixr model","title":"mavoglurant -- physiologically-based PK","text":"","code":"library(nlmixr2) library(xpose) library(xpose.nlmixr2) library(ggplot2)  pbpk <- function(){   ini({     ##theta=exp(c(1.1, .3, 2, 7.6, .003, .3))     lKbBR = 1.1     lKbMU = 0.3     lKbAD = 2     lCLint = 7.6     lKbBO = 0.03     lKbRB = 0.3     eta.LClint ~ 4     add.err <- 1     prop.err <- 10   })   model({     KbBR = exp(lKbBR)     KbMU = exp(lKbMU)     KbAD = exp(lKbAD)     CLint= exp(lCLint + eta.LClint)     KbBO = exp(lKbBO)     KbRB = exp(lKbRB)      ## Regional blood flows     CO  = (187.00*WT^0.81)*60/1000;         # Cardiac output (L/h) from White et al (1968)     QHT = 4.0 *CO/100;     QBR = 12.0*CO/100;     QMU = 17.0*CO/100;     QAD = 5.0 *CO/100;     QSK = 5.0 *CO/100;     QSP = 3.0 *CO/100;     QPA = 1.0 *CO/100;     QLI = 25.5*CO/100;     QST = 1.0 *CO/100;     QGU = 14.0*CO/100;     QHA = QLI - (QSP + QPA + QST + QGU); # Hepatic artery blood flow     QBO = 5.0 *CO/100;     QKI = 19.0*CO/100;     QRB = CO - (QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI);     QLU = QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI + QRB;      ## Organs' volumes = organs' weights / organs' density     VLU = (0.76 *WT/100)/1.051;     VHT = (0.47 *WT/100)/1.030;     VBR = (2.00 *WT/100)/1.036;     VMU = (40.00*WT/100)/1.041;     VAD = (21.42*WT/100)/0.916;     VSK = (3.71 *WT/100)/1.116;     VSP = (0.26 *WT/100)/1.054;     VPA = (0.14 *WT/100)/1.045;     VLI = (2.57 *WT/100)/1.040;     VST = (0.21 *WT/100)/1.050;     VGU = (1.44 *WT/100)/1.043;     VBO = (14.29*WT/100)/1.990;     VKI = (0.44 *WT/100)/1.050;     VAB = (2.81 *WT/100)/1.040;     VVB = (5.62 *WT/100)/1.040;     VRB = (3.86 *WT/100)/1.040;      ## Fixed parameters     BP = 0.61;      # Blood:plasma partition coefficient     fup = 0.028;    # Fraction unbound in plasma     fub = fup/BP;   # Fraction unbound in blood      KbLU = exp(0.8334);     KbHT = exp(1.1205);     KbSK = exp(-.5238);     KbSP = exp(0.3224);     KbPA = exp(0.3224);     KbLI = exp(1.7604);     KbST = exp(0.3224);     KbGU = exp(1.2026);     KbKI = exp(1.3171);      ##-----------------------------------------     S15 = VVB*BP/1000;     C15 = Venous_Blood/S15      ##-----------------------------------------     d/dt(Lungs) = QLU*(Venous_Blood/VVB - Lungs/KbLU/VLU);     d/dt(Heart) = QHT*(Arterial_Blood/VAB - Heart/KbHT/VHT);     d/dt(Brain) = QBR*(Arterial_Blood/VAB - Brain/KbBR/VBR);     d/dt(Muscles) = QMU*(Arterial_Blood/VAB - Muscles/KbMU/VMU);     d/dt(Adipose) = QAD*(Arterial_Blood/VAB - Adipose/KbAD/VAD);     d/dt(Skin) = QSK*(Arterial_Blood/VAB - Skin/KbSK/VSK);     d/dt(Spleen) = QSP*(Arterial_Blood/VAB - Spleen/KbSP/VSP);     d/dt(Pancreas) = QPA*(Arterial_Blood/VAB - Pancreas/KbPA/VPA);     d/dt(Liver) = QHA*Arterial_Blood/VAB + QSP*Spleen/KbSP/VSP + QPA*Pancreas/KbPA/VPA + QST*Stomach/KbST/VST + QGU*Gut/KbGU/VGU - CLint*fub*Liver/KbLI/VLI - QLI*Liver/KbLI/VLI;     d/dt(Stomach) = QST*(Arterial_Blood/VAB - Stomach/KbST/VST);     d/dt(Gut) = QGU*(Arterial_Blood/VAB - Gut/KbGU/VGU);     d/dt(Bones) = QBO*(Arterial_Blood/VAB - Bones/KbBO/VBO);     d/dt(Kidneys) = QKI*(Arterial_Blood/VAB - Kidneys/KbKI/VKI);     d/dt(Arterial_Blood) = QLU*(Lungs/KbLU/VLU - Arterial_Blood/VAB);     d/dt(Venous_Blood) = QHT*Heart/KbHT/VHT + QBR*Brain/KbBR/VBR + QMU*Muscles/KbMU/VMU + QAD*Adipose/KbAD/VAD + QSK*Skin/KbSK/VSK + QLI*Liver/KbLI/VLI + QBO*Bones/KbBO/VBO + QKI*Kidneys/KbKI/VKI + QRB*Rest_of_Body/KbRB/VRB - QLU*Venous_Blood/VVB;     d/dt(Rest_of_Body) = QRB*(Arterial_Blood/VAB - Rest_of_Body/KbRB/VRB);      C15 ~ add(add.err) + prop(prop.err)   }) }  dat <- nlmixr2data::mavoglurant dat$occ = unlist(with(dat, tapply(EVID, ID, function(x) cumsum(x>0)))) dat = subset(dat, occ==1) dat = subset(dat, ID<812) ## First 20 dat = subset(dat, EVID>0 | DV>0) dat$CMT[dat$CMT == 0]  <- 1; dat$CMT[dat$EVID == 1]  <- \"Venous_Blood\" ## Compartment dosed to is Venous Blood dat$CMT[dat$EVID != 1]  <- \"C15\" ## Observing C15  gofs <- function(fit){     ################################################################################     ## Standard plots     ################################################################################     plot(fit)      xpdb <- xpose_data_nlmixr(fit) ## Convert to nlmixr object      print(dv_vs_pred(xpdb) +           ylab(\"Observed Mavoglurant Concentrations (ng/mL)\") +           xlab(\"Population Predicted Mavoglurant Concentrations (ng/mL)\"));      print(dv_vs_ipred(xpdb) +           ylab(\"Observed Mavoglurant Concentrations (ng/mL)\") +           xlab(\"Individual Predicted Mavoglurant Concentrations (ng/mL)\"));      print(res_vs_pred(xpdb) +           ylab(\"Conditional Weighted Residuals\") +           xlab(\"Population Predicted Mavoglurant Concentrations (ng/mL)\"));      print(res_vs_idv(xpdb) +           ylab(\"Conditional Weighted Residuals\") +           xlab(\"Time (h)\"));      if (!is.null(fit$saem)){         print(prm_vs_iteration(xpdb));     }      print(absval_res_vs_idv(xpdb, res = 'IWRES') +           ylab(\"Individual Weighted Residuals\") +           xlab(\"Time (h)\"))      print(absval_res_vs_pred(xpdb, res = 'IWRES') +           ylab(\"Individual Weighted Residuals\") +           xlab(\"Population Predicted Mavoglurant Concentrations (ng/mL)\"))      print(ind_plots(xpdb, nrow=3, ncol=4) +           ylab(\"Predicted and Observed Mavoglurant Concentrations (ng/mL)\") +           xlab(\"Time (h)\"))      print(res_distrib(xpdb) +           ylab(\"Density\") +           xlab(\"Conditional Weighted Residuals\"));     # Visual Predictive Checks     f1 <- vpcPlot(fit,n=500,stratify=\"DOSE\", show=list(obs_dv=T), log_y=TRUE,            bins = c(0, 2, 4, 6, 8, 10, 20, 30, 40, 50),            ylab = \"Mavoglurant Concentrations (ng/mL)\",            xlab = \"Time (hours)\")     f2 <- vpcPlot(fit,n=500, show=list(obs_dv=T), bins = c(0, 2, 4, 6, 8, 10, 20, 30, 40, 50), log_y=TRUE,                  ylab = \"Mavoglurant Concentrations (ng/mL)\", xlab = \"Time (hours)\")     plot(f1)     plot(f2) }"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"fit-addprop-saem","dir":"Articles","previous_headings":"SAEM","what":"Fit add+prop SAEM","title":"mavoglurant -- physiologically-based PK","text":"","code":"fit.addProp.S <- nlmixr(pbpk, dat, est=\"saem\", control=list(print=0),                          table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 gofs(fit.addProp.S)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"change-error-to-lognormal","dir":"Articles","previous_headings":"SAEM","what":"Change error to lognormal","title":"mavoglurant -- physiologically-based PK","text":"NOTE: lognormal distribution AIC/loglik/etc normal scale. Therefore, can compare AICs fit.lnorm fit.addProp since calculated scale. case can see AIC log-normal model better AIC addProp model.","code":"fit.lnorm.S <- pbpk %>%     model({C15 ~ lnorm(lnorm.err)}) %>% # Change C15 to be log-normally distributed     ## Requires data since piping from pbpk model     nlmixr(dat,est=\"saem\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 gofs(fit.lnorm.S)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"piping-to-focei","dir":"Articles","previous_headings":"","what":"Piping to FOCEi","title":"mavoglurant -- physiologically-based PK","text":"can pipe models different estimation methods new estimation methods.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"additive-proportional","dir":"Articles","previous_headings":"Piping to FOCEi","what":"Additive + Proportional","title":"mavoglurant -- physiologically-based PK","text":"","code":"fit.addProp.F <- fit.addProp.S %>%     nlmixr(est=\"focei\",            control=list(print=0),             table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:16  #> done ## Since this was a model pipline, the data ## remains the same as the last fit.  gofs(fit.addProp.F)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"log-normal","dir":"Articles","previous_headings":"Piping to FOCEi","what":"Log-normal","title":"mavoglurant -- physiologically-based PK","text":"# Traditional lognormal estimates identical NOTE: estimates AIC different since calculated log scale.","code":"fit.lnorm.F <- fit.addProp.F %>%     model({C15 ~ lnorm(lnorm.err)}) %>%     nlmixr(est=\"focei\",            control=list(print=0),             table=list(cwres=TRUE, npde=TRUE)); #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:16  #> done ## In this model pipline we are changing the fit method to focei.  gofs(fit.lnorm.F); datL  <- dat datL$DV <- log(datL$DV);  pbpkL <- function() {   ini({     ##theta=exp(c(1.1, .3, 2, 7.6, .003, .3))     lKbBR = 1.1     lKbMU = 0.3     lKbAD = 2     lCLint = 7.6     lKbBO = 0.03     lKbRB = 0.3     eta.LClint ~ 4     add.err <- 1   })   model({     KbBR = exp(lKbBR)     KbMU = exp(lKbMU)     KbAD = exp(lKbAD)     CLint= exp(lCLint + eta.LClint)     KbBO = exp(lKbBO)     KbRB = exp(lKbRB)      ## Regional blood flows     CO  = (187.00*WT^0.81)*60/1000;         # Cardiac output (L/h) from White et al (1968)     QHT = 4.0 *CO/100;     QBR = 12.0*CO/100;     QMU = 17.0*CO/100;     QAD = 5.0 *CO/100;     QSK = 5.0 *CO/100;     QSP = 3.0 *CO/100;     QPA = 1.0 *CO/100;     QLI = 25.5*CO/100;     QST = 1.0 *CO/100;     QGU = 14.0*CO/100;     QHA = QLI - (QSP + QPA + QST + QGU); # Hepatic artery blood flow     QBO = 5.0 *CO/100;     QKI = 19.0*CO/100;     QRB = CO - (QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI);     QLU = QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI + QRB;      ## Organs' volumes = organs' weights / organs' density     VLU = (0.76 *WT/100)/1.051;     VHT = (0.47 *WT/100)/1.030;     VBR = (2.00 *WT/100)/1.036;     VMU = (40.00*WT/100)/1.041;     VAD = (21.42*WT/100)/0.916;     VSK = (3.71 *WT/100)/1.116;     VSP = (0.26 *WT/100)/1.054;     VPA = (0.14 *WT/100)/1.045;     VLI = (2.57 *WT/100)/1.040;     VST = (0.21 *WT/100)/1.050;     VGU = (1.44 *WT/100)/1.043;     VBO = (14.29*WT/100)/1.990;     VKI = (0.44 *WT/100)/1.050;     VAB = (2.81 *WT/100)/1.040;     VVB = (5.62 *WT/100)/1.040;     VRB = (3.86 *WT/100)/1.040;      ## Fixed parameters     BP = 0.61;      # Blood:plasma partition coefficient     fup = 0.028;    # Fraction unbound in plasma     fub = fup/BP;   # Fraction unbound in blood      KbLU = exp(0.8334);     KbHT = exp(1.1205);     KbSK = exp(-.5238);     KbSP = exp(0.3224);     KbPA = exp(0.3224);     KbLI = exp(1.7604);     KbST = exp(0.3224);     KbGU = exp(1.2026);     KbKI = exp(1.3171);      ##-----------------------------------------     S15 = VVB*BP/1000;     C15 = Venous_Blood/S15     lnC15 = log(C15);      ##-----------------------------------------     d/dt(Lungs) = QLU*(Venous_Blood/VVB - Lungs/KbLU/VLU);     d/dt(Heart) = QHT*(Arterial_Blood/VAB - Heart/KbHT/VHT);     d/dt(Brain) = QBR*(Arterial_Blood/VAB - Brain/KbBR/VBR);     d/dt(Muscles) = QMU*(Arterial_Blood/VAB - Muscles/KbMU/VMU);     d/dt(Adipose) = QAD*(Arterial_Blood/VAB - Adipose/KbAD/VAD);     d/dt(Skin) = QSK*(Arterial_Blood/VAB - Skin/KbSK/VSK);     d/dt(Spleen) = QSP*(Arterial_Blood/VAB - Spleen/KbSP/VSP);     d/dt(Pancreas) = QPA*(Arterial_Blood/VAB - Pancreas/KbPA/VPA);     d/dt(Liver) = QHA*Arterial_Blood/VAB + QSP*Spleen/KbSP/VSP + QPA*Pancreas/KbPA/VPA + QST*Stomach/KbST/VST + QGU*Gut/KbGU/VGU - CLint*fub*Liver/KbLI/VLI - QLI*Liver/KbLI/VLI;     d/dt(Stomach) = QST*(Arterial_Blood/VAB - Stomach/KbST/VST);     d/dt(Gut) = QGU*(Arterial_Blood/VAB - Gut/KbGU/VGU);     d/dt(Bones) = QBO*(Arterial_Blood/VAB - Bones/KbBO/VBO);     d/dt(Kidneys) = QKI*(Arterial_Blood/VAB - Kidneys/KbKI/VKI);     d/dt(Arterial_Blood) = QLU*(Lungs/KbLU/VLU - Arterial_Blood/VAB);     d/dt(Venous_Blood) = QHT*Heart/KbHT/VHT + QBR*Brain/KbBR/VBR +       QMU*Muscles/KbMU/VMU + QAD*Adipose/KbAD/VAD +       QSK*Skin/KbSK/VSK + QLI*Liver/KbLI/VLI + QBO*Bones/KbBO/VBO +       QKI*Kidneys/KbKI/VKI + QRB*Rest_of_Body/KbRB/VRB - QLU*Venous_Blood/VVB;     d/dt(Rest_of_Body) = QRB*(Arterial_Blood/VAB - Rest_of_Body/KbRB/VRB);      lnC15 ~ add(add.err)   }) }  fit.lnorm.trans <- pbpkL %>%     nlmixr(datL,est=\"saem\",            control=list(print=0),             table=list(npde=TRUE, cwres=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-models-via-piping","dir":"Articles","previous_headings":"","what":"Changing models via piping","title":"Modifying nlmixr2 models by piping","text":"running nlmixr vignette, Let’s start simple PK example, using single-dose theophylline dataset generously provided Dr. Robert . Upton University California, San Francisco: can try First-Order Conditional Estimation Interaction (FOCEi) method find good solution:","code":"library(nlmixr2)  one.compartment <- function() {   ini({     tka <- 0.45; label(\"Ka\")     tcl <- 1; label(\"Cl\")     tv <- 3.45; label(\"V\")     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     d/dt(depot) = -ka * depot     d/dt(center) = ka * depot - cl / v * center     cp = center / v     cp ~ add(add.sd)   }) } fit <- nlmixr(one.compartment, theo_sd, est=\"focei\",               control=list(print=0),               table=list(npde=TRUE, cwres=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(fit) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC     BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.8116 373.4114 393.591      -179.7057        115.6797        9.731882 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance table compress    other #> elapsed 0.013495 0.479885   0.479886 0.754    0.011 4.952734 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE  %RSE Back-transformed(95%CI) BSV(CV%) #> tka           Ka 0.474  0.199  42.1       1.61 (1.09, 2.38)     69.2 #> tcl           Cl  1.01 0.0742  7.34       2.75 (2.38, 3.18)     26.8 #> tv             V  3.46 0.0337 0.973         31.8 (29.8, 34)     14.0 #> add.sd           0.695                                0.695          #>        Shrink(SD)% #> tka        0.659%  #> tcl         4.19%  #> tv          10.6%  #> add.sd             #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     relative convergence (4)  #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 28 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD    PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.114  0.626  0.468  0.866 0.68   0.807  0     0.74   1.06  #> 2 1      0.25  2.84 3.66  -0.816 -0.431 -0.394 0.333  0.347  3.29 -0.451 -0.242 #> 3 1      0.57  6.57 5.97   0.604 -1.79   0.332 0.0367 0.63   5.87  0.702  0.284 #> # ℹ 129 more rows #> # ℹ 16 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-and-fixing-parameter-values-in-models","dir":"Articles","previous_headings":"","what":"Changing and fixing parameter values in models","title":"Modifying nlmixr2 models by piping","text":"Something may want change initial estimates model. simple modify model definition change , may also want change specific way; example try range starting values see system behaves (either full estimation posthoc estimation). situations can come tedious modify models hand. nlmixr provides ability : Change parameter estimates running model. (ie ini(tka=0.5)) Fix parameters arbitrary values, estimated values (ie ini(tka=fix(0.5)) ini(tka=fix)) easiest way illustrate showing examples piping changes model:","code":"## Example 1 -- Set inital estimate to 0.5 (shown w/posthoc) one.ka.0.5 <- fit %>%     ini(tka=0.5) %>%     nlmixr(est=\"posthoc\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE))  print(one.ka.0.5) ## Example 2 -- Fix tka to 0.5 and re-estimate. one.ka.0.5 <- fit %>%     ini(tka=fix(0.5)) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(one.ka.0.5) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.8471 371.4469 388.7437      -179.7234        17.52287        12.09477 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance table compress    other #> elapsed 0.001369 0.285763   0.285765 0.713    0.011 2.639103 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.    SE  %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka   0.5 FIXED FIXED                     0.5     69.2     0.600%  #> tcl           Cl  1.01 0.312  30.9       2.75 (1.49, 5.07)     26.8      4.21%  #> tv             V  3.46 0.174  5.04       31.8 (22.6, 44.7)     14.0      10.6%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • using S matrix to calculate covariance, can check sandwich or R matrix with $covRS and $covR  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 28 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD   PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.114  0.626  0.468  0.866  0.68 0.807  0     0.74   1.06  #> 2 1      0.25  2.84 3.72  -0.885 -0.358 -0.422  0.36 0.337  3.36 -0.520 -0.275 #> 3 1      0.57  6.57 6.04   0.526 -1.75   0.253  0.04 0.6    5.96  0.610  0.246 #> # ℹ 129 more rows #> # ℹ 16 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> ## Example 3 -- Fix tka to model estimated value and re-estimate. one.ka.0.5 <- fit %>%     ini(tka=fix) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(one.ka.0.5) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.8131 371.4128 388.7096      -179.7064        17.54673        12.12971 #>  #> ── Time (sec $time): ── #>  #>          setup optimize covariance table compress    other #> elapsed 0.0013 0.293937   0.293939 0.719     0.01 2.688824 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.    SE  %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka 0.474 FIXED FIXED                   0.474     69.2     0.670%  #> tcl           Cl  1.01 0.313  30.9       2.75 (1.49, 5.08)     26.8      4.19%  #> tv             V  3.46 0.175  5.05       31.8 (22.6, 44.8)     14.0      10.6%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • using S matrix to calculate covariance, can check sandwich or R matrix with $covRS and $covR  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 28 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD    PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.114  0.626  0.468  0.866 0.68   0.807  0     0.74   1.06  #> 2 1      0.25  2.84 3.66  -0.816 -0.431 -0.394 0.333  0.347  3.29 -0.451 -0.242 #> 3 1      0.57  6.57 5.97   0.604 -1.79   0.332 0.0367 0.63   5.87  0.702  0.284 #> # ℹ 129 more rows #> # ℹ 16 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> ## Example 4 -- Change tka to 0.7 in orginal model function and then estimate one.ka.0.7 <- one.compartment %>%     ini(tka=0.7) %>%     nlmixr(theo_sd, est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(one.ka.0.7) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF     AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.9872 373.587 393.7666      -179.7935        77.33962        11.86369 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance table compress    other #> elapsed 0.001101 0.477152   0.477153  0.33    0.008 2.282594 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka 0.481  0.213 44.2       1.62 (1.07, 2.46)     70.5      1.61%  #> tcl           Cl  1.02 0.0737 7.22         2.77 (2.4, 3.2)     28.0      7.96%  #> tv             V  3.46 0.0516 1.49       31.8 (28.8, 35.2)     15.3      15.1%  #> add.sd           0.693                               0.693                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 28 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD    PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.113  0.627  0.468  0.878 0.68   0.81   0     0.74   1.07  #> 2 1      0.25  2.84 3.68  -0.845 -0.332 -0.394 0.37   0.347  3.31 -0.468 -0.246 #> 3 1      0.57  6.57 5.99   0.582 -1.83   0.297 0.0333 0.617  5.89  0.680  0.270 #> # ℹ 129 more rows #> # ℹ 16 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-parameter-labels-and-order","dir":"Articles","previous_headings":"","what":"Changing parameter labels and order","title":"Modifying nlmixr2 models by piping","text":"aesthetic reasons, sometimes preferred update parameter labels order parameters. changes affect estimation parameters. affect output tables order parameters. using , can modify model model piping still desired output table format ready use report. example, can change label \"Ka\" \"Absorption rate\" follows: , ’d prefer volume come clearance parameter table (fit$parFixed), can change , . See documentation ini can modify parameters model piping.","code":"fit %>%   ini(     tka <- label(\"Absorption rate\")   ) #>  ── rxode2-based free-form 2-cmt ODE model ──────────────────────────────────────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>       tka       tcl        tv    add.sd  #> 0.4741772 1.0112664 3.4593293 0.6952432  #>  #> Omega ($omega):  #>           eta.ka    eta.cl      eta.v #> eta.ka 0.3913202 0.0000000 0.00000000 #> eta.cl 0.0000000 0.0695591 0.00000000 #> eta.v  0.0000000 0.0000000 0.01935147 #>  #> States ($state or $stateDf):  #>   Compartment Number Compartment Name #> 1                  1            depot #> 2                  2           center #>  ── μ-referencing ($muRefTable): ──   #>   theta    eta level #> 1   tka eta.ka    id #> 2   tcl eta.cl    id #> 3    tv  eta.v    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         tka <- 0.474177171359262 #>         label(\"Absorption rate\") #>         tcl <- 1.01126635373108 #>         label(\"Cl\") #>         tv <- 3.45932933156061 #>         label(\"V\") #>         add.sd <- c(0, 0.695243197595218) #>         eta.ka ~ 0.391320225986854 #>         eta.cl ~ 0.0695590964689484 #>         eta.v ~ 0.019351468331187 #>     }) #>     model({ #>         ka <- exp(tka + eta.ka) #>         cl <- exp(tcl + eta.cl) #>         v <- exp(tv + eta.v) #>         d/dt(depot) = -ka * depot #>         d/dt(center) = ka * depot - cl/v * center #>         cp = center/v #>         cp ~ add(add.sd) #>     }) #> } fit %>%   ini(     tv <- label(\"Central volume\"),     append = \"tcl\"   ) #>  ── rxode2-based free-form 2-cmt ODE model ──────────────────────────────────────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>       tka       tcl        tv    add.sd  #> 0.4741772 1.0112664 3.4593293 0.6952432  #>  #> Omega ($omega):  #>           eta.ka    eta.cl      eta.v #> eta.ka 0.3913202 0.0000000 0.00000000 #> eta.cl 0.0000000 0.0695591 0.00000000 #> eta.v  0.0000000 0.0000000 0.01935147 #>  #> States ($state or $stateDf):  #>   Compartment Number Compartment Name #> 1                  1            depot #> 2                  2           center #>  ── μ-referencing ($muRefTable): ──   #>   theta    eta level #> 1   tka eta.ka    id #> 2   tcl eta.cl    id #> 3    tv  eta.v    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         tka <- 0.474177171359262 #>         label(\"Ka\") #>         tcl <- 1.01126635373108 #>         label(\"Cl\") #>         tv <- 3.45932933156061 #>         label(\"Central volume\") #>         add.sd <- c(0, 0.695243197595218) #>         eta.ka ~ 0.391320225986854 #>         eta.cl ~ 0.0695590964689484 #>         eta.v ~ 0.019351468331187 #>     }) #>     model({ #>         ka <- exp(tka + eta.ka) #>         cl <- exp(tcl + eta.cl) #>         v <- exp(tv + eta.v) #>         d/dt(depot) = -ka * depot #>         d/dt(center) = ka * depot - cl/v * center #>         cp = center/v #>         cp ~ add(add.sd) #>     }) #> }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-model-features","dir":"Articles","previous_headings":"","what":"Changing model features","title":"Modifying nlmixr2 models by piping","text":"developing models, often add remove subject variability parameters, add covariates effects, /change residual errors. can change lines model piping fit nlmixr model specification function model","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"adding-or-removing-between-subject-variability","dir":"Articles","previous_headings":"Changing model features","what":"Adding or Removing between subject variability","title":"Modifying nlmixr2 models by piping","text":"Often developing model add remove subject variability certain model parameters. example, remove subject variability ka parameter changing line model; example remove eta prior fit prior model specification function, simply pipe model function. can re-estimate piping nlmixr function . course also add eta parameter way; can see name change examining omega matrix: Note new subject variability parameters distinguished types parameters (ie population parameters, individual covariates) name. Parameters starting ending following names assumed subject variability parameters: eta (NONMEM convention) ppv (per patient variability) psv (per subject variability) iiv (inter-individual variability) bsv (subject variability) bpv (patient variability)","code":"## Remove eta.ka on ka noEta <- fit %>%     model(ka <- exp(tka)) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(noEta) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 176.5777 431.1775 448.4743      -209.5887        33.12954        7.050454 #>  #> ── Time (sec $time): ── #>  #>           setup optimize covariance table compress    other #> elapsed 0.00131 0.292799     0.2928 0.766    0.009 3.467091 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka 0.433  0.167 38.6       1.54 (1.11, 2.14)                      #> tcl           Cl 0.988  0.076  7.7       2.69 (2.31, 3.12)     30.4      7.95%  #> tv             V  3.48 0.0481 1.38       32.4 (29.5, 35.6)     15.4      7.24%  #> add.sd            1.02                                1.02                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     relative convergence (4)  #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 27 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD    PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.167  0.573  0.126  0.477 0.55   0.683  0     0.74   0.724 #> 2 1      0.25  2.84 3.18  -0.342 -1.36  -0.253 0.0867 0.4    3.12 -0.282 -0.250 #> 3 1      0.57  6.57 5.68   0.888 -0.524  0.674 0.3    0.75   5.62  0.954  0.722 #> # ℹ 129 more rows #> # ℹ 15 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.cl <dbl>, eta.v <dbl>, depot <dbl>, #> #   center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl> addBackKa <- noEta %>%     model({ka <- exp(tka + bsv.ka)}) %>%     ini(bsv.ka=0.1) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(addBackKa) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.8978 373.4976 393.6772      -179.7488        50.95108        7.394634 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance table compress    other #> elapsed 0.001297 0.487517   0.487519 0.758    0.009 4.981667 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka 0.462  0.207 44.9       1.59 (1.06, 2.38)     69.1     0.451%  #> tcl           Cl  1.01 0.0715 7.08       2.74 (2.39, 3.16)     27.4      6.47%  #> tv             V  3.46 0.0505 1.46       31.9 (28.9, 35.2)     15.0      13.8%  #> add.sd           0.693                               0.693                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 28 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD   PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.114  0.626  0.468  0.878 0.68  0.81   0     0.74   1.07  #> 2 1      0.25  2.84 3.66  -0.825 -0.866 -0.271 0.193 0.393  3.25 -0.411 -0.222 #> 3 1      0.57  6.57 5.96   0.611 -1.48   0.314 0.07  0.623  5.81  0.758  0.306 #> # ℹ 129 more rows #> # ℹ 16 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.cl <dbl>, eta.v <dbl>, bsv.ka <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> addBackKa$omega #>            eta.cl      eta.v    bsv.ka #> eta.cl 0.07240395 0.00000000 0.0000000 #> eta.v  0.00000000 0.02217241 0.0000000 #> bsv.ka 0.00000000 0.00000000 0.3907193"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"adding-covariate-effects","dir":"Articles","previous_headings":"Changing model features","what":"Adding Covariate effects","title":"Modifying nlmixr2 models by piping","text":"","code":"## Note currently cov is needed as a prefix so nlmixr knows this is an ## estimated parameter not a parameter wt70 <- fit %>%   model({cl <- exp(tcl + eta.cl)*(WT/70)^covWtPow}) %>%   ini(covWtPow=fix(0.75)) %>%   ini(tka=fix(0.5)) %>%   nlmixr(est=\"focei\", control=list(print=0),          table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(wt70) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.2103 370.8101 388.1069      -179.4051        3.142512        2.615431 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance table compress    other #> elapsed 0.001329 0.288301   0.288302 0.752     0.01 3.352068 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>          Parameter  Est.     SE  %RSE Back-transformed(95%CI) BSV(CV%) #> tka             Ka   0.5  FIXED FIXED                     0.5     69.4 #> tcl             Cl  1.02 0.0777  7.62       2.77 (2.38, 3.23)     26.8 #> tv               V  3.46 0.0576  1.66       31.8 (28.4, 35.6)     14.0 #> add.sd             0.695                                0.695          #> covWtPow            0.75  FIXED FIXED                    0.75          #>          Shrink(SD)% #> tka           1.26%  #> tcl           6.79%  #> tv            12.6%  #> add.sd               #> covWtPow             #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 29 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD    PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.114  0.626  0.422  0.866 0.663  0.807  0     0.74   1.06  #> 2 1      0.25  2.84 3.72  -0.885 -0.297 -0.422 0.383  0.337  3.36 -0.520 -0.274 #> 3 1      0.57  6.57 6.03   0.541 -1.79   0.271 0.0367 0.607  5.95  0.622  0.252 #> # ℹ 129 more rows #> # ℹ 17 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>, WT <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-residual-errors","dir":"Articles","previous_headings":"Changing model features","what":"Changing residual errors","title":"Modifying nlmixr2 models by piping","text":"Changing residual errors also just easy, simply specifying error wish change: much can piping. complete discussion see see rxode2 piping documentation. Since rxode2 nlmixr2 models can share functional form piping applies fits well model definitions.","code":"## Since there are 0 predictions in the data, these are changed to ## 0.0150 to show proportional error change. d <- theo_sd d$DV[d$EVID == 0 & d$DV == 0] <- 0.0150  addPropModel <- fit %>%     model({cp ~ add(add.err)+prop(prop.err)}) %>%     ini(prop.err=0.1) %>%     nlmixr(d,est=\"focei\",            control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(addPropModel) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF     AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 104.9613 363.561 386.6235      -173.7805        29.38653        16.08647 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance table compress    other #> elapsed 0.001319 0.513168   0.513169 0.761    0.009 7.753344 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>          Parameter  Est.    SE %RSE Back-transformed(95%CI) BSV(CV%) #> tka             Ka 0.424 0.326 76.9       1.53 (0.806, 2.9)     72.2 #> tcl             Cl  1.02 0.111 10.9       2.77 (2.23, 3.44)     26.4 #> tv               V  3.46 0.176 5.08       31.8 (22.6, 44.9)     13.4 #> add.err            0.315                              0.315          #> prop.err            0.12                               0.12          #>          Shrink(SD)% #> tka           3.73%  #> tcl           1.93%  #> tv            14.3%  #> add.err              #> prop.err             #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     relative convergence (4)  #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 28 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD   PDE    PD  PRED    RES   WRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> #> 1 1      0     0.74 0.0516  0.688  0.954  2.22  0.83  0.987  0     0.74   2.35  #> 2 1      0.25  2.84 3.52   -0.679 -0.573 -0.305 0.283 0.38   3.16 -0.317 -0.177 #> 3 1      0.57  6.57 5.82    0.751 -0.515  0.358 0.303 0.64   5.69  0.885  0.350 #> # ℹ 129 more rows #> # ℹ 16 more variables: IPRED <dbl>, IRES <dbl>, IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"multiple-endpoints","dir":"Articles","previous_headings":"","what":"Multiple endpoints","title":"Working with multiple endpoints","text":"Joint PK/PD models, PK/PD models fix certain components common pharmacometrics. classic example, (provided Tomoo Funaki Nick Holford) Warfarin. example, transit-compartment (depot gut central volume) PK model effect compartment PCA measurement. illustrated example model can applied data: Notice two endpoints model cp effect. modeled nlmixr using ~ “modeled ” specification. see nlmixr handle multiple compartment model, quite informative parse model print information model. case initial parsing give: middle printout, shows data must formatted (using cmt dvid data items) allow nlmixr model multiple endpoint appropriately. course, interested can directly access information ui$multipleEndpoint. Notice cmt dvid items can use named variables directly either cmt dvid specification. flexible notation makes rename compartments run nlmixr model functions. thing note cp specified ODE compartment number compartments defined rxode2 part nlmixr model. cp defined compartment, related variable cp. last thing notice cmt items numbered cmt=5 cp cmt=4 effect even though specified model first cp cmt. ordering effect compartment rxode2 system. course cp related compartment center, may make sense pair cp center compartment. something want can specify compartment relate effect | operator. case change change, model updated : Notice case cmt variables numbered sequentially cp variable matches center compartment.","code":"library(nlmixr2) library(ggplot2) pk.turnover.emax <- function() {   ini({     tktr <- log(1)     tka <- log(1)     tcl <- log(0.1)     tv <- log(10)     ##     eta.ktr ~ 1     eta.ka ~ 1     eta.cl ~ 2     eta.v ~ 1     prop.err <- 0.1     pkadd.err <- 0.1     ##     temax <- logit(0.8)     #temax <- 7.5     tec50 <- log(0.5)     tkout <- log(0.05)     te0 <- log(100)     ##     eta.emax ~ .5     eta.ec50  ~ .5     eta.kout ~ .5     eta.e0 ~ .5     ##     pdadd.err <- 10   })   model({     ktr <- exp(tktr + eta.ktr)     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     ##     #poplogit = log(temax/(1-temax))     emax=expit(temax+eta.emax)     #logit=temax+eta.emax     ec50 =  exp(tec50 + eta.ec50)     kout = exp(tkout + eta.kout)     e0 = exp(te0 + eta.e0)     ##     DCP = center/v     PD=1-emax*DCP/(ec50+DCP)     ##     effect(0) = e0     kin = e0*kout     ##     d/dt(depot) = -ktr * depot     d/dt(gut) =  ktr * depot -ka * gut     d/dt(center) =  ka * gut - cl / v * center     d/dt(effect) = kin*PD -kout*effect     ##     cp = center / v     cp ~ prop(prop.err) + add(pkadd.err)     effect ~ add(pdadd.err)   }) } ui <- nlmixr(pk.turnover.emax) ui #>  ── rxode2-based free-form 4-cmt ODE model ──────────────────────────────────────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>       tktr        tka        tcl         tv   prop.err  pkadd.err      temax  #>  0.0000000  0.0000000 -2.3025851  2.3025851  0.1000000  0.1000000  1.3862944  #>      tec50      tkout        te0  pdadd.err  #> -0.6931472 -2.9957323  4.6051702 10.0000000  #>  #> Omega ($omega):  #>          eta.ktr eta.ka eta.cl eta.v eta.emax eta.ec50 eta.kout eta.e0 #> eta.ktr        1      0      0     0      0.0      0.0      0.0    0.0 #> eta.ka         0      1      0     0      0.0      0.0      0.0    0.0 #> eta.cl         0      0      2     0      0.0      0.0      0.0    0.0 #> eta.v          0      0      0     1      0.0      0.0      0.0    0.0 #> eta.emax       0      0      0     0      0.5      0.0      0.0    0.0 #> eta.ec50       0      0      0     0      0.0      0.5      0.0    0.0 #> eta.kout       0      0      0     0      0.0      0.0      0.5    0.0 #> eta.e0         0      0      0     0      0.0      0.0      0.0    0.5 #>  #> States ($state or $stateDf):  #>   Compartment Number Compartment Name #> 1                  1            depot #> 2                  2              gut #> 3                  3           center #> 4                  4           effect #>  ── Multiple Endpoint Model ($multipleEndpoint): ──   #>     variable                   cmt                   dvid* #> 1     cp ~ …     cmt='cp' or cmt=5     dvid='cp' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2 #>   * If dvids are outside this range, all dvids are re-numered sequentially, ie 1,7, 10 becomes 1,2,3 etc #>  #>  ── μ-referencing ($muRefTable): ──   #>   theta      eta level #> 1  tktr  eta.ktr    id #> 2   tka   eta.ka    id #> 3   tcl   eta.cl    id #> 4    tv    eta.v    id #> 5 temax eta.emax    id #> 6 tec50 eta.ec50    id #> 7 tkout eta.kout    id #> 8   te0   eta.e0    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         tktr <- 0 #>         tka <- 0 #>         tcl <- -2.30258509299405 #>         tv <- 2.30258509299405 #>         prop.err <- c(0, 0.1) #>         pkadd.err <- c(0, 0.1) #>         temax <- 1.38629436111989 #>         tec50 <- -0.693147180559945 #>         tkout <- -2.99573227355399 #>         te0 <- 4.60517018598809 #>         pdadd.err <- c(0, 10) #>         eta.ktr ~ 1 #>         eta.ka ~ 1 #>         eta.cl ~ 2 #>         eta.v ~ 1 #>         eta.emax ~ 0.5 #>         eta.ec50 ~ 0.5 #>         eta.kout ~ 0.5 #>         eta.e0 ~ 0.5 #>     }) #>     model({ #>         ktr <- exp(tktr + eta.ktr) #>         ka <- exp(tka + eta.ka) #>         cl <- exp(tcl + eta.cl) #>         v <- exp(tv + eta.v) #>         emax = expit(temax + eta.emax) #>         ec50 = exp(tec50 + eta.ec50) #>         kout = exp(tkout + eta.kout) #>         e0 = exp(te0 + eta.e0) #>         DCP = center/v #>         PD = 1 - emax * DCP/(ec50 + DCP) #>         effect(0) = e0 #>         kin = e0 * kout #>         d/dt(depot) = -ktr * depot #>         d/dt(gut) = ktr * depot - ka * gut #>         d/dt(center) = ka * gut - cl/v * center #>         d/dt(effect) = kin * PD - kout * effect #>         cp = center/v #>         cp ~ prop(prop.err) + add(pkadd.err) #>         effect ~ add(pdadd.err) #>     }) #> } ui$multipleEndpoint #>     variable                   cmt                   dvid* #> 1     cp ~ …     cmt='cp' or cmt=5     dvid='cp' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2 cp ~ prop(prop.err) + add(pkadd.err) cp ~ prop(prop.err) + add(pkadd.err) | center pk.turnover.emax2 <- function() {   ini({     tktr <- log(1)     tka <- log(1)     tcl <- log(0.1)     tv <- log(10)     ##     eta.ktr ~ 1     eta.ka ~ 1     eta.cl ~ 2     eta.v ~ 1     prop.err <- 0.1     pkadd.err <- 0.1     ##     temax <- logit(0.8)     tec50 <- log(0.5)     tkout <- log(0.05)     te0 <- log(100)     ##     eta.emax ~ .5     eta.ec50  ~ .5     eta.kout ~ .5     eta.e0 ~ .5     ##     pdadd.err <- 10   })   model({     ktr <- exp(tktr + eta.ktr)     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     ##     emax=expit(temax+eta.emax)     ec50 =  exp(tec50 + eta.ec50)     kout = exp(tkout + eta.kout)     e0 = exp(te0 + eta.e0)     ##     DCP = center/v     PD=1-emax*DCP/(ec50+DCP)     ##     effect(0) = e0     kin = e0*kout     ##     d/dt(depot) = -ktr * depot     d/dt(gut) =  ktr * depot -ka * gut     d/dt(center) =  ka * gut - cl / v * center     d/dt(effect) = kin*PD -kout*effect     ##     cp = center / v     cp ~ prop(prop.err) + add(pkadd.err) | center     effect ~ add(pdadd.err)   }) } ui2 <- nlmixr(pk.turnover.emax2) ui2$multipleEndpoint #>     variable                   cmt                   dvid* #> 1     cp ~ … cmt='center' or cmt=3 dvid='center' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"dvid-vs-cmt-which-one-is-used","dir":"Articles","previous_headings":"Multiple endpoints","what":"DVID vs CMT, which one is used","title":"Working with multiple endpoints","text":"dvid cmt combined dataset, cmt data item always used event information dvid used observations. nlmixr expects cmt data item match dvid item observations either zero one dvid replace cmt information. wish use dvid items define multiple endpoints nlmixr, can set following option: cmt items used multiple endpoint models. course can turn different models wish:","code":"options(rxode2.combine.dvid=FALSE) ui2$multipleEndpoint #>     variable                   cmt #> 1     cp ~ … cmt='center' or cmt=3 #> 2 effect ~ … cmt='effect' or cmt=4 options(rxode2.combine.dvid=TRUE) ui2$multipleEndpoint #>     variable                   cmt                   dvid* #> 1     cp ~ … cmt='center' or cmt=3 dvid='center' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"running-a-multiple-endpoint-model","dir":"Articles","previous_headings":"Multiple endpoints","what":"Running a multiple endpoint model","title":"Working with multiple endpoints","text":"information, can use built-warfarin dataset nlmixr2: Since dvid specifies pca effect endpoint, can update model explicit making one last change: ","code":"summary(warfarin) #>        id             time             amt                dv          dvid     #>  Min.   : 1.00   Min.   :  0.00   Min.   :  0.000   Min.   :  0.00   cp :283   #>  1st Qu.: 8.00   1st Qu.: 24.00   1st Qu.:  0.000   1st Qu.:  4.50   pca:232   #>  Median :15.00   Median : 48.00   Median :  0.000   Median : 11.40             #>  Mean   :16.08   Mean   : 52.08   Mean   :  6.524   Mean   : 20.02             #>  3rd Qu.:24.00   3rd Qu.: 96.00   3rd Qu.:  0.000   3rd Qu.: 26.00             #>  Max.   :33.00   Max.   :144.00   Max.   :153.000   Max.   :100.00             #>       evid               wt              age            sex      #>  Min.   :0.00000   Min.   : 40.00   Min.   :21.00   female:101   #>  1st Qu.:0.00000   1st Qu.: 60.00   1st Qu.:23.00   male  :414   #>  Median :0.00000   Median : 70.00   Median :28.00                #>  Mean   :0.06214   Mean   : 69.27   Mean   :31.85                #>  3rd Qu.:0.00000   3rd Qu.: 78.00   3rd Qu.:36.00                #>  Max.   :1.00000   Max.   :102.00   Max.   :63.00 cp ~ prop(prop.err) + add(pkadd.err) effect ~ add(pdadd.err) cp ~ prop(prop.err) + add(pkadd.err) effect ~ add(pdadd.err)  | pca pk.turnover.emax3 <- function() {   ini({     tktr <- log(1)     tka <- log(1)     tcl <- log(0.1)     tv <- log(10)     ##     eta.ktr ~ 1     eta.ka ~ 1     eta.cl ~ 2     eta.v ~ 1     prop.err <- 0.1     pkadd.err <- 0.1     ##     temax <- logit(0.8)     tec50 <- log(0.5)     tkout <- log(0.05)     te0 <- log(100)     ##     eta.emax ~ .5     eta.ec50  ~ .5     eta.kout ~ .5     eta.e0 ~ .5     ##     pdadd.err <- 10   })   model({     ktr <- exp(tktr + eta.ktr)     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     emax = expit(temax+eta.emax)     ec50 =  exp(tec50 + eta.ec50)     kout = exp(tkout + eta.kout)     e0 = exp(te0 + eta.e0)     ##     DCP = center/v     PD=1-emax*DCP/(ec50+DCP)     ##     effect(0) = e0     kin = e0*kout     ##     d/dt(depot) = -ktr * depot     d/dt(gut) =  ktr * depot -ka * gut     d/dt(center) =  ka * gut - cl / v * center     d/dt(effect) = kin*PD -kout*effect     ##     cp = center / v     cp ~ prop(prop.err) + add(pkadd.err)     effect ~ add(pdadd.err) | pca   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"run-the-models-with-saem","dir":"Articles","previous_headings":"Multiple endpoints","what":"Run the models with SAEM","title":"Working with multiple endpoints","text":"","code":"fit.TOS <- nlmixr(pk.turnover.emax3, warfarin, \"saem\", control=list(print=0),                   table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 print(fit.TOS) #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>          OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 1383.99 2309.685 2389.105      -1135.842        1711.869        19.29712 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance    saem  table compress #> elapsed 0.002451    5e-06   0.060006 119.586 10.914    0.026 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>            Est.     SE  %RSE Back-transformed(95%CI) BSV(CV% or SD) Shrink(SD)% #> tktr      0.426  0.443   104      1.53 (0.642, 3.65)           103.      52.3%  #> tka       -0.19  0.225   118     0.827 (0.532, 1.28)           41.7      63.6%  #> tcl       -1.97  0.051  2.58    0.139 (0.126, 0.153)           26.6      5.33%  #> tv            2 0.0475  2.37       7.41 (6.75, 8.14)           21.4      17.9%  #> prop.err  0.124                                0.124                            #> pkadd.err 0.758                                0.758                            #> temax      2.93  0.398  13.6     0.95 (0.896, 0.976)          0.107      83.9%  #> tec50     -0.17  0.147  86.5     0.844 (0.633, 1.13)           49.2      8.67%  #> tkout      -2.9  0.039  1.34 0.0548 (0.0507, 0.0591)           6.31      46.2%  #> te0        4.57 0.0115 0.252       96.5 (94.3, 98.7)           5.15      17.8%  #> pdadd.err  3.73                                 3.73                            #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 483 × 44 #>   ID     TIME CMT      DV EPRED  ERES  NPDE    NPD    PDE     PD  PRED   RES #>   <fct> <dbl> <fct> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> <dbl> <dbl> #> 1 1       0.5 cp      0    1.91 -1.91 -1.68 -1.50  0.0467 0.0667  1.45 -1.45 #> 2 1       1   cp      1.9  4.32 -2.42  1.83 -0.954 0.967  0.17    4.06 -2.16 #> 3 1       2   cp      3.3  8.12 -4.82 -2.05 -1.53  0.02   0.0633  8.47 -5.17 #> # ℹ 480 more rows #> # ℹ 32 more variables: WRES <dbl>, IPRED <dbl>, IRES <dbl>, IWRES <dbl>, #> #   CPRED <dbl>, CRES <dbl>, CWRES <dbl>, eta.ktr <dbl>, eta.ka <dbl>, #> #   eta.cl <dbl>, eta.v <dbl>, eta.emax <dbl>, eta.ec50 <dbl>, eta.kout <dbl>, #> #   eta.e0 <dbl>, depot <dbl>, gut <dbl>, center <dbl>, effect <dbl>, #> #   ktr <dbl>, ka <dbl>, cl <dbl>, v <dbl>, emax <dbl>, ec50 <dbl>, kout <dbl>, #> #   e0 <dbl>, DCP <dbl>, PD.1 <dbl>, kin <dbl>, tad <dbl>, dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"saem-diagnostic-plots","dir":"Articles","previous_headings":"Multiple endpoints > Run the models with SAEM","what":"SAEM Diagnostic plots","title":"Working with multiple endpoints","text":"","code":"plot(fit.TOS) v1s <- vpcPlot(fit.TOS, show=list(obs_dv=TRUE), scales=\"free_y\") +   ylab(\"Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v2s <- vpcPlot(fit.TOS, show=list(obs_dv=TRUE), pred_corr = TRUE) +   ylab(\"Prediction Corrected Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v1s v2s"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"focei-fits","dir":"Articles","previous_headings":"Multiple endpoints","what":"FOCEi fits","title":"Working with multiple endpoints","text":"","code":"## FOCEi fit/vpcs fit.TOF <- nlmixr(pk.turnover.emax3, warfarin, \"focei\", control=list(print=0),                   table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:01:29  #> done"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"focei-diagnostic-plots","dir":"Articles","previous_headings":"Multiple endpoints > FOCEi fits","what":"FOCEi Diagnostic Plots","title":"Working with multiple endpoints","text":"","code":"print(fit.TOF) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 1369.349 2295.043 2374.464      -1128.522         1007646        6234.877 #>  #> ── Time (sec $time): ── #>  #>            setup optimize covariance table compress    other #> elapsed 0.001961 89.30359   89.30359 1.852    0.008 184.7599 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>            Est.     SE  %RSE Back-transformed(95%CI) BSV(CV% or SD) Shrink(SD)% #> tktr      0.589  0.303  51.4       1.8 (0.995, 3.26)           181.      63.8%  #> tka       0.347  0.135  38.9       1.41 (1.09, 1.84)           151.      66.3%  #> tcl       -2.03  0.239  11.8   0.132 (0.0827, 0.211)           31.4      8.61%  #> tv         2.06 0.0192  0.93       7.89 (7.59, 8.19)           23.1      7.27%  #> prop.err  0.117                                0.117                            #> pkadd.err 0.249                                0.249                            #> temax      5.45   2.18  40.1        0.996 (0.763, 1)          0.480      97.7%  #> tec50     0.173 0.0853  49.4        1.19 (1.01, 1.4)           51.8      11.7%  #> tkout     -2.94  0.014 0.476 0.0527 (0.0513, 0.0542)           10.4      29.6%  #> te0        4.57 0.0156 0.341       96.4 (93.5, 99.4)           7.08      26.1%  #> pdadd.err   3.8                                  3.8                            #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • last objective function was not at minimum, possible problems in optimization  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 483 × 44 #>   ID     TIME CMT      DV EPRED  ERES  NPDE    NPD    PDE    PD  PRED   RES #>   <fct> <dbl> <fct> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl> <dbl> #> 1 1       0.5 cp      0    3.19 -3.19 -1.64 -2.05  0.05   0.02   2.40 -2.40 #> 2 1       1   cp      1.9  5.70 -3.80  1.99 -0.941 0.977  0.173  5.94 -4.04 #> 3 1       2   cp      3.3  8.52 -5.22 -2.13 -1.16  0.0167 0.123 10.3  -6.97 #> # ℹ 480 more rows #> # ℹ 32 more variables: WRES <dbl>, IPRED <dbl>, IRES <dbl>, IWRES <dbl>, #> #   CPRED <dbl>, CRES <dbl>, CWRES <dbl>, eta.ktr <dbl>, eta.ka <dbl>, #> #   eta.cl <dbl>, eta.v <dbl>, eta.emax <dbl>, eta.ec50 <dbl>, eta.kout <dbl>, #> #   eta.e0 <dbl>, depot <dbl>, gut <dbl>, center <dbl>, effect <dbl>, #> #   ktr <dbl>, ka <dbl>, cl <dbl>, v <dbl>, emax <dbl>, ec50 <dbl>, kout <dbl>, #> #   e0 <dbl>, DCP <dbl>, PD.1 <dbl>, kin <dbl>, tad <dbl>, dosenum <dbl> plot(fit.TOF) v1f <- vpcPlot(fit.TOF, show=list(obs_dv=TRUE), scales=\"free_y\") +   ylab(\"Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v2f <- vpcPlot(fit.TOF, show=list(obs_dv=TRUE), pred_corr = TRUE) +   ylab(\"Prediction Corrected Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v1f v2f"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nimo.html","id":"nlmixr-model","dir":"Articles","previous_headings":"","what":"nlmixr model","title":"Nimotuzumab","text":"","code":"library(nlmixr2) library(xpose) library(xpose.nlmixr2) library(ggplot2)  nimo <- function() {   ini({     ## Note that the UI can take expressions     ## Also note that these initial estimates should be provided on the log-scale     tcl <- log(0.001)     tv1 <- log(1.45)     tQ <- log(0.004)     tv2 <- log(44)     tkss <- log(12)     tkint <- log(0.3)     tksyn <- log(1)     tkdeg <- log(7)     ## Initial estimates should be high for SAEM ETAs     eta.cl  ~ 2     eta.v1  ~ 2     eta.kss ~ 2     ##  Also true for additive error (also ignored in SAEM)     add.err <- 10   })   model({     cl <- exp(tcl + eta.cl)     v1 <- exp(tv1 + eta.v1)     Q  <- exp(tQ)     v2 <- exp(tv2)     kss <- exp(tkss + eta.kss)     kint <- exp(tkint)     ksyn <- exp(tksyn)     kdeg <- exp(tkdeg)      k <- cl/v1     k12 <- Q/v1     k21 <- Q/v2      eff(0) <- ksyn/kdeg ##initializing compartment      ## Concentration is calculated     conc = 0.5*(central/v1-eff-kss)+0.5*sqrt((central/v1-eff-kss)**2+4*kss*central/v1)      d/dt(central)  = -(k+k12)*conc*v1+k21*peripheral-kint*eff*conc*v1/(kss+conc)     d/dt(peripheral) = k12*conc*v1-k21*peripheral  ##Free Drug second compartment amount     d/dt(eff) = ksyn - kdeg*eff - (kint-kdeg)*conc*eff/(kss+conc)      IPRED=log(conc)      IPRED ~ add(add.err)   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nimo.html","id":"fit","dir":"Articles","previous_headings":"","what":"Fit","title":"Nimotuzumab","text":"","code":"fit <- nlmixr(nimo, nimoData, est=\"saem\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> 001: -7.082156   0.240380    -5.322648   3.706002    2.535890    -1.294407   -0.102901   1.975165    1.900000    1.900000    2.150501    1.391724     #> 002: -7.318608   0.337788    -5.472643   3.604174    2.671940    -1.381532   0.004361    1.965802    1.805000    1.805000    2.042976    0.830852     #> 003: -7.004796   0.329353    -5.552719   3.663648    2.576095    -1.342266   0.094213    2.169032    1.714750    1.714750    1.940827    0.704378     #> 004: -6.831052   0.337039    -5.509392   3.581316    2.619975    -1.473308   0.193564    2.039580    1.629012    1.629012    1.843786    0.673922     #> 005: -6.988888   0.327350    -5.438457   3.546217    2.611964    -1.375401   0.032029    2.028963    1.547562    1.547562    1.751597    0.664592     #> 006: -6.877438   0.309723    -5.508254   3.692787    2.673534    -1.385796   -0.048632   1.984854    1.470184    1.470184    1.664017    0.659652     #> 007: -6.898159   0.314886    -5.496362   3.638982    2.747608    -1.255406   -0.026410   1.947620    1.407505    1.396675    1.580816    0.663774     #> 008: -6.957871   0.319272    -5.352725   3.503540    2.776519    -1.197933   0.000427    1.968390    1.337130    1.326841    1.501775    0.670739     #> 009: -6.826759   0.315714    -5.227308   3.580258    2.922322    -1.203666   -0.010643   2.177228    1.270273    1.260499    1.483524    0.661929     #> 010: -7.082397   0.308379    -5.273932   3.611745    2.874421    -1.137025   0.115752    2.203563    1.305004    1.197474    1.517557    0.656455     #> 011: -7.083805   0.294951    -5.267117   3.697103    2.937389    -1.228824   0.136825    2.298366    1.239753    1.137600    1.522041    0.661686     #> 012: -7.229129   0.369998    -5.290768   3.737127    2.879780    -1.195137   0.181972    2.281019    1.177766    1.080720    1.445939    0.660513     #> 013: -7.118783   0.316777    -5.198435   3.808386    3.007388    -1.298448   0.173969    2.200194    1.118877    1.026684    1.545758    0.659895     #> 014: -7.107046   0.296195    -5.247466   3.826552    3.068812    -1.449512   0.198110    2.171824    1.062934    0.975350    1.468470    0.664803     #> 015: -7.101186   0.342107    -5.262732   3.789245    3.006193    -1.467174   0.209708    2.105610    1.173838    0.926582    1.395047    0.661338     #> 016: -7.054116   0.293809    -5.404022   3.710325    2.800496    -1.446669   0.248707    2.016275    1.115146    0.880253    1.325294    0.661297     #> 017: -6.900522   0.299893    -5.468624   3.730384    2.913575    -1.388838   0.287952    2.001241    1.059389    0.836241    1.259030    0.662951     #> 018: -6.847400   0.259424    -5.462242   3.782073    2.941709    -1.430433   0.325918    2.151714    1.006419    0.794429    1.196078    0.674475     #> 019: -6.753272   0.299121    -5.510133   3.743449    2.954801    -1.441600   0.390829    2.220912    0.956098    0.754707    1.136274    0.665982     #> 020: -6.837756   0.315087    -5.621735   3.778400    2.916021    -1.288673   0.366226    2.244962    1.106701    0.716972    1.079461    0.667779     #> 021: -6.893220   0.306474    -5.591735   3.473458    2.872476    -1.289627   0.381579    2.338688    1.255998    0.681123    1.025488    0.670320     #> 022: -7.005703   0.363949    -5.581785   3.500052    2.745047    -1.268654   0.294263    2.201461    1.193198    0.647067    0.974213    0.668004     #> 023: -6.939491   0.324638    -5.455178   3.494135    2.667590    -1.310115   0.298623    2.255601    1.133538    0.614714    0.925503    0.653433     #> 024: -6.885500   0.269202    -5.425549   3.477327    2.519646    -1.295313   0.341746    2.453918    1.201937    0.583978    0.879227    0.657180     #> 025: -7.003679   0.329172    -5.462586   3.450449    2.399445    -1.392637   0.407089    2.493273    1.141840    0.554779    0.835266    0.657478     #> 026: -6.998503   0.308081    -5.503414   3.378182    2.240570    -1.395307   0.507344    2.538508    1.084748    0.527040    0.793503    0.652995     #> 027: -6.983049   0.251959    -5.415440   3.357185    2.331519    -1.429724   0.469920    2.487613    1.053474    0.500688    0.753828    0.653142     #> 028: -7.064152   0.281134    -5.428507   3.340922    2.360536    -1.343881   0.489512    2.441413    1.031793    0.475654    0.744672    0.656158     #> 029: -7.153328   0.259568    -5.408880   3.332953    2.419550    -1.396986   0.552957    2.412138    1.038802    0.451871    0.755118    0.654489     #> 030: -7.137799   0.269775    -5.430981   3.324828    2.505459    -1.450748   0.544276    2.356400    0.986862    0.429278    0.717362    0.654892     #> 031: -7.278104   0.306992    -5.462212   3.347481    2.481115    -1.393738   0.510631    2.404250    0.937519    0.407814    0.681494    0.653134     #> 032: -7.366002   0.296299    -5.462750   3.354325    2.493465    -1.385500   0.511527    2.445562    0.890643    0.387423    0.647419    0.659970     #> 033: -7.126602   0.319700    -5.438877   3.445812    2.471803    -1.441491   0.498690    2.510886    0.846111    0.368052    0.615049    0.662377     #> 034: -7.011533   0.319809    -5.457466   3.448620    2.549336    -1.433274   0.440205    2.477871    0.803806    0.349649    0.601210    0.661287     #> 035: -7.030069   0.328177    -5.430406   3.521252    2.568902    -1.477423   0.431840    2.497634    0.777766    0.332167    0.571150    0.669577     #> 036: -6.790538   0.306774    -5.527834   3.622364    2.476747    -1.425994   0.382638    2.494380    0.738878    0.315558    0.542592    0.668018     #> 037: -6.800334   0.270544    -5.414146   3.402385    2.582889    -1.400895   0.474395    2.576823    0.818234    0.299781    0.560308    0.659367     #> 038: -6.779983   0.198230    -5.460225   3.326120    2.459665    -1.312269   0.425136    2.498573    0.777322    0.284791    0.532293    0.662861     #> 039: -6.671886   0.254019    -5.570037   3.257240    2.441459    -1.403449   0.505908    2.453239    0.738456    0.270552    0.552395    0.655443     #> 040: -6.801421   0.264928    -5.582054   3.187304    2.426505    -1.432948   0.510497    2.418150    0.701533    0.257024    0.524775    0.661263     #> 041: -6.867235   0.280701    -5.643455   3.254848    2.508290    -1.478873   0.516456    2.354902    0.719071    0.258599    0.498537    0.658930     #> 042: -6.780870   0.297515    -5.625829   3.229796    2.525800    -1.423885   0.545876    2.247574    0.704235    0.262364    0.473610    0.656337     #> 043: -7.000980   0.308498    -5.643916   3.368084    2.518038    -1.448837   0.571972    2.253661    0.838864    0.261131    0.449929    0.660254     #> 044: -6.881316   0.361812    -5.676801   3.302498    2.485286    -1.378273   0.610588    2.406006    0.796921    0.287254    0.427433    0.659041     #> 045: -6.992270   0.311070    -5.460939   3.297823    2.493164    -1.394428   0.574134    2.346399    0.987389    0.272891    0.406061    0.657335     #> 046: -6.937286   0.255586    -5.505305   3.189254    2.469744    -1.477122   0.595653    2.387849    0.938020    0.259247    0.385758    0.657275     #> 047: -6.910055   0.278884    -5.524470   3.291595    2.395307    -1.531927   0.560231    2.426453    0.891119    0.261829    0.366470    0.657160     #> 048: -7.067394   0.288722    -5.510406   3.356396    2.365454    -1.578588   0.642720    2.429590    0.846563    0.296891    0.348147    0.655746     #> 049: -6.923328   0.270119    -5.450789   3.414379    2.366448    -1.585423   0.629513    2.466967    0.893002    0.282046    0.330739    0.658189     #> 050: -6.975794   0.288132    -5.435516   3.347858    2.392924    -1.608769   0.643707    2.417948    0.932213    0.277081    0.314202    0.648781     #> 051: -6.875901   0.353712    -5.416865   3.611819    2.462963    -1.660868   0.661059    2.438330    0.970314    0.294981    0.298492    0.652593     #> 052: -6.765307   0.271983    -5.391472   3.626409    2.527210    -1.643741   0.684367    2.440789    0.921799    0.288411    0.283568    0.655201     #> 053: -6.620037   0.310457    -5.451163   3.854368    2.628403    -1.630681   0.646037    2.405277    0.875709    0.273990    0.269389    0.661798     #> 054: -6.541914   0.322377    -5.602161   3.918050    2.661677    -1.588618   0.619825    2.408575    0.831923    0.260291    0.255920    0.656715     #> 055: -6.373490   0.295359    -5.581440   3.790033    2.702007    -1.567283   0.614160    2.346308    0.843537    0.265659    0.284322    0.657369     #> 056: -6.361577   0.312322    -5.637698   3.785505    2.787302    -1.527121   0.574659    2.272041    0.801360    0.252376    0.270106    0.659265     #> 057: -6.297834   0.286892    -5.705691   3.762464    2.794607    -1.540606   0.548523    2.251223    0.761292    0.239758    0.276525    0.662021     #> 058: -6.402065   0.258021    -5.810660   3.777895    2.758826    -1.493502   0.544410    2.192527    0.862540    0.263461    0.262699    0.656946     #> 059: -6.488559   0.275667    -5.779645   3.824903    2.822481    -1.496432   0.516002    2.169180    0.941809    0.280023    0.249564    0.661064     #> 060: -6.537952   0.322100    -5.844695   4.198486    2.774870    -1.501122   0.532435    2.161901    0.894719    0.287462    0.237086    0.663263     #> 061: -6.416021   0.343720    -5.758680   3.940205    2.650611    -1.499860   0.520846    2.224032    0.849983    0.273089    0.225231    0.664169     #> 062: -6.310170   0.299830    -5.611265   3.839088    2.686540    -1.439855   0.487623    2.288302    0.807484    0.259434    0.213970    0.663122     #> 063: -6.294908   0.311997    -5.540899   3.862490    2.707261    -1.423113   0.494748    2.327657    0.767109    0.246462    0.203271    0.660175     #> 064: -6.366629   0.316682    -5.694336   3.936071    2.652013    -1.427522   0.492013    2.282279    0.835532    0.234139    0.193108    0.670102     #> 065: -6.180801   0.364973    -5.741631   3.493918    2.689585    -1.489510   0.476151    2.215031    0.793756    0.235573    0.183452    0.667527     #> 066: -6.179648   0.348374    -5.749013   3.402021    2.762067    -1.490865   0.520905    2.185092    0.929906    0.254211    0.174280    0.661183     #> 067: -6.263086   0.327637    -5.634331   3.234640    2.755069    -1.510695   0.550426    2.217312    0.979119    0.322320    0.176250    0.662333     #> 068: -6.292892   0.362669    -5.612425   3.180375    2.701803    -1.509967   0.559493    2.262292    0.930163    0.306204    0.209163    0.659376     #> 069: -6.406907   0.311112    -5.588864   2.947345    2.659620    -1.506976   0.586969    2.254385    1.083297    0.321730    0.198705    0.665014     #> 070: -6.314687   0.246440    -5.595287   2.908022    2.630289    -1.497341   0.549582    2.261500    1.029132    0.314350    0.206450    0.657920     #> 071: -6.217709   0.265446    -5.567675   2.798543    2.600281    -1.531825   0.566408    2.206204    0.977676    0.298633    0.196128    0.659110     #> 072: -6.157095   0.238023    -5.754847   2.756068    2.610835    -1.545311   0.590166    2.188482    0.928792    0.302674    0.215475    0.656766     #> 073: -6.287617   0.255763    -5.782974   2.668018    2.562220    -1.547860   0.620664    2.168260    0.961688    0.313501    0.204701    0.659373     #> 074: -6.509203   0.260687    -5.652472   2.846293    2.500960    -1.562527   0.515292    2.121736    1.267267    0.297826    0.194466    0.668704     #> 075: -6.416412   0.278495    -5.663658   2.889233    2.531158    -1.575245   0.563700    2.156104    1.203903    0.282935    0.184743    0.660703     #> 076: -6.372197   0.258099    -5.726064   2.809855    2.497007    -1.585770   0.554655    2.130951    1.143708    0.268788    0.175506    0.656914     #> 077: -6.345672   0.278881    -5.670182   2.647593    2.595867    -1.575106   0.604909    2.152797    1.189868    0.296868    0.166730    0.657233     #> 078: -6.348930   0.262330    -5.658917   2.462042    2.552281    -1.543080   0.649866    2.176722    1.130374    0.282025    0.158394    0.658202     #> 079: -6.182329   0.305910    -5.622486   2.681155    2.576799    -1.530473   0.609340    2.235116    1.073856    0.267924    0.151881    0.666624     #> 080: -6.278351   0.247696    -5.611191   2.640099    2.540012    -1.529954   0.613512    2.216091    1.020163    0.254528    0.152491    0.665660     #> 081: -6.161229   0.308140    -5.648894   2.746375    2.584527    -1.542349   0.612081    2.185029    0.969155    0.251895    0.144867    0.658389     #> 082: -6.134250   0.290519    -5.697368   2.861817    2.573103    -1.554697   0.594581    2.126595    0.920697    0.239300    0.137623    0.654481     #> 083: -6.157780   0.293400    -5.674551   2.596083    2.552749    -1.554927   0.613874    2.102997    0.874662    0.227335    0.130742    0.649084     #> 084: -6.043718   0.270041    -5.524905   2.548757    2.544325    -1.547110   0.572517    2.204878    0.830929    0.215968    0.132570    0.649058     #> 085: -6.035218   0.203893    -5.464928   2.517038    2.519986    -1.562535   0.583354    2.289152    0.809167    0.205170    0.125942    0.659515     #> 086: -6.155169   0.188440    -5.358699   2.760529    2.498737    -1.578073   0.580119    2.283462    0.904021    0.194911    0.120566    0.652512     #> 087: -6.115400   0.156386    -5.284803   2.778030    2.502999    -1.590966   0.603655    2.235995    0.858820    0.185166    0.114538    0.654176     #> 088: -6.158905   0.168182    -5.450443   2.449863    2.516668    -1.578885   0.565575    2.174054    0.887651    0.235742    0.113189    0.672454     #> 089: -6.264660   0.164214    -5.592644   2.405672    2.533449    -1.562987   0.581745    2.165362    1.141834    0.228379    0.107530    0.663633     #> 090: -6.279971   0.227163    -5.563073   2.419175    2.545061    -1.556209   0.595420    2.181293    1.239181    0.235747    0.102153    0.659207     #> 091: -6.211909   0.182332    -5.561700   2.445815    2.572867    -1.544233   0.596836    2.182525    1.177222    0.223959    0.128134    0.653343     #> 092: -6.054699   0.227844    -5.661706   2.325238    2.516278    -1.536466   0.568745    2.156513    1.118361    0.212761    0.122333    0.654642     #> 093: -6.060565   0.272713    -5.729856   2.462729    2.511964    -1.535758   0.574684    2.156639    1.062443    0.212576    0.116217    0.657862     #> 094: -6.246009   0.287082    -5.862449   2.551871    2.478441    -1.539652   0.606569    2.199354    1.234343    0.247500    0.110406    0.654755     #> 095: -6.430293   0.274664    -5.696054   2.580877    2.460005    -1.534625   0.608098    2.271460    1.691609    0.236875    0.104886    0.658308     #> 096: -6.235785   0.261008    -5.573622   2.627211    2.484236    -1.537258   0.653057    2.253702    1.607029    0.225031    0.099641    0.659037     #> 097: -6.424872   0.273861    -5.622372   2.356470    2.528754    -1.536887   0.689467    2.268328    1.556114    0.213780    0.094659    0.654865     #> 098: -6.292736   0.285177    -5.715682   2.226018    2.579253    -1.531399   0.684539    2.272246    1.600298    0.203091    0.089926    0.662134     #> 099: -6.272271   0.291946    -5.757178   2.435993    2.512930    -1.534143   0.677665    2.285231    1.520283    0.224477    0.095242    0.661521     #> 100: -6.212044   0.249385    -5.898241   2.320787    2.509986    -1.546925   0.700892    2.320300    1.444269    0.213253    0.123807    0.664829     #> 101: -6.145608   0.204983    -5.761245   2.475931    2.517424    -1.559297   0.720140    2.349080    1.372055    0.202590    0.117616    0.663993     #> 102: -6.088134   0.202131    -5.798948   2.318193    2.482019    -1.557104   0.714314    2.330478    1.303453    0.192461    0.111736    0.656278     #> 103: -6.155875   0.197593    -5.842397   2.162408    2.429311    -1.566786   0.730617    2.305273    1.238280    0.182838    0.106149    0.656881     #> 104: -6.087011   0.207827    -5.953135   2.118611    2.511587    -1.562439   0.767974    2.280894    1.176366    0.188620    0.100841    0.666994     #> 105: -6.039989   0.251439    -5.966304   2.123777    2.549131    -1.557299   0.757149    2.254959    1.117548    0.253200    0.095799    0.666102     #> 106: -6.290345   0.268955    -5.975043   2.145418    2.573836    -1.550764   0.743828    2.239197    1.151869    0.245265    0.091009    0.659745     #> 107: -6.286730   0.287510    -5.955899   2.111745    2.594305    -1.561735   0.747215    2.250038    1.094275    0.248733    0.086459    0.659499     #> 108: -6.273823   0.297585    -6.016208   2.113022    2.595285    -1.566934   0.734420    2.258948    1.039562    0.277755    0.082136    0.660153     #> 109: -6.267443   0.316282    -6.038765   2.197108    2.609124    -1.577313   0.734572    2.255037    1.005796    0.315716    0.078029    0.661130     #> 110: -6.157332   0.269255    -6.051623   2.140537    2.550621    -1.569779   0.731601    2.273520    0.955506    0.299930    0.074935    0.659734     #> 111: -6.076713   0.269728    -5.953031   2.187567    2.523093    -1.573527   0.738749    2.270180    0.907731    0.284934    0.078932    0.655210     #> 112: -5.964195   0.169871    -5.815473   2.113463    2.501764    -1.570052   0.722121    2.274298    0.931897    0.270687    0.079653    0.658917     #> 113: -6.037903   0.193654    -5.686140   2.183916    2.521836    -1.569770   0.686944    2.272125    0.885302    0.257152    0.075670    0.656216     #> 114: -6.212603   0.207454    -5.578621   2.227185    2.468546    -1.572799   0.704449    2.289144    0.852730    0.244295    0.071886    0.659052     #> 115: -6.087506   0.159465    -5.562266   2.362240    2.467027    -1.569250   0.703103    2.295304    0.810094    0.232080    0.068292    0.659037     #> 116: -6.271836   0.207026    -5.771661   2.317987    2.466562    -1.567764   0.735192    2.279674    1.040933    0.220476    0.074169    0.661909     #> 117: -6.181938   0.247848    -5.916636   2.197798    2.461699    -1.577292   0.724590    2.285703    0.988886    0.221815    0.073582    0.656724     #> 118: -6.105514   0.259773    -6.031286   2.199732    2.433550    -1.573767   0.713413    2.310808    0.939442    0.227781    0.077772    0.662981     #> 119: -6.139682   0.230993    -5.775459   2.245673    2.475944    -1.576630   0.720349    2.319870    1.079576    0.255713    0.092191    0.660103     #> 120: -6.222458   0.265085    -5.780395   2.238269    2.407321    -1.563498   0.717967    2.312104    1.343394    0.242927    0.087581    0.662831     #> 121: -6.205576   0.292690    -5.818731   2.215492    2.353619    -1.568312   0.708781    2.332225    1.276224    0.237629    0.083202    0.658801     #> 122: -6.340574   0.248690    -5.792620   2.186040    2.336950    -1.568947   0.751458    2.336919    1.327683    0.225748    0.079042    0.664029     #> 123: -6.240619   0.286918    -5.922783   2.151440    2.385952    -1.578815   0.739304    2.315010    1.261299    0.239872    0.075090    0.665589     #> 124: -6.062197   0.188491    -5.671910   2.065987    2.407938    -1.575661   0.754348    2.354000    1.198234    0.258650    0.071335    0.655621     #> 125: -5.938171   0.133588    -5.669819   2.098894    2.394591    -1.567429   0.766950    2.346589    1.138322    0.245718    0.067769    0.647558     #> 126: -6.050836   0.159536    -5.575193   2.028379    2.321413    -1.567408   0.759598    2.356169    1.081406    0.233432    0.064380    0.646938     #> 127: -6.043550   0.162555    -5.630182   2.028261    2.279293    -1.565329   0.757574    2.375814    1.027336    0.221760    0.063550    0.652070     #> 128: -6.163815   0.156006    -5.713401   2.082449    2.292989    -1.567436   0.783207    2.368118    0.994222    0.210672    0.060373    0.652423     #> 129: -6.026360   0.134431    -5.730523   2.080405    2.279718    -1.560976   0.774327    2.367867    0.944511    0.207261    0.057354    0.646028     #> 130: -6.182462   0.182418    -5.854656   2.108885    2.282749    -1.562019   0.772143    2.336400    1.141696    0.206348    0.054486    0.651123     #> 131: -6.123334   0.226231    -5.956765   2.269243    2.261948    -1.562097   0.764782    2.345229    1.084611    0.203200    0.063076    0.646223     #> 132: -6.157793   0.253613    -5.899925   2.213909    2.231974    -1.566266   0.763625    2.348024    1.030380    0.193040    0.072373    0.646635     #> 133: -6.160282   0.176399    -5.600395   2.237008    2.202996    -1.566850   0.759821    2.343707    0.978861    0.200522    0.068755    0.643980     #> 134: -6.091373   0.214783    -5.522203   2.174087    2.204914    -1.567717   0.766791    2.351139    0.929918    0.190496    0.065317    0.639176     #> 135: -6.223544   0.196752    -5.619198   2.134648    2.148990    -1.569439   0.762407    2.354880    1.029688    0.189921    0.062051    0.638897     #> 136: -6.351980   0.222879    -5.619590   1.940290    2.136948    -1.569182   0.777299    2.362702    0.978204    0.180425    0.060331    0.638686     #> 137: -6.254703   0.238560    -5.325081   1.962909    2.156771    -1.567986   0.778301    2.386634    0.929294    0.197500    0.060935    0.642611     #> 138: -6.325032   0.223826    -5.596957   1.927149    2.119538    -1.568227   0.777141    2.401026    0.882829    0.208409    0.057888    0.645660     #> 139: -6.327387   0.252262    -5.794480   1.837559    2.130708    -1.571525   0.771579    2.385050    0.849735    0.205737    0.054994    0.648003     #> 140: -6.315469   0.252960    -5.515650   1.918284    2.087438    -1.569570   0.765491    2.393909    1.066001    0.200785    0.052244    0.650808     #> 141: -6.259260   0.196768    -5.359083   1.898649    2.102203    -1.572031   0.760099    2.389715    1.012701    0.190746    0.054229    0.650098     #> 142: -6.286116   0.207886    -5.429603   1.828356    2.113582    -1.568979   0.760490    2.398108    1.040263    0.210455    0.051517    0.644076     #> 143: -6.277863   0.144409    -5.400326   1.798129    2.124122    -1.568783   0.766750    2.390298    1.135030    0.199932    0.083070    0.640880     #> 144: -6.097191   0.152707    -5.265616   1.784166    2.067682    -1.569320   0.775770    2.387152    1.078278    0.189935    0.081843    0.640220     #> 145: -6.030562   0.169422    -5.372859   1.638945    2.042808    -1.571701   0.782241    2.388795    1.024364    0.182802    0.079024    0.646379     #> 146: -5.929208   0.183166    -5.215155   1.582296    2.124695    -1.572587   0.799206    2.384018    0.973146    0.173661    0.080349    0.649840     #> 147: -6.091094   0.148861    -5.413417   1.518910    2.117711    -1.577794   0.803974    2.390770    1.018066    0.189119    0.076332    0.651413     #> 148: -6.038322   0.163040    -5.364643   1.405403    2.060034    -1.580065   0.800919    2.394011    0.967163    0.199397    0.075860    0.643081     #> 149: -6.144971   0.162795    -5.434824   1.639964    2.046322    -1.578302   0.788771    2.397330    0.918804    0.189427    0.100187    0.642488     #> 150: -6.158308   0.153766    -5.322483   1.715597    2.019627    -1.577785   0.777469    2.393026    0.872864    0.179956    0.095178    0.642393     #> 151: -6.325919   0.162711    -5.333445   1.774397    1.980282    -1.576951   0.764681    2.393685    0.924791    0.177011    0.090419    0.640315     #> 152: -6.275873   0.140045    -5.434571   1.728362    1.946403    -1.579603   0.779750    2.395632    0.947999    0.177398    0.074118    0.640285     #> 153: -6.388154   0.204051    -5.674642   1.587373    1.920670    -1.577911   0.790669    2.395030    0.973367    0.198067    0.059956    0.633047     #> 154: -6.392683   0.185443    -5.801330   1.582848    1.964034    -1.578287   0.793954    2.392946    1.015318    0.204812    0.070121    0.631243     #> 155: -6.318437   0.228441    -5.918381   1.503735    1.936745    -1.577975   0.794713    2.391426    0.593669    0.212431    0.062457    0.635381     #> 156: -6.244482   0.191055    -5.744870   1.600130    1.955168    -1.577474   0.795110    2.391378    0.654095    0.239660    0.058790    0.636975     #> 157: -6.280873   0.176652    -5.640207   1.532814    1.973167    -1.579682   0.792470    2.391740    0.693335    0.222825    0.054457    0.642161     #> 158: -6.347095   0.192369    -5.639766   1.674537    1.995592    -1.580147   0.791439    2.396190    0.803920    0.212944    0.051899    0.642383     #> 159: -6.316945   0.133937    -5.675075   1.639609    1.976042    -1.579965   0.785751    2.394868    0.984798    0.193061    0.052124    0.642193     #> 160: -6.196957   0.133609    -5.674684   1.679991    1.981697    -1.580074   0.785797    2.393723    0.826229    0.196067    0.071522    0.636361     #> 161: -6.158592   0.155390    -5.689167   1.712191    2.025802    -1.580988   0.784514    2.392092    0.581564    0.166288    0.073511    0.634819     #> 162: -6.137448   0.154718    -5.678096   1.699526    2.025256    -1.580696   0.782306    2.393472    0.572338    0.162702    0.065574    0.636686     #> 163: -6.100945   0.148876    -5.661370   1.590237    2.003860    -1.582737   0.776825    2.392300    0.717984    0.148697    0.056941    0.645844     #> 164: -6.169722   0.144153    -5.675152   1.588790    2.007761    -1.583089   0.780865    2.393946    0.791595    0.180963    0.062668    0.639522     #> 165: -6.165415   0.136011    -5.468960   1.626551    2.036934    -1.584196   0.776216    2.391671    0.953662    0.223472    0.055287    0.653602     #> 166: -6.168184   0.169013    -5.549479   1.658533    2.018651    -1.584383   0.776294    2.390741    1.047761    0.222250    0.050838    0.653822     #> 167: -6.228627   0.220283    -5.594599   1.565492    2.028183    -1.583950   0.781883    2.391679    1.008091    0.206021    0.035260    0.641002     #> 168: -6.313146   0.222538    -5.916894   1.534677    2.032115    -1.584270   0.784079    2.390755    1.151038    0.223107    0.030725    0.645640     #> 169: -6.245363   0.215022    -5.951179   1.528584    2.022510    -1.584000   0.785383    2.389286    0.970954    0.219767    0.032126    0.647806     #> 170: -6.147276   0.130025    -5.557288   1.601452    2.020010    -1.584146   0.787341    2.386905    0.940890    0.185054    0.031372    0.650503     #> 171: -6.189950   0.113086    -5.714958   1.737105    2.031047    -1.584089   0.782702    2.386961    1.128114    0.135486    0.036217    0.647351     #> 172: -6.221322   0.102054    -5.701951   1.781948    2.055567    -1.583864   0.781344    2.387267    1.214306    0.128140    0.033982    0.652524     #> 173: -6.375344   0.146202    -5.820274   1.867366    2.078362    -1.583308   0.788934    2.388403    1.604321    0.132159    0.027481    0.653632     #> 174: -6.317145   0.145986    -5.704583   1.950026    2.081375    -1.583737   0.794455    2.389226    1.069156    0.151687    0.024780    0.645972     #> 175: -6.354248   0.193550    -5.778465   1.889422    2.079067    -1.583930   0.799495    2.388396    1.196044    0.158432    0.027334    0.655684     #> 176: -6.474609   0.164674    -5.288514   1.896971    2.095629    -1.584153   0.802286    2.389881    1.636644    0.176902    0.025370    0.642049     #> 177: -6.481511   0.194558    -5.409854   1.920877    2.108349    -1.583950   0.800018    2.388218    1.798048    0.155473    0.027795    0.651002     #> 178: -6.236869   0.174708    -5.611176   1.800213    2.116938    -1.583644   0.802930    2.386063    1.219576    0.140254    0.032773    0.649996     #> 179: -6.402773   0.160141    -5.504130   1.821194    2.150982    -1.583531   0.807279    2.384348    1.661895    0.128963    0.034756    0.648968     #> 180: -6.200352   0.201573    -5.379617   1.622757    2.098665    -1.583212   0.808068    2.384942    1.291450    0.136027    0.034760    0.648252     #> 181: -6.154629   0.134022    -5.703647   1.517957    2.097937    -1.583226   0.808596    2.384396    1.267142    0.109287    0.038464    0.653541     #> 182: -6.017586   0.152084    -5.621212   1.590407    2.115783    -1.582320   0.809266    2.382520    0.877975    0.112818    0.049803    0.646612     #> 183: -6.035195   0.155852    -5.613930   1.541263    2.122084    -1.582177   0.812211    2.383690    1.082328    0.138553    0.063931    0.643363     #> 184: -6.030149   0.160561    -5.707476   1.547401    2.114630    -1.581728   0.814090    2.381816    0.915867    0.133825    0.054102    0.644635     #> 185: -6.104584   0.163207    -5.560511   1.570250    2.105220    -1.582416   0.815267    2.381782    0.914228    0.115981    0.058587    0.651400     #> 186: -6.083656   0.135009    -5.726392   1.448787    2.091375    -1.582231   0.812878    2.382702    1.109141    0.121905    0.049311    0.642818     #> 187: -6.043931   0.169513    -5.764281   1.324844    2.099793    -1.581689   0.812464    2.383573    1.185721    0.131987    0.028303    0.653317     #> 188: -6.248159   0.200303    -5.876567   1.222233    2.095785    -1.580985   0.814765    2.382389    1.274920    0.189190    0.025971    0.654679     #> 189: -6.216796   0.232604    -6.068976   1.185167    2.121533    -1.581243   0.814869    2.380470    0.890098    0.128944    0.026408    0.657332     #> 190: -6.051454   0.196362    -5.889591   1.267705    2.123353    -1.581451   0.813807    2.380939    0.935833    0.110422    0.029227    0.662972     #> 191: -5.991635   0.211124    -5.881368   1.313101    2.106945    -1.580983   0.816506    2.382569    0.892656    0.156577    0.024955    0.654841     #> 192: -6.047691   0.215289    -5.768730   1.315070    2.103683    -1.580539   0.820562    2.383456    0.727932    0.177825    0.023876    0.651624     #> 193: -6.053332   0.208433    -5.776476   1.347489    2.108651    -1.579734   0.820091    2.383674    0.700510    0.190835    0.022941    0.649058     #> 194: -6.123540   0.202063    -5.700192   1.444472    2.111670    -1.579863   0.821033    2.384423    1.008728    0.164231    0.017636    0.642233     #> 195: -6.218184   0.192921    -5.639303   1.445180    2.068593    -1.579882   0.822934    2.383242    0.897313    0.191179    0.011468    0.639504     #> 196: -6.285609   0.167080    -5.523271   1.453079    2.058030    -1.580034   0.821900    2.384355    0.759962    0.198764    0.011644    0.647291     #> 197: -6.134340   0.224728    -5.594996   1.423208    2.062669    -1.580017   0.821988    2.384156    0.772882    0.154793    0.011072    0.653979     #> 198: -6.155253   0.218676    -5.762134   1.424059    2.085973    -1.579790   0.821053    2.384384    0.731096    0.143189    0.009429    0.652154     #> 199: -6.045881   0.177204    -5.636785   1.439550    2.070981    -1.579288   0.830498    2.386089    0.639387    0.124564    0.009880    0.655914     #> 200: -6.055478   0.209543    -6.063878   1.199574    2.077961    -1.579419   0.833684    2.386815    0.575297    0.143785    0.011720    0.659664     #> 201: -6.037418   0.198611    -6.093451   1.217432    2.074870    -1.579223   0.832098    2.386906    0.532374    0.144897    0.011077    0.660308     #> 202: -6.074725   0.210894    -5.998796   1.214613    2.063287    -1.579066   0.830320    2.387384    0.564264    0.154532    0.011140    0.659082     #> 203: -6.091109   0.218927    -5.960044   1.201478    2.055370    -1.579145   0.830100    2.387662    0.601134    0.159588    0.011460    0.658665     #> 204: -6.105597   0.219126    -5.964669   1.231455    2.048827    -1.579183   0.831098    2.387578    0.603384    0.161013    0.010930    0.658939     #> 205: -6.096807   0.214335    -5.952901   1.238991    2.046068    -1.579252   0.831319    2.387162    0.609380    0.163230    0.010500    0.657699     #> 206: -6.087488   0.207680    -5.923162   1.228464    2.045265    -1.579303   0.831680    2.386755    0.621802    0.166719    0.010294    0.657861     #> 207: -6.071840   0.200371    -5.899969   1.216463    2.046658    -1.579275   0.832070    2.386550    0.614502    0.170331    0.010192    0.657761     #> 208: -6.065574   0.201665    -5.848686   1.206129    2.047026    -1.579319   0.831664    2.386522    0.619872    0.171661    0.010531    0.656912     #> 209: -6.063189   0.201077    -5.839097   1.202585    2.046578    -1.579385   0.831411    2.386416    0.622716    0.174177    0.010417    0.655942     #> 210: -6.063305   0.197269    -5.836365   1.198254    2.047620    -1.579384   0.831114    2.386404    0.630926    0.176023    0.010390    0.655562     #> 211: -6.067943   0.197980    -5.847309   1.190643    2.047523    -1.579372   0.831228    2.386387    0.634219    0.179484    0.010593    0.654887     #> 212: -6.056753   0.196640    -5.871002   1.184433    2.047436    -1.579335   0.831147    2.386499    0.632418    0.180047    0.010865    0.655014     #> 213: -6.049761   0.196915    -5.864488   1.193781    2.047104    -1.579357   0.830967    2.386601    0.635111    0.178485    0.011130    0.654298     #> 214: -6.051699   0.195731    -5.857607   1.200313    2.046627    -1.579373   0.830825    2.386797    0.654442    0.175970    0.011481    0.654196     #> 215: -6.046734   0.196397    -5.847588   1.194736    2.046321    -1.579405   0.831030    2.386905    0.661428    0.173087    0.011493    0.653840     #> 216: -6.044855   0.192708    -5.836508   1.194547    2.046263    -1.579366   0.830665    2.386951    0.667204    0.171216    0.011635    0.653311     #> 217: -6.041256   0.189992    -5.833164   1.195505    2.046501    -1.579332   0.830390    2.386961    0.669282    0.171713    0.011667    0.653050     #> 218: -6.040552   0.188114    -5.825899   1.195071    2.046500    -1.579332   0.830343    2.386879    0.667698    0.172848    0.011602    0.652917     #> 219: -6.041706   0.187935    -5.827650   1.193297    2.046167    -1.579337   0.830204    2.386839    0.673168    0.172418    0.011582    0.652717     #> 220: -6.040923   0.187858    -5.826091   1.191068    2.046317    -1.579322   0.829879    2.386898    0.677496    0.172795    0.011446    0.652684     #> 221: -6.031841   0.184546    -5.818764   1.185344    2.046799    -1.579308   0.829943    2.386914    0.679127    0.172090    0.011317    0.652913     #> 222: -6.027131   0.183334    -5.813323   1.185231    2.047118    -1.579318   0.830009    2.386954    0.681745    0.172352    0.011277    0.652750     #> 223: -6.028836   0.183496    -5.811891   1.187753    2.045743    -1.579332   0.830173    2.386971    0.681366    0.172628    0.011470    0.652661     #> 224: -6.029598   0.182832    -5.807053   1.189294    2.044740    -1.579336   0.830326    2.386992    0.682544    0.172985    0.011507    0.652776     #> 225: -6.030101   0.181380    -5.803794   1.192640    2.043908    -1.579338   0.830447    2.387027    0.680371    0.172376    0.011501    0.652624     #> 226: -6.031507   0.182399    -5.810773   1.196079    2.044494    -1.579355   0.830324    2.387071    0.675101    0.173093    0.011642    0.652537     #> 227: -6.032667   0.182962    -5.806224   1.198234    2.044621    -1.579363   0.830503    2.387154    0.670883    0.173915    0.011571    0.652498     #> 228: -6.032264   0.184453    -5.796634   1.199624    2.044230    -1.579407   0.830594    2.387187    0.670582    0.174462    0.011569    0.652353     #> 229: -6.028916   0.183285    -5.793965   1.196713    2.044632    -1.579414   0.830643    2.387209    0.674898    0.174125    0.011463    0.652093     #> 230: -6.028921   0.183653    -5.791007   1.195125    2.044342    -1.579420   0.830701    2.387286    0.677747    0.174179    0.011419    0.651960     #> 231: -6.027478   0.182719    -5.794337   1.190773    2.044201    -1.579421   0.830904    2.387342    0.678057    0.173973    0.011386    0.652007     #> 232: -6.028107   0.182883    -5.793973   1.189968    2.044126    -1.579446   0.831017    2.387354    0.679718    0.174387    0.011371    0.652116     #> 233: -6.026146   0.181489    -5.796603   1.188469    2.044252    -1.579462   0.831025    2.387376    0.679750    0.175606    0.011344    0.651899     #> 234: -6.027695   0.182845    -5.797839   1.191645    2.044907    -1.579465   0.830893    2.387288    0.678211    0.176828    0.011369    0.651612     #> 235: -6.030135   0.182271    -5.798147   1.189381    2.045080    -1.579475   0.830877    2.387263    0.688212    0.177701    0.011318    0.651636     #> 236: -6.030725   0.181940    -5.797892   1.189258    2.045424    -1.579471   0.830745    2.387269    0.694006    0.179197    0.011286    0.651486     #> 237: -6.028246   0.181194    -5.801297   1.188542    2.046052    -1.579464   0.830597    2.387284    0.693111    0.180762    0.011243    0.651516     #> 238: -6.030284   0.182256    -5.795379   1.189480    2.047095    -1.579447   0.830620    2.387264    0.698448    0.181233    0.011208    0.651573     #> 239: -6.032709   0.182134    -5.792755   1.191578    2.047679    -1.579453   0.830634    2.387240    0.702301    0.180944    0.011173    0.651450     #> 240: -6.035075   0.182489    -5.796219   1.190613    2.047291    -1.579452   0.830719    2.387233    0.706047    0.180037    0.011061    0.651368     #> 241: -6.036239   0.183473    -5.794169   1.191153    2.048123    -1.579458   0.830600    2.387230    0.710595    0.179563    0.011009    0.651567     #> 242: -6.036142   0.183188    -5.791239   1.191375    2.047816    -1.579474   0.830709    2.387164    0.711367    0.179810    0.010995    0.651476     #> 243: -6.036491   0.182301    -5.792732   1.192755    2.047771    -1.579484   0.830786    2.387142    0.705716    0.180320    0.010956    0.651351     #> 244: -6.039181   0.181941    -5.790970   1.191967    2.047515    -1.579486   0.830940    2.387124    0.709274    0.179943    0.011039    0.651296     #> 245: -6.039574   0.180886    -5.791047   1.190976    2.047688    -1.579489   0.830977    2.387116    0.713114    0.178660    0.011118    0.651259     #> 246: -6.038403   0.179715    -5.793274   1.187608    2.048261    -1.579489   0.830996    2.387092    0.714676    0.178303    0.011134    0.651292     #> 247: -6.039593   0.179429    -5.797415   1.188356    2.048581    -1.579481   0.830951    2.387094    0.718571    0.177630    0.011179    0.651307     #> 248: -6.040672   0.179452    -5.802954   1.187781    2.048939    -1.579457   0.830912    2.387089    0.724880    0.176294    0.011218    0.651307     #> 249: -6.040283   0.178987    -5.807010   1.188216    2.049590    -1.579461   0.830958    2.387085    0.724918    0.176107    0.011280    0.651359     #> 250: -6.041485   0.178522    -5.803293   1.190114    2.049874    -1.579449   0.830880    2.387080    0.726640    0.175874    0.011356    0.651201     #> 251: -6.044769   0.178673    -5.805846   1.191374    2.050411    -1.579435   0.830828    2.387090    0.730368    0.176722    0.011361    0.651277     #> 252: -6.045081   0.178082    -5.809361   1.191183    2.050640    -1.579438   0.830854    2.387152    0.732381    0.177291    0.011265    0.651080     #> 253: -6.044815   0.178126    -5.812862   1.191434    2.050990    -1.579440   0.830990    2.387163    0.734909    0.177757    0.011268    0.651010     #> 254: -6.045637   0.179179    -5.814103   1.191126    2.050915    -1.579453   0.830950    2.387187    0.735563    0.178208    0.011233    0.650989     #> 255: -6.045281   0.179233    -5.814319   1.189830    2.050672    -1.579463   0.830969    2.387190    0.733706    0.179411    0.011273    0.650873     #> 256: -6.044909   0.179224    -5.813710   1.190693    2.050759    -1.579467   0.830982    2.387201    0.733159    0.179879    0.011269    0.650623     #> 257: -6.045287   0.178914    -5.818396   1.190292    2.051007    -1.579471   0.830974    2.387203    0.731533    0.180913    0.011256    0.650512     #> 258: -6.045196   0.178430    -5.821831   1.190603    2.051099    -1.579476   0.831022    2.387216    0.732036    0.180894    0.011212    0.650486     #> 259: -6.045716   0.178756    -5.823485   1.189669    2.051086    -1.579487   0.831152    2.387190    0.733440    0.180764    0.011144    0.650347     #> 260: -6.045814   0.178353    -5.821948   1.190272    2.051117    -1.579503   0.831276    2.387168    0.732752    0.180759    0.011107    0.650387     #> 261: -6.047894   0.178167    -5.822819   1.190855    2.050962    -1.579511   0.831300    2.387176    0.733017    0.180942    0.011103    0.650581     #> 262: -6.049017   0.178202    -5.823395   1.191791    2.051176    -1.579520   0.831299    2.387200    0.735905    0.181303    0.011110    0.650564     #> 263: -6.050157   0.178619    -5.823480   1.190946    2.051049    -1.579526   0.831260    2.387199    0.735843    0.181910    0.011110    0.650425     #> 264: -6.050288   0.178834    -5.825973   1.190918    2.050871    -1.579530   0.831225    2.387224    0.734832    0.182394    0.011114    0.650400     #> 265: -6.049614   0.178549    -5.828619   1.190333    2.050444    -1.579522   0.831149    2.387231    0.734240    0.182514    0.011028    0.650336     #> 266: -6.051179   0.178318    -5.831555   1.190193    2.050249    -1.579514   0.831109    2.387237    0.734298    0.182429    0.010961    0.650316     #> 267: -6.050425   0.177066    -5.833400   1.190721    2.049922    -1.579507   0.831171    2.387252    0.732616    0.182427    0.010933    0.650268     #> 268: -6.050517   0.176183    -5.831380   1.190695    2.049781    -1.579505   0.831198    2.387254    0.732532    0.182453    0.010932    0.650169     #> 269: -6.050097   0.175902    -5.829630   1.189763    2.049729    -1.579497   0.831162    2.387269    0.731700    0.182682    0.010922    0.650060     #> 270: -6.049825   0.175797    -5.823545   1.189178    2.049524    -1.579492   0.831170    2.387271    0.732611    0.182572    0.010918    0.650064     #> 271: -6.049179   0.176104    -5.823946   1.189330    2.049368    -1.579498   0.831174    2.387277    0.733712    0.182495    0.010938    0.650141     #> 272: -6.050914   0.176881    -5.823622   1.189662    2.049214    -1.579495   0.831185    2.387276    0.735293    0.182319    0.010923    0.650165     #> 273: -6.051903   0.177584    -5.824934   1.189587    2.049346    -1.579491   0.831145    2.387278    0.737204    0.182697    0.010911    0.650197     #> 274: -6.054039   0.177962    -5.827075   1.190329    2.049127    -1.579487   0.831132    2.387283    0.738987    0.183443    0.010909    0.650176     #> 275: -6.054253   0.177643    -5.826051   1.190858    2.049065    -1.579494   0.831081    2.387269    0.738160    0.183491    0.010899    0.650134     #> 276: -6.055671   0.177332    -5.824016   1.192295    2.048812    -1.579492   0.831043    2.387266    0.737716    0.183256    0.010925    0.650044     #> 277: -6.056754   0.177174    -5.824446   1.193013    2.048733    -1.579490   0.831066    2.387272    0.736508    0.183407    0.010936    0.649992     #> 278: -6.057840   0.176963    -5.825816   1.193538    2.048521    -1.579486   0.831095    2.387275    0.735471    0.183743    0.010908    0.649989     #> 279: -6.055365   0.176417    -5.824374   1.193328    2.048459    -1.579485   0.831101    2.387292    0.735699    0.183779    0.010870    0.650075     #> 280: -6.055098   0.176581    -5.823018   1.193775    2.048137    -1.579483   0.831081    2.387310    0.736072    0.183805    0.010852    0.650225     #> 281: -6.054662   0.176355    -5.822090   1.194264    2.048089    -1.579480   0.831059    2.387328    0.738238    0.183691    0.010830    0.650219     #> 282: -6.054954   0.176700    -5.820986   1.195055    2.048092    -1.579480   0.831074    2.387323    0.740086    0.183461    0.010790    0.650207     #> 283: -6.054855   0.176624    -5.820457   1.196077    2.048353    -1.579481   0.831095    2.387329    0.738999    0.183519    0.010794    0.650279     #> 284: -6.053718   0.176310    -5.820577   1.196581    2.048594    -1.579479   0.831112    2.387341    0.738365    0.183706    0.010758    0.650290     #> 285: -6.054837   0.175969    -5.819811   1.197163    2.048717    -1.579476   0.831118    2.387336    0.739086    0.183962    0.010728    0.650329     #> 286: -6.054094   0.175523    -5.819596   1.196997    2.048947    -1.579478   0.831173    2.387337    0.738440    0.184307    0.010750    0.650442     #> 287: -6.053474   0.175279    -5.819974   1.197133    2.049235    -1.579481   0.831241    2.387339    0.737342    0.184158    0.010753    0.650500     #> 288: -6.053648   0.175584    -5.821407   1.196546    2.049334    -1.579485   0.831321    2.387338    0.735954    0.184526    0.010749    0.650507     #> 289: -6.055871   0.176060    -5.822254   1.196799    2.049348    -1.579485   0.831338    2.387334    0.735922    0.184701    0.010738    0.650545     #> 290: -6.057906   0.176692    -5.821673   1.197480    2.049410    -1.579486   0.831326    2.387337    0.736821    0.184767    0.010729    0.650650     #> 291: -6.058278   0.176544    -5.820620   1.197045    2.049350    -1.579486   0.831287    2.387341    0.736845    0.184888    0.010701    0.650768     #> 292: -6.057822   0.176122    -5.820517   1.197091    2.049523    -1.579485   0.831259    2.387342    0.736183    0.185168    0.010660    0.650697     #> 293: -6.057357   0.175553    -5.821762   1.197110    2.049732    -1.579484   0.831253    2.387343    0.735810    0.184962    0.010631    0.650755     #> 294: -6.058023   0.175377    -5.821405   1.197762    2.049804    -1.579485   0.831267    2.387356    0.737845    0.184838    0.010635    0.650799     #> 295: -6.058442   0.175248    -5.823396   1.198525    2.049947    -1.579484   0.831256    2.387360    0.739066    0.184722    0.010664    0.650915     #> 296: -6.059286   0.174834    -5.825005   1.198886    2.050122    -1.579482   0.831226    2.387370    0.740183    0.184920    0.010669    0.650925     #> 297: -6.059679   0.174972    -5.825805   1.198811    2.050331    -1.579480   0.831227    2.387365    0.740264    0.184991    0.010708    0.650969     #> 298: -6.060177   0.175088    -5.825383   1.199166    2.050227    -1.579482   0.831244    2.387356    0.740962    0.185339    0.010679    0.651082     #> 299: -6.060598   0.174778    -5.825341   1.198994    2.050309    -1.579484   0.831244    2.387352    0.740977    0.185802    0.010683    0.651035     #> 300: -6.060052   0.174512    -5.825305   1.198753    2.050484    -1.579484   0.831227    2.387349    0.741640    0.185463    0.010666    0.651102     #> 301: -6.060990   0.174045    -5.825185   1.198931    2.050461    -1.579485   0.831202    2.387341    0.743479    0.185307    0.010666    0.651133     #> 302: -6.061123   0.173578    -5.825024   1.198703    2.050519    -1.579485   0.831190    2.387343    0.744186    0.185525    0.010692    0.651138     #> 303: -6.062172   0.173710    -5.825630   1.198391    2.050641    -1.579485   0.831158    2.387343    0.745380    0.186279    0.010691    0.651083     #> 304: -6.062943   0.174174    -5.825900   1.197886    2.050731    -1.579486   0.831146    2.387339    0.744729    0.186364    0.010699    0.651161     #> 305: -6.063397   0.174121    -5.825873   1.198074    2.050573    -1.579484   0.831143    2.387343    0.743725    0.186452    0.010696    0.651202     #> 306: -6.063236   0.174450    -5.824594   1.198339    2.050636    -1.579487   0.831123    2.387347    0.743346    0.186166    0.010709    0.651292     #> 307: -6.063155   0.174318    -5.823954   1.198566    2.050603    -1.579486   0.831095    2.387357    0.745145    0.185630    0.010710    0.651424     #> 308: -6.064193   0.174445    -5.824002   1.198658    2.050624    -1.579485   0.831068    2.387360    0.746479    0.185443    0.010742    0.651509     #> 309: -6.065370   0.174331    -5.823644   1.198970    2.050646    -1.579486   0.831060    2.387358    0.748181    0.185297    0.010729    0.651622     #> 310: -6.066001   0.174270    -5.824979   1.199296    2.050607    -1.579485   0.831079    2.387355    0.749151    0.185172    0.010717    0.651714     #> 311: -6.067609   0.174125    -5.825373   1.199660    2.050663    -1.579483   0.831072    2.387354    0.750689    0.185528    0.010748    0.651771     #> 312: -6.071300   0.174434    -5.825806   1.199826    2.050639    -1.579481   0.831065    2.387353    0.754733    0.185676    0.010753    0.651906     #> 313: -6.073328   0.174242    -5.826462   1.200030    2.050550    -1.579477   0.831051    2.387351    0.758623    0.185347    0.010773    0.652156     #> 314: -6.074236   0.174438    -5.826614   1.199945    2.050432    -1.579477   0.831044    2.387354    0.759999    0.185253    0.010778    0.652295     #> 315: -6.075277   0.174369    -5.827435   1.200099    2.050080    -1.579477   0.831028    2.387350    0.760421    0.185119    0.010787    0.652371     #> 316: -6.075647   0.174016    -5.828365   1.200212    2.050149    -1.579476   0.831018    2.387348    0.760800    0.185141    0.010790    0.652442     #> 317: -6.074873   0.173835    -5.828380   1.200333    2.050222    -1.579476   0.830997    2.387347    0.760485    0.185101    0.010753    0.652577     #> 318: -6.075851   0.173957    -5.829418   1.200677    2.050228    -1.579476   0.830993    2.387348    0.761798    0.185264    0.010733    0.652754     #> 319: -6.075915   0.173401    -5.829284   1.200996    2.050462    -1.579478   0.830988    2.387348    0.762057    0.185444    0.010714    0.652877     #> 320: -6.075997   0.173114    -5.829800   1.201027    2.050773    -1.579480   0.830988    2.387350    0.761478    0.185361    0.010702    0.653019     #> 321: -6.075930   0.173000    -5.830617   1.200902    2.050928    -1.579479   0.830980    2.387349    0.761883    0.185541    0.010683    0.653162     #> 322: -6.077828   0.173042    -5.831770   1.200676    2.050945    -1.579479   0.830958    2.387351    0.766041    0.185550    0.010671    0.653282     #> 323: -6.078748   0.172915    -5.832968   1.200245    2.051014    -1.579481   0.830948    2.387351    0.769077    0.185684    0.010683    0.653455     #> 324: -6.079321   0.172885    -5.834469   1.200035    2.051120    -1.579480   0.830943    2.387346    0.769822    0.185896    0.010701    0.653571     #> 325: -6.080297   0.172576    -5.836348   1.199924    2.051170    -1.579482   0.830943    2.387344    0.771948    0.185953    0.010742    0.653657     #> 326: -6.080651   0.172461    -5.837793   1.199693    2.051454    -1.579483   0.830935    2.387341    0.772924    0.185870    0.010741    0.653799     #> 327: -6.081379   0.172525    -5.838636   1.199408    2.051669    -1.579486   0.830925    2.387341    0.774039    0.185826    0.010761    0.653943     #> 328: -6.081670   0.172427    -5.840043   1.199288    2.051975    -1.579487   0.830922    2.387339    0.774594    0.185418    0.010752    0.654123     #> 329: -6.082429   0.172425    -5.840843   1.199231    2.052101    -1.579487   0.830900    2.387340    0.775743    0.185199    0.010750    0.654282     #> 330: -6.082947   0.172312    -5.842195   1.199262    2.052251    -1.579488   0.830885    2.387336    0.776030    0.185112    0.010741    0.654427     #> 331: -6.083433   0.172684    -5.843093   1.199334    2.052353    -1.579489   0.830881    2.387332    0.776828    0.185032    0.010732    0.654529     #> 332: -6.083493   0.172271    -5.844282   1.199648    2.052243    -1.579491   0.830882    2.387330    0.777095    0.184981    0.010724    0.654643     #> 333: -6.084202   0.172084    -5.845606   1.200024    2.052181    -1.579492   0.830886    2.387329    0.776676    0.185011    0.010759    0.654706     #> 334: -6.084942   0.171817    -5.846207   1.200270    2.052270    -1.579493   0.830885    2.387326    0.776477    0.185388    0.010794    0.654819     #> 335: -6.085331   0.171894    -5.846656   1.200446    2.052652    -1.579492   0.830885    2.387324    0.777063    0.185533    0.010843    0.654949     #> 336: -6.085309   0.171901    -5.847335   1.200577    2.052865    -1.579492   0.830883    2.387322    0.776956    0.185380    0.010878    0.655144     #> 337: -6.086467   0.172122    -5.848304   1.200479    2.053080    -1.579493   0.830868    2.387319    0.776274    0.185741    0.010870    0.655347     #> 338: -6.087671   0.172313    -5.848983   1.200450    2.053392    -1.579493   0.830861    2.387319    0.777639    0.185993    0.010876    0.655504     #> 339: -6.088606   0.172482    -5.849853   1.200451    2.053614    -1.579493   0.830866    2.387318    0.778066    0.186131    0.010902    0.655722     #> 340: -6.089364   0.172539    -5.850417   1.200644    2.053538    -1.579493   0.830872    2.387320    0.779755    0.186105    0.010910    0.655955     #> 341: -6.091562   0.172456    -5.851590   1.200644    2.053376    -1.579494   0.830873    2.387321    0.784532    0.185802    0.010928    0.656095     #> 342: -6.093540   0.172430    -5.852885   1.200566    2.053274    -1.579494   0.830875    2.387323    0.788421    0.185717    0.010922    0.656309     #> 343: -6.094680   0.172450    -5.853537   1.200493    2.053127    -1.579494   0.830881    2.387325    0.790456    0.185500    0.010923    0.656542     #> 344: -6.096284   0.172698    -5.854322   1.200415    2.052872    -1.579494   0.830884    2.387325    0.792268    0.185385    0.010934    0.656716     #> 345: -6.098183   0.172696    -5.854925   1.200458    2.052617    -1.579494   0.830883    2.387323    0.793947    0.185386    0.010932    0.656867     #> 346: -6.099082   0.172904    -5.855826   1.200441    2.052588    -1.579494   0.830876    2.387324    0.795260    0.185244    0.010936    0.657042     #> 347: -6.099537   0.172904    -5.856673   1.200342    2.052692    -1.579495   0.830873    2.387322    0.795728    0.185312    0.010935    0.657232     #> 348: -6.100042   0.172659    -5.857234   1.200362    2.052736    -1.579495   0.830872    2.387321    0.797461    0.185395    0.010914    0.657431     #> 349: -6.100642   0.172609    -5.857718   1.200399    2.052712    -1.579496   0.830863    2.387320    0.798307    0.185370    0.010927    0.657626     #> 350: -6.101860   0.172633    -5.858544   1.200430    2.052648    -1.579495   0.830851    2.387319    0.799734    0.185548    0.010951    0.657856     #> 351: -6.103918   0.172859    -5.858844   1.200464    2.052596    -1.579495   0.830836    2.387318    0.803448    0.185595    0.010983    0.658014     #> 352: -6.105158   0.173134    -5.858920   1.200477    2.052470    -1.579495   0.830838    2.387320    0.804163    0.185583    0.010974    0.658184     #> 353: -6.105837   0.172938    -5.859399   1.200442    2.052480    -1.579495   0.830843    2.387321    0.804381    0.185805    0.010989    0.658342     #> 354: -6.106663   0.173158    -5.860199   1.200477    2.052586    -1.579495   0.830843    2.387322    0.804435    0.186123    0.010987    0.658531     #> 355: -6.107458   0.173359    -5.860599   1.200587    2.052676    -1.579495   0.830845    2.387319    0.805566    0.186047    0.011001    0.658732     #> 356: -6.108082   0.173548    -5.861304   1.200674    2.052785    -1.579495   0.830849    2.387317    0.805610    0.185767    0.011033    0.658897     #> 357: -6.108975   0.173619    -5.861657   1.200694    2.052846    -1.579495   0.830846    2.387319    0.805788    0.185562    0.011051    0.659064     #> 358: -6.109106   0.173552    -5.862635   1.200608    2.052991    -1.579495   0.830845    2.387319    0.805696    0.185240    0.011049    0.659252     #> 359: -6.109321   0.173639    -5.863246   1.200674    2.053066    -1.579495   0.830849    2.387318    0.806739    0.185044    0.011046    0.659500     #> 360: -6.110853   0.173896    -5.863655   1.200690    2.053195    -1.579495   0.830853    2.387318    0.808761    0.184909    0.011035    0.659719     #> 361: -6.112543   0.174398    -5.864353   1.200597    2.053260    -1.579494   0.830855    2.387318    0.809947    0.184901    0.011027    0.659947     #> 362: -6.114088   0.174626    -5.864966   1.200577    2.053323    -1.579494   0.830859    2.387318    0.811580    0.184808    0.011020    0.660197     #> 363: -6.115910   0.174883    -5.865428   1.200614    2.053315    -1.579494   0.830856    2.387318    0.812852    0.184579    0.011024    0.660397     #> 364: -6.116765   0.174920    -5.866058   1.200594    2.053277    -1.579494   0.830859    2.387319    0.811850    0.184545    0.011038    0.660573     #> 365: -6.117887   0.175090    -5.867099   1.200717    2.053234    -1.579494   0.830859    2.387320    0.811690    0.184789    0.011044    0.660805     #> 366: -6.118970   0.175091    -5.867961   1.200721    2.053226    -1.579494   0.830867    2.387320    0.811123    0.184616    0.011059    0.661085     #> 367: -6.120330   0.175222    -5.868353   1.200678    2.053238    -1.579493   0.830871    2.387319    0.811369    0.184610    0.011072    0.661340     #> 368: -6.121938   0.175654    -5.868754   1.200593    2.053271    -1.579493   0.830870    2.387319    0.813320    0.184731    0.011057    0.661592     #> 369: -6.123707   0.176155    -5.868783   1.200562    2.053298    -1.579493   0.830867    2.387320    0.815323    0.184851    0.011035    0.661785     #> 370: -6.124142   0.176149    -5.869339   1.200552    2.053470    -1.579493   0.830867    2.387319    0.814998    0.184863    0.011041    0.661986     #> 371: -6.124759   0.176197    -5.869777   1.200532    2.053488    -1.579493   0.830867    2.387319    0.814701    0.184877    0.011032    0.662209     #> 372: -6.125487   0.176021    -5.870028   1.200501    2.053566    -1.579493   0.830868    2.387318    0.815465    0.184993    0.011027    0.662482     #> 373: -6.127186   0.176094    -5.870440   1.200507    2.053509    -1.579493   0.830871    2.387317    0.818744    0.185056    0.011047    0.662697     #> 374: -6.128353   0.176209    -5.870915   1.200477    2.053593    -1.579493   0.830872    2.387317    0.821513    0.184967    0.011062    0.662914     #> 375: -6.129919   0.176660    -5.871212   1.200515    2.053568    -1.579492   0.830874    2.387316    0.823749    0.184903    0.011088    0.663129     #> 376: -6.131644   0.177069    -5.871792   1.200499    2.053542    -1.579492   0.830875    2.387315    0.825639    0.184875    0.011109    0.663331     #> 377: -6.133236   0.177334    -5.872170   1.200535    2.053501    -1.579492   0.830876    2.387315    0.828080    0.184585    0.011122    0.663511     #> 378: -6.134394   0.177449    -5.872585   1.200585    2.053472    -1.579492   0.830876    2.387315    0.829454    0.184372    0.011167    0.663695     #> 379: -6.135371   0.177561    -5.872993   1.200658    2.053565    -1.579492   0.830874    2.387314    0.831185    0.184153    0.011184    0.663879     #> 380: -6.135824   0.177504    -5.873049   1.200697    2.053696    -1.579492   0.830871    2.387314    0.833535    0.183849    0.011181    0.664071     #> 381: -6.136943   0.177686    -5.873157   1.200617    2.053800    -1.579492   0.830867    2.387314    0.836649    0.183591    0.011173    0.664252     #> 382: -6.137785   0.177882    -5.873422   1.200563    2.053831    -1.579492   0.830865    2.387313    0.838287    0.183622    0.011184    0.664481     #> 383: -6.138789   0.177967    -5.873855   1.200572    2.053865    -1.579492   0.830865    2.387312    0.840525    0.183683    0.011181    0.664709     #> 384: -6.138867   0.177920    -5.874240   1.200600    2.054025    -1.579492   0.830865    2.387313    0.841091    0.183711    0.011187    0.664947     #> 385: -6.139536   0.178197    -5.874486   1.200595    2.054168    -1.579492   0.830862    2.387313    0.841759    0.183732    0.011170    0.665189     #> 386: -6.140125   0.178050    -5.874679   1.200620    2.054333    -1.579492   0.830861    2.387314    0.842507    0.183569    0.011167    0.665436     #> 387: -6.140221   0.178157    -5.874843   1.200584    2.054489    -1.579492   0.830860    2.387315    0.842648    0.183411    0.011162    0.665675     #> 388: -6.140366   0.178246    -5.875190   1.200606    2.054653    -1.579492   0.830858    2.387314    0.843840    0.183192    0.011190    0.665911     #> 389: -6.140925   0.178421    -5.875596   1.200651    2.054784    -1.579492   0.830859    2.387314    0.845008    0.183062    0.011190    0.666167     #> 390: -6.141427   0.178460    -5.876042   1.200704    2.054883    -1.579492   0.830859    2.387313    0.845693    0.182972    0.011203    0.666403     #> 391: -6.142777   0.178517    -5.876421   1.200701    2.055008    -1.579492   0.830858    2.387313    0.847730    0.182746    0.011233    0.666633     #> 392: -6.143989   0.178695    -5.876533   1.200701    2.055110    -1.579492   0.830858    2.387312    0.849540    0.182784    0.011235    0.666884     #> 393: -6.144962   0.178799    -5.876644   1.200715    2.055177    -1.579492   0.830858    2.387312    0.851905    0.182668    0.011245    0.667118     #> 394: -6.145093   0.178740    -5.876876   1.200684    2.055127    -1.579492   0.830856    2.387312    0.852005    0.182574    0.011260    0.667358     #> 395: -6.145696   0.178815    -5.876935   1.200657    2.055027    -1.579492   0.830854    2.387312    0.851843    0.182437    0.011268    0.667623     #> 396: -6.146140   0.178854    -5.876986   1.200661    2.055009    -1.579492   0.830857    2.387312    0.851916    0.182127    0.011276    0.667868     #> 397: -6.145810   0.178809    -5.877216   1.200669    2.054994    -1.579492   0.830858    2.387312    0.851486    0.181902    0.011284    0.668138     #> 398: -6.145360   0.178693    -5.877324   1.200648    2.055019    -1.579491   0.830858    2.387312    0.850883    0.181810    0.011272    0.668398     #> 399: -6.145428   0.178777    -5.877387   1.200627    2.055165    -1.579492   0.830858    2.387313    0.850639    0.181604    0.011275    0.668654     #> 400: -6.145031   0.178821    -5.877388   1.200609    2.055248    -1.579492   0.830857    2.387313    0.850573    0.181696    0.011289    0.668889     #> 401: -6.145925   0.179186    -5.877371   1.200609    2.055244    -1.579491   0.830856    2.387312    0.851643    0.181645    0.011307    0.669119     #> 402: -6.146838   0.179335    -5.877534   1.200624    2.055286    -1.579492   0.830856    2.387312    0.852291    0.181441    0.011313    0.669322     #> 403: -6.147098   0.179393    -5.877518   1.200607    2.055194    -1.579491   0.830856    2.387313    0.852506    0.181296    0.011311    0.669538     #> 404: -6.147371   0.179546    -5.877577   1.200576    2.055164    -1.579491   0.830857    2.387312    0.852174    0.181091    0.011307    0.669768     #> 405: -6.148736   0.179702    -5.877568   1.200570    2.055261    -1.579491   0.830857    2.387312    0.853850    0.180990    0.011297    0.669992     #> 406: -6.149501   0.179860    -5.877500   1.200580    2.055391    -1.579491   0.830857    2.387312    0.855034    0.181020    0.011293    0.670204     #> 407: -6.150580   0.179928    -5.877568   1.200637    2.055403    -1.579491   0.830856    2.387313    0.857183    0.181121    0.011273    0.670440     #> 408: -6.151903   0.180081    -5.877606   1.200674    2.055463    -1.579490   0.830855    2.387313    0.858199    0.181315    0.011255    0.670697     #> 409: -6.152836   0.180278    -5.877658   1.200679    2.055485    -1.579490   0.830855    2.387313    0.859181    0.181246    0.011274    0.670917     #> 410: -6.153281   0.180395    -5.877715   1.200682    2.055382    -1.579490   0.830855    2.387314    0.859627    0.181090    0.011284    0.671197     #> 411: -6.153972   0.180533    -5.877792   1.200664    2.055304    -1.579490   0.830854    2.387314    0.859758    0.180878    0.011271    0.671425     #> 412: -6.154445   0.180514    -5.877945   1.200668    2.055214    -1.579490   0.830854    2.387314    0.859553    0.180738    0.011250    0.671675     #> 413: -6.155711   0.180615    -5.878066   1.200693    2.055146    -1.579490   0.830852    2.387314    0.861316    0.180602    0.011266    0.671878     #> 414: -6.156575   0.180837    -5.878085   1.200703    2.055187    -1.579490   0.830853    2.387314    0.862491    0.180647    0.011286    0.672087     #> 415: -6.157931   0.180947    -5.878088   1.200709    2.055241    -1.579490   0.830854    2.387314    0.863377    0.180856    0.011294    0.672270     #> 416: -6.158198   0.181204    -5.878116   1.200714    2.055297    -1.579490   0.830854    2.387314    0.863566    0.181034    0.011297    0.672484     #> 417: -6.159327   0.181374    -5.878110   1.200708    2.055298    -1.579490   0.830855    2.387314    0.863950    0.180901    0.011313    0.672723     #> 418: -6.160794   0.181616    -5.878291   1.200733    2.055318    -1.579490   0.830854    2.387314    0.865153    0.181069    0.011292    0.672911     #> 419: -6.162256   0.181726    -5.878452   1.200749    2.055451    -1.579491   0.830854    2.387314    0.866759    0.181001    0.011282    0.673143     #> 420: -6.163162   0.181932    -5.878477   1.200738    2.055514    -1.579490   0.830855    2.387314    0.867608    0.180865    0.011265    0.673350     #> 421: -6.163450   0.182135    -5.878474   1.200725    2.055650    -1.579490   0.830855    2.387314    0.867744    0.180763    0.011267    0.673591     #> 422: -6.163795   0.182280    -5.878439   1.200749    2.055812    -1.579490   0.830855    2.387314    0.867700    0.180682    0.011265    0.673803     #> 423: -6.164692   0.182347    -5.878637   1.200760    2.055883    -1.579490   0.830856    2.387314    0.868826    0.180556    0.011257    0.674022     #> 424: -6.164858   0.182136    -5.878807   1.200779    2.055841    -1.579490   0.830858    2.387314    0.869351    0.180367    0.011265    0.674235     #> 425: -6.165271   0.182228    -5.878899   1.200826    2.055865    -1.579490   0.830858    2.387314    0.870201    0.180083    0.011255    0.674456     #> 426: -6.165668   0.182418    -5.878929   1.200851    2.055866    -1.579490   0.830858    2.387314    0.870429    0.179998    0.011243    0.674677     #> 427: -6.166103   0.182539    -5.878918   1.200880    2.055903    -1.579490   0.830857    2.387314    0.870426    0.179795    0.011233    0.674967     #> 428: -6.166646   0.183016    -5.878941   1.200887    2.055998    -1.579490   0.830855    2.387314    0.871483    0.179534    0.011240    0.675203     #> 429: -6.167115   0.183133    -5.879023   1.200871    2.056047    -1.579490   0.830855    2.387313    0.871724    0.179406    0.011246    0.675391     #> 430: -6.167605   0.183201    -5.879113   1.200868    2.056031    -1.579490   0.830855    2.387313    0.871642    0.179330    0.011262    0.675579     #> 431: -6.168522   0.183336    -5.879092   1.200855    2.056111    -1.579490   0.830855    2.387313    0.872489    0.179261    0.011274    0.675761     #> 432: -6.168937   0.183313    -5.879121   1.200846    2.056208    -1.579490   0.830856    2.387313    0.873366    0.179304    0.011283    0.675944     #> 433: -6.170052   0.183358    -5.879173   1.200848    2.056169    -1.579490   0.830855    2.387313    0.875655    0.179130    0.011287    0.676118     #> 434: -6.170614   0.183206    -5.879279   1.200846    2.056123    -1.579490   0.830855    2.387313    0.877458    0.178922    0.011286    0.676295     #> 435: -6.171766   0.183320    -5.879239   1.200866    2.056135    -1.579490   0.830856    2.387313    0.879293    0.178757    0.011272    0.676482     #> 436: -6.172472   0.183375    -5.879317   1.200848    2.056191    -1.579490   0.830855    2.387313    0.880316    0.178580    0.011268    0.676648     #> 437: -6.173349   0.183520    -5.879396   1.200855    2.056230    -1.579490   0.830855    2.387313    0.881096    0.178468    0.011275    0.676831     #> 438: -6.174284   0.183871    -5.879396   1.200841    2.056375    -1.579490   0.830855    2.387313    0.882702    0.178449    0.011276    0.677038     #> 439: -6.174683   0.184041    -5.879447   1.200846    2.056609    -1.579490   0.830855    2.387313    0.883002    0.178545    0.011299    0.677195     #> 440: -6.175346   0.184352    -5.879375   1.200834    2.056633    -1.579490   0.830855    2.387314    0.883707    0.178527    0.011302    0.677364     #> 441: -6.175870   0.184456    -5.879349   1.200819    2.056671    -1.579490   0.830855    2.387314    0.883608    0.178619    0.011299    0.677563     #> 442: -6.176289   0.184580    -5.879366   1.200806    2.056744    -1.579490   0.830855    2.387314    0.883310    0.178538    0.011294    0.677756     #> 443: -6.176523   0.184700    -5.879410   1.200811    2.056720    -1.579490   0.830855    2.387314    0.883064    0.178535    0.011274    0.677941     #> 444: -6.177131   0.184865    -5.879399   1.200832    2.056783    -1.579490   0.830855    2.387314    0.884506    0.178447    0.011252    0.678119     #> 445: -6.178670   0.184912    -5.879441   1.200847    2.056757    -1.579490   0.830854    2.387314    0.885996    0.178483    0.011240    0.678274     #> 446: -6.180276   0.185141    -5.879503   1.200849    2.056778    -1.579490   0.830854    2.387314    0.887537    0.178447    0.011233    0.678445     #> 447: -6.181375   0.185433    -5.879506   1.200830    2.056767    -1.579490   0.830855    2.387314    0.888009    0.178287    0.011236    0.678629     #> 448: -6.182060   0.185640    -5.879499   1.200832    2.056797    -1.579490   0.830855    2.387314    0.888496    0.178187    0.011228    0.678789     #> 449: -6.182388   0.185733    -5.879460   1.200831    2.056906    -1.579490   0.830854    2.387314    0.889697    0.178059    0.011231    0.678986     #> 450: -6.182682   0.185817    -5.879522   1.200841    2.057031    -1.579490   0.830855    2.387314    0.889598    0.177962    0.011249    0.679156     #> 451: -6.182457   0.185871    -5.879552   1.200847    2.057237    -1.579490   0.830855    2.387314    0.889303    0.177825    0.011270    0.679344     #> 452: -6.183075   0.186100    -5.879636   1.200846    2.057353    -1.579490   0.830855    2.387314    0.889293    0.177835    0.011286    0.679526     #> 453: -6.183884   0.186359    -5.879632   1.200838    2.057438    -1.579490   0.830856    2.387314    0.889883    0.177755    0.011281    0.679691     #> 454: -6.184640   0.186508    -5.879677   1.200857    2.057524    -1.579490   0.830855    2.387314    0.889447    0.177802    0.011269    0.679846     #> 455: -6.185347   0.186704    -5.879688   1.200853    2.057537    -1.579490   0.830855    2.387314    0.889752    0.177786    0.011253    0.680029     #> 456: -6.186170   0.186979    -5.879702   1.200847    2.057559    -1.579490   0.830855    2.387314    0.890002    0.177677    0.011248    0.680197     #> 457: -6.186798   0.187114    -5.879713   1.200851    2.057633    -1.579490   0.830856    2.387314    0.890504    0.177843    0.011247    0.680359     #> 458: -6.187041   0.187211    -5.879694   1.200857    2.057790    -1.579490   0.830856    2.387314    0.891333    0.177818    0.011236    0.680504     #> 459: -6.187394   0.187298    -5.879688   1.200865    2.057871    -1.579490   0.830856    2.387314    0.892181    0.177778    0.011219    0.680667     #> 460: -6.188005   0.187404    -5.879720   1.200860    2.057906    -1.579490   0.830857    2.387314    0.892554    0.177796    0.011207    0.680812     #> 461: -6.188131   0.187614    -5.879743   1.200851    2.057962    -1.579490   0.830857    2.387315    0.892711    0.177648    0.011209    0.680981     #> 462: -6.188725   0.187779    -5.879719   1.200855    2.057923    -1.579490   0.830857    2.387315    0.893415    0.177511    0.011217    0.681145     #> 463: -6.189685   0.187898    -5.879719   1.200857    2.057915    -1.579490   0.830857    2.387315    0.894260    0.177459    0.011215    0.681281     #> 464: -6.190744   0.188007    -5.879703   1.200852    2.057937    -1.579490   0.830858    2.387314    0.895977    0.177360    0.011228    0.681427     #> 465: -6.191259   0.188020    -5.879724   1.200856    2.057910    -1.579489   0.830858    2.387314    0.896649    0.177185    0.011241    0.681603     #> 466: -6.191545   0.188207    -5.879742   1.200860    2.058006    -1.579490   0.830858    2.387315    0.896558    0.177017    0.011260    0.681758     #> 467: -6.191373   0.188286    -5.879739   1.200854    2.058021    -1.579490   0.830858    2.387315    0.897293    0.176865    0.011273    0.681952     #> 468: -6.191634   0.188443    -5.879753   1.200857    2.058119    -1.579490   0.830858    2.387315    0.898326    0.176726    0.011285    0.682123     #> 469: -6.192186   0.188437    -5.879743   1.200852    2.058278    -1.579490   0.830859    2.387315    0.899635    0.176512    0.011303    0.682297     #> 470: -6.192971   0.188718    -5.879724   1.200862    2.058366    -1.579490   0.830859    2.387315    0.900616    0.176479    0.011320    0.682441     #> 471: -6.193860   0.188904    -5.879756   1.200866    2.058428    -1.579490   0.830858    2.387315    0.901429    0.176393    0.011322    0.682586     #> 472: -6.194394   0.189112    -5.879751   1.200867    2.058512    -1.579490   0.830858    2.387315    0.901913    0.176267    0.011336    0.682724     #> 473: -6.194880   0.189203    -5.879779   1.200865    2.058530    -1.579490   0.830858    2.387315    0.902779    0.176116    0.011348    0.682863     #> 474: -6.195162   0.189273    -5.879789   1.200862    2.058520    -1.579490   0.830858    2.387314    0.903560    0.175994    0.011358    0.683025     #> 475: -6.195068   0.189251    -5.879811   1.200874    2.058607    -1.579490   0.830858    2.387314    0.903593    0.176087    0.011375    0.683166     #> 476: -6.195441   0.189389    -5.879799   1.200874    2.058682    -1.579490   0.830858    2.387314    0.903494    0.176200    0.011377    0.683306     #> 477: -6.195697   0.189586    -5.879792   1.200875    2.058734    -1.579490   0.830859    2.387314    0.903958    0.176198    0.011371    0.683463     #> 478: -6.196177   0.189769    -5.879784   1.200883    2.058860    -1.579490   0.830859    2.387314    0.904497    0.176180    0.011381    0.683607     #> 479: -6.196587   0.189817    -5.879786   1.200890    2.058826    -1.579490   0.830859    2.387314    0.905260    0.175991    0.011377    0.683735     #> 480: -6.196811   0.189934    -5.879794   1.200889    2.058989    -1.579490   0.830859    2.387314    0.906125    0.175830    0.011400    0.683872     #> 481: -6.196594   0.189908    -5.879829   1.200891    2.059043    -1.579490   0.830859    2.387314    0.905836    0.175600    0.011407    0.684019     #> 482: -6.196842   0.189647    -5.879847   1.200890    2.059069    -1.579490   0.830859    2.387314    0.905986    0.175579    0.011407    0.684176     #> 483: -6.197460   0.189626    -5.879854   1.200888    2.059084    -1.579490   0.830859    2.387314    0.906125    0.175455    0.011418    0.684327     #> 484: -6.197804   0.189899    -5.879826   1.200892    2.059137    -1.579490   0.830859    2.387314    0.906452    0.175295    0.011429    0.684467     #> 485: -6.198453   0.190083    -5.879826   1.200894    2.059129    -1.579490   0.830859    2.387314    0.907069    0.175111    0.011430    0.684621     #> 486: -6.198856   0.190081    -5.879843   1.200900    2.059068    -1.579490   0.830859    2.387314    0.906844    0.174968    0.011431    0.684746     #> 487: -6.199473   0.190138    -5.879849   1.200903    2.059011    -1.579490   0.830859    2.387314    0.906948    0.174815    0.011440    0.684882     #> 488: -6.199854   0.190322    -5.879834   1.200903    2.058928    -1.579490   0.830859    2.387314    0.907097    0.174644    0.011455    0.685011     #> 489: -6.200131   0.190539    -5.879852   1.200900    2.058997    -1.579490   0.830859    2.387314    0.907821    0.174548    0.011457    0.685137     #> 490: -6.200349   0.190702    -5.879879   1.200905    2.059038    -1.579490   0.830859    2.387314    0.908038    0.174420    0.011470    0.685282     #> 491: -6.201074   0.190752    -5.879894   1.200905    2.059042    -1.579490   0.830860    2.387314    0.909186    0.174281    0.011480    0.685406     #> 492: -6.201215   0.190804    -5.879886   1.200901    2.059043    -1.579490   0.830860    2.387314    0.908662    0.174201    0.011505    0.685535     #> 493: -6.201787   0.190948    -5.879898   1.200904    2.058984    -1.579490   0.830860    2.387314    0.908998    0.174062    0.011514    0.685661     #> 494: -6.202129   0.191016    -5.879918   1.200907    2.059039    -1.579490   0.830860    2.387314    0.909021    0.174020    0.011517    0.685766     #> 495: -6.202744   0.191175    -5.879915   1.200911    2.059126    -1.579490   0.830860    2.387314    0.909702    0.174028    0.011519    0.685903     #> 496: -6.203025   0.191428    -5.879908   1.200903    2.059216    -1.579490   0.830860    2.387314    0.909762    0.174049    0.011513    0.686040     #> 497: -6.203383   0.191487    -5.879919   1.200903    2.059258    -1.579490   0.830860    2.387314    0.909814    0.174040    0.011509    0.686174     #> 498: -6.203699   0.191535    -5.879915   1.200896    2.059282    -1.579490   0.830860    2.387314    0.909695    0.173908    0.011511    0.686304     #> 499: -6.203989   0.191612    -5.879893   1.200889    2.059334    -1.579490   0.830860    2.387314    0.909469    0.173669    0.011505    0.686468     #> 500: -6.204474   0.191575    -5.879888   1.200884    2.059361    -1.579490   0.830860    2.387314    0.910054    0.173555    0.011493    0.686604     #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nimo.html","id":"goodness-of-fit-plots","dir":"Articles","previous_headings":"","what":"Goodness of fit Plots","title":"Nimotuzumab","text":"","code":"## Add cwres/npde after fit fit  <- fit %>% addCwres() %>% addNpde() #> [====|====|====|====|====|====|====|====|====|====] 0:00:02  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:03  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:01  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:01  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 plot(fit) ## Standard nlmixr plots ################################################################################ ## Xpose plots; Need to print otherwise running a script won't ## show xpose plots ################################################################################ xpdb <- xpose_data_nlmixr(fit) ## first convert to nlmixr object  print(dv_vs_pred(xpdb) +       ylab(\"Observed Nimotuzumab Concentrations (ug/mL)\") +       xlab(\"Population Predicted Nimotuzumab Concentrations (ug/mL)\")) print(dv_vs_ipred(xpdb) +       ylab(\"Observed Nimotuzumab Concentrations (ug/mL)\") +       xlab(\"Individual Predicted Nimotuzumab Concentrations (ug/mL)\")) print(res_vs_pred(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Population Predicted Nimotuzumab Concentrations (ug/mL)\")) print(res_vs_idv(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Time (h)\")) print(prm_vs_iteration(xpdb)) print(absval_res_vs_idv(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_pred(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Population Predicted Nimotuzumab Concentrations (ug/mL)\")) print(ind_plots(xpdb, nrow=3, ncol=4) +       ylab(\"Predicted and Observed Nimotuzumab concentrations (ug/mL)\") +       xlab(\"Time (h)\")) print(res_distrib(xpdb) +      ylab(\"Density\") +      xlab(\"Conditional Weighted Residuals\")) ################################################################################ ##Visual Predictive Checks ################################################################################ vpcPlot(fit,n=500,stratify=c(\"DOS\"), show=list(obs_dv=T),        bins = c(-0.5,0,25,75,100,200,400,600,750,900,1100,1200,1400,1600,1900,2150,2300),        ylab = \"Nimotuzumab Concentrations (ug/mL)\", xlab = \"Time (h)\") vpcPlot(fit,n=500, show=list(obs_dv=T),        bins = c(-0.5,0,25,75,100,200,400,600,750,900,1100,1200,1400,1600,1900,2150,2300),        ylab = \"Nimotuzumab Concentrations (ug/mL)\", xlab = \"Time (h)\")"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nlmixr2-team-and-advisory-committee.html","id":"the-nlmixr2-team","dir":"Articles","previous_headings":"","what":"The nlmixr2 team","title":"nlmixr2 team and advisory committee","text":"nlmixr2 team currently following members: Matt Fidler (Lead developer) Bill Denney John Harrold Richard Hooijmaijers Theodoros Papathanasiou Rik Schoemaker Mirjam Trame Justin Wilkins also following emeritus members: Wenping Wang (founder nlmixr) Teun Post Yuan Xiong Huijuan Xu","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nlmixr2-team-and-advisory-committee.html","id":"the-nlmixr2-advisory-committee","dir":"Articles","previous_headings":"","what":"The nlmixr2 advisory committee","title":"nlmixr2 team and advisory committee","text":"Paolo Denti Stephen Duffull Marc Gastonguay Lisa Hendricks Manuel Ibarra Mats Karlsson Joseph Standing","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"running-pk-models-with-nlmixr","dir":"Articles","previous_headings":"","what":"Running PK models with nlmixr","title":"Running PK models with nlmixr","text":"nlmixr uses unified interface specifying running models. Let’s start simple PK example, using single-dose theophylline dataset generously provided Dr. Robert . Upton University California, San Francisco: can try fitting simple one-compartment PK model small dataset. write model follows: can now run model… can alternatively express model ordinary differential equations (ODEs): can try Stochastic Approximation EM (SAEM) method model: wanted , even apply traditional R method nlme method model: example delivers complete model fit fit object, including parameter history, set fixed effect estimates, random effects included subjects.","code":"## Load libraries library(nlmixr2) str(theo_sd) #> 'data.frame':    144 obs. of  7 variables: #>  $ ID  : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ TIME: num  0 0 0.25 0.57 1.12 2.02 3.82 5.1 7.03 9.05 ... #>  $ DV  : num  0 0.74 2.84 6.57 10.5 9.66 8.58 8.36 7.47 6.89 ... #>  $ AMT : num  320 0 0 0 0 ... #>  $ EVID: int  101 0 0 0 0 0 0 0 0 0 ... #>  $ CMT : int  1 2 2 2 2 2 2 2 2 2 ... #>  $ WT  : num  79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 ... one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  f <- nlmixr(one.cmt) fit <- nlmixr(one.cmt, theo_sd, est=\"focei\",               control=list(print=0)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done print(fit) #> ── nlmixr² FOCEi (outer: nlminb) ── #>  #>           OBJF      AIC     BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.8096 373.4094 393.589      -179.7047        67.96527        9.332554 #>  #> ── Time (sec $time): ── #>  #>           setup optimize covariance table compress    other #> elapsed 0.01321  0.20955   0.209551 0.026     0.01 1.564689 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka 0.469  0.195 41.6        1.6 (1.09, 2.34)     70.0      1.40%  #> tcl       Log Cl  1.01 0.0751 7.43       2.75 (2.37, 3.18)     26.7      4.16%  #> tv         log V  3.46 0.0436 1.26       31.9 (29.2, 34.7)     14.2      11.1%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Information about run found ($runInfo): #>    • gradient problems with initial estimate and covariance; see $scaleInfo  #>    • ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.))  #>    • initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     relative convergence (4)  #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 20 #>   ID     TIME    DV      PRED    RES   WRES IPRED   IRES  IWRES    CPRED   CRES #>   <fct> <dbl> <dbl>     <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl>    <dbl>  <dbl> #> 1 1      0     0.74 -1.78e-15  0.740  1.06   0     0.74   1.06  5.64e-16  0.740 #> 2 1      0.25  2.84  3.27e+ 0 -0.431 -0.230  3.85 -1.01  -1.45  3.23e+ 0 -0.388 #> 3 1      0.57  6.57  5.84e+ 0  0.731  0.294  6.79 -0.215 -0.310 5.78e+ 0  0.786 #> # ℹ 129 more rows #> # ℹ 9 more variables: CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl> one.compartment <- function() {   ini({     tka <- 0.45 # Log Ka     tcl <- 1 # Log Cl     tv <- 3.45    # Log V     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     d/dt(depot) = -ka * depot     d/dt(center) = ka * depot - cl / v * center     cp = center / v     cp ~ add(add.sd)   }) } fit2 <- nlmixr(one.compartment, theo_sd,  est=\"saem\",                control=list(print=0)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 print(fit2) #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ── #>  #>            setup covariance  saem table compress    other #> elapsed 0.001272   0.009005 4.208 0.065    0.021 0.953723 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.454  0.196 43.1       1.57 (1.07, 2.31)     71.5   -0.0203%  #> tcl       Log Cl  1.02 0.0853  8.4       2.76 (2.34, 3.26)     27.6      3.46%  #> tv         Log V  3.45 0.0454 1.32       31.5 (28.8, 34.4)     13.4      9.89%  #> add.sd           0.693                               0.693                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 19 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    cp #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.103 -0.491 -0.0820  0    #> 2 1      0.25  2.84  3.27 -0.426  3.87 -1.03  -1.48   0.103 -0.491 -0.0820  3.87 #> 3 1      0.57  6.57  5.85  0.723  6.82 -0.246 -0.356  0.103 -0.491 -0.0820  6.82 #> # ℹ 129 more rows #> # ℹ 7 more variables: depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, #> #   tad <dbl>, dosenum <dbl> fitN <- nlmixr(one.compartment, theo_sd, list(pnlsTol=0.5), est=\"nlme\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> **Iteration 1 #> LME step: Loglik: -183.2083, nlminb iterations: 1 #> reStruct  parameters: #>       ID1       ID2       ID3  #> 0.2195819 0.9924330 1.6502972  #>  Beginning PNLS step: ..  completed fit_nlme() step. #> PNLS step: RSS =  64.59841  #>  fixed effects: 0.4443024  1.038584  3.449959   #>  iterations: 3  #> Convergence crit. (must all become <= tolerance = 1e-05): #>      fixed   reStruct  #> 0.03715048 0.91006943  #>  #> **Iteration 2 #> LME step: Loglik: -182.0743, nlminb iterations: 1 #> reStruct  parameters: #>       ID1       ID2       ID3  #> 0.1149602 0.9686071 1.6508466  #>  Beginning PNLS step: ..  completed fit_nlme() step. #> PNLS step: RSS =  64.59843  #>  fixed effects: 0.4443024  1.038584  3.449959   #>  iterations: 1  #> Convergence crit. (must all become <= tolerance = 1e-05): #>        fixed     reStruct  #> 0.000000e+00 5.047516e-06  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 print(fitN) #> ── nlmixr² nlme by maximum likelihood ── #>  #>          OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> nlme 121.5489 378.1487 398.3283      -182.0743        18.17386               1 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.001314 0.049    0.005 2.173686 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter   Est.      SE  %RSE Back-transformed(95%CI) BSV(CV%) #> tka       Log Ka 0.4443  0.1916 43.12     1.559 (1.071, 2.27)     68.7 #> tcl       Log Cl  1.039 0.08335 8.026    2.825 (2.399, 3.327)     27.0 #> tv         Log V   3.45 0.04494 1.303      31.5 (28.84, 34.4)     13.5 #> add.sd           0.6979                                0.6979          #>        Shrink(SD)% #> tka        -3.49%  #> tcl         7.85%  #> tv          7.29%  #> add.sd             #>   #>   Covariance Type ($covMethod): nlme #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 19 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    cp #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.06  0.0756 -0.483 -0.0896  0    #> 2 1      0.25  2.84  3.24 -0.401  3.78 -0.943 -1.35  0.0756 -0.483 -0.0896  3.78 #> 3 1      0.57  6.57  5.81  0.760  6.72 -0.146 -0.210 0.0756 -0.483 -0.0896  6.72 #> # ℹ 129 more rows #> # ℹ 7 more variables: depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, #> #   tad <dbl>, dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"the-ui","dir":"Articles","previous_headings":"","what":"The UI","title":"Running PK models with nlmixr","text":"nlmixr modeling dialect, inspired R NONMEM, can used fit models using current future estimation algorithms within nlmixr. Using widely-used tools inspiration advantage delivering model specification syntax instantly familiar majority analysts working pharmacometrics related fields.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"overall-model-structure","dir":"Articles","previous_headings":"The UI","what":"Overall model structure","title":"Running PK models with nlmixr","text":"Model specifications nlmixr written using functions containing ini model blocks. functions can called anything, often contain two components. Let’s look simple one-compartment model covariates.","code":"f <- function() {   ini({   # Initial conditions/variables     # are specified here   })   model({ # The model is specified     # here   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"the-ini-block","dir":"Articles","previous_headings":"The UI > Overall model structure","what":"The ini block","title":"Running PK models with nlmixr","text":"ini block specifies initial conditions, including initial estimates boundaries algorithms support (currently, built-nlme saem methods ). Nomenclature similar used NONMEM, Monolix similar packages. NONMEM world, ini block analogous $THETA, $OMEGA $SIGMA blocks. shown example: Simple parameter values specified using R-compatible assignment Boundaries may specified c(lower, est, upper). Like NONMEM, c(lower,est) equivalent c(lower,est,Inf) Also like NONMEM, c(est) specify lower bound, equivalent specifying parameter without using R’s c() function. parameters can named using almost R-compatible name. Please note : Residual error estimates coded population estimates (.e. using = <-, ~). Variable names start _ supported. Note R allow variable starting _ assigned without quoting . Naming variables start rx nlmixr suggested, since rxode2() nlmixr use prefixes internally certain estimation routines calculating residuals. Variable names case-sensitive, just like R. CL Cl. mixture models, multivariate normal individual deviations normal population parameters estimated (NONMEM called “ETA” parameters). Additionally, variance/covariance matrix deviations also estimated (NONMEM “OMEGA” matrix). also take initial estimates. nlmixr, specified ~ operator. typically used statistics R “modeled ”, chosen distinguish estimates population residual error parameters. Continuing prior example, can annotate estimates -subject error distribution… shown example: Simple variances specified variable name estimate separated ~ Correlated parameters specified sum variable labels lower triangular matrix covariance specified left handed side equation. also separated ~. initial estimates specified variance scale, analogy NONMEM, square roots diagonal elements correspond coefficients variation used exponential IIV implementation.","code":"f <- function() { # Note that arguments to the function are currently   # ignored by nlmixr   ini({     # Initial conditions for population parameters (sometimes     # called THETA parameters) are defined by either '<-' or '='     lCl <- 1.6      # log Cl (L/hr)          # Note that simple expressions that evaluate to a number are     # OK for defining initial conditions (like in R)     lVc = log(90)  # log V (L)          ## Also, note that a comment on a parameter is captured as a parameter label     lKa <- 1       # log Ka (1/hr)          # Bounds may be specified by c(lower, est, upper), like NONMEM:     # Residuals errors are assumed to be population parameters     prop.err <- c(0, 0.2, 1)          # IIV terms will be discussed in the next example   })      # The model block will be discussed later   model({}) } f <- function() {   ini({     lCl <- 1.6      ; label(\"log Cl (L/hr)\")     lVc = log(90)   ; label(\"log V (L)\")     lKa <- 1        ; label(\"log Ka (1/hr)\")     prop.err <- c(0, 0.2, 1)          # Initial estimate for ka IIV variance     # Labels work for single parameters     eta.ka ~ 0.1    ## BSV Ka      # For correlated parameters, you specify the names of each     # correlated parameter separated by a addition operator `+`     # and the left handed side specifies the lower triangular     # matrix initial of the covariance matrix.     eta.cl + eta.vc ~ c(0.1,                         0.005, 0.1)          # Note that labels do not currently work for correlated     # parameters.  Also, do not put comments inside the lower     # triangular matrix as this will currently break the model.   })      # The model block will be discussed later   model({}) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"the-model-block","dir":"Articles","previous_headings":"The UI > Overall model structure","what":"The model block","title":"Running PK models with nlmixr","text":"model block specifies model, analogous $PK, $PRED $ERROR blocks NONMEM. initialization block defined, can define model terms variables defined ini block. can also mix rxode2() blocks model needed. current method defining nlmixr model specify parameters, required rxode2() lines. Continuing annotated example: points note: Parameters defined differential equations. Currently directly defining differential equations terms population parameters supported. differential equations, parameters error terms single block, instead multiple sections. Additionally state names, calculated variables, also start either rx_ nlmixr_ since used internally estimation routines. Errors specified using tilde, ~. Currently can use either add(parameter) additive error, prop(parameter) proportional error add(parameter1) + prop(parameter2) combined additive proportional error. can also specify norm(parameter) additive error, since follows normal distribution. routines, like saem, require parameters expressed terms Pop.Parameter + Individual.Deviation.Parameter +   Covariate*Covariate.Parameter. order parameters matter. similar NONMEM’s mu-referencing, though restrictive. means saem, parameterization form Cl <- Cl*exp(eta.Cl) allowed. type parameter model determined ini block; covariates used model included ini block. variables need present modeling dataset model run.","code":"f <- function() {   ini({     lCl <- 1.6       # log Cl (L/hr)     lVc <- log(90)   # log Vc (L)     lKA <- 0.1       # log Ka (1/hr)     prop.err <- c(0, 0.2, 1)          eta.Cl ~ 0.1     # BSV Cl     eta.Vc ~ 0.1     # BSV Vc     eta.KA ~ 0.1     # BSV Ka   })   model({     # Parameters are defined in terms of the previously-defined     # parameter names:     Cl <- exp(lCl + eta.Cl)     Vc =  exp(lVc + eta.Vc)     KA <- exp(lKA + eta.KA)          # Next, the differential equations are defined:     kel <- Cl / Vc;          d/dt(depot)  = -KA*depot;     d/dt(centr)  =  KA*depot-kel*centr;          # And the concentration is then calculated     cp = centr / Vc;     # Finally, we specify that the plasma concentration follows     # a proportional error distribution (estimated by the parameter      # prop.err)     cp ~ prop(prop.err)   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"running-models","dir":"Articles","previous_headings":"The UI","what":"Running models","title":"Running PK models with nlmixr","text":"Models can fitted several ways, including via [magrittr] forward-pipe operator. Options estimation routines can specified using nlmeControl nlme estimation: options specified nlme documentation. Options saem can specified using saemControl: example specifies 250 burn-iterations, 350 em iterations print progress every 50 runs.","code":"fit <- nlmixr(one.compartment) %>% saem.fit(data=theo_sd) fit2 <- nlmixr(one.compartment, data=theo_sd, est=\"saem\") fit3 <- one.compartment %>% saem.fit(data=theo_sd) fit4 <- nlmixr(one.compartment, theo_sd,est=\"nlme\",control = nlmeControl(pnlsTol = .5)) fit5 <- nlmixr(one.compartment,theo_sd,est=\"saem\",control=saemControl(n.burn=250,n.em=350,print=50))"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"model-syntax-for-solved-pk-systems","dir":"Articles","previous_headings":"The UI","what":"Model Syntax for solved PK systems","title":"Running PK models with nlmixr","text":"Solved PK systems also currently supported nlmixr ‘linCmt()’ pseudo-function. annotated example solved system : things keep mind: solved systems implemented one, two three compartment models without first-order absorption. models support lag time tlag parameter. general linear compartment model figures model parameter names. nlmixr2 currently knows numbered volumes, Vc/Vp, Clearances terms Cl Q/CLD. Additionally nlmixr knows elimination micro-constants (ie K12). Mixing parameters models currently supported. --date information linCmt() models see rxode2 documentation.","code":"f <- function(){   ini({     lCl <- 1.6      ; label(\"log Cl (L/hr)\")     lVc <- log(90)  ; label(\"log Vc (L)\")     lKA <- 0.1      ; label(\"log Ka (1/hr)\")     prop.err <- c(0, 0.2, 1)     eta.Cl ~ 0.1   # BSV Cl     eta.Vc ~ 0.1   # BSV Vc     eta.KA ~ 0.1   # BSV Ka   })   model({     Cl <- exp(lCl + eta.Cl)     Vc = exp(lVc + eta.Vc)     KA <- exp(lKA + eta.KA)     ## Instead of specifying the ODEs, you can use     ## the linCmt() function to use the solved system.     ##     ## This function determines the type of PK solved system     ## to use by the parameters that are defined.  In this case     ## it knows that this is a one-compartment model with first-order     ## absorption.     linCmt() ~ prop(prop.err)   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"checking-model-syntax","dir":"Articles","previous_headings":"The UI","what":"Checking model syntax","title":"Running PK models with nlmixr","text":"specifying model syntax can check nlmixr interpreting correctly using nlmixr function . Using function can get: general gives information model (type solved system/rxode2()), initial estimates well code model block.","code":"nlmixr(f) #>  ── rxode2-based solved PK 1-compartment model with first-order absorption ──────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>      lCl      lVc      lKA prop.err  #>  1.60000  4.49981  0.10000  0.20000  #>  #> Omega ($omega):  #>        eta.Cl eta.Vc eta.KA #> eta.Cl    0.1    0.0    0.0 #> eta.Vc    0.0    0.1    0.0 #> eta.KA    0.0    0.0    0.1 #>  ── μ-referencing ($muRefTable): ──   #>   theta    eta level #> 1   lCl eta.Cl    id #> 2   lVc eta.Vc    id #> 3   lKA eta.KA    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         lCl <- 1.6 #>         label(\"log Cl (L/hr)\") #>         lVc <- 4.49980967033027 #>         label(\"log Vc (L)\") #>         lKA <- 0.1 #>         label(\"log Ka (1/hr)\") #>         prop.err <- c(0, 0.2, 1) #>         eta.Cl ~ 0.1 #>         eta.Vc ~ 0.1 #>         eta.KA ~ 0.1 #>     }) #>     model({ #>         Cl <- exp(lCl + eta.Cl) #>         Vc = exp(lVc + eta.Vc) #>         KA <- exp(lKA + eta.KA) #>         linCmt() ~ prop(prop.err) #>     }) #> }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/wbc.html","id":"fit-model-using-saem","dir":"Articles","previous_headings":"","what":"Fit model using saem","title":"Friberg myelosuppression model","text":"","code":"d3 <- read.csv(\"Simulated_WBC_pacl_ddmore_samePK_nlmixr.csv\", na.strings = \".\")  fit.S <- nlmixr(wbc, d3, est=\"saem\", list(print=0), table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:02  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 library(xpose.nlmixr2)  xpdb <- xpose_data_nlmixr(fit.S)  plot(fit.S) print(dv_vs_pred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(dv_vs_ipred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Individual Predicted Neutrophil Count (10^9/L)\")) print(res_vs_pred(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(res_vs_idv(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Time (h)\")) print(prm_vs_iteration(xpdb)) print(absval_res_vs_idv(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_pred(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(ind_plots(xpdb, nrow=3, ncol=4) +       ylab(\"Predicted and Observed Neutrophil Count (10^9/L)\") +       xlab(\"Time (h)\")) print(res_distrib(xpdb) +       ylab(\"Density\") +       xlab(\"Conditional Weighted Residuals\")) vpcPlot(fit.S, n=500, n_bins = 10, show=list(obs_dv=TRUE),         ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:04 vpcPlot(fit.S, n=500, bins = c(0,170,300,350,500,600,900,3000,4580),         show=list(obs_dv=TRUE), ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:04"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/wbc.html","id":"fit-model-using-focei","dir":"Articles","previous_headings":"","what":"Fit model using FOCEi","title":"Friberg myelosuppression model","text":"","code":"fit.F <- nlmixr(wbc, d3, est=\"focei\", list(print=0), table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:28  #> done #> [====|====|====|====|====|====|====|====|====|====] 0:00:02"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/wbc.html","id":"focei-goodness-of-fit-plots","dir":"Articles","previous_headings":"Fit model using FOCEi","what":"FOCEi goodness of fit plots","title":"Friberg myelosuppression model","text":"","code":"xpdb <- xpose_data_nlmixr(fit.F) plot(fit.F) print(dv_vs_pred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(dv_vs_ipred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Individual Predicted Neutrophil Count (10^9/L)\")) print(res_vs_pred(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(res_vs_idv(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_idv(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_pred(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(ind_plots(xpdb, nrow=3, ncol=4) +       ylab(\"Predicted and Observed Neutrophil Count (10^9/L)\") +       xlab(\"Time (h)\")) print(res_distrib(xpdb) +       ylab(\"Density\") +       xlab(\"Conditional Weighted Residuals\")) # 10 bins is slightly better than auto bin vpcPlot(fit.F, n=500, n_bins = 10, show=list(obs_dv=TRUE),         ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:04 # specify bins vpcPlot(fit.F, n=500, bins = c(0, 170, 300, 350, 500, 600, 900, 3000, 4580),         show=list(obs_dv=TRUE),         ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:04"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"load-the-data","dir":"Articles","previous_headings":"","what":"Load the data","title":"xgxr and ggPMX integration with nlmixr2","text":"","code":"pkpd_data <-   case1_pkpd %>%   arrange(DOSE) %>%   select(-IPRED) %>%   mutate(TRTACT_low2high = factor(TRTACT, levels = unique(TRTACT)),          TRTACT_high2low = factor(TRTACT, levels = rev(unique(TRTACT))),          DAY_label = paste(\"Day\", PROFDAY),          DAY_label = ifelse(DAY_label == \"Day 0\",\"Baseline\",DAY_label))   pk_data <- pkpd_data %>%   filter(CMT == 2)  pk_data_cycle1 <- pk_data %>%   filter(CYCLE == 1)"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"use-xgxr-for-simplified-concentration-over-time-colored-by-dose-mean---95-ci","dir":"Articles","previous_headings":"Exploratory analysis using ggplot and xgx helper functions","what":"Use xgxr for simplified concentration over time, colored by Dose, mean +/- 95% CI","title":"xgxr and ggPMX integration with nlmixr2","text":"Often exploring data worthwhile plot dose nominal time add 95% confidence interval. typical plot can cumbersome lack nice features xgxr can help . Note following helper functions: xgx_theme_set() sets theme black white color theme best practices xgxr. xgx_geom_ci() creates Confidence Interval mean plots simple interface. xgx_scale_y_log10() creates log-scale includes minor grids immediately show viewer plot semi-log plot without carefully examining y axis. xgx_scale_x_time_units() creates appropriate scale based times observed units use. also allows convert units easily right display. xgx_annote_status() adds DRAFT annotation often considered best practice data plots draft.  plot see mean concentrations confidence intervals stratified dose","code":"xgx_theme_set() # This uses black and white theme based on xgxr best                 # practices  # flag for labeling figures as draft status <- \"DRAFT\"  time_units_dataset <- \"hours\" time_units_plot    <- \"days\" trtact_label       <- \"Dose\" dose_label         <- \"Dose (mg)\" conc_label         <- \"Concentration (ng/ml)\"  auc_label          <- \"AUCtau (h.(ng/ml))\" concnorm_label     <- \"Normalized Concentration (ng/ml)/mg\" sex_label          <- \"Sex\" w100_label         <- \"WEIGHTB>100\" pd_label           <- \"FEV1 (mL)\" cens_label         <- \"Censored\"   ggplot(data = pk_data_cycle1, aes(x     = NOMTIME,                                   y     = LIDV,                                   group = DOSE,                                   color = TRTACT_high2low)) +     xgx_geom_ci(conf_level = 0.95) + # Easy CI with xgxr     xgx_scale_y_log10() + # semi-log plots with semi-log grid minor lines     xgx_scale_x_time_units(units_dataset = time_units_dataset,                            units_plot = time_units_plot) +     # The last line creates an appropriate x scale based on time-units     # and time unit scale     labs(y = conc_label, color = trtact_label) +     xgx_annotate_status(status) #  Adds draft status to plot"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"concentration-over-time-faceted-by-dose-mean---95-ci-overlaid-on-gray-spaghetti-plots","dir":"Articles","previous_headings":"Exploratory analysis using ggplot and xgx helper functions","what":"Concentration over time, faceted by Dose, mean +/- 95% CI, overlaid on gray spaghetti plots","title":"xgxr and ggPMX integration with nlmixr2","text":"useful look mean concentrations, often useful look mean concentrations relationship actual individual profiles. Using ggplot coupled xgxr helper functions used , can easily create plots well:  appears variability seems higher higher doses higher later times.","code":"ggplot(data = pk_data_cycle1, aes(x = TIME, y = LIDV)) +   geom_line(aes(group = ID), color = \"grey50\", linewidth = 1, alpha = 0.3) +   geom_cens(aes(cens=CENS)) +    xgx_geom_ci(aes(x = NOMTIME, color = NULL, group = NULL, shape = NULL), conf_level = 0.95) +   xgx_scale_y_log10() +   xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +   labs(y = conc_label, color = trtact_label) +   theme(legend.position = \"none\") +   facet_grid(.~TRTACT_low2high) +   xgx_annotate_status(status)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"exploring-the-dose-linearity","dir":"Articles","previous_headings":"Exploratory analysis using ggplot and xgx helper functions","what":"Exploring the dose linearity","title":"xgxr and ggPMX integration with nlmixr2","text":"common way explore dose linearity normalize dose. confidence intervals overlap, often dose linear example.  example seems dose-linear, exception censored data. can made even clear removing censored data plot:  lowest dose, censoring, one seems outlier. likely artifact censoring. ways explore data include looking normalized Cmax AUC values (skip vignette).","code":"ggplot(data = pk_data_cycle1,        aes(x = NOMTIME,            y = LIDV / as.numeric(as.character(DOSE)),            group = DOSE,            color = TRTACT_high2low)) +   xgx_geom_ci(conf_level = 0.95, alpha = 0.5, position = position_dodge(1)) +   xgx_scale_y_log10() +   xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +   labs(y = concnorm_label, color = trtact_label) +   xgx_annotate_status(status) ggplot(data = pk_data_cycle1 %>% filter(CENS == 0),        aes(x = NOMTIME,            y = LIDV / as.numeric(as.character(DOSE)),            group = DOSE,            color = TRTACT_high2low)) +   xgx_geom_ci(conf_level = 0.95, alpha = 0.5, position = position_dodge(1)) +   xgx_scale_y_log10() +   xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +   labs(y = concnorm_label, color = trtact_label) +   xgx_annotate_status(status)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"exploring-covariates-in-the-dataset","dir":"Articles","previous_headings":"","what":"Exploring Covariates in the dataset","title":"xgxr and ggPMX integration with nlmixr2","text":"Using xgx helper functions ggplot can explore effect high baseline weight. particular plot shown :  seems weight effect extreme either dose group","code":"ggplot(data = pk_data_cycle1, aes(x = NOMTIME,                                   y = LIDV,                                   group = WEIGHTB > 100,                                   color = WEIGHTB > 100)) +      xgx_geom_ci(conf_level = 0.95) +     xgx_scale_y_log10() +     xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +     facet_grid(.~DOSE) +     labs(y = conc_label, color = w100_label) +     xgx_annotate_status(status)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"summary-of-exploratory-analysis-findings","dir":"Articles","previous_headings":"Exploring Covariates in the dataset","what":"Summary of exploratory analysis findings","title":"xgxr and ggPMX integration with nlmixr2","text":"exploratory analysis see: - doses seem proportional - PK seems 2-compartment model - Censoring large effect PK data.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"fitting-the-data-with-nlmixr","dir":"Articles","previous_headings":"","what":"Fitting the data with nlmixr","title":"xgxr and ggPMX integration with nlmixr2","text":"First need subset PK data rename LIDV DV Next, purpose demonstration subset 7 patients per dose group): approach good demonstration, allows variety structural models applied quickly developing base model. full dataset can applied selected model make sure makes sense data. Next create 2 compartment model: Now parsing nlmixr model complete start compare models: Now run 3 different estimation methods, can compare results side--side Note additive proportional model additive component approach zero. comparing objective functions log-normal proportional models, proportional model lowest objective function value. (Since modeled log-normal without data transformation appropriate compare AIC/Objective function values)","code":"dat <-   case1_pkpd %>%   rename(DV=LIDV) %>%   filter(CMT %in% 1:2) %>%   filter(TRTACT != \"Placebo\") doses <- unique(dat$DOSE) nid <- 20 # 7 ids per dose group dat2 <-   dat %>%   group_by(DOSE) %>%   filter(ID %in% sort(unique(ID))[1:nid]) %>%   ungroup() ## Use 2 compartment model cmt2 <- function() {   ini({     lka <- log(0.1); label(\"Ka\")     lv <- log(10); label(\"Vc\")     lcl <- log(4); label(\"Cl\")     lq <- log(10); label(\"Q\")     lvp <- log(20); label(\"Vp\")      eta.ka ~ 0.01     eta.v ~ 0.1     eta.cl ~ 0.1     logn.sd = 10   })   model({     ka <- exp(lka + eta.ka)     cl <- exp(lcl + eta.cl)     v <- exp(lv + eta.v)     q <- exp(lq)     vp <- exp(lvp)     linCmt() ~ lnorm(logn.sd)   }) }  ## Check parsing cmt2m <- nlmixr(cmt2) print(cmt2m) #>  ── rxode2-based solved PK 2-compartment model with first-order absorption ──────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>       lka        lv       lcl        lq       lvp   logn.sd  #> -2.302585  2.302585  1.386294  2.302585  2.995732 10.000000  #>  #> Omega ($omega):  #>        eta.ka eta.v eta.cl #> eta.ka   0.01   0.0    0.0 #> eta.v    0.00   0.1    0.0 #> eta.cl   0.00   0.0    0.1 #>  ── μ-referencing ($muRefTable): ──   #>   theta    eta level #> 1   lka eta.ka    id #> 2   lcl eta.cl    id #> 3    lv  eta.v    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         lka <- -2.30258509299405 #>         label(\"Ka\") #>         lv <- 2.30258509299405 #>         label(\"Vc\") #>         lcl <- 1.38629436111989 #>         label(\"Cl\") #>         lq <- 2.30258509299405 #>         label(\"Q\") #>         lvp <- 2.99573227355399 #>         label(\"Vp\") #>         logn.sd <- c(0, 10) #>         eta.ka ~ 0.01 #>         eta.v ~ 0.1 #>         eta.cl ~ 0.1 #>     }) #>     model({ #>         ka <- exp(lka + eta.ka) #>         cl <- exp(lcl + eta.cl) #>         v <- exp(lv + eta.v) #>         q <- exp(lq) #>         vp <- exp(lvp) #>         linCmt() ~ lnorm(logn.sd) #>     }) #> } ## First try log-normal (since the variability seemed proportional to concentration) cmt2fit.logn <-   nlmixr(     cmt2m, data = dat2,     est = \"saem\",     control=list(print=0),      table=tableControl(cwres=TRUE, npde=TRUE)   ) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 ## Now try proportional cmt2fit.prop <-   cmt2fit.logn %>%   update(linCmt() ~ prop(prop.sd)) %>%   nlmixr(     est=\"saem\", control=list(print=0),     table=tableControl(npde=TRUE, cwres=TRUE)   ) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 ## now try add+prop cmt2fit.add.prop <-   cmt2fit.prop %>%   update(linCmt() ~ prop(prop.sd) + add(add.sd)) %>%   nlmixr(     est=\"saem\", control=list(print=0),      table=tableControl(npde=TRUE, cwres=TRUE)   ) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 library(huxtable)  huxreg(   \"lognormal\"=cmt2fit.logn,   \"proportional\"=cmt2fit.prop,   \"add+prop\"=cmt2fit.add.prop,   statistics=c(N=\"nobs\", \"logLik\", \"AIC\"),   stars = NULL )"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"model-diagnostics-with-ggpmx","dir":"Articles","previous_headings":"","what":"Model Diagnostics with ggPMX","title":"xgxr and ggPMX integration with nlmixr2","text":"creates two reports default settings, pdf word document. report can customized editing default template include project specificities (change labels, stratifications, filtering, etc.).    creates two reports default settings, pdf word document. report can customized editing default template include project specifics (change labels, stratification, filtering, etc.).","code":"## The controller then can be piped into a specific plot ctr <- pmx_nlmixr(cmt2fit.logn, conts = \"WEIGHTB\", cats=\"TRTACT\", vpc=TRUE) ctr %>% pmx_plot_npde_pred() ## Modify graphical options and remove DRAFT label: ctr %>%   pmx_plot_npde_time(     smooth = list(color=\"blue\"), point = list(shape=4), is.draft=FALSE,      labels = list(x = \"Time after first dose (days)\", y = \"Normalized PDE\")   ) ctr %>% pmx_plot_dv_ipred(scale_x_log10=TRUE, scale_y_log10=TRUE, filter=IPRED>0.001) ctr %>% pmx_plot_dv_pred(scale_x_log10=TRUE, scale_y_log10=TRUE, filter=IPRED>0.001) ctr %>% pmx_plot_abs_iwres_ipred() ctr %>%   pmx_plot_individual(     1,     filter= TIME > 0 & TIME < 48,     facets = list(nrow = 2, ncol = 2)   ) ctr %>% pmx_plot_iwres_dens() ctr %>% pmx_plot_eta_qq() ctr %>% pmx_plot_eta_box() ctr %>% pmx_plot_eta_hist() ctr %>% pmx_plot_eta_matrix()"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"simulation-of-a-new-scenario-with-rxode2","dir":"Articles","previous_headings":"","what":"Simulation of a new scenario with rxode2","title":"xgxr and ggPMX integration with nlmixr2","text":"creating events can simply simulate new scenario. Perhaps drug development team wants explore 100 mg dose 3 times day dosing see happens PK. can simply simulate nlmixr model using new event table created rxode2(). case wish simulate variability see happens steady state: nlmixr model already includes information parameter estimates can simulate without uncertainty population parameters covariances, like done VPC. wish simulate 100 patients repeated 100 different theoretical studies simulate uncertainty fixed parameter estimates covariances can easily nlmixr2/rxode2: may examine simulated study information easily, show rxode2() printout: can also see covariance matricies simulated (note come inverse Wishart distribution): also easy enough create plot see going simulation:   complex simulations variability can also simulate dosing windows sampling windows use tool want summarize way wish.","code":"# Start a new simulation ev <- et(amt=100, ii=8, ss=1) ev$add.sampling(seq(0, 8, length.out=50)) print(ev) #> ── EventTable with 51 records ── #> 1 dosing records (see $get.dosing(); add with add.dosing or et) #> 50 observation times (see $get.sampling(); add with add.sampling or et) #> ── First part of : ── #> # A tibble: 51 × 5 #>     time   amt    ii evid             ss #>    <dbl> <dbl> <dbl> <evid>        <int> #>  1 0        NA    NA 0:Observation    NA #>  2 0       100     8 1:Dose (Add)      1 #>  3 0.163    NA    NA 0:Observation    NA #>  4 0.327    NA    NA 0:Observation    NA #>  5 0.490    NA    NA 0:Observation    NA #>  6 0.653    NA    NA 0:Observation    NA #>  7 0.816    NA    NA 0:Observation    NA #>  8 0.980    NA    NA 0:Observation    NA #>  9 1.14     NA    NA 0:Observation    NA #> 10 1.31     NA    NA 0:Observation    NA #> # ℹ 41 more rows set.seed(100) sim1 <- rxSolve(cmt2fit.logn, ev, nSub=100, nStud=100) print(sim1) #> ── Solved rxode2 object ── #> ── Parameters ($params): ── #> # A tibble: 10,000 × 10 #>    sim.id   lka    lv   lcl    lq   lvp logn.sd  eta.ka    eta.v  eta.cl #>     <int> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>   <dbl>    <dbl>   <dbl> #>  1      1 -2.37  2.05  1.82  2.00  2.80    1.07  0.0115 -0.0107  -0.847  #>  2      2 -2.37  2.05  1.82  2.00  2.80    1.07  0.194  -0.0697  -0.651  #>  3      3 -2.37  2.05  1.82  2.00  2.80    1.07  0.156   0.390   -0.0146 #>  4      4 -2.37  2.05  1.82  2.00  2.80    1.07 -0.0461  0.00446  0.391  #>  5      5 -2.37  2.05  1.82  2.00  2.80    1.07  0.251  -0.264    0.252  #>  6      6 -2.37  2.05  1.82  2.00  2.80    1.07  0.165   0.253   -0.335  #>  7      7 -2.37  2.05  1.82  2.00  2.80    1.07 -0.0479 -0.114   -1.07   #>  8      8 -2.37  2.05  1.82  2.00  2.80    1.07 -0.0655 -0.820   -0.0410 #>  9      9 -2.37  2.05  1.82  2.00  2.80    1.07 -0.0117  0.287    0.218  #> 10     10 -2.37  2.05  1.82  2.00  2.80    1.07  0.168  -0.104    0.112  #> # ℹ 9,990 more rows #> ── Initial Conditions ($inits): ── #> named numeric(0) #>  #> Simulation with uncertainty in: #> • parameters ($thetaMat for changes) #> • omega matrix ($omegaList) #> • sigma matrix ($sigmaList) #>  #> ── First part of data (object): ── #> # A tibble: 500,000 × 9 #>   sim.id  time     ka    cl     v     q    vp ipredSim   sim #>    <int> <dbl>  <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl> <dbl> #> 1      1 0     0.0946  2.65  7.67  7.35  16.4     4.31  6.65 #> 2      1 0.163 0.0946  2.65  7.67  7.35  16.4     4.47  2.06 #> 3      1 0.327 0.0946  2.65  7.67  7.35  16.4     4.58 15.3  #> 4      1 0.490 0.0946  2.65  7.67  7.35  16.4     4.68 41.1  #> 5      1 0.653 0.0946  2.65  7.67  7.35  16.4     4.75  1.28 #> 6      1 0.816 0.0946  2.65  7.67  7.35  16.4     4.80  2.56 #> # ℹ 499,994 more rows head(sim1$thetaMat) #>              lka          lv         lcl          lq        lvp #> [1,] -0.08185950 -0.12747136 -0.01401328 -0.19834260 -0.2039910 #> [2,] -0.06325313 -0.13788637 -0.07355197  0.39646454 -0.2124947 #> [3,]  0.02719113  0.04279752  0.02012297 -0.13041034  0.2271712 #> [4,] -0.04482512 -0.13964879 -0.12688340  0.01159764 -0.2040580 #> [5,] -0.05921310  0.03727557 -0.20171452 -0.47452940 -0.1990387 #> [6,]  0.12180032  0.19929710  0.11656215  0.04746766  0.3845787 head(sim1$omegaList) #> [[1]] #>             eta.ka        eta.v       eta.cl #> eta.ka 0.012753101  0.001091743  0.005611709 #> eta.v  0.001091743  0.113187728 -0.021403817 #> eta.cl 0.005611709 -0.021403817  0.671377841 #>  #> [[2]] #>              eta.ka        eta.v       eta.cl #> eta.ka  0.013192573 -0.002407201  0.008154693 #> eta.v  -0.002407201  0.105115215 -0.026919657 #> eta.cl  0.008154693 -0.026919657  0.530291035 #>  #> [[3]] #>             eta.ka       eta.v      eta.cl #> eta.ka  0.01297879 -0.00541988  0.01049447 #> eta.v  -0.00541988  0.11909746 -0.02799901 #> eta.cl  0.01049447 -0.02799901  0.55595993 #>  #> [[4]] #>             eta.ka       eta.v      eta.cl #> eta.ka 0.010256283 0.002931796 0.005431144 #> eta.v  0.002931796 0.112131185 0.018322456 #> eta.cl 0.005431144 0.018322456 0.621125163 #>  #> [[5]] #>              eta.ka        eta.v      eta.cl #> eta.ka  0.012953569 -0.001709199 0.006299318 #> eta.v  -0.001709199  0.112763029 0.006084967 #> eta.cl  0.006299318  0.006084967 0.614363222 #>  #> [[6]] #>              eta.ka        eta.v       eta.cl #> eta.ka  0.011380171 -0.003698008  0.001783818 #> eta.v  -0.003698008  0.106754778 -0.030783628 #> eta.cl  0.001783818 -0.030783628  0.509223758 head(sim1$sigmaList) #> [[1]] #>                rxerr.rxLinCmt #> rxerr.rxLinCmt      0.9911237 #>  #> [[2]] #>                rxerr.rxLinCmt #> rxerr.rxLinCmt       1.028955 #>  #> [[3]] #>                rxerr.rxLinCmt #> rxerr.rxLinCmt       1.016967 #>  #> [[4]] #>                rxerr.rxLinCmt #> rxerr.rxLinCmt       1.024366 #>  #> [[5]] #>                rxerr.rxLinCmt #> rxerr.rxLinCmt      0.9737614 #>  #> [[6]] #>                rxerr.rxLinCmt #> rxerr.rxLinCmt       1.025798 conf <- confint(sim1, \"sim\")  p1 <- plot(conf) ## This returns a ggplot2 object  ## you can tweak the plot by the standard ggplot commands p1 +   xlab(\"Time (hr)\") +    ylab(\"Simulated Concentrations of TID steady state\") # And put the same plot on a semi-log plot p1 +   xlab(\"Time (hr)\") +    ylab(\"Simulated Concentrations of TID steady state\") +   xgx_scale_y_log10()"},{"path":"https://nlmixr2.github.io/nlmixr2/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Matthew Fidler. Author, maintainer. Yuan Xiong. Contributor. Rik Schoemaker. Contributor. Justin Wilkins. Contributor. Wenping Wang. Contributor. Mirjam Trame. Contributor. Huijuan Xu. Contributor. John Harrold. Contributor. Bill Denney. Contributor. Theodoros Papathanasiou. Contributor. Teun Post. Contributor. Richard Hooijmaijers. Contributor.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fidler M (????). nlmixr2: Nonlinear Mixed Effects Models Population PK/PD. R package version 2.1.2, https://github.com/nlmixr2/nlmixr2/, https://nlmixr2.org/. Fidler M, Wilkins J, Hooijmaijers R, Post T, Schoemaker R, Trame M, Xiong Y, Wang W (2019). “Nonlinear Mixed-Effects Model Development Simulation Using nlmixr Related R Open-Source Packages.” CPT: Pharmacometrics & Systems Pharmacology, 8(9), 621–633. https://doi.org/10.1002/psp4.12445. Schoemaker R, Fidler M, Laveille C, Wilkins J, Hooijmaijers R, Post T, Trame M, Xiong Y, Wang W (2019). “Performance SAEM FOCEI Algorithms Open-Source, Nonlinear Mixed Effect Modeling Tool nlmixr.” CPT: Pharmacometrics & Systems Pharmacology, 8(12), 923–930. https://doi.org/10.1002/psp4.12471.","code":"@Manual{,   title = {nlmixr2: Nonlinear Mixed Effects Models in Population PK/PD},   author = {Matthew Fidler},   note = {R package version 2.1.2, https://github.com/nlmixr2/nlmixr2/},   url = {https://nlmixr2.org/}, } @Article{,   title = {Nonlinear Mixed-Effects Model Development and Simulation Using nlmixr and Related R Open-Source Packages},   author = {Matthew Fidler and Justin Wilkins and Richard Hooijmaijers and Teun Post and Rik Schoemaker and Mirjam Trame and Yuan Xiong and Wenping Wang},   journal = {CPT: Pharmacometrics \\& Systems Pharmacology},   year = {2019},   volume = {8},   pages = {621--633},   number = {9},   month = {sep},   abstract = {nlmixr is a free and open-source R package for fitting nonlinear pharmacokinetic (PK), pharmacodynamic (PD), joint PK-PD, and quantitative systems pharmacology mixed-effects models. Currently, nlmixr is capable of fitting both traditional compartmental PK models as well as more complex models implemented using ordinary differential equations. We believe that, over time, it will become a capable, credible alternative to commercial software tools, such as NONMEM, Monolix, and Phoenix NLME.},   address = {Hoboken},   publisher = {John Wiley and Sons Inc.},   url = {https://doi.org/10.1002/psp4.12445}, } @Article{,   title = {Performance of the SAEM and FOCEI Algorithms in the Open-Source, Nonlinear Mixed Effect Modeling Tool nlmixr},   author = {Rik Schoemaker and Matthew Fidler and Christian Laveille and Justin Wilkins and Richard Hooijmaijers and Teun Post and Mirjam Trame and Yuan Xiong and Wenping Wang},   journal = {CPT: Pharmacometrics \\& Systems Pharmacology},   year = {2019},   volume = {8},   pages = {923--930},   number = {12},   month = {dec},   abstract = {The free and open-source package nlmixr implements pharmacometric nonlinear mixed effects model parameter estimation in R. It provides a uniform language to define pharmacometric models using ordinary differential equations. Performances of the stochastic approximation expectation-maximization (SAEM) and first order-conditional estimation with interaction (FOCEI) algorithms in nlmixr were compared with those found in the industry standards, Monolix and NONMEM, using the following two scenarios: a simple model fit to 500 sparsely sampled data sets and a range of more complex compartmental models with linear and nonlinear clearance fit to data sets with rich sampling. Estimation results obtained from nlmixr for FOCEI and SAEM matched the corresponding output from NONMEM/FOCEI and Monolix/SAEM closely both in terms of parameter estimates and associated standard errors. These results indicate that nlmixr may provide a viable alternative to existing tools for pharmacometric parameter estimation.},   url = {https://doi.org/10.1002/psp4.12471}, }"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"nlmixr2","dir":"","previous_headings":"","what":"Nonlinear Mixed Effects Models in Population PK/PD","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"vision nlmixr2 develop R-based open-source nonlinear mixed-effects modeling software package can compete commercial pharmacometric tools suitable regulatory submissions. short, goal nlmixr2 support easy robust nonlinear mixed effects models R. supported team advisory committee","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"blog-for-more-information","dir":"","previous_headings":"","what":"Blog for more information","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"information ongoing development, best practices, news nlmixr2, please see nlmixr2 blog.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"versions R, need compiler setup run nlmixr2 rxode2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"windows-compilation-tools-setup","dir":"","previous_headings":"Installation","what":"Windows compilation tools setup","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"Windows compilers come RTools. Download install version RTools version R https://cran.r-project.org/bin/windows/Rtools/","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"mac-compilation-tools-setup","dir":"","previous_headings":"Installation","what":"Mac compilation tools setup","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"setup mac compilers, simply Install Xcode app store Install gfortran: Download install https://mac.r-project.org/tools/ Add gfortran directory path : export     PATH=$PATH:/usr/local/gfortran/bin","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"r-package-installation","dir":"","previous_headings":"","what":"R package installation","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"Installation nlmixr2 easiest latest version R compilation required supporting packages available. R, run: R-4.0.x R-4.1.x, symengine package need downgraded run earlier R versions. can done : followed :","code":"install.packages(\"nlmixr2\",dependencies = TRUE) # install.packages(\"remotes\") remotes::install_version(\"symengine\", version = \"0.1.6\") install.packages(\"nlmixr2\",dependencies = TRUE)"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"checking-installation","dir":"","previous_headings":"","what":"Checking installation","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"can check installation likely setup correctly following command installing nlmixr2 package:","code":"nlmixr2::nlmixr2CheckInstall()"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"development-version-installation","dir":"","previous_headings":"","what":"Development version installation","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"compilers setup compatible version symengine installed, can install development version nlmixr2 nlmixr2-family dependencies either using r-universe installing manually.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"install-using-the-r-universe","dir":"","previous_headings":"Development version installation","what":"Install using the R universe","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"many people fastest way install development version nlmixr2 since provides binaries mac, windows latest last version R (need wait compile). using Ubuntu latest flavor (time writing jammy) can also use binaries (though use bspm install dependencies first reduce computation time) Support packages R universe can also installed packages nlmixr2 domain: Ubuntu latest similar","code":"install.packages(c(\"dparser\", \"nlmixr2data\", \"lotri\", \"rxode2ll\",                    \"rxode2parse\", \"rxode2random\", \"rxode2et\",                    \"rxode2\", \"nlmixr2est\", \"nlmixr2extra\", \"nlmixr2plot\",                    \"nlmixr2\"),                  repos = c('https://nlmixr2.r-universe.dev',                            'https://cloud.r-project.org')) # bspm::disable() # if you are using r2u or other ubuntu binary for CRAN oldOptions <- options()  options(repos=c(   linux = 'https://nlmixr2.r-universe.dev/bin/linux/jammy/4.2/',   sources = 'https://nlmixr2.r-universe.dev',   cran = 'https://cloud.r-project.org' )) install.packages(c(\"dparser\", \"nlmixr2data\", \"lotri\", \"rxode2ll\",                    \"rxode2parse\", \"rxode2random\", \"rxode2et\",                    \"rxode2\", \"nlmixr2est\", \"nlmixr2extra\", \"nlmixr2plot\",                    \"nlmixr2\"))  options(oldOptions) #bspm::enable() install.packages(c(\"xpose.nlmixr2\", # Additional goodness of fit plots                                     # baesd on xpose                    \"nlmixr2targets\", # Simplify work with the                                      # `targets` package                    \"babelmixr2\", # Convert/run from nlmixr2-based                                  # models to NONMEM, Monolix, and                                  # initialize models with PKNCA                    \"nonmem2rx\", # Convert from NONMEM to                                 # rxode2/nlmixr2-based models                    \"nlmixr2lib\", # a model library and model                                  # modification functions that                                  # complement model piping                    \"nlmixr2rpt\" # Automated Microsoft Word and                                 # PowerPoint reporting for nlmixr2                    ),                  repos = c('https://nlmixr2.r-universe.dev',                            'https://cloud.r-project.org'))  # Some additional packages outside of the `nlmixr2.r-univers.dev` # install.packages(\"remotes\") remotes::install_github(\"ggPMXdevelopment/ggPMX\") # Goodness of fit plots remotes::install_github(\"RichardHooijmaijers/shinyMixR\") # Shiny run manager (like Piranha) # bspm::disable() # if you are using r2u or other ubuntu binary for CRAN oldOptions <- options()  options(repos=c(   linux = 'https://nlmixr2.r-universe.dev/bin/linux/jammy/4.2/',   sources = 'https://nlmixr2.r-universe.dev',   cran = 'https://cloud.r-project.org' )) install.packages(c(\"xpose.nlmixr2\", \"nlmixr2targets\", \"babelmixr2\", \"nonmem2rx\", \"nlmixr2lib\", \"nlmixr2rpt\"))  options(oldOptions) #bspm::enable() # install.packages(\"remotes\") remotes::install_github(\"ggPMXdevelopment/ggPMX\") # Goodness of fit plots remotes::install_github(\"RichardHooijmaijers/shinyMixR\") # Shiny run manager (like Piranha)"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"install-using-remotes","dir":"","previous_headings":"Development version installation","what":"Install using remotes","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"sure give latest development version Optional supporting packages can installed like :","code":"# install.packages(\"remotes\") remotes::install_github(\"nlmixr2/dparser-R\") remotes::install_github(\"nlmixr2/nlmixr2data\") remotes::install_github(\"nlmixr2/lotri\") remotes::install_github(\"nlmixr2/rxode2ll\") remotes::install_github(\"nlmixr2/rxode2parse\") remotes::install_github(\"nlmixr2/rxode2random\") remotes::install_github(\"nlmixr2/rxode2et\") remotes::install_github(\"nlmixr2/rxode2\") remotes::install_github(\"nlmixr2/nlmixr2est\") remotes::install_github(\"nlmixr2/nlmixr2extra\") remotes::install_github(\"nlmixr2/nlmixr2plot\") remotes::install_github(\"nlmixr2/nlmixr2\") # install.packages(\"remotes\") # Goodness of fit plots remotes::install_github(\"ggPMXdevelopment/ggPMX\") # Additional goodness of fit plots remotes::install_github(\"nlmixr2/xpose.nlmixr2\") # Shiny run manager (like Piranha) remotes::install_github(\"RichardHooijmaijers/shinyMixR\") # Simplify work with the `targets` package remotes::install_github(\"nlmixr2/nlmixr2targets\") # Convert/run from nlmixr2-based models to NONMEM, Monolix, and initialize # models with PKNCA remotes::install_github(\"nlmixr2/babelmixr2\") # Convert from NONMEM to rxode2/nlmixr2-based models remotes::install_github(\"nlmixr2/nonmem2rx\") # A library of models and model modification functions remotes::install_github(\"nlmixr2/nlmixr2lib\") # Automated Microsoft Word and PowerPoint reporting for nlmixr2 remotes::install_github(\"nlmixr2/nlmixr2rpt\")"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"refreshing-the-installation-with-the-latest-cran-version","dir":"","previous_headings":"Development version installation","what":"Refreshing the installation with the latest CRAN version","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"difficulties due errors compiling models, may useful re-install nlmixr2 dependencies. development versions, please use remotes::install_github() install.package() r-universe . stable version, please use following command:","code":"install.packages(c(\"dparser\", \"lotri\", \"rxode2ll\", \"rxode2parse\",                    \"rxode2random\", \"rxode2et\", \"rxode2\",                    \"nlmixr2data\", \"nlmixr2est\", \"nlmixr2extra\",                    \"nlmixr2plot\", \"nlmixr2\"))"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"basic example shows solve common problem:","code":"library(nlmixr2)  ## The basic model consists of an ini block that has initial estimates one.compartment <- function() {   ini({     tka <- log(1.57); label(\"Ka\")     tcl <- log(2.72); label(\"Cl\")     tv <- log(31.5); label(\"V\")     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   # and a model block with the error specification and model specification   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     d/dt(depot) <- -ka * depot     d/dt(center) <- ka * depot - cl / v * center     cp <- center / v     cp ~ add(add.sd)   }) }  ## The fit is performed by the function nlmixr/nlmixr2 specifying the model, data and estimate fit <- nlmixr2(one.compartment, theo_sd,  est=\"saem\", saemControl(print=0)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 print(fit) #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ── #>  #>            setup covariance  saem table compress    other #> elapsed 0.000891   0.020004 2.792 0.043    0.017 2.397105 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka  0.46  0.196 42.7       1.58 (1.08, 2.33)     71.9    -0.291%  #> tcl           Cl  1.01 0.0839 8.29       2.75 (2.34, 3.25)     27.0      3.42%  #> tv             V  3.45 0.0469 1.36       31.6 (28.8, 34.7)     14.0      10.7%  #> add.sd           0.694                               0.694                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 19 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    cp #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07  0.0988 -0.484 -0.0843  0    #> 2 1      0.25  2.84  3.27 -0.433  3.87 -1.03  -1.49  0.0988 -0.484 -0.0843  3.87 #> 3 1      0.57  6.57  5.85  0.718  6.82 -0.247 -0.356 0.0988 -0.484 -0.0843  6.82 #> # ℹ 129 more rows #> # ℹ 7 more variables: depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, #> #   tad <dbl>, dosenum <dbl>"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"base-r-graphics","dir":"","previous_headings":"","what":"Base R Graphics","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"can use built-plot fit produce standard set goodness fit plots:","code":"pdf(file=\"myplots.pdf\") plot(fit) dev.off()"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"xposenlmixr2","dir":"","previous_headings":"","what":"xpose.nlmixr2","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"{xpose.nlmixr2} package extends xpose support nlmixr2. simply need convert fit results xpose database: can use xpose functions generating goodness fit plots:","code":"library(xpose.nlmixr2) xpdb = xpose_data_nlmixr(fit) library(xpose) plt <- dv_vs_ipred(xpdb)"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"ggpmx","dir":"","previous_headings":"","what":"ggPMX","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"Another option use ggPMX package. first create ggPMX controller object nlmixr fit object. controller object can used generate figures:","code":"library(ggPMX) ctr = pmx_nlmixr(fit) pmx_plot_dv_ipred(ctr)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":null,"dir":"Reference","previous_headings":"","what":"Add CWRES — addCwres","title":"Add CWRES — addCwres","text":"returns new fit object CWRES attached","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add CWRES — addCwres","text":"","code":"addCwres(fit, focei = TRUE, updateObject = TRUE, envir = parent.frame(1))"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add CWRES — addCwres","text":"fit nlmixr2 fit without WRES/CWRES focei Boolean indicating focei objective function added.  foce objective function added. updateObject Boolean indicating original fit object updated. default true. envir Environment checked object update.  default global environment.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add CWRES — addCwres","text":"fit CWRES","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add CWRES — addCwres","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add CWRES — addCwres","text":"","code":"# \\donttest{  one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Log Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  f <- try(nlmixr2(one.cmt, theo_sd, \"saem\")) #>   #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ℹ calculate uninformed etas #> ℹ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd #> rxode2 2.1.3.9000 using 2 threads (see ?getRxThreads) #>   no cache: create with `rxCreateCache()` #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHistData in nlmixr2 object, save 13816 #> → compress saem0 in nlmixr2 object, save 26032  print(f) #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ── #>  #>           setup covariance  saem table compress    other #> elapsed 0.00115   0.008005 1.818 0.088    0.018 2.317845 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 16 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # ℹ 129 more rows #> # ℹ 4 more variables: cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl>  # even though you may have forgotten to add the cwres, you can add it to the data.frame:  if (!inherits(f, \"try-error\")) {   f <- try(addCwres(f))   print(f) } #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(η) #> → calculate ∂(R²)/∂(η) #> → finding duplicate expressions in inner model... #> → optimizing duplicate expressions in inner model... #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling inner model... #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ✔ done #> → finding duplicate expressions in FD model... #> → compiling EBE model... #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ✔ done #> → compiling events FD model... #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ✔ done #> → Calculating residuals/tables #> ✔ done #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> FOCEi 116.9949 373.5947 393.7743      -179.7973        18.15903        1.404028 #>  #> ── Time (sec $time): ── #>  #>           setup covariance  saem table compress    other #> elapsed 0.00115   0.008005 1.818 0.088    0.018 2.317845 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 20 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # ℹ 129 more rows #> # ℹ 8 more variables: cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl>, WRES <dbl>, #> #   CPRED <dbl>, CRES <dbl>, CWRES <dbl>  # Note this also adds the FOCEi objective function # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":null,"dir":"Reference","previous_headings":"","what":"NPDE calculation for nlmixr2 — addNpde","title":"NPDE calculation for nlmixr2 — addNpde","text":"NPDE calculation nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NPDE calculation for nlmixr2 — addNpde","text":"","code":"addNpde(   object,   updateObject = TRUE,   table = tableControl(),   ...,   envir = parent.frame(1) )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NPDE calculation for nlmixr2 — addNpde","text":"object nlmixr2 fit object updateObject Boolean indicating original object updated.  default TRUE. table `tableControl()` list options ... Additional arguments passed nlmixr2est::addNpde(). envir Environment checked object update.  default global environment.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NPDE calculation for nlmixr2 — addNpde","text":"New nlmixr2 fit object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"NPDE calculation for nlmixr2 — addNpde","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"NPDE calculation for nlmixr2 — addNpde","text":"","code":"# \\donttest{  one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Log Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  f <- nlmixr2(one.cmt, theo_sd, \"saem\") #>   #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ℹ calculate uninformed etas #> ℹ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHistData in nlmixr2 object, save 13816 #> → compress saem0 in nlmixr2 object, save 26672  # even though you may have forgotten to add the NPDE, you can add it to the data.frame:  f <- addNpde(f) #> → Add NPDE #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ✔ done  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Add table information to nlmixr2 fit object without tables — addTable","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"Add table information nlmixr2 fit object without tables","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"","code":"addTable(   object,   updateObject = FALSE,   data = object$dataSav,   thetaEtaParameters = object$foceiThetaEtaParameters,   table = tableControl(),   keep = NULL,   drop = NULL,   envir = parent.frame(1) )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"object nlmixr2 family objects updateObject Update object (default FALSE) data Saved data thetaEtaParameters Internal theta/eta parameters table `tableControl()` list options keep Character Vector items keep drop Character Vector items drop NULL envir Environment search updating","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"Fit table information attached","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"Matthew Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"","code":"# \\donttest{  one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Log Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  # run without tables step f <- nlmixr2(one.cmt, theo_sd, \"saem\", control=list(calcTables=FALSE)) #>   #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> ℹ calculate uninformed etas #> ℹ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHistData in nlmixr2 object, save 13816 #> → compress saem0 in nlmixr2 object, save 27848  print(f) #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ── #>  #>            setup covariance saem compress    other #> elapsed 0.001068   0.006004 1.34    0.019 1.151928 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring  # Now add the tables  f <- addTable(f) #> → Calculating residuals/tables #> ✔ done  print(f) #> ── nlmixr² SAEM OBJF by FOCEi approximation ── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ── #>  #>            setup covariance saem compress    other #> elapsed 0.001068   0.006004 1.34    0.019 1.151928 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 132 × 16 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # ℹ 129 more rows #> # ℹ 4 more variables: cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl>  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bobyqaControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control for bobyqa estimation method in nlmixr2 — bobyqaControl","title":"Control for bobyqa estimation method in nlmixr2 — bobyqaControl","text":"Control bobyqa estimation method nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bobyqaControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control for bobyqa estimation method in nlmixr2 — bobyqaControl","text":"","code":"bobyqaControl(   npt = NULL,   rhobeg = NULL,   rhoend = NULL,   iprint = 0L,   maxfun = 100000L,   returnBobyqa = FALSE,   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bobyqaControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control for bobyqa estimation method in nlmixr2 — bobyqaControl","text":"npt number points used approximate objective function via quadratic approximation. value npt must interval [n+2,(n+1)(n+2)/2] n number parameters `par`. Choices exceed 2*n+1 recommended.  defined, set min(n * 2, n+2). rhobeg `rhobeg` `rhoend` must set initial final values trust region radius, must positive `0 < rhoend < rhobeg`. Typically `rhobeg` one tenth greatest expected change variable.  user provide value, set `min(0.95, 0.2 * max(abs(par)))`.  Note also smallest difference `abs(upper-lower)` greater equal `rhobeg*2`. case `rhobeg` adjusted. rhoend smallest value trust region radius allowed. defined, 1e-6 times value set `rhobeg` used. iprint value `iprint` set integer value `0, 1, 2, 3, ...`, controls amount printing.  Specifically, output `iprint=0` output start return `iprint=1`. Otherwise, new value `rho` printed, best vector variables far corresponding value objective function. , new value objective function variables output `iprint=3`.  `iprint > 3`, objective function value corresponding variables output every `iprint` evaluations.  Default value `0`. maxfun maximum allowed number function evaluations. exceeded, method terminate. returnBobyqa return bobyqa output instead nlmixr2 fit stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::bobyqaControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bobyqaControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control for bobyqa estimation method in nlmixr2 — bobyqaControl","text":"bobqya control structure","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bobyqaControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control for bobyqa estimation method in nlmixr2 — bobyqaControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bobyqaControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control for bobyqa estimation method in nlmixr2 — bobyqaControl","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"bobyqa\") #>   #>   #>   #>   #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → loading llik model into symengine environment... #> → finding duplicate expressions in population log-likelihood model... #> → optimizing duplicate expressions in population log-likelihood model... #> ✔ done #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9112 #> → compress parHistData in nlmixr2 object, save 13456  print(fit2) #> ── nlmixr² log-likelihood bobyqa ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -686.7649 1157.112 1171.835      -575.5561        1260.208        108.0744 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.002224 0.037    0.012 2.133776 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.     SE  %RSE  Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.6063 0.2264 37.33 -0.6063 (-1.05, -0.1627)                     #> Em    6.905  4.445 64.38    6.905 (-1.807, 15.62)                     #> E50   3.536  1.864  52.7   3.536 (-0.1162, 7.189)                     #> g         2  FIXED FIXED                        2                     #>   #>   Covariance Type ($covMethod): r #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0304     0 -0.435 -0.606 #> 2 1     0.0320     1 -1.04  -0.606 #> 3 1     0.0329     1 -1.04  -0.606 #> # ℹ 997 more rows  # you can also get the nlm output with  fit2$bobyqa #> parameter estimates: -0.606323594615133, 6.90508042704782, 3.53639314998716  #> objective: 575.556073649054  #> number of function evaluations: 211   # The nlm control has been modified slightly to include # extra components and name the parameters # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce delta objective function for boostrap — bootplot","title":"Produce delta objective function for boostrap — bootplot","text":"Produce delta objective function boostrap","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce delta objective function for boostrap — bootplot","text":"","code":"bootplot(x, ...)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce delta objective function for boostrap — bootplot","text":"x fit object ... Additional arguments passed nlmixr2extra::bootplot().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce delta objective function for boostrap — bootplot","text":"Fit traceplot nothing.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootplot.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Produce delta objective function for boostrap — bootplot","text":"R Niebecker,  MO Karlsson. (2013) datasets NLME models large enough bootstrap provide reliable parameter uncertainty distributions? PAGE 2013. https://www.page-meeting.org/?abstract=2899","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce delta objective function for boostrap — bootplot","text":"Vipul Mann,  Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootstrapFit.html","id":null,"dir":"Reference","previous_headings":"","what":"Bootstrap nlmixr2 fit — bootstrapFit","title":"Bootstrap nlmixr2 fit — bootstrapFit","text":"Bootstrap input dataset rerun model get confidence bounds aggregated parameters","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootstrapFit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Bootstrap nlmixr2 fit — bootstrapFit","text":"","code":"bootstrapFit(   fit,   nboot = 200,   nSampIndiv,   stratVar,   stdErrType = c(\"perc\", \"sd\", \"se\"),   ci = 0.95,   pvalues = NULL,   restart = FALSE,   plotHist = FALSE,   fitName = as.character(substitute(fit)) )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootstrapFit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Bootstrap nlmixr2 fit — bootstrapFit","text":"fit nlmixr2 fit object nboot integer giving number bootstrapped models fit; default value 200 nSampIndiv integer specifying number samples bootstrapped sample; default number unique subjects original dataset stratVar Variable original dataset stratify ; useful distinguish sparse full sampling features may wish keep distinct bootstrap stdErrType gives standard error type updated standard errors; current possibilities : \"perc\" gives standard errors percentiles (default), \"sd\" gives standard errors using normal approximation mean standard devaition, \"se\" uses normal approximation standard errors calculated nSampIndiv ci Confidence interval level calculate.  Default 0.95 95 percent confidence interval pvalues vector pvalues indicating probability subject get selected; default value NULL implying probability subject restart boolean try restart interrupted incomplete boostrap.  default FALSE plotHist boolean indicating histogram plot assess well bootstrap .  default turned (FALSE) fitName fit name used name boostrap files.  default fit provided though something else.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootstrapFit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Bootstrap nlmixr2 fit — bootstrapFit","text":"Nothing, called side effects; original fit updated bootstrap confidence bands","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootstrapFit.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Bootstrap nlmixr2 fit — bootstrapFit","text":"Vipul Mann, Matthew Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/bootstrapFit.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Bootstrap nlmixr2 fit — bootstrapFit","text":"","code":"if (FALSE) { one.cmt <- function() {   ini({     tka <- 0.45; label(\"Ka\")     tcl <- 1; label(\"Cl\")     tv <- 3.45; label(\"V\")     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  fit <- nlmixr2(one.cmt, nlmixr2data::theo_sd, est = \"saem\", control = list(print = 0))  withr::with_tempdir({ # Run example in temp dir  bootstrapFit(fit, nboot = 5, restart = TRUE) # overwrites any of the existing data or model files bootstrapFit(fit, nboot = 7) # resumes fitting using the stored data and model files  # Note this resumes because the total number of bootstrap samples is not 10  bootstrapFit(fit, nboot=10)  # Note the boostrap standard error and variance/covariance matrix is retained. # If you wish to switch back you can change the covariance matrix by  nlmixr2est::setCov(fit, \"linFim\")  # And change it back again  nlmixr2est::setCov(fit, \"boot10\")  # This change will affect any simulations with uncertainty in their parameters  # You may also do a chi-square diagnostic plot check for the bootstrap with bootplot(fit) }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/covarSearchAuto.html","id":null,"dir":"Reference","previous_headings":"","what":"Stepwise Covariate Model-selection (SCM) method — covarSearchAuto","title":"Stepwise Covariate Model-selection (SCM) method — covarSearchAuto","text":"Stepwise Covariate Model-selection (SCM) method","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/covarSearchAuto.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Stepwise Covariate Model-selection (SCM) method — covarSearchAuto","text":"","code":"covarSearchAuto(   fit,   varsVec,   covarsVec,   pVal = list(fwd = 0.05, bck = 0.01),   catvarsVec = NULL,   searchType = c(\"scm\", \"forward\", \"backward\"),   restart = FALSE )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/covarSearchAuto.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Stepwise Covariate Model-selection (SCM) method — covarSearchAuto","text":"fit nlmixr2 'fit' object varsVec list candidate variables covariates added covarsVec list candidate covariates need tested pVal named list names 'fwd' 'bck' specifying p-values forward backward searches, respectively catvarsVec character vector categorical covariates need added searchType one 'scm', 'forward' 'backward' specify covariate search method; default 'scm' restart boolean controls search restarted; default FALSE","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/covarSearchAuto.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Stepwise Covariate Model-selection (SCM) method — covarSearchAuto","text":"list summarizing covariate selection steps output; list \"summaryTable\" overall summary covariate selection well \"resFwd\" forward selection method \"resBck\" backward selection method.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/covarSearchAuto.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Stepwise Covariate Model-selection (SCM) method — covarSearchAuto","text":"Vipul Mann, Matthew Fidler, Vishal Sarsani","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/covarSearchAuto.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Stepwise Covariate Model-selection (SCM) method — covarSearchAuto","text":"","code":"if (FALSE) { one.cmt <- function() {   ini({     tka <- 0.45; label(\"Ka\")     tcl <- log(c(0, 2.7, 100)); label(\"Cl\")     tv <- 3.45; label(\"V\")     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  fit <- nlmixr2(one.cmt, nlmixr2data::theo_sd, est = \"saem\", control = list(print = 0)) rxode2::.rxWithWd(tempdir(), {# with temporary directory  auto1 <- covarSearchAuto(fit, varsVec = c(\"ka\", \"cl\"),     covarsVec = c(\"WT\"))  })  ## Note that this didn't include sex, add it to dataset and restart model   d <- nlmixr2data::theo_sd d$SEX <-0 d$SEX[d$ID<=6] <-1  fit <- nlmixr2(one.cmt, d, est = \"saem\", control = list(print = 0))  # This would restart if for some reason the search crashed:  rxode2::.rxWithWd(tempdir(), {# with temporary directory  auto2 <- covarSearchAuto(fit, varsVec = c(\"ka\", \"cl\"), covarsVec = c(\"WT\"),                 catvarsVec= c(\"SEX\"), restart = TRUE)  auto3 <- covarSearchAuto(fit, varsVec = c(\"ka\", \"cl\"), covarsVec = c(\"WT\"),                 catvarsVec=  c(\"SEX\"), restart = TRUE,                 searchType = \"forward\") }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Options for FOCEi — foceiControl","title":"Control Options for FOCEi — foceiControl","text":"Control Options FOCEi","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Options for FOCEi — foceiControl","text":"","code":"foceiControl(   sigdig = 3,   ...,   epsilon = NULL,   maxInnerIterations = 1000,   maxOuterIterations = 5000,   n1qn1nsim = NULL,   print = 1L,   printNcol = floor((getOption(\"width\") - 23)/12),   scaleTo = 1,   scaleObjective = 0,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleC0 = 1e+05,   derivEps = rep(20 * sqrt(.Machine$double.eps), 2),   derivMethod = c(\"switch\", \"forward\", \"central\"),   derivSwitchTol = NULL,   covDerivMethod = c(\"central\", \"forward\"),   covMethod = c(\"r,s\", \"r\", \"s\", \"\"),   hessEps = (.Machine$double.eps)^(1/3),   hessEpsLlik = (.Machine$double.eps)^(1/3),   optimHessType = c(\"central\", \"forward\"),   optimHessCovType = c(\"central\", \"forward\"),   eventType = c(\"central\", \"forward\"),   centralDerivEps = rep(20 * sqrt(.Machine$double.eps), 2),   lbfgsLmm = 7L,   lbfgsPgtol = 0,   lbfgsFactr = NULL,   eigen = TRUE,   addPosthoc = TRUE,   diagXform = c(\"sqrt\", \"log\", \"identity\"),   sumProd = FALSE,   optExpression = TRUE,   literalFix = TRUE,   ci = 0.95,   useColor = crayon::has_color(),   boundTol = NULL,   calcTables = TRUE,   noAbort = TRUE,   interaction = TRUE,   cholSEtol = (.Machine$double.eps)^(1/3),   cholAccept = 0.001,   resetEtaP = 0.15,   resetThetaP = 0.05,   resetThetaFinalP = 0.15,   diagOmegaBoundUpper = 5,   diagOmegaBoundLower = 100,   cholSEOpt = FALSE,   cholSECov = FALSE,   fo = FALSE,   covTryHarder = FALSE,   outerOpt = c(\"nlminb\", \"bobyqa\", \"lbfgsb3c\", \"L-BFGS-B\", \"mma\", \"lbfgsbLG\", \"slsqp\",     \"Rvmmin\"),   innerOpt = c(\"n1qn1\", \"BFGS\"),   rhobeg = 0.2,   rhoend = NULL,   npt = NULL,   rel.tol = NULL,   x.tol = NULL,   eval.max = 4000,   iter.max = 2000,   abstol = NULL,   reltol = NULL,   resetHessianAndEta = FALSE,   stateTrim = Inf,   shi21maxOuter = 0L,   shi21maxInner = 20L,   shi21maxInnerCov = 20L,   shi21maxFD = 20L,   gillK = 10L,   gillStep = 4,   gillFtol = 0,   gillRtol = sqrt(.Machine$double.eps),   gillKcov = 10L,   gillKcovLlik = 10L,   gillStepCovLlik = 4.5,   gillStepCov = 2,   gillFtolCov = 0,   gillFtolCovLlik = 0,   rmatNorm = TRUE,   rmatNormLlik = TRUE,   smatNorm = TRUE,   smatNormLlik = TRUE,   covGillF = TRUE,   optGillF = TRUE,   covSmall = 1e-05,   adjLik = TRUE,   gradTrim = Inf,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   gradCalcCentralSmall = 1e-04,   gradCalcCentralLarge = 10000,   etaNudge = qnorm(1 - 0.05/2)/sqrt(3),   etaNudge2 = qnorm(1 - 0.05/2) * sqrt(3/5),   nRetries = 3,   seed = 42,   resetThetaCheckPer = 0.1,   etaMat = NULL,   repeatGillMax = 1,   stickyRecalcN = 4,   gradProgressOfvTime = 10,   addProp = c(\"combined2\", \"combined1\"),   badSolveObjfAdj = 100,   compress = TRUE,   rxControl = NULL,   sigdigTable = NULL,   fallbackFD = FALSE,   smatPer = 0.6,   sdLowerFact = 0.001 )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Options for FOCEi — foceiControl","text":"sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) ... Additional arguments passed nlmixr2est::foceiControl(). epsilon Precision estimate n1qn1 optimization. maxInnerIterations Number iterations n1qn1 optimization. maxOuterIterations Maximum number L-BFGS-B optimization outer problem. n1qn1nsim Number function evaluations n1qn1 optimization. print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. printNcol Number columns printout wrapping parameter estimates/gradient scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. scaleObjective Scale initial objective function value.  default 0 (meaning scale) normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleC0 Number adjust scaling factor initial gradient zero. derivEps Forward difference tolerances,     vector relative difference absolute difference.      central/forward difference step size h calculated : h = abs(x)*derivEps[1] + derivEps[2] derivMethod indicates method calculating derivatives outer problem.  Currently supports \"switch\", \"central\" \"forward\" difference methods.  Switch starts forward differences.  switch central differences abs(delta(OFV)) <= derivSwitchTol switch back forward differences abs(delta(OFV)) > derivSwitchTol. derivSwitchTol tolerance switch forward central differences. covDerivMethod indicates method calculating derivatives calculating covariance components (Hessian S). covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. hessEps double value representing epsilon Hessian calculation. used R matrix calculation. hessEpsLlik double value representing epsilon Hessian calculation focei generalized log-likelihood estimation.  used R matrix calculation. optimHessType hessian type calculating individual hessian numeric differences (generalized log-likelihood estimation).  options \"central\", \"forward\".  central differences R's `optimHess()` uses default method. (Though \"forward\" faster still reasonable cases).  Shi21 changed Gill83 algorithm optimHess generalized likelihood problem. optimHessCovType hessian type calculating individual hessian numeric differences (generalized log-likelihood estimation).  options \"central\", \"forward\".  central differences R's `optimHess()` uses.  takes longer optimization, accurate, calculating covariance final likelihood, central differences used. also uses modified Shi21 method eventType Event gradient type dosing events; Can \"central\" \"forward\" centralDerivEps Central difference tolerances.    numeric vector relative difference absolute difference.   central/forward difference step size h calculated : h = abs(x)*derivEps[1] + derivEps[2] lbfgsLmm integer giving number BFGS updates retained \"L-BFGS-B\" method, defaults 7. lbfgsPgtol double precision variable. entry pgtol >= 0 specified user.  iteration     stop : max(\\| proj g_i \\| = 1, ..., n) <= lbfgsPgtol pg_i ith component projected gradient. exit pgtol unchanged.  defaults zero,     check suppressed. lbfgsFactr Controls convergence \"L-BFGS-B\" method.  Convergence occurs reduction objective within factor machine tolerance. Default 1e10, gives tolerance 2e-6, approximately 4 sigdigs.  can check exact tolerance multiplying value .Machine$double.eps eigen boolean indicating eigenvectors calculated include condition number calculation. addPosthoc Boolean indicating posthoc parameters added table output. diagXform transformation used diagonal     chol(solve(omega)). matrix values     parameters estimated FOCEi. possibilities : sqrt Estimates sqrt diagonal elements chol(solve(omega)).  default method. log Estimates log diagonal elements chol(solve(omega)) identity Estimates diagonal elements without transformations sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. optExpression Optimize rxode2 expression speed calculation. default turned . literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. ci Confidence level tables.  default 0.95 95% confidence. useColor Boolean indicating focei can use ASCII color codes boundTol Tolerance boundary issues. calcTables boolean determine foceiFit calculate tables. default TRUE noAbort Boolean indicate abort FOCEi evaluation runs troubles.  (default TRUE) interaction Boolean indicate FOCEi used (TRUE) instead FOCE (FALSE) cholSEtol tolerance Generalized Cholesky Decomposition.  Defaults suggested (.Machine$double.eps)^(1/3) cholAccept Tolerance accept Generalized Cholesky Decomposition R S matrix. resetEtaP represents p-value reseting individual ETA 0 optimization (instead saved value).  two test statistics used z-test either chol(omega^-1) %*% eta eta/sd(allEtas).  p-value 0 indicates ETAs never reset.  p-value 1 indicates ETAs always reset. resetThetaP represents p-value reseting population mu-referenced THETA parameters based ETA drift optimization, resetting optimization.  p-value 0 indicates THETAs never reset.  p-value 1 indicates THETAs always reset allowed.  theta reset checked beginning nearing local minima.  percent change objective function theta reset check initiated controlled resetThetaCheckPer. resetThetaFinalP represents p-value reseting population mu-referenced THETA parameters based ETA drift optimization, resetting optimization one final time. diagOmegaBoundUpper represents upper bound diagonal omega matrix.  upper bound given diag(omega)*diagOmegaBoundUpper.  diagOmegaBoundUpper 1, upper bound Omega. diagOmegaBoundLower represents lower bound diagonal omega matrix.  lower bound given diag(omega)/diagOmegaBoundUpper.  diagOmegaBoundLower 1, lower bound Omega. cholSEOpt Boolean indicating generalized Cholesky used optimizing. cholSECov Boolean indicating generalized Cholesky used calculating Covariance Matrix. fo boolean indicating FO approximation routine. covTryHarder R matrix non-positive definite corrected non-positive definite try estimating Hessian unscaled parameter space. outerOpt optimization method outer problem innerOpt optimization method inner problem (implemented yet.) rhobeg Beginning change parameters bobyqa algorithm (trust region).  default 0.2 20 parameters parameters scaled 1. rhobeg rhoend must set initial final values trust region radius, must positive 0 < rhoend < rhobeg. Typically rhobeg one tenth greatest expected change variable.  Note also smallest difference abs(upper-lower) greater equal rhobeg*2. case rhobeg adjusted. (bobyqa) rhoend smallest value trust region radius allowed. defined, 10^(-sigdig-1) used. (bobyqa) npt number points used approximate objective function via quadratic approximation bobyqa. value npt must interval [n+2,(n+1)(n+2)/2] n number parameters par. Choices exceed 2*n+1 recommended. defined, set 2*n + 1. (bobyqa) rel.tol Relative tolerance nlminb stops (nlmimb). x.tol X tolerance nlmixr2 optimizer eval.max Number maximum evaluations objective function (nlmimb) iter.max Maximum number iterations allowed (nlmimb) abstol Absolute tolerance nlmixr2 optimizer (BFGS) reltol tolerance nlmixr2 (BFGS) resetHessianAndEta boolean representing individual Hessian reset ETAs reset using option resetEtaP. stateTrim Trim state amounts/concentrations value. shi21maxOuter maximum number steps optimization forward-difference step size.  zero, use instead Gill differences. shi21maxInner maximum number steps optimization individual Hessian matrices generalized likelihood problem. 0, un-optimized finite differences used. shi21maxInnerCov maximum number steps optimization individual Hessian matrices generalized likelihood problem covariance step. 0, un-optimized finite differences used. shi21maxFD maximum number steps optimization forward difference step size using dosing events (lag time, modeled duration/rate bioavailability) gillK total number possible steps determine optimal forward/central difference step size per parameter (Gill 1983 method).  0, optimal step size determined.  Otherwise optimal step size determined. gillStep looking optimal forward difference step size, step size increase initial estimate .  iteration new step size = (prior step size)*gillStep gillFtol gillFtol gradient error tolerance acceptable issuing warning/error gradient estimates. gillRtol relative tolerance used Gill 1983 determination optimal step size. gillKcov total number possible steps determine optimal forward/central difference step size per parameter (Gill 1983 method) covariance step.  0, optimal step size determined.  Otherwise optimal step size determined. gillKcovLlik total number possible steps determine optimal forward/central difference step per parameter using generalized focei log-likelihood method (Gill 1986 method).  0, optimal step size determined. Otherwise optimal step size determined gillStepCovLlik generalized focei log-likelihood gillStepCov looking optimal forward difference step size, step size increase initial estimate .  iteration covariance step equal new step size = (prior step size)*gillStepCov gillFtolCov gillFtol gradient error tolerance acceptable issuing warning/error gradient estimates covariance step. gillFtolCovLlik applied generalized log-likelihood estimation. rmatNorm parameter normalize gradient step size parameter value calculation R matrix rmatNormLlik parameter normalize gradient step size parameter value calculation R matrix using generalized log-likelihood Hessian matrix. smatNorm parameter normalize gradient step size parameter value calculation S matrix smatNormLlik parameter normalize gradient step size parameter value calculation S matrix using generalized log-likelihood. covGillF Use Gill calculated optimal Forward difference step size instead central difference step size central difference gradient calculation. optGillF Use Gill calculated optimal Forward difference step size instead central difference step size central differences optimization. covSmall covSmall small number compare covariance numbers rejecting estimate covariance final estimate (comparing sandwich vs R/S matrix estimates covariance).  number controls small variance covariance matrix rejected. adjLik nlmixr2, objective function matches NONMEM's objective function, removes 2*pi constant likelihood calculation. TRUE, likelihood function adjusted 2*pi factor.  adjusted number closely matches likelihood approximations nlme, SAS approximations.  Regardless turned objective function matches NONMEM's objective function. gradTrim parameter adjust gradient |gradient| large. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced gradCalcCentralSmall small number represents value |grad| < gradCalcCentralSmall forward differences switch central differences. gradCalcCentralLarge large number represents value |grad| > gradCalcCentralLarge forward differences switch central differences. etaNudge default initial ETA estimates start zero; Sometimes optimize appropriately.  value non-zero, n1qn1 optimization perform appropriately, reset Hessian, nudge ETA value; ETA still move, nudge ETA value. default value qnorm(1-0.05/2)*1/sqrt(3), first Gauss Quadrature numbers times 0.95% normal region. successful try second eta nudge number ().  +-etaNudge2 successful, assign zero optimize longer etaNudge2 second eta nudge.  default qnorm(1-0.05/2)*sqrt(3/5), n=3 quadrature point (excluding zero) times 0.95% normal region nRetries FOCEi fit current parameter estimates, randomly sample new parameter estimates restart problem.  similar 'PsN' resampling. seed object specifying random number generator initialized resetThetaCheckPer represents objective function % percentage resetThetaP checked. etaMat Eta matrix initial estimates final estimates ETAs. repeatGillMax tolerances reduced calculating initial Gill differences, Gill difference repeated maximum number times defined parameter. stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. gradProgressOfvTime time single objective function evaluation (seconds) start progress bars gradient evaluations addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) badSolveObjfAdj objective function adjustment ODE system solved.  based individual bad solve. compress object compressed items rxControl `rxode2` ODE solving options fitting, created `rxControl()` sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. fallbackFD Fallback finite differences sensitivity equations solve. smatPer percentage representing number failed parameter gradients individual (replaced overall gradient parameter) total number gradients parameters (ie `ntheta*nsub`) S matrix considered bad matrix. sdLowerFact factor multiplying estimate lower estimate zero error known represent standard deviation parameter (like add.sd, prop.sd, pow.sd, lnorm.sd, etc).  zero, factor applied.  initial estimate 0.15 lower bound zero, lower bound assumed 0.00015.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Options for FOCEi — foceiControl","text":"control object changes options FOCEi   family estimation methods","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Control Options for FOCEi — foceiControl","text":"Note uses R's L-BFGS-B optim outer problem BFGS n1qn1 allows restoring prior individual Hessian (faster optimization speed). However inner problem scaled.  Since eta estimates start near zero, scaling parameters make sense. process scaling can fix ill conditioning unscaled problem.  covariance step performed unscaled problem, condition number matrix may reflective scaled problem's condition-number.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Control Options for FOCEi — foceiControl","text":"Gill, P.E., Murray, W., Saunders, M.., & Wright, M.H. (1983). Computing Forward-Difference Intervals Numerical Optimization. Siam Journal Scientific Statistical Computing, 4, 310-321. Shi, H.M., Xie, Y., Xuan, M.Q., & Nocedal, J. (2021). Adaptive Finite-Difference Interval Estimation Noisy Derivative-Free Optimization.","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control Options for FOCEi — foceiControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/lbfgsb3cControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control for lbfgsb3c estimation method in nlmixr2 — lbfgsb3cControl","title":"Control for lbfgsb3c estimation method in nlmixr2 — lbfgsb3cControl","text":"Control lbfgsb3c estimation method nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/lbfgsb3cControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control for lbfgsb3c estimation method in nlmixr2 — lbfgsb3cControl","text":"","code":"lbfgsb3cControl(   trace = 0,   factr = 1e+07,   pgtol = 0,   abstol = 0,   reltol = 0,   lmm = 5L,   maxit = 10000L,   returnLbfgsb3c = FALSE,   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   gradTo = 1,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/lbfgsb3cControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control for lbfgsb3c estimation method in nlmixr2 — lbfgsb3cControl","text":"trace positive, tracing information progress optimization produced. Higher values may produce tracing information: method \"L-BFGS-B\" six levels tracing. (understand exactly see source code: higher levels give detail.) factr controls convergence \"L-BFGS-B\" method. Convergence occurs reduction objective within factor machine tolerance. Default 1e7, tolerance 1e-8. pgtol helps control convergence \"L-BFGS-B\" method. tolerance projected gradient current search direction. defaults zero, check suppressed. abstol helps control convergence \"L-BFGS-B\" method. absolute tolerance difference x values. defaults zero, check suppressed. reltol helps control convergence \"L-BFGS-B\" method. relative tolerance difference x values. defaults zero, check suppressed. lmm integer giving number BFGS updates retained \"L-BFGS-B\" method, defaults 5. maxit maximum number iterations. returnLbfgsb3c return lbfgsb3c output instead nlmixr2 fit stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. gradTo factor gradient scaled optimizing.  works scaleType=\"nlmixr2\". rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::lbfgsb3cControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/lbfgsb3cControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control for lbfgsb3c estimation method in nlmixr2 — lbfgsb3cControl","text":"bobqya control structure","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/lbfgsb3cControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control for lbfgsb3c estimation method in nlmixr2 — lbfgsb3cControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/lbfgsb3cControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control for lbfgsb3c estimation method in nlmixr2 — lbfgsb3cControl","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"lbfgsb3c\") #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(θ) #> → finding duplicate expressions in nlm llik gradient... #> → optimizing duplicate expressions in nlm llik gradient... #> → finding duplicate expressions in nlm pred-only... #> → optimizing duplicate expressions in nlm pred-only... #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9072 #> → compress parHistData in nlmixr2 object, save 3232  print(fit2) #> ── nlmixr² log-likelihood lbfgsb3c ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -697.0046 1146.872 1161.596      -570.4362        2413.921        177.6711 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.003013 0.035    0.012 2.480987 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.    SE  %RSE   Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.7401 0.242  32.7 -0.7401 (-1.214, -0.2657)                     #> Em    7.816 6.269  80.2       7.816 (-4.47, 20.1)                     #> E50   3.667 2.317 63.17    3.667 (-0.8734, 8.208)                     #> g         2 FIXED FIXED                         2                     #>   #>   Covariance Type ($covMethod): r #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH  #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0323     0 -0.390 -0.739 #> 2 1     0.0398     0 -0.390 -0.739 #> 3 1     0.0418     0 -0.390 -0.739 #> # ℹ 997 more rows  # you can also get the nlm output with fit2$lbfgsb3c  fit2$lbfgsb3c #> $par #>         E0         Em        E50  #> -0.7400788  7.8160167  3.6674259  #>  #> $grad #> [1]  1.057740e-06  8.700145e-07 -1.452527e-06 #>  #> $value #> [1] 570.4362 #>  #> $counts #> [1] 22 22 #>  #> $convergence #> [1] 0 #>  #> $message #> [1] \"CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH\" #>  #> $scaleC #> [1] 0.00271054 0.03576667 0.03178478 #>  #> $par.scaled #>         E0         Em        E50  #> -458.50252  203.54847   53.45989  #>  #> $hessian #>               E0           Em          E50 #> E0   0.001456989  0.001610660 -0.004897627 #> Em   0.001610660  0.004191952 -0.011053679 #> E50 -0.004897627 -0.011053679  0.030404986 #>  #> $covMethod #> [1] \"r\" #>  #> $cov.scaled #>           E0       Em       E50 #> E0  7973.091  7810.19  4123.684 #> Em  7810.190 30717.79 12425.461 #> E50 4123.684 12425.46  5313.054 #>  #> $cov #>             E0         Em        E50 #> E0  0.05857851  0.7571743  0.3552715 #> Em  0.75717427 39.2958674 14.1257053 #> E50 0.35527148 14.1257053  5.3676295 #>  #> $r #>                E0           Em          E50 #> E0   0.0007284945  0.000805330 -0.002448813 #> Em   0.0008053300  0.002095976 -0.005526839 #> E50 -0.0024488135 -0.005526839  0.015202493 #>   # The nlm control has been modified slightly to include # extra components and name the parameters # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/n1qn1Control.html","id":null,"dir":"Reference","previous_headings":"","what":"Control for n1qn1 estimation method in nlmixr2 — n1qn1Control","title":"Control for n1qn1 estimation method in nlmixr2 — n1qn1Control","text":"Control n1qn1 estimation method nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/n1qn1Control.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control for n1qn1 estimation method in nlmixr2 — n1qn1Control","text":"","code":"n1qn1Control(   epsilon = (.Machine$double.eps)^0.25,   max_iterations = 10000,   nsim = 10000,   imp = 0,   print.functions = FALSE,   returnN1qn1 = FALSE,   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   gradTo = 1,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"n1qn1\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/n1qn1Control.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control for n1qn1 estimation method in nlmixr2 — n1qn1Control","text":"epsilon Precision estimate n1qn1 optimization. max_iterations Number iterations nsim Number function evaluations imp Verbosity messages. print.functions Boolean control function value parameter estimates echoed every time function called. returnN1qn1 return n1qn1 output instead nlmixr2 fit stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. gradTo factor gradient scaled optimizing.  works scaleType=\"nlmixr2\". rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::n1qn1Control().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/n1qn1Control.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control for n1qn1 estimation method in nlmixr2 — n1qn1Control","text":"bobqya control structure","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/n1qn1Control.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control for n1qn1 estimation method in nlmixr2 — n1qn1Control","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/n1qn1Control.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control for n1qn1 estimation method in nlmixr2 — n1qn1Control","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"n1qn1\") #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(θ) #> → finding duplicate expressions in nlm llik gradient... #> → optimizing duplicate expressions in nlm llik gradient... #> → finding duplicate expressions in nlm pred-only... #> → optimizing duplicate expressions in nlm pred-only... #>   #>   #>   #>   #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9104 #> → compress parHistData in nlmixr2 object, save 3952  print(fit2) #> ── nlmixr² log-likelihood n1qn1 ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -705.6043 1138.273 1152.996      -566.1364        210.1712         38.1853 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.001934 0.022    0.008 1.685066 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.     SE  %RSE   Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.5664 0.2303 40.66 -0.5664 (-1.018, -0.1151)                     #> Em    4.922  1.714 34.83      4.922 (1.562, 8.282)                     #> E50   2.593 0.9697  37.4     2.593 (0.6922, 4.493)                     #> g         2  FIXED FIXED                         2                     #>   #>   Covariance Type ($covMethod): r #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0550     1 -1.01  -0.564 #> 2 1     0.0756     1 -1.01  -0.562 #> 3 1     0.0881     0 -0.452 -0.561 #> # ℹ 997 more rows  # you can also get the nlm output with fit2$n1qn1  fit2$n1qn1 #> $value #> [1] 566.1364 #>  #> $par #>         E0         Em        E50  #> -0.5664025  4.9217412  2.5926911  #>  #> $H #>              [,1]         [,2]         [,3] #> [1,]  0.001946127  0.003798068 -0.008872114 #> [2,]  0.003798068  0.017671038 -0.031869789 #> [3,] -0.008872114 -0.031869789  0.067981312 #>  #> $c.hess #>  [1]  0.001946127  0.003798068 -0.008872114  0.017671038 -0.031869789 #>  [6]  0.067981312  0.000000000  0.000000000  0.000000000  0.000000000 #> [11]  0.000000000  0.000000000  0.000000000  0.000000000  0.000000000 #> [16]  0.000000000  0.000000000  0.000000000  0.000000000  0.000000000 #> [21]  0.000000000  0.000000000  0.000000000  0.000000000 #>  #> $n.fn #> [1] 35 #>  #> $n.gr #> [1] 35 #>  #> $scaleC #> [1] 0.003122613 0.043013784 0.040016408 #>  #> $par.scaled #>        E0        Em       E50  #> -342.5097  101.7982   15.8112  #>  #> $hessian #>               E0           Em          E50 #> E0   0.001907130  0.003728541 -0.008692555 #> Em   0.003728541  0.017459716 -0.031502834 #> E50 -0.008692555 -0.031502834  0.067129390 #>  #> $covMethod #> [1] \"r\" #>  #> $cov.scaled #>            E0        Em       E50 #> E0  5438.0348  712.7973 1038.6740 #> Em   712.7973 1588.2549  837.6444 #> E50 1038.6740  837.6444  587.1781 #>  #> $cov #>             E0         Em       E50 #> E0  0.05302471 0.09573966 0.1297883 #> Em  0.09573966 2.93856641 1.4418015 #> E50 0.12978830 1.44180147 0.9402558 #>  #> $r #>                E0           Em          E50 #> E0   0.0009535648  0.001864271 -0.004346278 #> Em   0.0018642706  0.008729858 -0.015751417 #> E50 -0.0043462777 -0.015751417  0.033564695 #>   # The nlm control has been modified slightly to include # extra components and name the parameters # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/newuoaControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control for newuoa estimation method in nlmixr2 — newuoaControl","title":"Control for newuoa estimation method in nlmixr2 — newuoaControl","text":"Control newuoa estimation method nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/newuoaControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control for newuoa estimation method in nlmixr2 — newuoaControl","text":"","code":"newuoaControl(   npt = NULL,   rhobeg = NULL,   rhoend = NULL,   iprint = 0L,   maxfun = 100000L,   returnNewuoa = FALSE,   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/newuoaControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control for newuoa estimation method in nlmixr2 — newuoaControl","text":"npt number points used approximate objective function via quadratic approximation bobyqa. value npt must interval [n+2,(n+1)(n+2)/2] n number parameters par. Choices exceed 2*n+1 recommended. defined, set 2*n + 1. (bobyqa) rhobeg Beginning change parameters bobyqa algorithm (trust region).  default 0.2 20 parameters parameters scaled 1. rhobeg rhoend must set initial final values trust region radius, must positive 0 < rhoend < rhobeg. Typically rhobeg one tenth greatest expected change variable.  Note also smallest difference abs(upper-lower) greater equal rhobeg*2. case rhobeg adjusted. (bobyqa) rhoend smallest value trust region radius allowed. defined, 10^(-sigdig-1) used. (bobyqa) iprint value `iprint` set integer value `0, 1, 2, 3, ...`, controls amount printing.  Specifically, output `iprint=0` output start return `iprint=1`. Otherwise, new value `rho` printed, best vector variables far corresponding value objective function. , new value objective function variables output `iprint=3`.  `iprint > 3`, objective function value corresponding variables output every `iprint` evaluations.  Default value `0`. maxfun maximum allowed number function evaluations. exceeded, method terminate. returnNewuoa return newuoa output instead nlmixr2 fit stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::newuoaControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/newuoaControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control for newuoa estimation method in nlmixr2 — newuoaControl","text":"newuoa control structure","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/newuoaControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control for newuoa estimation method in nlmixr2 — newuoaControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/newuoaControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control for newuoa estimation method in nlmixr2 — newuoaControl","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"newuoa\") #>   #>   #>   #>   #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → loading llik model into symengine environment... #> → finding duplicate expressions in population log-likelihood model... #> → optimizing duplicate expressions in population log-likelihood model... #> ✔ done #>   #>   #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9112 #> → compress parHistData in nlmixr2 object, save 15744  print(fit2) #> ── nlmixr² log-likelihood newuoa ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -682.4784 1161.399 1176.122      -577.6994        730.3071        73.77655 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.002014 0.022    0.018 1.371986 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.     SE  %RSE     Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.5334 0.2235 41.91 -0.5334 (-0.9715, -0.09529)                     #> Em    6.102  3.286 53.85      6.102 (-0.3387, 12.54)                     #> E50   3.537  1.708 48.28       3.537 (0.1904, 6.884)                     #> g         2  FIXED FIXED                           2                     #>   #>   Covariance Type ($covMethod): r #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0255     0 -0.462 -0.533 #> 2 1     0.0524     0 -0.462 -0.532 #> 3 1     0.0626     0 -0.462 -0.531 #> # ℹ 997 more rows  # you can also get the nlm output with  fit2$newuoa #> parameter estimates: -0.533371781715002, 6.10190377164553, 3.53717877267146  #> objective: 577.69935467934  #> number of function evaluations: 261   # The nlm control has been modified slightly to include # extra components and name the parameters # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmControl.html","id":null,"dir":"Reference","previous_headings":"","what":"nlmixr2 defaults controls for nlm — nlmControl","title":"nlmixr2 defaults controls for nlm — nlmControl","text":"nlmixr2 defaults controls nlm","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nlmixr2 defaults controls for nlm — nlmControl","text":"","code":"nlmControl(   typsize = NULL,   fscale = 1,   print.level = 0,   ndigit = NULL,   gradtol = 1e-06,   stepmax = NULL,   steptol = 1e-06,   iterlim = 10000,   check.analyticals = FALSE,   returnNlm = FALSE,   solveType = c(\"hessian\", \"grad\", \"fun\"),   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   eventType = c(\"central\", \"forward\"),   shiErr = (.Machine$double.eps)^(1/3),   shi21maxFD = 20L,   optimHessType = c(\"central\", \"forward\"),   hessErr = (.Machine$double.eps)^(1/3),   shi21maxHess = 20L,   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   gradTo = 1,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"nlm\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nlmixr2 defaults controls for nlm — nlmControl","text":"typsize estimate size parameter     minimum. fscale estimate size f minimum. print.level argument determines level printing     done minimization process.  default     value 0 means printing occurs, value 1     means initial final details printed value     2 means full tracing information printed. ndigit number significant digits function f. gradtol positive scalar giving tolerance     scaled gradient considered close enough zero     terminate algorithm.  scaled gradient     measure relative change f direction     p[] divided relative change p[]. stepmax positive scalar gives maximum allowable     scaled step length.  stepmax used prevent steps     cause optimization function overflow, prevent     algorithm leaving area interest parameter space,     detect divergence algorithm. stepmax chosen     small enough prevent first two occurrences,     larger anticipated reasonable step. steptol positive scalar providing minimum allowable     relative step length. iterlim positive integer specifying maximum number     iterations performed program terminated. check.analyticals logical scalar specifying whether     analytic gradients Hessians, supplied,     checked numerical derivatives initial parameter     values. can help detect incorrectly formulated gradients     Hessians. returnNlm logical allows return `nlm` object solveType tells `nlm` use nlmixr2's analytical   gradients available (finite differences used   event-related parameters like parameters controlling lag time,   duration/rate infusion, modeled bioavailability). can   : - `\"hessian\"` use analytical gradients create     Hessian finite differences. - `\"gradient\"` use gradient let `nlm` calculate    finite difference hessian - `\"fun\"` nlm calculate finite difference    gradient finite difference Hessian using nlmixr2's finite differences, \"ideal\" step size  either central forward differences optimized  Shi2021 method may give accurate derivatives stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced eventType Event gradient type dosing events; Can \"central\" \"forward\" shiErr represents epsilon optimizing ideal step size numeric differentiation using Shi2021 method shi21maxFD maximum number steps optimization forward difference step size using dosing events (lag time, modeled duration/rate bioavailability) optimHessType hessian type calculating individual hessian numeric differences (generalized log-likelihood estimation).  options \"central\", \"forward\".  central differences R's `optimHess()` uses default method. (Though \"forward\" faster still reasonable cases).  Shi21 changed Gill83 algorithm optimHess generalized likelihood problem. hessErr represents epsilon optimizing Hessian step size using Shi2021 method. shi21maxHess Maximum number times optimize best step size hessian calculation useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. gradTo factor gradient scaled optimizing.  works scaleType=\"nlmixr2\". rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod allows selection \"r\", uses nlmixr2's `nlmixr2Hess()` hessian calculation \"nlm\" uses hessian `stats::nlm(.., hessian=TRUE)`. using `nlmixr2's` hessian optimization `nlmixr2's` gradient solving defaults \"nlm\" since `stats::optimHess()` assumes accurate gradient faster `nlmixr2Hess` adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::nlmControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"nlmixr2 defaults controls for nlm — nlmControl","text":"nlm control object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nlmixr2 defaults controls for nlm — nlmControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"nlmixr2 defaults controls for nlm — nlmControl","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"nlm\") #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(θ) #> → finding duplicate expressions in nlm llik gradient... #> → optimizing duplicate expressions in nlm llik gradient... #> → finding duplicate expressions in nlm pred-only... #> → optimizing duplicate expressions in nlm pred-only... #>   #>   #>   #>   #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9120 #> → compress parHistData in nlmixr2 object, save 3528  print(fit2) #> ── nlmixr² log-likelihood nlm ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -700.2497 1143.627 1158.351      -568.8137         1211115        216098.1 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.002037 0.021    0.007 1.697963 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.    SE  %RSE Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.6554 7.837  1196  -0.6554 (-16.02, 14.7)                     #> Em     5.69 129.4  2274      5.69 (-248, 259.4)                     #> E50   2.907 68.67  2362   2.907 (-131.7, 137.5)                     #> g         2 FIXED FIXED                       2                     #>   #>   Covariance Type ($covMethod): r (nlm) #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     relative gradient is close to zero, current iterate is probably solution  #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0394     0 -0.419 -0.654 #> 2 1     0.0410     0 -0.419 -0.654 #> 3 1     0.0491     0 -0.419 -0.654 #> # ℹ 997 more rows  # you can also get the nlm output with fit2$nlm  fit2$nlm #> $minimum #> [1] 568.8137 #>  #> $estimate #>         E0         Em        E50  #> -0.6554413  5.6904595  2.9073089  #>  #> $gradient #> [1]  2.299551e-09 -2.859105e-08 -7.022353e-07 #>  #> $hessian #>               E0           Em          E50 #> E0   0.001696269  0.002693875 -0.006887672 #> Em   0.002693875  0.009539621 -0.020827645 #> E50 -0.006887672 -0.020827645  0.044208239 #>  #> $code #> [1] 1 #>  #> $iterations #> [1] 9 #>  #> $scaleC #> [1] 0.002932331 0.038852338 0.035018139 #>  #> $estimate.scaled #>         E0         Em        E50  #> -395.03513  132.59452   26.90968  #>  #> $covMethod #> [1] \"r (nlm)\" #>  #> $cov.scaled #>          E0       Em     E50 #> E0  7142983  8899282 5239213 #> Em  8899282 11097178 6531959 #> E50 5239213  6531959 3845044 #>  #> $cov #>             E0        Em       E50 #> E0    61.41939  1013.877  537.9873 #> Em  1013.87655 16751.237 8886.9695 #> E50  537.98732  8886.970 4715.0619 #>  #> $r #>                E0           Em          E50 #> E0   0.0008481345  0.001346938 -0.003443836 #> Em   0.0013469377  0.004769810 -0.010413822 #> E50 -0.0034438360 -0.010413822  0.022104120 #>   # The nlm control has been modified slightly to include # extra components and name the parameters # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmeControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Values for nlme Fit with extra options for nlmixr — nlmeControl","title":"Control Values for nlme Fit with extra options for nlmixr — nlmeControl","text":"values supplied function call replace defaults list possible arguments returned.  returned list used ‘control’ argument ‘nlme’ function.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmeControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Values for nlme Fit with extra options for nlmixr — nlmeControl","text":"","code":"nlmeControl(   maxIter = 100,   pnlsMaxIter = 100,   msMaxIter = 100,   minScale = 0.001,   tolerance = 1e-05,   niterEM = 25,   pnlsTol = 0.001,   msTol = 1e-06,   returnObject = FALSE,   msVerbose = FALSE,   msWarnNoConv = TRUE,   gradHess = TRUE,   apVar = TRUE,   .relStep = .Machine$double.eps^(1/3),   minAbsParApVar = 0.05,   opt = c(\"nlminb\", \"nlm\"),   natural = TRUE,   sigma = NULL,   optExpression = TRUE,   literalFix = TRUE,   sumProd = FALSE,   rxControl = NULL,   method = c(\"ML\", \"REML\"),   random = NULL,   fixed = NULL,   weights = NULL,   verbose = TRUE,   returnNlme = FALSE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   muRefCovAlg = TRUE,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmeControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Values for nlme Fit with extra options for nlmixr — nlmeControl","text":"maxIter maximum number iterations nlme    optimization algorithm.  Default 50. pnlsMaxIter maximum number iterations    PNLS optimization step inside nlme    optimization.  Default 7. msMaxIter maximum number iterations nlminb    (iter.max) nlm (iterlim,    10-th step) optimization step inside nlme    optimization.  Default 50 (may small e.g.    overparametrized cases). minScale minimum factor shrink default step size    attempt decrease sum squares PNLS step.    Default 0.001. tolerance tolerance convergence criterion    nlme algorithm.  Default 1e-6. niterEM number iterations EM algorithm used refine    initial estimates random effects variance-covariance    coefficients.  Default 25. pnlsTol tolerance convergence criterion PNLS    step.  Default 1e-3. msTol tolerance convergence criterion nlm,    passed gradtol argument function (see    documentation nlm).  Default 1e-7. returnObject logical value indicating whether fitted    object returned maximum number iterations    reached without convergence algorithm.  Default    FALSE. msVerbose logical value passed trace    nlminb(.., control= list(trace = *, ..))    argument print.level nlm().  Default    FALSE. msWarnNoConv logical indicating warning    signalled whenever minimization (opt)    LME step converge; defaults TRUE. gradHess logical value indicating whether numerical gradient    vectors Hessian matrices log-likelihood function    used nlm optimization. option available    correlation structure (corStruct) variance    function structure (varFunc) \"varying\" parameters    pdMat classes used random effects structure    pdSymm (general positive-definite), pdDiag (diagonal),    pdIdent (multiple identity),     pdCompSymm (compound symmetry).  Default TRUE. apVar logical value indicating whether approximate    covariance matrix variance-covariance parameters    calculated.  Default TRUE. .relStep relative step numerical derivatives    calculations.  Default .Machine$double.eps^(1/3). minAbsParApVar numeric value - minimum absolute parameter value    approximate variance calculation.  default 0.05. opt optimizer used, either \"nlminb\" (   default) \"nlm\". natural logical value indicating whether pdNatural    parametrization used general positive-definite matrices    (pdSymm) reStruct, approximate covariance    matrix estimators calculated.  Default TRUE. sigma optionally positive number fix residual error .    NULL, default, 0, sigma estimated. optExpression Optimize rxode2 expression speed calculation. default turned . literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. rxControl `rxode2` ODE solving options fitting, created `rxControl()` method character string.  \"REML\" model fit    maximizing restricted log-likelihood.  \"ML\"    log-likelihood maximized.  Defaults \"ML\". random optionally, following: () two-sided formula    form r1+...+rn~x1+...+xm | g1/.../gQ,    r1,...,rn naming parameters included right    hand side model, x1+...+xm specifying    random-effects model    parameters g1/.../gQ grouping structure    (Q may equal 1, case /    required). random effects formula repeated    levels grouping, case multiple levels    grouping; (ii) two-sided formula form    r1+...+rn~x1+..+xm, list two-sided formulas form    r1~x1+...+xm, possibly different random-effects models    different parameters, pdMat object two-sided    formula, list two-sided formulas (.e. non-NULL value    formula(random)), list pdMat objects two-sided    formulas, lists two-sided formulas. case, grouping    structure formula given groups, derived    data used fit nonlinear mixed-effects model,    inherit class  groupedData,; (iii) named list    formulas, lists formulas, pdMat objects (ii),    grouping factors names. order nesting    assumed order order elements    list; (iv) reStruct object. See documentation    pdClasses description available pdMat    classes. Defaults fixed,    resulting fixed effects also random effects. fixed two-sided linear formula form    f1+...+fn~x1+...+xm, list two-sided formulas form    f1~x1+...+xm, possibly different models different    parameters. f1,...,fn names parameters included    right hand side model x1+...+xm    expressions define linear models parameters (left    hand side formula contains several parameters,    assumed follow linear model, described right hand    side expression).    1 right hand side formula(s) indicates single    fixed effects corresponding parameter(s). weights optional varFunc object one-sided formula    describing within-group heteroscedasticity structure. given    formula, used argument varFixed,    corresponding fixed variance weights. See documentation    varClasses description available varFunc    classes. Defaults NULL, corresponding homoscedastic    within-group errors. verbose optional logical value. TRUE information    evolution iterative algorithm printed. Default    FALSE. returnNlme Returns nlme object instead nlmixr object (default FALSE).  nlme specific options `random`, `fixed`, `sens`, nlme object returned addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. muRefCovAlg controls algebraic expressions can   mu-referenced treated mu-referenced covariates : 1. Creating internal data-variable `nlmixrMuDerCov#`      algebraic mu-referenced expression 2. Change algebraic expression `nlmixrMuDerCov# * mu_cov_theta` 3. Use internal mu-referenced covariate saem 4. optimization completed, replace `model()` old   `model()` expression 5. Remove `nlmixrMuDerCov#` nlmix2 output general, covariates accurate since changes system linear compartment model.  Therefore, default `TRUE`. ... Additional arguments passed nlmixr2est::nlmeControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmeControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Values for nlme Fit with extra options for nlmixr — nlmeControl","text":"nlmixr-nlme list","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmeControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control Values for nlme Fit with extra options for nlmixr — nlmeControl","text":"","code":"nlmeControl() #> $maxIter #> [1] 100 #>  #> $pnlsMaxIter #> [1] 100 #>  #> $msMaxIter #> [1] 100 #>  #> $minScale #> [1] 0.001 #>  #> $tolerance #> [1] 1e-05 #>  #> $niterEM #> [1] 25 #>  #> $pnlsTol #> [1] 0.001 #>  #> $msTol #> [1] 1e-06 #>  #> $returnObject #> [1] FALSE #>  #> $msVerbose #> [1] FALSE #>  #> $msWarnNoConv #> [1] TRUE #>  #> $gradHess #> [1] TRUE #>  #> $apVar #> [1] TRUE #>  #> $.relStep #> [1] 6.055454e-06 #>  #> $minAbsParApVar #> [1] 0.05 #>  #> $opt #> [1] \"nlminb\" #>  #> $natural #> [1] TRUE #>  #> $sigma #> [1] 0 #>  #> $optExpression #> [1] TRUE #>  #> $literalFix #> [1] TRUE #>  #> $sumProd #> [1] FALSE #>  #> $rxControl #> $scale #> NULL #>  #> $method #> liblsoda  #>        2  #>  #> $atol #> [1] 1e-04 #>  #> $rtol #> [1] 1e-04 #>  #> $maxsteps #> [1] 70000 #>  #> $hmin #> [1] 0 #>  #> $hmax #> [1] NA #>  #> $hini #> [1] 0 #>  #> $maxordn #> [1] 12 #>  #> $maxords #> [1] 5 #>  #> $covsInterpolation #> locf  #>    1  #>  #> $addCov #> [1] TRUE #>  #> $returnType #> rxSolve  #>       0  #>  #> $sigma #> NULL #>  #> $sigmaDf #> NULL #>  #> $nCoresRV #> [1] 1 #>  #> $sigmaIsChol #> [1] FALSE #>  #> $sigmaSeparation #> [1] \"auto\" #>  #> $sigmaXform #> identity  #>        4  #>  #> $nDisplayProgress #> [1] 10000 #>  #> $amountUnits #> [1] NA #>  #> $timeUnits #> [1] \"hours\" #>  #> $addDosing #> [1] FALSE #>  #> $stateTrim #> [1] Inf #>  #> $updateObject #> [1] FALSE #>  #> $omega #> NULL #>  #> $omegaDf #> NULL #>  #> $omegaIsChol #> [1] FALSE #>  #> $omegaSeparation #> [1] \"auto\" #>  #> $omegaXform #> variance  #>        6  #>  #> $nSub #> [1] 1 #>  #> $thetaMat #> NULL #>  #> $thetaDf #> NULL #>  #> $thetaIsChol #> [1] FALSE #>  #> $nStud #> [1] 1 #>  #> $dfSub #> [1] 0 #>  #> $dfObs #> [1] 0 #>  #> $seed #> NULL #>  #> $nsim #> NULL #>  #> $minSS #> [1] 10 #>  #> $maxSS #> [1] 1000 #>  #> $strictSS #> [1] 1 #>  #> $infSSstep #> [1] 12 #>  #> $istateReset #> [1] TRUE #>  #> $subsetNonmem #> [1] TRUE #>  #> $hmaxSd #> [1] 0 #>  #> $maxAtolRtolFactor #> [1] 0.1 #>  #> $from #> NULL #>  #> $to #> NULL #>  #> $by #> NULL #>  #> $length.out #> NULL #>  #> $iCov #> NULL #>  #> $keep #> NULL #>  #> $keepF #> character(0) #>  #> $drop #> NULL #>  #> $warnDrop #> [1] TRUE #>  #> $omegaLower #> [1] -Inf #>  #> $omegaUpper #> [1] Inf #>  #> $sigmaLower #> [1] -Inf #>  #> $sigmaUpper #> [1] Inf #>  #> $thetaLower #> [1] -Inf #>  #> $thetaUpper #> [1] Inf #>  #> $indLinPhiM #> [1] 0 #>  #> $indLinPhiTol #> [1] 1e-07 #>  #> $indLinMatExpType #> expokit  #>       2  #>  #> $indLinMatExpOrder #> [1] 6 #>  #> $idFactor #> [1] TRUE #>  #> $mxhnil #> [1] 0 #>  #> $hmxi #> [1] 0 #>  #> $warnIdSort #> [1] TRUE #>  #> $ssAtol #> [1] 1e-08 #>  #> $ssRtol #> [1] 1e-06 #>  #> $safeZero #> [1] 1 #>  #> $sumType #> pairwise  #>        1  #>  #> $prodType #> long double  #>           1  #>  #> $sensType #> advan  #>     4  #>  #> $linDiff #>    tlag       f    rate     dur   tlag2      f2   rate2    dur2  #> 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05  #>  #> $linDiffCentral #>  tlag     f  rate   dur tlag2    f2 rate2  dur2  #>  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  #>  #> $resample #> NULL #>  #> $resampleID #> [1] TRUE #>  #> $maxwhile #> [1] 100000 #>  #> $cores #> [1] 0 #>  #> $atolSens #> [1] 1e-08 #>  #> $rtolSens #> [1] 1e-06 #>  #> $ssAtolSens #> [1] 1e-08 #>  #> $ssRtolSens #> [1] 1e-06 #>  #> $simVariability #> [1] NA #>  #> $nLlikAlloc #> NULL #>  #> $useStdPow #> [1] 0 #>  #> $naTimeHandle #> ignore  #>      1  #>  #> $addlKeepsCov #> [1] FALSE #>  #> $addlDropSs #> [1] TRUE #>  #> $ssAtDoseTime #> [1] TRUE #>  #> $ss2cancelAllPending #> [1] FALSE #>  #> $.zeros #> NULL #>  #> attr(,\"class\") #> [1] \"rxControl\" #>  #> $method #> [1] \"ML\" #>  #> $verbose #> [1] TRUE #>  #> $returnNlme #> [1] FALSE #>  #> $addProp #> [1] \"combined2\" #>  #> $calcTables #> [1] TRUE #>  #> $compress #> [1] TRUE #>  #> $random #> NULL #>  #> $fixed #> NULL #>  #> $weights #> NULL #>  #> $ci #> [1] 0.95 #>  #> $sigdig #> [1] 4 #>  #> $sigdigTable #> [1] 4 #>  #> $muRefCovAlg #> [1] TRUE #>  #> $genRxControl #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"nlmeControl\" nlmixr2NlmeControl() #> $maxIter #> [1] 100 #>  #> $pnlsMaxIter #> [1] 100 #>  #> $msMaxIter #> [1] 100 #>  #> $minScale #> [1] 0.001 #>  #> $tolerance #> [1] 1e-05 #>  #> $niterEM #> [1] 25 #>  #> $pnlsTol #> [1] 0.001 #>  #> $msTol #> [1] 1e-06 #>  #> $returnObject #> [1] FALSE #>  #> $msVerbose #> [1] FALSE #>  #> $msWarnNoConv #> [1] TRUE #>  #> $gradHess #> [1] TRUE #>  #> $apVar #> [1] TRUE #>  #> $.relStep #> [1] 6.055454e-06 #>  #> $minAbsParApVar #> [1] 0.05 #>  #> $opt #> [1] \"nlminb\" #>  #> $natural #> [1] TRUE #>  #> $sigma #> [1] 0 #>  #> $optExpression #> [1] TRUE #>  #> $literalFix #> [1] TRUE #>  #> $sumProd #> [1] FALSE #>  #> $rxControl #> $scale #> NULL #>  #> $method #> liblsoda  #>        2  #>  #> $atol #> [1] 1e-04 #>  #> $rtol #> [1] 1e-04 #>  #> $maxsteps #> [1] 70000 #>  #> $hmin #> [1] 0 #>  #> $hmax #> [1] NA #>  #> $hini #> [1] 0 #>  #> $maxordn #> [1] 12 #>  #> $maxords #> [1] 5 #>  #> $covsInterpolation #> locf  #>    1  #>  #> $addCov #> [1] TRUE #>  #> $returnType #> rxSolve  #>       0  #>  #> $sigma #> NULL #>  #> $sigmaDf #> NULL #>  #> $nCoresRV #> [1] 1 #>  #> $sigmaIsChol #> [1] FALSE #>  #> $sigmaSeparation #> [1] \"auto\" #>  #> $sigmaXform #> identity  #>        4  #>  #> $nDisplayProgress #> [1] 10000 #>  #> $amountUnits #> [1] NA #>  #> $timeUnits #> [1] \"hours\" #>  #> $addDosing #> [1] FALSE #>  #> $stateTrim #> [1] Inf #>  #> $updateObject #> [1] FALSE #>  #> $omega #> NULL #>  #> $omegaDf #> NULL #>  #> $omegaIsChol #> [1] FALSE #>  #> $omegaSeparation #> [1] \"auto\" #>  #> $omegaXform #> variance  #>        6  #>  #> $nSub #> [1] 1 #>  #> $thetaMat #> NULL #>  #> $thetaDf #> NULL #>  #> $thetaIsChol #> [1] FALSE #>  #> $nStud #> [1] 1 #>  #> $dfSub #> [1] 0 #>  #> $dfObs #> [1] 0 #>  #> $seed #> NULL #>  #> $nsim #> NULL #>  #> $minSS #> [1] 10 #>  #> $maxSS #> [1] 1000 #>  #> $strictSS #> [1] 1 #>  #> $infSSstep #> [1] 12 #>  #> $istateReset #> [1] TRUE #>  #> $subsetNonmem #> [1] TRUE #>  #> $hmaxSd #> [1] 0 #>  #> $maxAtolRtolFactor #> [1] 0.1 #>  #> $from #> NULL #>  #> $to #> NULL #>  #> $by #> NULL #>  #> $length.out #> NULL #>  #> $iCov #> NULL #>  #> $keep #> NULL #>  #> $keepF #> character(0) #>  #> $drop #> NULL #>  #> $warnDrop #> [1] TRUE #>  #> $omegaLower #> [1] -Inf #>  #> $omegaUpper #> [1] Inf #>  #> $sigmaLower #> [1] -Inf #>  #> $sigmaUpper #> [1] Inf #>  #> $thetaLower #> [1] -Inf #>  #> $thetaUpper #> [1] Inf #>  #> $indLinPhiM #> [1] 0 #>  #> $indLinPhiTol #> [1] 1e-07 #>  #> $indLinMatExpType #> expokit  #>       2  #>  #> $indLinMatExpOrder #> [1] 6 #>  #> $idFactor #> [1] TRUE #>  #> $mxhnil #> [1] 0 #>  #> $hmxi #> [1] 0 #>  #> $warnIdSort #> [1] TRUE #>  #> $ssAtol #> [1] 1e-08 #>  #> $ssRtol #> [1] 1e-06 #>  #> $safeZero #> [1] 1 #>  #> $sumType #> pairwise  #>        1  #>  #> $prodType #> long double  #>           1  #>  #> $sensType #> advan  #>     4  #>  #> $linDiff #>    tlag       f    rate     dur   tlag2      f2   rate2    dur2  #> 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05  #>  #> $linDiffCentral #>  tlag     f  rate   dur tlag2    f2 rate2  dur2  #>  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  #>  #> $resample #> NULL #>  #> $resampleID #> [1] TRUE #>  #> $maxwhile #> [1] 100000 #>  #> $cores #> [1] 0 #>  #> $atolSens #> [1] 1e-08 #>  #> $rtolSens #> [1] 1e-06 #>  #> $ssAtolSens #> [1] 1e-08 #>  #> $ssRtolSens #> [1] 1e-06 #>  #> $simVariability #> [1] NA #>  #> $nLlikAlloc #> NULL #>  #> $useStdPow #> [1] 0 #>  #> $naTimeHandle #> ignore  #>      1  #>  #> $addlKeepsCov #> [1] FALSE #>  #> $addlDropSs #> [1] TRUE #>  #> $ssAtDoseTime #> [1] TRUE #>  #> $ss2cancelAllPending #> [1] FALSE #>  #> $.zeros #> NULL #>  #> attr(,\"class\") #> [1] \"rxControl\" #>  #> $method #> [1] \"ML\" #>  #> $verbose #> [1] TRUE #>  #> $returnNlme #> [1] FALSE #>  #> $addProp #> [1] \"combined2\" #>  #> $calcTables #> [1] TRUE #>  #> $compress #> [1] TRUE #>  #> $random #> NULL #>  #> $fixed #> NULL #>  #> $weights #> NULL #>  #> $ci #> [1] 0.95 #>  #> $sigdig #> [1] 4 #>  #> $sigdigTable #> [1] 4 #>  #> $muRefCovAlg #> [1] TRUE #>  #> $genRxControl #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"nlmeControl\""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlminbControl.html","id":null,"dir":"Reference","previous_headings":"","what":"nlmixr2 nlminb defaults — nlminbControl","title":"nlmixr2 nlminb defaults — nlminbControl","text":"nlmixr2 nlminb defaults","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlminbControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nlmixr2 nlminb defaults — nlminbControl","text":"","code":"nlminbControl(   eval.max = 200,   iter.max = 150,   trace = 0,   abs.tol = 0,   rel.tol = 1e-10,   x.tol = 1.5e-08,   xf.tol = 2.2e-14,   step.min = 1,   step.max = 1,   sing.tol = rel.tol,   scale = 1,   scale.init = NULL,   diff.g = NULL,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   returnNlminb = FALSE,   solveType = c(\"hessian\", \"grad\", \"fun\"),   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   eventType = c(\"central\", \"forward\"),   shiErr = (.Machine$double.eps)^(1/3),   shi21maxFD = 20L,   optimHessType = c(\"central\", \"forward\"),   hessErr = (.Machine$double.eps)^(1/3),   shi21maxHess = 20L,   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   gradTo = 1,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"nlminb\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlminbControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nlmixr2 nlminb defaults — nlminbControl","text":"eval.max Maximum number evaluations objective function allowed.  Defaults 200. iter.max Maximum number iterations allowed.  Defaults 150. trace value objective function parameters printed every trace'th iteration.  0 trace information printed abs.tol Absolute tolerance.  Defaults 0 absolute convergence test used.  objective function known non-negative, previous default `1e-20` appropriate rel.tol Relative tolerance.  Defaults `1e-10`. x.tol X tolerance.  Defaults `1.5e-8`. xf.tol false convergence tolerance.  Defaults `2.2e-14`. step.min Minimum step size.  Default ‘1.’. step.max Maximum step size.  Default ‘1.’. sing.tol singular convergence tolerance; defaults `rel.tol;. scale See PORT documentation (leave alone). scale.init ... probably need check PORT documentation diff.g estimated bound relative error objective function value rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. returnNlminb logical; TRUE return nlminb result instead nlmixr2 fit object solveType tells `nlm` use nlmixr2's analytical   gradients available (finite differences used   event-related parameters like parameters controlling lag time,   duration/rate infusion, modeled bioavailability). can   : - `\"hessian\"` use analytical gradients create     Hessian finite differences. - `\"gradient\"` use gradient let `nlm` calculate    finite difference hessian - `\"fun\"` nlm calculate finite difference    gradient finite difference Hessian using nlmixr2's finite differences, \"ideal\" step size  either central forward differences optimized  Shi2021 method may give accurate derivatives stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced eventType Event gradient type dosing events; Can \"central\" \"forward\" shiErr represents epsilon optimizing ideal step size numeric differentiation using Shi2021 method shi21maxFD maximum number steps optimization forward difference step size using dosing events (lag time, modeled duration/rate bioavailability) optimHessType hessian type calculating individual hessian numeric differences (generalized log-likelihood estimation).  options \"central\", \"forward\".  central differences R's `optimHess()` uses default method. (Though \"forward\" faster still reasonable cases).  Shi21 changed Gill83 algorithm optimHess generalized likelihood problem. hessErr represents epsilon optimizing Hessian step size using Shi2021 method. shi21maxHess Maximum number times optimize best step size hessian calculation useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. gradTo factor gradient scaled optimizing.  works scaleType=\"nlmixr2\". addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::nlminbControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlminbControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nlmixr2 nlminb defaults — nlminbControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlminbControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"nlmixr2 nlminb defaults — nlminbControl","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"nlminb\") #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(θ) #> → finding duplicate expressions in nlm llik gradient... #> → optimizing duplicate expressions in nlm llik gradient... #> → finding duplicate expressions in nlm pred-only... #> → optimizing duplicate expressions in nlm pred-only... #>   #>   #>   #>   #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9072 #> → compress parHistData in nlmixr2 object, save 2808  print(fit2) #> ── nlmixr² log-likelihood nlminb ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -687.2881 1156.589 1171.312      -575.2945        587.8147        74.15538 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.002062 0.038    0.009 1.774938 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.     SE  %RSE  Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.5676 0.2307 40.65 -0.5676 (-1.02, -0.1154)                     #> Em    5.732  2.927 51.07 5.732 (-0.005937, 11.47)                     #> E50    3.14  1.492  47.5     3.14 (0.2169, 6.064)                     #> g         2  FIXED FIXED                        2                     #>   #>   Covariance Type ($covMethod): r (nlminb) #>   Censoring ($censInformation): No censoring #>   Minimization message ($message):   #>     relative convergence (4)  #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0165     0 -0.449 -0.567 #> 2 1     0.0372     1 -1.02  -0.567 #> 3 1     0.0882     1 -1.01  -0.563 #> # ℹ 997 more rows  # you can also get the nlm output with fit2$nlminb  fit2$nlminb #> $par #>         E0         Em        E50  #> -0.5676345  5.7316674  3.1404447  #>  #> $objective #> [1] 575.2945 #>  #> $convergence #> [1] 0 #>  #> $iterations #> [1] 8 #>  #> $evaluations #> function gradient  #>       16        9  #>  #> $message #> [1] \"relative convergence (4)\" #>  #> $scaleC #> [1] 0.002991343 0.037227160 0.034581662 #>  #> $parHistData #>    iter                type     objf            E0            Em           E50 #> 1     1              Scaled 667.4395 -1.000000e+00 -1.000000e+00  1.000000e+00 #> 2     1            Unscaled 667.4395  5.000000e-01  5.000000e-01  2.000000e+00 #> 3     1    Back-Transformed 667.4395  5.000000e-01  5.000000e-01  2.000000e+00 #> 4     2              Scaled 666.5136 -1.225326e+00 -1.115838e-01  1.020822e+00 #> 5     2            Unscaled 666.5136  4.993260e-01  5.330732e-01  2.000720e+00 #> 6     2    Back-Transformed 666.5136  4.993260e-01  5.330732e-01  2.000720e+00 #> 7     3              Scaled 663.9271 -2.093563e+00  2.514772e+00  1.177080e+00 #> 8     3            Unscaled 663.9271  4.967288e-01  6.308450e-01  2.006124e+00 #> 9     3    Back-Transformed 663.9271  4.967288e-01  6.308450e-01  2.006124e+00 #> 10    4              Scaled 655.8650 -9.000211e+00  1.126673e+01  3.342632e+00 #> 11    4            Unscaled 655.8650  4.760686e-01  9.566555e-01  2.081012e+00 #> 12    4    Back-Transformed 655.8650  4.760686e-01  9.566555e-01  2.081012e+00 #> 13    5              Scaled 642.6739 -3.478339e+01  2.137661e+01  1.019116e+01 #> 14    5            Unscaled 642.6739  3.989423e-01  1.333018e+00  2.317846e+00 #> 15    5    Back-Transformed 642.6739  3.989423e-01  1.333018e+00  2.317846e+00 #> 16    6              Scaled 619.4996 -1.030791e+02  3.486979e+01  1.767987e+01 #> 17    6            Unscaled 619.4996  1.946463e-01  1.835330e+00  2.576818e+00 #> 18    6    Back-Transformed 619.4996  1.946463e-01  1.835330e+00  2.576818e+00 #> 19    7              Scaled 589.6730 -2.727326e+02  6.085355e+01  1.808770e+01 #> 20    7            Unscaled 589.6730 -3.128454e-01  2.802632e+00  2.590921e+00 #> 21    7    Back-Transformed 589.6730 -3.128454e-01  2.802632e+00  2.590921e+00 #> 22    8              Scaled 756.6679 -4.903503e+02  8.896321e+01 -4.082895e+01 #> 23    8            Unscaled 756.6679 -9.638147e-01  3.849075e+00  5.534855e-01 #> 24    8    Back-Transformed 756.6679 -9.638147e-01  3.849075e+00  5.534855e-01 #> 25    9              Scaled 581.9043 -2.858492e+02  7.803395e+01  9.813798e+00 #> 26    9            Unscaled 581.9043 -3.520817e-01  3.442210e+00  2.304796e+00 #> 27    9    Back-Transformed 581.9043 -3.520817e-01  3.442210e+00  2.304796e+00 #> 28   10              Scaled 578.7259 -3.010772e+02  9.316947e+01  1.884865e+01 #> 29   10            Unscaled 578.7259 -3.976339e-01  4.005662e+00  2.617236e+00 #> 30   10    Back-Transformed 578.7259 -3.976339e-01  4.005662e+00  2.617236e+00 #> 31   11              Scaled 576.3628 -3.363878e+02  1.057256e+02  2.169725e+01 #> 32   11            Unscaled 576.3628 -5.032600e-01  4.473092e+00  2.715745e+00 #> 33   11    Back-Transformed 576.3628 -5.032600e-01  4.473092e+00  2.715745e+00 #> 34   12              Scaled 575.3869 -3.650403e+02  1.247436e+02  2.639989e+01 #> 35   12            Unscaled 575.3869 -5.889695e-01  5.181076e+00  2.878370e+00 #> 36   12    Back-Transformed 575.3869 -5.889695e-01  5.181076e+00  2.878370e+00 #> 37   13              Scaled 575.3004 -3.591877e+02  1.354750e+02  3.202478e+01 #> 38   13            Unscaled 575.3004 -5.714624e-01  5.580576e+00  3.072888e+00 #> 39   13    Back-Transformed 575.3004 -5.714624e-01  5.580576e+00  3.072888e+00 #> 40   14              Scaled 575.2945 -3.580384e+02  1.391476e+02  3.379290e+01 #> 41   14            Unscaled 575.2945 -5.680245e-01  5.717296e+00  3.134033e+00 #> 42   14    Back-Transformed 575.2945 -5.680245e-01  5.717296e+00  3.134033e+00 #> 43   15              Scaled 575.2945 -3.579110e+02  1.395271e+02  3.397491e+01 #> 44   15            Unscaled 575.2945 -5.676433e-01  5.731426e+00  3.140327e+00 #> 45   15    Back-Transformed 575.2945 -5.676433e-01  5.731426e+00  3.140327e+00 #> 46   16              Scaled 575.2945 -3.579081e+02  1.395336e+02  3.397831e+01 #> 47   16            Unscaled 575.2945 -5.676345e-01  5.731667e+00  3.140445e+00 #> 48   16    Back-Transformed 575.2945 -5.676345e-01  5.731667e+00  3.140445e+00 #> 49   17              Scaled 575.2945 -3.579081e+02  1.395336e+02  3.397831e+01 #> 50   17            Unscaled 575.2945 -5.676345e-01  5.731667e+00  3.140445e+00 #> 51   17    Back-Transformed 575.2945 -5.676345e-01  5.731667e+00  3.140445e+00 #> 52    1 Forward Sensitivity       NA  2.374484e-01 -1.001859e+00 -1.550203e-02 #> 53    7 Forward Sensitivity       NA -1.455773e-02 -6.061276e-01  4.122381e-01 #> 54    9 Forward Sensitivity       NA  8.977175e-02 -7.292494e-02 -1.668496e-01 #> 55   11 Forward Sensitivity       NA  2.009114e-02 -7.229962e-02  3.156044e-02 #> 56   12 Forward Sensitivity       NA -3.813890e-03 -2.128132e-02  1.770812e-02 #> 57   13 Forward Sensitivity       NA -4.754851e-04 -4.823774e-03  4.115251e-03 #> 58   14 Forward Sensitivity       NA -5.738836e-05 -4.434199e-04  4.145758e-04 #> 59   15 Forward Sensitivity       NA -5.381231e-07 -4.341575e-06  5.911731e-07 #> 60   16 Forward Sensitivity       NA  6.723736e-10  1.404030e-09 -7.745115e-08 #>  #> $par.scaled #>         E0         Em        E50  #> -357.90805  139.53362   33.97831  #>  #> $hessian #>               E0           Em          E50 #> E0   0.001787365  0.002540405 -0.006239682 #> Em   0.002540405  0.008714471 -0.017563512 #> E50 -0.006239682 -0.017563512  0.038745748 #>  #> $covMethod #> [1] \"r (nlminb)\" #>  #> $cov.scaled #>           E0       Em      E50 #> E0  5949.638 2276.271 1989.977 #> Em  2276.271 6183.655 3169.636 #> E50 1989.977 3169.636 1860.508 #>  #> $cov #>             E0        Em       E50 #> E0  0.05323816 0.2534838 0.2058545 #> Em  0.25348381 8.5696890 4.0805163 #> E50 0.20585446 4.0805163 2.2249650 #>  #> $r #>                E0           Em          E50 #> E0   0.0008936825  0.001270203 -0.003119841 #> Em   0.0012702027  0.004357236 -0.008781756 #> E50 -0.0031198409 -0.008781756  0.019372874 #>  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":null,"dir":"Reference","previous_headings":"","what":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"nlmixr2 R package fitting population pharmacokinetic (PK) pharmacokinetic-pharmacodynamic (PKPD) models.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"","code":"nlmixr2(   object,   data,   est = NULL,   control = list(),   table = tableControl(),   ...,   save = NULL,   envir = parent.frame() )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"object Fitted object function specifying model. data nlmixr data est estimation method (methods shown `nlmixr2AllEst()`). Methods can added tools control estimation control object.  expected different type estimation method table output table control object (like `tableControl()`) ... Additional arguments passed nlmixr2est::nlmixr2(). save Boolean save nlmixr2 object rds file working directory.  NULL, uses option \"nlmixr2.save\" envir Environment nlmixr object/function evaluated running estimation routine.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"Either nlmixr2 model nlmixr2 fit object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"nlmixr2 generalized function allows common access nlmixr2 estimation routines. nlmixr object following fields:","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"nlmixr-modeling-mini-language","dir":"Reference","previous_headings":"","what":"nlmixr modeling mini-language","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"Rationale nlmixr estimation routines way specifying models.  Often models specified ways intuitive one estimation routine, make sense another estimation routine.  Sometimes, legacy estimation routines like nlme syntax outside control nlmixr package. unique syntax routine makes routines easier maintain expand, allows interfacing existing packages outside nlmixr (like nlme).  However, model definition language common estimation methods, output object uniform, make easier switch estimation routines facilitate interfacing output external packages like Xpose. nlmixr mini-modeling language, attempts address issue incorporating common language.  language inspired R NONMEM, since languages familiar many pharmacometricians. Initial Estimates boundaries population parameters nlmixr models contained R function two blocks: ini model.  R function can named anything, meant called directly R.  fact try likely get error Error: find function \"ini\". ini model block meant hold initial estimates model, boundaries parameters estimation routines support boundaries (note nlmixr's saem nlme currently support parameter boundaries). explain initial estimates specified start annotated example: shown examples: Simple parameter values specified R-compatible assignment Boundaries specified c(lower, est, upper). Like NONMEM, c(lower,est) equivalent c(lower,est,Inf) Also like NONMEM, c(est) specify lower bound, equivalent   specifying parameter  without R's `c` function. initial estimates specified variance scale, analogy      NONMEM, square roots diagonal elements correspond coefficients      variation used exponential IIV implementation parameters can named almost R compatible name.  Please note : Residual error estimates coded population estimates (.e. using    '=' '<-' statement, '~'). Naming variables start \"_\" supported.  Note R     allow variable starting \"_\" assigned without quoting . Naming variables start \"rx_\" \"nlmixr_\"   supported since rxode2 nlmixr2 use prefixes   internally certain estimation routines calculating residuals. Variable names case sensitive, just like R. \"CL\"    \"Cl\". Initial Estimates subject error distribution (NONMEM's  $OMEGA) mixture models, multivariate normal individual deviations population parameters estimated (NONMEM called eta parameters).  Additionally variance/covariance matrix deviations also estimated (NONMEM OMEGA matrix).  also initial estimates.  nlmixr specified `~` operator typically used R \"modeled \", chosen distinguish estimates population residual error parameters. Continuing prior example, can annotate estimates subject error distribution shown examples: Simple variances specified variable name     estimate separated `~`. Correlated parameters specified sum variable    labels lower triangular matrix covariance    specified left handed side equation. also    separated `~`. Currently model syntax allow comments inside lower triangular matrix. Model Syntax ODE based models (NONMEM's $PK, $PRED, $DES $ERROR) initialization block defined, can define model terms defined variables ini block.  can also mix RxODE blocks model. current method defining nlmixr model specify parameters, possibly RxODE lines: Continuing describing syntax annotated example: points note: Parameters often defined differential equations. differential equations, parameters error terms single      block, instead multiple sections. State names, calculated variables start either \"rx_\"      \"nlmixr_\" since used internally estimation routines. Errors specified using `~`.  Currently can use either add(parameter)      additive error,  prop(parameter) proportional error add(parameter1) + prop(parameter2)      additive plus proportional error.  can also specify norm(parameter) additive error,      since follows normal distribution. routines, like saem require  parameters terms Pop.Parameter + Individual.Deviation.Parameter + Covariate*Covariate.Parameter.      order parameters matter.  similar NONMEM's mu-referencing, though      quite restrictive. type parameter model determined initial block;  Covariates used      model missing ini block.  variables need present modeling      dataset model run. Model Syntax solved PK systems Solved PK systems also currently supported nlmixr `linCmt()` pseudo-function.  annotated example solved system : ##' things keep mind: RxODE allows mixing solved systems ODEs,     implemented nlmixr yet. solved systems implemented one, two three compartment     models without first-order absorption.  models support     lag time tlag parameter. general linear compartment model figures model parameter names.     nlmixr currently knows numbered volumes, Vc/Vp, Clearances terms Cl     Q/CLD.  Additionally nlmixr knows elimination micro-constants (ie K12).  Mixing     parameters models currently supported. Checking model syntax specifying model syntax can check nlmixr interpreting correctly using nlmixr function . Using function can get: general gives information model (type solved system/RxODE), initial estimates well code model block. Using model syntax estimating model model function created, can use dataset estimate parameters model given dataset. dataset RxODE compatible events IDs.  Monolix NONMEM use similar standard nlmixr can support. data converted appropriate format, can use nlmixr function run appropriate code. method estimate model : Currently nlme saem implemented.  example, run model saem, following: options saem controlled saemControl. may wish make sure minimization complete case saem.  can traceplot shows iteration history divided burn-EM phases.  case, burn seems reasonable; may wish increase number iterations EM phase estimation. Overall probably semi-reasonable solution. nlmixr output objects addition unifying modeling language sent estimation routines, outputs currently unified structure. can see fit object typing object name: example shows typical printout nlmixr fit object.  elements fit : type fit (nlme, saem, etc) Metrics goodness fit (AIC, BIC,    logLik). align comparison methods, FOCEi likelihood objective calculated           regardless method used used goodness fit metrics. FOCEi likelihood compared NONMEM's objective function gives          values (based data Wang 2007) Also note saem calculate objective function,             FOCEi used objective function fit. Even though objective functions calculated manner, caution          used comparing fits various estimation routines. next item timing steps fit. can also accessed (fit.s$time). mnemonic, access item shown printout.         true almost items printout. timing fit, parameter estimates displayed (can accessed    fit.s$par.fixed) items rounded R printing, estimate without rounding still accessible `$` syntax.        example, `$Untransformed` gives untransformed parameter values. Untransformed parameter takes log-space parameters back-transforms normal parameters.  CIs        listed back-transformed parameter space. Proportional Errors converted Omega block (accessed fit.s$omega) table fit data. Please note: nlmixr fit object actually data frame.  Saving Rdata object loading        without nlmixr just show data .  worry; fit information vanished,        can bring back simply loading nlmixr, accessing data. Special access fit information (like $omega) needs nlmixr extract information. use $ access information, order precedence : Fit data overall data.frame Information parsed nlmixr model (via $uif) Parameter history available (via $par.hist $par.hist.stacked) Fixed effects table (via $par.fixed) Individual differences typical population parameters (via $eta) Fit information list information generated post-hoc            residual calculation. Fit information environment post-hoc residual calculated Fit information data options interacted specified model            (estimation options solved system infusion IV bolus). printout may displays data data.table object tbl        object, data objects, rather derived data frame. Since object data.frame, can treat like one. addition properties fit object, additional may helpful modeler: $theta gives fixed effects parameter estimates (NONMEM     thetas). can also accessed fixed.effects     function. Note residual variability treated fixed effect parameter     included list. $eta gives random effects parameter estimates, NONMEM     etas.  can also accessed using random.effects     function.","code":"f <- function(){ ## Note the arguments to the function are currently                  ## ignored by nlmixr     ini({         ## Initial conditions for population parameters (sometimes         ## called theta parameters) are defined by either `<-` or '='         lCl <- 1.6      #log Cl (L/hr)         ## Note that simple expressions that evaluate to a number are         ## OK for defining initial conditions (like in R)         lVc = log(90)  #log V (L)         ## Also a comment on a parameter is captured as a parameter label         lKa <- 1 #log Ka (1/hr)         ## Bounds may be specified by c(lower, est, upper), like NONMEM:         ## Residuals errors are assumed to be population parameters         prop.err <- c(0, 0.2, 1)     })     ## The model block will be discussed later     model({}) } f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc = log(90)  #log V (L)         lKa <- 1 #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         ## Initial estimate for ka IIV variance         ## Labels work for single parameters         eta.ka ~ 0.1 # BSV Ka          ## For correlated parameters, you specify the names of each         ## correlated parameter separated by a addition operator `+`         ## and the left handed side specifies the lower triangular         ## matrix initial of the covariance matrix.         eta.cl + eta.vc ~ c(0.1,                             0.005, 0.1)         ## Note that labels do not currently work for correlated         ## parameters.  Also do not put comments inside the lower         ## triangular matrix as this will currently break the model.     })     ## The model block will be discussed later     model({}) } f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc <- log(90)   #log Vc (L)         lKA <- 0.1      #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         eta.Cl ~ 0.1 ## BSV Cl         eta.Vc ~ 0.1 ## BSV Vc         eta.KA ~ 0.1 ## BSV Ka     })     model({         ## First parameters are defined in terms of the initial estimates         ## parameter names.         Cl <- exp(lCl + eta.Cl)         Vc = exp(lVc + eta.Vc)         KA <- exp(lKA + eta.KA)         ## After the differential equations are defined         kel <- Cl / Vc;         d/dt(depot)    = -KA*depot;         d/dt(centr)  =  KA*depot-kel*centr;         ## And the concentration is then calculated         cp = centr / Vc;         ## Last, nlmixr is told that the plasma concentration follows         ## a proportional error (estimated by the parameter prop.err)         cp ~ prop(prop.err)     }) } f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc <- log(90)   #log Vc (L)         lKA <- 0.1      #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         eta.Cl ~ 0.1 ## BSV Cl         eta.Vc ~ 0.1 ## BSV Vc         eta.KA ~ 0.1 ## BSV Ka     })     model({         Cl <- exp(lCl + eta.Cl)         Vc = exp(lVc + eta.Vc)         KA <- exp(lKA + eta.KA)         ## Instead of specifying the ODEs, you can use         ## the linCmt() function to use the solved system.         ##         ## This function determines the type of PK solved system         ## to use by the parameters that are defined.  In this case         ## it knows that this is a one-compartment model with first-order         ## absorption.         linCmt() ~ prop(prop.err)     }) } > nlmixr(f) ## 1-compartment model with first-order absorption in terms of Cl ## Initialization: ################################################################################ Fixed Effects ($theta):     lCl     lVc     lKA 1.60000 4.49981 0.10000  Omega ($omega):      [,1] [,2] [,3] [1,]  0.1  0.0  0.0 [2,]  0.0  0.1  0.0 [3,]  0.0  0.0  0.1  ## Model: ################################################################################ Cl <- exp(lCl + eta.Cl) Vc = exp(lVc + eta.Vc) KA <- exp(lKA + eta.KA) ## Instead of specifying the ODEs, you can use ## the linCmt() function to use the solved system. ## ## This function determines the type of PK solved system ## to use by the parameters that are defined.  In this case ## it knows that this is a one-compartment model with first-order ## absorption. linCmt() ~ prop(prop.err) fit <- nlmixr(model.function, dataset, est=\"est\", control=estControl(options)) > f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc <- log(90)   #log Vc (L)         lKA <- 0.1      #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         eta.Cl ~ 0.1 ## BSV Cl         eta.Vc ~ 0.1 ## BSV Vc         eta.KA ~ 0.1 ## BSV Ka     })     model({         ## First parameters are defined in terms of the initial estimates         ## parameter names.         Cl <- exp(lCl + eta.Cl)         Vc = exp(lVc + eta.Vc)         KA <- exp(lKA + eta.KA)         ## After the differential equations are defined         kel <- Cl / Vc;         d/dt(depot)    = -KA*depot;         d/dt(centr)  =  KA*depot-kel*centr;         ## And the concentration is then calculated         cp = centr / Vc;         ## Last, nlmixr is told that the plasma concentration follows         ## a proportional error (estimated by the parameter prop.err)         cp ~ prop(prop.err)     }) } > fit.s <- nlmixr(f,d,est=\"saem\",control=saemControl(n.burn=50,n.em=100,print=50)); Compiling RxODE differential equations...done. c:/Rtools/mingw_64/bin/g++  -I\"c:/R/R-34~1.1/include\" -DNDEBUG     -I\"d:/Compiler/gcc-4.9.3/local330/include\"  -Ic:/nlmixr/inst/include -Ic:/R/R-34~1.1/library/STANHE~1/include -Ic:/R/R-34~1.1/library/Rcpp/include -Ic:/R/R-34~1.1/library/RCPPAR~1/include -Ic:/R/R-34~1.1/library/RCPPEI~1/include -Ic:/R/R-34~1.1/library/BH/include   -O2 -Wall  -mtune=core2 -c saem3090757b4bd1x64.cpp -o saem3090757b4bd1x64.o In file included from c:/R/R-34~1.1/library/RCPPAR~1/include/armadillo:52:0,                  from c:/R/R-34~1.1/library/RCPPAR~1/include/RcppArmadilloForward.h:46,                  from c:/R/R-34~1.1/library/RCPPAR~1/include/RcppArmadillo.h:31,                  from saem3090757b4bd1x64.cpp:1: c:/R/R-34~1.1/library/RCPPAR~1/include/armadillo_bits/compiler_setup.hpp:474:96: note: #pragma message: WARNING: use of OpenMP disabled; this compiler doesn't support OpenMP 3.0+    #pragma message (\"WARNING: use of OpenMP disabled; this compiler doesn't support OpenMP 3.0+\")                                                                                                 ^ c:/Rtools/mingw_64/bin/g++ -shared -s -static-libgcc -o saem3090757b4bd1x64.dll tmp.def saem3090757b4bd1x64.o c:/nlmixr/R/rx_855815def56a50f0e7a80e48811d947c_x64.dll -Lc:/R/R-34~1.1/bin/x64 -lRblas -Lc:/R/R-34~1.1/bin/x64 -lRlapack -lgfortran -lm -lquadmath -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -Lc:/R/R-34~1.1/bin/x64 -lR done. 1:    1.8174   4.6328   0.0553   0.0950   0.0950   0.0950   0.6357 50:    1.3900   4.2039   0.0001   0.0679   0.0784   0.1082   0.1992 100:    1.3894   4.2054   0.0107   0.0686   0.0777   0.1111   0.1981 150:    1.3885   4.2041   0.0089   0.0683   0.0778   0.1117   0.1980 Using sympy via SnakeCharmR ## Calculate ETA-based prediction and error derivatives: Calculate Jacobian...................done. Calculate sensitivities....... done. ## Calculate d(f)/d(eta) ## ... ## done ## ... ## done The model-based sensitivities have been calculated Calculating Table Variables... done > fit.s  -- nlmixr SAEM fit (ODE); OBJF calculated from FOCEi approximation -------------       OBJF      AIC      BIC Log-likelihood Condition Number   62337.09 62351.09 62399.01      -31168.55          82.6086   -- Time (sec; fit.s$time): -----------------------------------------------------            saem setup Likelihood Calculation covariance table  elapsed 430.25 31.64                   1.19          0  3.44   -- Parameters (fit.s$par.fixed): -----------------------------------------------               Parameter Estimate     SE    lCl      log Cl (L/hr)     1.39 0.0240  1.73       4.01 (3.83, 4.20)    26.6  lVc         log Vc (L)     4.20 0.0256 0.608       67.0 (63.7, 70.4)    28.5  lKA      log Ka (1/hr)  0.00924 0.0323  349.      1.01 (0.947, 1.08)    34.3  prop.err      prop.err    0.198                             19.8           Shrink(SD)  lCl          0.248  lVc           1.09  lKA           4.19  prop.err      1.81     No correlations in between subject variability (BSV) matrix    Full BSV covariance (fit.s$omega) or correlation (fit.s$omega.R; diagonals=SDs)    Distribution stats (mean/skewness/kurtosis/p-value) available in fit.s$shrink   -- Fit Data (object fit.s is a modified data.frame): ---------------------------  # A tibble: 6,947 x 22    ID     TIME    DV  PRED    RES    WRES IPRED  IRES  IWRES CPRED   CRES  * <fct> <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  1 1      0.25  205.  198.   6.60  0.0741  189.  16.2  0.434  198.   6.78  2 1      0.5   311.  349. -38.7  -0.261   330. -19.0 -0.291  349. -38.3  3 1      0.75  389.  464. -74.5  -0.398   434. -45.2 -0.526  463. -73.9  # ... with 6,944 more rows, and 11 more variables: CWRES <dbl>, eta.Cl <dbl>,  #   eta.Vc <dbl>, eta.KA <dbl>, depot <dbl>, centr <dbl>, Cl <dbl>, Vc <dbl>,  #   KA <dbl>, kel <dbl>, cp <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"","code":"# \\donttest{  one.cmt <- function() {  ini({    ## You may label each parameter with a comment    tka <- 0.45 # Ka    tcl <- log(c(0, 2.7, 100)) # Log Cl    ## This works with interactive models    ## You may also label the preceding line with label(\"label text\")    tv <- 3.45; label(\"log V\")    ## the label(\"Label name\") works with all models    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7    prop.sd <- 0.01  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd) + prop(prop.sd)  }) }  # fitF <- nlmixr(one.cmt, theo_sd, \"focei\")  fitS <- nlmixr(one.cmt, theo_sd, \"saem\") #>   #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> ℹ calculate uninformed etas #> ℹ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd\tprop.sd #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> → optimizing duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 64632 #> → compress parHistData in nlmixr2 object, save 14784 #> → compress saem0 in nlmixr2 object, save 29000  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2CheckInstall.html","id":null,"dir":"Reference","previous_headings":"","what":"Check your nlmixr2 installation for potential issues — nlmixr2CheckInstall","title":"Check your nlmixr2 installation for potential issues — nlmixr2CheckInstall","text":"Check nlmixr2 installation potential issues","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2CheckInstall.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Check your nlmixr2 installation for potential issues — nlmixr2CheckInstall","text":"","code":"nlmixr2CheckInstall()"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2CheckInstall.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Check your nlmixr2 installation for potential issues — nlmixr2CheckInstall","text":"","code":"nlmixr2CheckInstall() #> ℹ Operating system: Linux 6.5.0-1021-azure #22~22.04.1-Ubuntu SMP Tue Apr 30 16:08:18 UTC 2024 #> Loading required namespace: devtools #> ✔ The 'make' command was found:  /usr/bin/make #> ℹ GNU Make 4.3 #> Built for x86_64-pc-linux-gnu #> Copyright (C) 1988-2020 Free Software Foundation, Inc. #> License GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html> #> This is free software: you are free to change and redistribute it. #> There is NO WARRANTY, to the extent permitted by law. #> ✔ The package 'rxode2' is installed and seems to be up to date, version 2.1.3.9000 #> ✔ The package 'rxode2et' is installed and seems to be up to date, version 2.0.13 #> ✔ The package 'rxode2parse' is installed and seems to be up to date, version 2.0.19 #> ✔ The package 'rxode2ll' is installed and seems to be up to date, version 2.0.11.9000 #> ✔ The package 'rxode2random' is installed and seems to be up to date, version 2.1.1.9000 #> ✔ The package 'lotri' is installed and seems to be up to date, version 0.4.4 #> ✔ The package 'nlmixr2' is installed and seems to be up to date, version 2.1.2 #> ✔ The package 'nlmixr2est' is installed and seems to be up to date, version 2.2.2.9000 #> ✔ The package 'nlmixr2data' is installed and seems to be up to date, version 2.0.9 #> ✔ The package 'nlmixr2extra' is installed and seems to be up to date, version 2.0.10 #> ✔ The package 'nlmixr2plot' is installed and seems to be up to date, version 2.0.9 #> ✖ The package 'nlmixr2lib' is not installed (it is optional for all rxode2/nlmixr2 work) #> ✖ The package 'nonmem2rx' is not installed (it is optional for all rxode2/nlmixr2 work) #> ✖ The package 'babelmixr2' is not installed (it is optional for all rxode2/nlmixr2 work) #> ℹ To install missing packages, run the following command: #> install.packages(c('nlmixr2lib', 'nonmem2rx', 'babelmixr2'))"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlsControl.html","id":null,"dir":"Reference","previous_headings":"","what":"nlmixr2 defaults controls for nls — nlsControl","title":"nlmixr2 defaults controls for nls — nlsControl","text":"nlmixr2 defaults controls nls","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlsControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nlmixr2 defaults controls for nls — nlsControl","text":"","code":"nlsControl(   maxiter = 10000,   tol = 1e-05,   minFactor = 1/1024,   printEval = FALSE,   warnOnly = FALSE,   scaleOffset = 0,   nDcentral = FALSE,   algorithm = c(\"LM\", \"default\", \"plinear\", \"port\"),   ftol = sqrt(.Machine$double.eps),   ptol = sqrt(.Machine$double.eps),   gtol = 0,   diag = list(),   epsfcn = 0,   factor = 100,   maxfev = integer(),   nprint = 0,   solveType = c(\"grad\", \"fun\"),   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   eventType = c(\"central\", \"forward\"),   shiErr = (.Machine$double.eps)^(1/3),   shi21maxFD = 20L,   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   gradTo = 1,   trace = FALSE,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   returnNls = FALSE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlsControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nlmixr2 defaults controls for nls — nlsControl","text":"maxiter positive integer specifying maximum number     iterations allowed. tol positive numeric value specifying tolerance level     relative offset convergence criterion. minFactor positive numeric value specifying minimum     step-size factor allowed step iteration.      increment calculated Gauss-Newton algorithm     successively halved residual sum squares     decreased step-size factor reduced     limit. printEval logical specifying whether number evaluations     (steps gradient direction taken iteration) printed. warnOnly logical specifying whether nls()     return instead signalling error case termination     convergence.     Termination convergence happens upon completion maxiter     iterations, case singular gradient, case     step-size factor reduced minFactor. scaleOffset constant added denominator relative     offset convergence criterion calculation avoid zero divide case     fit model data close.  default value     0 keeps legacy behaviour nls().  value     1 seems work problems reasonable scale small     residuals. nDcentral numerical derivatives used:     logical indicating central differences     employed, .e., numericDeriv(*, central=TRUE)     used. algorithm character string specifying algorithm use.     default algorithm Gauss-Newton algorithm.  possible     values \"plinear\" Golub-Pereyra algorithm     partially linear least-squares models \"port\"     ‘nl2sol’ algorithm Port library -- see     references.  Can abbreviated. ftol non-negative numeric. Termination occurs       actual predicted relative reductions sum       squares ftol. Therefore, ftol measures       relative error desired sum squares. ptol non-negative numeric. Termination occurs       relative error two consecutive iterates       ptol. Therefore, ptol measures relative error       desired approximate solution. gtol non-negative numeric. Termination occurs       cosine angle result fn evaluation       \\(fvec\\) column Jacobian gtol       absolute value. Therefore, gtol measures       orthogonality desired function vector       columns Jacobian. diag list numeric vector containing positive       entries serve multiplicative scale factors       parameters. Length diag equal       par. , user-provided diag ignored       diag internally set. epsfcn (used jac provided)       numeric used determining suitable step       forward-difference approximation. approximation assumes       relative errors functions order       epsfcn. epsfcn less machine       precision, assumed relative errors       functions order machine precision. factor positive numeric, used determining       initial step bound.  bound set product       factor \\(|\\code{diag}*\\code{par}|\\) nonzero,       else factor . cases factor       lie interval (0.1,100). 100 generally       recommended value. maxfev integer; termination occurs       number calls fn reached maxfev.       Note nls.lm sets value maxfev        100*(length(par) + 1)        maxfev = integer(), par list       vector parameters optimized. nprint integer; set nprint positive       enable printing iterates solveType tells `nlm` use nlmixr2's analytical   gradients available (finite differences used   event-related parameters like parameters controlling lag time,   duration/rate infusion, modeled bioavailability). can   : - `\"hessian\"` use analytical gradients create     Hessian finite differences. - `\"gradient\"` use gradient let `nlm` calculate    finite difference hessian - `\"fun\"` nlm calculate finite difference    gradient finite difference Hessian using nlmixr2's finite differences, \"ideal\" step size  either central forward differences optimized  Shi2021 method may give accurate derivatives stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced eventType Event gradient type dosing events; Can \"central\" \"forward\" shiErr represents epsilon optimizing ideal step size numeric differentiation using Shi2021 method shi21maxFD maximum number steps optimization forward difference step size using dosing events (lag time, modeled duration/rate bioavailability) useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. gradTo factor gradient scaled optimizing.  works scaleType=\"nlmixr2\". trace logical value indicating trace iteration     progress printed.  Default FALSE.      TRUE residual (weighted) sum--squares, convergence     criterion parameter values printed conclusion     iteration.  Note format() used,     mostly depend getOption(\"digits\").     \"plinear\" algorithm used, conditional     estimates linear parameters printed nonlinear     parameters.  \"port\" algorithm used     objective function value printed half residual (weighted)     sum--squares. rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. returnNls logical; TRUE, return nls object instead nlmixr object addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::nlsControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlsControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"nlmixr2 defaults controls for nls — nlsControl","text":"nls control object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlsControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nlmixr2 defaults controls for nls — nlsControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlsControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"nlmixr2 defaults controls for nls — nlsControl","text":"","code":"# \\donttest{  if (rxode2parse::.linCmtSens()) {  one.cmt <- function() {   ini({    tka <- 0.45    tcl <- log(c(0, 2.7, 100))    tv <- 3.45    add.sd <- 0.7  })  model({    ka <- exp(tka)    cl <- exp(tcl)    v <- exp(tv)    linCmt() ~ add(add.sd)  }) }  # Uses nlsLM from minpack.lm if available  fit1 <- nlmixr(one.cmt, nlmixr2data::theo_sd, est=\"nls\", nlsControl(algorithm=\"LM\"))  # Uses port and respect parameter boundaries fit2 <- nlmixr(one.cmt, nlmixr2data::theo_sd, est=\"nls\", nlsControl(algorithm=\"port\"))  # You can access the underlying nls object with `$nls` fit2$nls } #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of nls model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(θ) #> → finding duplicate expressions in nls gradient... #> → optimizing duplicate expressions in nls gradient... #> → finding duplicate expressions in nls pred-only... #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress parHistData in nlmixr2 object, save 2320 #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of nls model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(θ) #> → finding duplicate expressions in nls gradient... #> → optimizing duplicate expressions in nls gradient... #> → finding duplicate expressions in nls pred-only... #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress parHistData in nlmixr2 object, save 2296 #> Nonlinear regression model #>   model: 0 ~ nlmixr2est::.nlmixrNlsFunValGrad(DV, tka, tcl, tv) #>    data: nlmixr2est::.nlmixrNlsData() #>     tka     tcl      tv  #> -1.0097 -0.6696  1.0423  #>  residual sum-of-squares: 249.7 #>  #> Algorithm \"port\", convergence message: relative convergence (4) # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/optimControl.html","id":null,"dir":"Reference","previous_headings":"","what":"nlmixr2 optim defaults — optimControl","title":"nlmixr2 optim defaults — optimControl","text":"nlmixr2 optim defaults","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/optimControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nlmixr2 optim defaults — optimControl","text":"","code":"optimControl(   method = c(\"Nelder-Mead\", \"BFGS\", \"CG\", \"L-BFGS-B\", \"SANN\", \"Brent\"),   trace = 0,   fnscale = 1,   parscale = 1,   ndeps = 0.001,   maxit = 10000,   abstol = 1e-08,   reltol = 1e-08,   alpha = 1,   beta = 0.5,   gamma = 2,   REPORT = NULL,   warn.1d.NelderMead = TRUE,   type = NULL,   lmm = 5,   factr = 1e+07,   pgtol = 0,   temp = 10,   tmax = 10,   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   eventType = c(\"central\", \"forward\"),   shiErr = (.Machine$double.eps)^(1/3),   shi21maxFD = 20L,   solveType = c(\"grad\", \"fun\"),   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   gradTo = 1,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   returnOptim = FALSE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"optim\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/optimControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nlmixr2 optim defaults — optimControl","text":"method method used. See ‘Details’.  Can abbreviated. trace Non-negative integer. positive, tracing information progress optimization produced. Higher values may produce tracing information: method `\"L-BFGS-B\"`, six levels tracing. See `optim()` information fnscale overall scaling applied value `fn` `gr` optimization. negative, turns problem maximization problem. Optimization performed `fn(par)/fnscale` parscale vector scaling values parameters. Optimization performed `par/parscale` comparable sense unit change element produces unit change scaled value.  used (needed) `method = \"Brent\"` ndeps vector step sizes finite-difference approximation gradient, `par/parscale` scale.  Defaults `1e-3` maxit maximum number iterations. Defaults `100` derivative-based methods, `500` `\"Nelder-Mead\"`. abstol absolute convergence tolerance. useful non-negative functions, tolerance reaching zero. reltol Relative convergence tolerance.  algorithm stops unable reduce value factor `reltol * (abs(val) + reltol)` step alpha Reflection factor `\"Nelder-Mead\"` method. beta Contraction factor `\"Nelder-Mead\"` method gamma Expansion  factor `\"Nelder-Mead\"` method REPORT frequency reports `\"BFGS\"`, `\"L-BFGS-B\"` `\"SANN\"` methods `control$trace` positive. Defaults every 10 iterations `\"BFGS\"` `\"L-BFGS-B\"`, every 100 temperatures `\"SANN\"` warn.1d.NelderMead logical indicating (default) `\"Nelder-Mead\"` method signal warning used one-dimensional minimization.  warning sometimes inappropriate, can suppress setting option `FALSE` type conjugate-gradients method.  Takes value `1` Fletcher-Reeves update, `2` Polak-Ribiere `3` Beale-Sorenson. lmm integer giving number BFGS updates retained `\"L-BFGS-B\"` method, defaults `5` factr controls convergence `\"L-BFGS-B\"` method. Convergence occurs reduction objective within factor machine tolerance. Default `1e7`, tolerance `1e-8`. pgtol helps control convergence ‘\"L-BFGS-B\"’ method.  tolerance projected gradient current search direction. defaults zero, check suppressed temp controls `\"SANN\"` method. starting temperature cooling schedule. Defaults `10`. tmax number function evaluations temperature `\"SANN\"` method. Defaults `10`. stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced eventType Event gradient type dosing events; Can \"central\" \"forward\" shiErr represents epsilon optimizing ideal step size numeric differentiation using Shi2021 method shi21maxFD maximum number steps optimization forward difference step size using dosing events (lag time, modeled duration/rate bioavailability) solveType tells `optim` use nlmixr2's analytical   gradients available (finite differences used   event-related parameters like parameters controlling lag time,   duration/rate infusion, modeled bioavailability). can   : - `\"gradient\"` use gradient let `optim` calculate    finite difference hessian - `\"fun\"` optim calculate finite difference    gradient finite difference Hessian using nlmixr2's finite differences, \"ideal\" step size  either central forward differences optimized  Shi2021 method may give accurate derivatives applied gradient based methods: \"BFGS\", \"CG\", \"L-BFGS-B\" useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. gradTo factor gradient scaled optimizing.  works scaleType=\"nlmixr2\". rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. returnOptim logical; TRUE return optim list instead nlmixr2 fit object addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod allows selection \"r\", uses nlmixr2's `nlmixr2Hess()` hessian calculation \"optim\" uses hessian `stats::optim(.., hessian=TRUE)` adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::optimControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/optimControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"nlmixr2 optim defaults — optimControl","text":"optimControl object nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/optimControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nlmixr2 optim defaults — optimControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/optimControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"nlmixr2 optim defaults — optimControl","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"optim\", optimControl(method=\"BFGS\")) #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(θ) #> → finding duplicate expressions in nlm llik gradient... #> → optimizing duplicate expressions in nlm llik gradient... #> → finding duplicate expressions in nlm pred-only... #> → optimizing duplicate expressions in nlm pred-only... #>   #>   #>   #>   #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9112 #> → compress parHistData in nlmixr2 object, save 10512 fit2 #> ── nlmixr² log-likelihood optim with BFGS method ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -686.7363 1157.141 1171.864      -575.5704        1812.586        137.8774 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.001954 0.021    0.008 2.015046 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.     SE  %RSE   Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.5958 0.2283 38.32 -0.5958 (-1.043, -0.1483)                     #> Em      7.3  5.377 73.66       7.3 (-3.239, 17.84)                     #> E50   3.699  2.165 58.53    3.699 (-0.5442, 7.942)                     #> g         2  FIXED FIXED                         2                     #>   #>   Covariance Type ($covMethod): r #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0304     0 -0.439 -0.595 #> 2 1     0.0320     1 -1.03  -0.595 #> 3 1     0.0329     1 -1.03  -0.595 #> # ℹ 997 more rows # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/preconditionFit.html","id":null,"dir":"Reference","previous_headings":"","what":"Linearly re-parameterize the model to be less sensitive to rounding errors — preconditionFit","title":"Linearly re-parameterize the model to be less sensitive to rounding errors — preconditionFit","text":"Linearly re-parameterize model less sensitive rounding errors","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/preconditionFit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Linearly re-parameterize the model to be less sensitive to rounding errors — preconditionFit","text":"","code":"preconditionFit(fit, estType = c(\"full\", \"posthoc\", \"none\"), ntry = 10L)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/preconditionFit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Linearly re-parameterize the model to be less sensitive to rounding errors — preconditionFit","text":"fit nlmixr2 fit preconditioned estType fit linearly reparameterized, \"full\" estimation, \"posthoc\" estimation simply estimation covariance matrix \"none\" fit updated ntry number tries giving pre-conditioned covariance estimate","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/preconditionFit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Linearly re-parameterize the model to be less sensitive to rounding errors — preconditionFit","text":"nlmixr2 fit object preconditioned stabilize variance/covariance calculation","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/preconditionFit.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Linearly re-parameterize the model to be less sensitive to rounding errors — preconditionFit","text":"Aoki Y, Nordgren R, Hooker AC. Preconditioning Nonlinear Mixed Effects Models Stabilisation Variance-Covariance Matrix Computations. AAPS J. 2016;18(2):505-518. doi:10.1208/s12248-016-9866-5","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. lotri lotri magrittr %>% nlmixr2est .nlmixrNlmeFun, ACF, augPred, fixed.effects, fixef, getData, getVarCov, groupedData, nlme, nlmixr, nlmixr2AllEst, nlmixr2NlmeControl, pdBlocked, pdCompSymm, pdConstruct, pdDiag, pdFactor, pdIdent, pdLogChol, pdMat, pdMatrix, pdNatural, pdSymm, random.effects, ranef, reStruct, varComb, varConstPower, VarCorr, varExp, varFixed, varFunc, varIdent, varPower, varWeights rxode2 add.dosing, add.sampling, et, etExpand, eventTable, expit, geom_amt, geom_cens, ini, ini<-, logit, lotri, model, model<-, probit, probitInv, rxCat, rxClean, rxControl, rxDerived, rxFun, rxode, RxODE, rxode2, rxParam, rxParams, rxSetPipingAuto, rxSolve, stat_amt, stat_cens","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Options for SAEM — saemControl","title":"Control Options for SAEM — saemControl","text":"Control Options SAEM","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Options for SAEM — saemControl","text":"","code":"saemControl(   seed = 99,   nBurn = 200,   nEm = 300,   nmc = 3,   nu = c(2, 2, 2),   print = 1,   trace = 0,   covMethod = c(\"linFim\", \"fim\", \"r,s\", \"r\", \"s\", \"\"),   calcTables = TRUE,   logLik = FALSE,   nnodesGq = 3,   nsdGq = 1.6,   optExpression = TRUE,   literalFix = TRUE,   adjObf = TRUE,   sumProd = FALSE,   addProp = c(\"combined2\", \"combined1\"),   tol = 1e-06,   itmax = 30,   type = c(\"nelder-mead\", \"newuoa\"),   powRange = 10,   lambdaRange = 3,   odeRecalcFactor = 10^(0.5),   maxOdeRecalc = 5L,   perSa = 0.75,   perNoCor = 0.75,   perFixOmega = 0.1,   perFixResid = 0.1,   compress = TRUE,   rxControl = NULL,   sigdig = NULL,   sigdigTable = NULL,   ci = 0.95,   muRefCov = TRUE,   muRefCovAlg = TRUE,   handleUninformativeEtas = TRUE,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Options for SAEM — saemControl","text":"seed Random Seed SAEM step.  (Needs set reproducibility.)  default 99. nBurn Number iterations first phase, ie  MCMC/Stochastic Approximation steps. equivalent Monolix's K_0 K_b. nEm Number iterations Expectation-Maximization (EM) Step. equivalent Monolix's K_1. nmc Number Markov Chains. default 3.  increase number chains numerical integration MC method accurate cost computation.  Monolix equivalent L. nu vector 3 integers. represent     numbers transitions three different kernels used     Hasting-Metropolis algorithm.  default value c(2,2,2),     representing 40 transition initially (value     multiplied 20). first value represents initial number multi-variate     Gibbs samples taken normal distribution. second value represents number uni-variate, multi-     dimensional random walk Gibbs samples taken. third value represents number bootstrap/reshuffling     uni-dimensional random samples taken. print number iterations completed anything printed console.  default, 1. trace integer indicating want trace(1) SAEM algorithm process.  Useful debugging, typical fitting. covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual's     gradient cross-product (evaluated individual empirical     Bayes estimates). \"linFim\" Use Linearized Fisher Information Matrix calculate covariance. \"fim\" Use SAEM-calculated Fisher Information Matrix calculate covariance. \"r,s\" Uses sandwich matrix calculate covariance, : \\(R^-1 \\times S \\times R^-1\\) \"r\" Uses Hessian matrix calculate covariance \\(2\\times R^-1\\) \"s\" Uses crossproduct matrix calculate covariance \\(4\\times S^-1\\) \"\" calculate covariance step. calcTables boolean determine foceiFit calculate tables. default TRUE logLik boolean indicating log-likelihood calculate Gaussian quadrature. nnodesGq number nodes use Gaussian quadrature computing likelihood method (defaults 1, equivalent Laplacian likelihood) nsdGq span (SD) integrate computing likelihood Gaussian quadrature. Defaults 3 (eg 3 times SD) optExpression Optimize rxode2 expression speed calculation. default turned . literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) tol tolerance regression models used complex residual errors (ie add+prop etc) itmax maximum number iterations regression models used complex residual errors.  number iterations itmax*number parameters type indicates type optimization residuals; Can one c(\"nelder-mead\", \"newuoa\") powRange indicates range powers can take residual errors;  default 10 indicating range c(-10, 10) lambdaRange indicates range Box-Cox Yeo-Johnson parameters constrained ;  default 3 indicating range c(-3,3) odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. perSa percent time `nBurn` iterations phase runs runs simulated annealing. perNoCor percentage MCMC phase SAEM algorithm variance/covariance matrix correlations. default 0.75 75 Monte-carlo iteration. perFixOmega percentage `nBurn` phase omega values unfixed allow better exploration likelihood surface.  time, omegas fixed optimization. perFixResid percentage `nBurn` phase residual components unfixed allow better exploration likelihood surface. compress object compressed items rxControl `rxode2` ODE solving options fitting, created `rxControl()` sigdig Specifies \"significant digits\" ode solving requests.  specified controls relative absolute tolerances ODE solvers.  default tolerance 0.5*10^(-sigdig-2) regular ODEs. sensitivity equations default 0.5*10\\^(-sigdig-1.5) (sensitivity changes applicable liblsoda).  also controls atol/rtol steady state solutions. ssAtol/ssRtol 0.5*10\\^(-sigdig) sensitivities 0.5*10\\^(-sigdig+0.625).  default unspecified (NULL) uses standard atol/rtol. sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ci Confidence level tables.  default 0.95 95% confidence. muRefCov controls mu-referenced covariates `saem` handled differently non mu-referenced covariates.  `TRUE`, mu-referenced covariates special handling.  `FALSE` mu-referenced covariates treated input parameter. muRefCovAlg controls algebraic expressions can   mu-referenced treated mu-referenced covariates : 1. Creating internal data-variable `nlmixrMuDerCov#`      algebraic mu-referenced expression 2. Change algebraic expression `nlmixrMuDerCov# * mu_cov_theta` 3. Use internal mu-referenced covariate saem 4. optimization completed, replace `model()` old   `model()` expression 5. Remove `nlmixrMuDerCov#` nlmix2 output general, covariates accurate since changes system linear compartment model.  Therefore, default `TRUE`. handleUninformativeEtas boolean tells nlmixr2's saem calculate uninformative etas handle specially (default `TRUE`). ... Additional arguments passed nlmixr2est::saemControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Options for SAEM — saemControl","text":"List options used nlmixr2 fit     SAEM.","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control Options for SAEM — saemControl","text":"Wenping Wang & Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":null,"dir":"Reference","previous_headings":"","what":"Set/get Objective function type for a nlmixr2 object — setOfv","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"Set/get Objective function type nlmixr2 object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"","code":"setOfv(x, type)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"x nlmixr2 fit object type Type objective function use AIC, BIC, $objective","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"Nothing","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Output table/data.frame options — tableControl","title":"Output table/data.frame options — tableControl","text":"Output table/data.frame options","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output table/data.frame options — tableControl","text":"","code":"tableControl(   npde = NULL,   cwres = NULL,   nsim = 300,   ties = TRUE,   censMethod = c(\"truncated-normal\", \"cdf\", \"ipred\", \"pred\", \"epred\", \"omit\"),   seed = 1009,   cholSEtol = (.Machine$double.eps)^(1/3),   state = TRUE,   lhs = TRUE,   eta = TRUE,   covariates = TRUE,   addDosing = FALSE,   subsetNonmem = TRUE,   cores = NULL,   keep = NULL,   drop = NULL )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Output table/data.frame options — tableControl","text":"npde TRUE, request npde regardless algorithm used. cwres TRUE, request CWRES FOCEi likelihood regardless algorithm used. nsim represents number simulations.  rxode2, supply single subject event tables (created [eventTable()]) ties `TRUE` jitter prediction-discrepancy points discourage ties cdf. censMethod Handle censoring method: - `\"truncated-normal\"` Simulates truncated normal distribution assumption model censoring. - `\"cdf\"` Use cdf-method censoring npde use residuals (`cwres` etc) - `\"omit\"` omit residuals censoring seed object specifying random number generator initialized cholSEtol tolerance `rxode2::choleSE` function state Boolean indicating `state` values included (default `TRUE`) lhs Boolean indicating remaining `lhs` values included (default `TRUE`) eta Boolean indicating `eta` values included (default `TRUE`) covariates Boolean indicating covariates included (default `TRUE`) addDosing Boolean indicating solve add rxode2 EVID related columns.  also include dosing information estimates doses.  default, rxode2 includes estimates observations. (default FALSE). addDosing NULL, include EVID=0 solve exclude model-times EVID=2. addDosing NA classic rxode2 EVID events returned. addDosing TRUE add event information NONMEM-style format; subsetNonmem=FALSE rxode2 also include extra event types (EVID) ending infusion modeled times: EVID=-1 modeled rate infusions turned (matches rate=-1) EVID=-2 modeled duration infusions turned (matches rate=-2) EVID=-10 specified rate infusions turned (matches rate>0) EVID=-20 specified dur infusions turned (matches dur>0) EVID=101,102,103,... Modeled time 101 first model time, 102 second etc. subsetNonmem subset NONMEM compatible EVIDs .  default TRUE. cores Number cores used parallel ODE solving.  equivalent calling setRxThreads() keep keep sent table drop dropped variables sent table","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Output table/data.frame options — tableControl","text":"list table options nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Output table/data.frame options — tableControl","text":"ever want add CWRES/FOCEi objective function can use addCwres ever want add NPDE/EPRED columns can use addNpde","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Output table/data.frame options — tableControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce trace-plot for fit if applicable — traceplot","title":"Produce trace-plot for fit if applicable — traceplot","text":"Produce trace-plot fit applicable","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce trace-plot for fit if applicable — traceplot","text":"","code":"traceplot(x, ...)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce trace-plot for fit if applicable — traceplot","text":"x fit object ... Additional arguments passed nlmixr2plot::traceplot().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce trace-plot for fit if applicable — traceplot","text":"Fit traceplot nothing.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce trace-plot for fit if applicable — traceplot","text":"Rik Schoemaker, Wenping Wang & Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Produce trace-plot for fit if applicable — traceplot","text":"","code":"# \\donttest{  library(nlmixr2est) #>  #> Attaching package: ‘nlmixr2est’ #> The following objects are masked from ‘package:nlmixr2’: #>  #>     addCwres, addNpde, addTable, bobyqaControl, foceiControl, #>     lbfgsb3cControl, n1qn1Control, newuoaControl, nlmControl, #>     nlmeControl, nlminbControl, nlmixr2, nlsControl, optimControl, #>     saemControl, setOfv, tableControl, uobyqaControl, vpcSim ## The basic model consiss of an ini block that has initial estimates one.compartment <- function() {   ini({     tka <- 0.45 # Log Ka     tcl <- 1 # Log Cl     tv <- 3.45    # Log V     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   # and a model block with the error sppecification and model specification   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     d/dt(depot) = -ka * depot     d/dt(center) = ka * depot - cl / v * center     cp = center / v     cp ~ add(add.sd)   }) }  ## The fit is performed by the function nlmixr/nlmix2 specifying the model, data and estimate fit <- nlmixr2(one.compartment, theo_sd,  est=\"saem\", saemControl(print=0)) #>   #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> → optimizing duplicate expressions in saem model... #> ✔ done #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> ℹ calculate uninformed etas #> ℹ done #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → optimizing duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> using C compiler: ‘gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0’ #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 62360 #> → compress parHistData in nlmixr2 object, save 13848 #> → compress saem0 in nlmixr2 object, save 25840  # This shows the traceplot of the fit (useful for saem) traceplot(fit)   # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/uobyqaControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control for uobyqa estimation method in nlmixr2 — uobyqaControl","title":"Control for uobyqa estimation method in nlmixr2 — uobyqaControl","text":"Control uobyqa estimation method nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/uobyqaControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control for uobyqa estimation method in nlmixr2 — uobyqaControl","text":"","code":"uobyqaControl(   npt = NULL,   rhobeg = NULL,   rhoend = NULL,   iprint = 0L,   maxfun = 100000L,   returnUobyqa = FALSE,   stickyRecalcN = 4,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   useColor = crayon::has_color(),   printNcol = floor((getOption(\"width\") - 23)/12),   print = 1L,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleTo = 1,   rxControl = NULL,   optExpression = TRUE,   sumProd = FALSE,   literalFix = TRUE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   covMethod = c(\"r\", \"\"),   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/uobyqaControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control for uobyqa estimation method in nlmixr2 — uobyqaControl","text":"npt number points used approximate objective function via quadratic approximation bobyqa. value npt must interval [n+2,(n+1)(n+2)/2] n number parameters par. Choices exceed 2*n+1 recommended. defined, set 2*n + 1. (bobyqa) rhobeg Beginning change parameters bobyqa algorithm (trust region).  default 0.2 20 parameters parameters scaled 1. rhobeg rhoend must set initial final values trust region radius, must positive 0 < rhoend < rhobeg. Typically rhobeg one tenth greatest expected change variable.  Note also smallest difference abs(upper-lower) greater equal rhobeg*2. case rhobeg adjusted. (bobyqa) rhoend smallest value trust region radius allowed. defined, 10^(-sigdig-1) used. (bobyqa) iprint value `iprint` set integer value `0, 1, 2, 3, ...`, controls amount printing.  Specifically, output `iprint=0` output start return `iprint=1`. Otherwise, new value `rho` printed, best vector variables far corresponding value objective function. , new value objective function variables output `iprint=3`.  `iprint > 3`, objective function value corresponding variables output every `iprint` evaluations.  Default value `0`. maxfun maximum allowed number function evaluations. exceeded, method terminate. returnUobyqa return uobyqa output instead nlmixr2 fit stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced useColor Boolean indicating focei can use ASCII color codes printNcol Number columns printout wrapping parameter estimates/gradient print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ data normalization approaches follow following formula $$v_{scaled}$$ = ($$v_{unscaled}-C_{1}$$)/$$C_{2}$$ rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : $$C_{1}$$ = (max(unscaled values)+min(unscaled values))/2 $$C_{2}$$ = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: $$C_{1}$$ = min(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: $$C_{1}$$ = mean(unscaled values) $$C_{2}$$ = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : $$C_{1}$$ = 0 $$C_{2}$$ = $$\\sqrt(v_1^2 + v_2^2 + \\cdots + v_n^2)$$ constant perform data normalization. $$C_{1}$$ = 0 $$C_{2}$$ = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: $$v_{scaled}$$ = ($$v_{current} - v_{init}$$)*scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : $$v_{scaled}$$ = ($$v_{current}-v_{init}$$) + scaleTo Otherwise parameter scaled multiplicatively. $$v_{scaled}$$ = $$v_{current}$$/$$v_{init}$$*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(initial_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. rxControl `rxode2` ODE solving options fitting, created `rxControl()` optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. literalFix boolean, substitute fixed population values literals re-adjust ui parameter estimates optimization; Default `TRUE`. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: $$y = f + (+ b\\times f^c) \\times \\varepsilon$$ combined2 error model can described following equation: $$y = f + \\sqrt{^2 + b^2\\times f^{2\\times c}} \\times \\varepsilon$$ : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::uobyqaControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/uobyqaControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control for uobyqa estimation method in nlmixr2 — uobyqaControl","text":"uobyqa control structure","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/uobyqaControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control for uobyqa estimation method in nlmixr2 — uobyqaControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/uobyqaControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control for uobyqa estimation method in nlmixr2 — uobyqaControl","text":"","code":"# \\donttest{ # A logit regression example with emax model  dsn <- data.frame(i=1:1000) dsn$time <- exp(rnorm(1000)) dsn$DV=rbinom(1000,1,exp(-1+dsn$time)/(1+exp(-1+dsn$time)))  mod <- function() {  ini({    E0 <- 0.5    Em <- 0.5    E50 <- 2    g <- fix(2)  })  model({    v <- E0+Em*time^g/(E50^g+time^g)    ll(bin) ~ DV * v - log(1 + exp(v))  }) }  fit2 <- nlmixr(mod, dsn, est=\"uobyqa\") #>   #>   #>   #>   #> → pruning branches (`if`/`else`) of population log-likelihood model... #> ✔ done #> → loading llik model into symengine environment... #> → finding duplicate expressions in population log-likelihood model... #> → optimizing duplicate expressions in population log-likelihood model... #> ✔ done #>   #>   #> → calculating covariance #> ✔ done #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling EBE model... #>   #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 9112 #> → compress parHistData in nlmixr2 object, save 6664  print(fit2) #> ── nlmixr² log-likelihood uobyqa ── #>  #>           OBJF      AIC      BIC Log-likelihood Condition#(Cov) Condition#(Cor) #> lPop -686.7649 1157.112 1171.835      -575.5561        1260.207        108.0743 #>  #> ── Time (sec $time): ── #>  #>            setup table compress    other #> elapsed 0.002063 0.021    0.008 1.397937 #>  #> ── ($parFixed or $parFixedDf): ── #>  #>        Est.     SE  %RSE  Back-transformed(95%CI) BSV(SD) Shrink(SD)% #> E0  -0.6063 0.2264 37.33 -0.6063 (-1.05, -0.1627)                     #> Em    6.905  4.445 64.38    6.905 (-1.807, 15.62)                     #> E50   3.536  1.864  52.7   3.536 (-0.1162, 7.189)                     #> g         2  FIXED FIXED                        2                     #>   #>   Covariance Type ($covMethod): r #>   Censoring ($censInformation): No censoring #>  #> ── Fit Data (object is a modified tibble): ── #> # A tibble: 1,000 × 5 #>   ID      TIME    DV  IPRED      v #>   <fct>  <dbl> <dbl>  <dbl>  <dbl> #> 1 1     0.0304     0 -0.435 -0.606 #> 2 1     0.0320     1 -1.04  -0.606 #> 3 1     0.0329     1 -1.04  -0.606 #> # ℹ 997 more rows  # you can also get the nlm output with fit2$nlm  fit2$uobyqa #> parameter estimates: -0.606323556873061, 6.90508037483582, 3.53639314697913  #> objective: 575.556073649054  #> number of function evaluations: 84   # The nlm control has been modified slightly to include # extra components and name the parameters # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCens.html","id":null,"dir":"Reference","previous_headings":"","what":"VPC based on ui model — vpcCens","title":"VPC based on ui model — vpcCens","text":"VPC based ui model","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCens.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VPC based on ui model — vpcCens","text":"","code":"vpcCens(..., cens = TRUE, idv = \"time\")"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCens.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VPC based on ui model — vpcCens","text":"... Additional arguments passed nlmixr2plot::vpcCens(). cens boolean show censoring plot .  cens=TRUE actually censoring vpc plot (vpcCens() vpcCensTad()).  cens=FALSE traditional VPC plot (vpcPlot() vpcPlotTad()). idv Name independent variable. vpcPlot() vpcCens() default \"time\" vpcPlotTad() vpcCensTad() \"tad\"","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCens.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VPC based on ui model — vpcCens","text":"Simulated dataset (invisibly)","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCens.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"VPC based on ui model — vpcCens","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCens.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VPC based on ui model — vpcCens","text":"","code":"# \\donttest{ one.cmt <- function() {  ini({    tka <- 0.45; label(\"Ka\")    tcl <- log(c(0, 2.7, 100)); label(\"Cl\")    tv <- 3.45; label(\"V\")    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7; label(\"Additive residual error\")  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd)  }) }  fit <-   nlmixr2est::nlmixr(     one.cmt,     data = nlmixr2data::theo_sd,     est = \"saem\",     control = list(print = 0)   ) #>   #>   #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> ℹ calculate uninformed etas #> ℹ done #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHistData in nlmixr2 object, save 13816 #> → compress saem0 in nlmixr2 object, save 27992  vpcPlot(fit) #>   #>    # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCensTad.html","id":null,"dir":"Reference","previous_headings":"","what":"VPC based on ui model — vpcCensTad","title":"VPC based on ui model — vpcCensTad","text":"VPC based ui model","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCensTad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VPC based on ui model — vpcCensTad","text":"","code":"vpcCensTad(..., cens = TRUE, idv = \"tad\")"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCensTad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VPC based on ui model — vpcCensTad","text":"... Additional arguments passed nlmixr2plot::vpcCensTad(). cens boolean show censoring plot .  cens=TRUE actually censoring vpc plot (vpcCens() vpcCensTad()).  cens=FALSE traditional VPC plot (vpcPlot() vpcPlotTad()). idv Name independent variable. vpcPlot() vpcCens() default \"time\" vpcPlotTad() vpcCensTad() \"tad\"","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCensTad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VPC based on ui model — vpcCensTad","text":"Simulated dataset (invisibly)","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCensTad.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"VPC based on ui model — vpcCensTad","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcCensTad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VPC based on ui model — vpcCensTad","text":"","code":"# \\donttest{ one.cmt <- function() {  ini({    tka <- 0.45; label(\"Ka\")    tcl <- log(c(0, 2.7, 100)); label(\"Cl\")    tv <- 3.45; label(\"V\")    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7; label(\"Additive residual error\")  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd)  }) }  fit <-   nlmixr2est::nlmixr(     one.cmt,     data = nlmixr2data::theo_sd,     est = \"saem\",     control = list(print = 0)   ) #>   #>   #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> ℹ calculate uninformed etas #> ℹ done #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHistData in nlmixr2 object, save 13816 #> → compress saem0 in nlmixr2 object, save 27992  vpcPlot(fit) #>   #>    # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"VPC based on ui model — vpcPlot","title":"VPC based on ui model — vpcPlot","text":"VPC based ui model","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VPC based on ui model — vpcPlot","text":"","code":"vpcPlot(   fit,   data = NULL,   n = 300,   bins = \"jenks\",   n_bins = \"auto\",   bin_mid = \"mean\",   show = NULL,   stratify = NULL,   pred_corr = FALSE,   pred_corr_lower_bnd = 0,   pi = c(0.05, 0.95),   ci = c(0.05, 0.95),   uloq = fit$dataUloq,   lloq = fit$dataLloq,   log_y = FALSE,   log_y_min = 0.001,   xlab = NULL,   ylab = NULL,   title = NULL,   smooth = TRUE,   vpc_theme = NULL,   facet = \"wrap\",   scales = \"fixed\",   labeller = NULL,   vpcdb = FALSE,   verbose = FALSE,   ...,   seed = 1009,   idv = \"time\",   cens = FALSE )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VPC based on ui model — vpcPlot","text":"fit nlmixr2 fit object data data use augment VPC fit.  default fitted data, (can retrieved getData), can changed specifying argument. n Number VPC simulations bins either \"density\", \"time\", \"data\", \"none\", one approaches available classInterval() \"jenks\" (default) \"pretty\", numeric vector specifying bin separators. n_bins using \"auto\" binning method, number bins aim bin_mid either \"mean\" mean timepoints (default) \"middle\" use average bin boundaries. show show VPC (obs_dv, obs_ci, pi, pi_as_area, pi_ci, obs_median, sim_median, sim_median_ci) stratify character vector stratification variables. 1 2 stratification variables can supplied. pred_corr perform prediction-correction? pred_corr_lower_bnd lower bound prediction-correction pi simulated prediction interval plot. Default c(0.05, 0.95), ci confidence interval plot. Default (0.05, 0.95) uloq Number NULL indicating upper limit quantification. Default NULL. lloq Number NULL indicating lower limit quantification. Default NULL. log_y Boolean indicting whether y-axis shown logarithmic. Default FALSE. log_y_min minimal value using log_y argument. Default 1e-3. xlab label x axis ylab label y axis title title smooth \"smooth\" VPC (connect bin midpoints) show bins rectangular boxes. Default TRUE. vpc_theme theme used VPC. Expects list class vpc_theme created function vpc_theme() facet either \"wrap\", \"columns\", \"rows\" scales either \"fixed\" (default), \"free_y\", \"free_x\" \"free\" labeller ggplot2 labeller function passed underlying ggplot object vpcdb Boolean whether return underlying vpcdb rather plot verbose show debugging information (TRUE FALSE) ... Additional arguments passed nlmixr2plot::vpcPlot(). seed object specifying random number generator initialized idv Name independent variable. vpcPlot() vpcCens() default \"time\" vpcPlotTad() vpcCensTad() \"tad\" cens boolean show censoring plot .  cens=TRUE actually censoring vpc plot (vpcCens() vpcCensTad()).  cens=FALSE traditional VPC plot (vpcPlot() vpcPlotTad()).","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VPC based on ui model — vpcPlot","text":"Simulated dataset (invisibly)","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"VPC based on ui model — vpcPlot","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VPC based on ui model — vpcPlot","text":"","code":"# \\donttest{ one.cmt <- function() {  ini({    tka <- 0.45; label(\"Ka\")    tcl <- log(c(0, 2.7, 100)); label(\"Cl\")    tv <- 3.45; label(\"V\")    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7; label(\"Additive residual error\")  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd)  }) }  fit <-   nlmixr2est::nlmixr(     one.cmt,     data = nlmixr2data::theo_sd,     est = \"saem\",     control = list(print = 0)   ) #>   #>   #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> ℹ calculate uninformed etas #> ℹ done #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHistData in nlmixr2 object, save 13816 #> → compress saem0 in nlmixr2 object, save 27984  vpcPlot(fit) #>   #>    # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlotTad.html","id":null,"dir":"Reference","previous_headings":"","what":"VPC based on ui model — vpcPlotTad","title":"VPC based on ui model — vpcPlotTad","text":"VPC based ui model","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlotTad.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VPC based on ui model — vpcPlotTad","text":"","code":"vpcPlotTad(..., idv = \"tad\")"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlotTad.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VPC based on ui model — vpcPlotTad","text":"... Additional arguments passed nlmixr2plot::vpcPlotTad(). idv Name independent variable. vpcPlot() vpcCens() default \"time\" vpcPlotTad() vpcCensTad() \"tad\"","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlotTad.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VPC based on ui model — vpcPlotTad","text":"Simulated dataset (invisibly)","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlotTad.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"VPC based on ui model — vpcPlotTad","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlotTad.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VPC based on ui model — vpcPlotTad","text":"","code":"# \\donttest{ one.cmt <- function() {  ini({    tka <- 0.45; label(\"Ka\")    tcl <- log(c(0, 2.7, 100)); label(\"Cl\")    tv <- 3.45; label(\"V\")    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7; label(\"Additive residual error\")  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd)  }) }  fit <-   nlmixr2est::nlmixr(     one.cmt,     data = nlmixr2data::theo_sd,     est = \"saem\",     control = list(print = 0)   ) #>   #>   #>   #>   #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> ℹ calculate uninformed etas #> ℹ done #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHistData in nlmixr2 object, save 13816 #> → compress saem0 in nlmixr2 object, save 27992  vpcPlot(fit) #>   #>    # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":null,"dir":"Reference","previous_headings":"","what":"VPC simulation — vpcSim","title":"VPC simulation — vpcSim","text":"VPC simulation","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VPC simulation — vpcSim","text":"","code":"vpcSim(   object,   ...,   keep = NULL,   n = 300,   pred = FALSE,   seed = 1009,   nretry = 50,   minN = 10,   normRelated = TRUE )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VPC simulation — vpcSim","text":"object nlmixr2 fit object ... Additional arguments passed nlmixr2est::vpcSim(). keep Column names keep output simulated dataset n Number simulations pred predictions added simulation seed Seed set VPC simulation nretry Number times retry simulation NA values simulation minN retries, minimum number studies restimulate (default 10) normRelated VPC style simulation normal related variables ","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VPC simulation — vpcSim","text":"data frame VPC simulation","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"VPC simulation — vpcSim","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VPC simulation — vpcSim","text":"","code":"# \\donttest{  if (rxode2parse::.linCmtSens()) {  one.cmt <- function() {  ini({    ## You may label each parameter with a comment    tka <- 0.45 # Log Ka    tcl <- log(c(0, 2.7, 100)) # Log Cl    ## This works with interactive models    ## You may also label the preceding line with label(\"label text\")    tv <- 3.45; label(\"log V\")    ## the label(\"Label name\") works with all models    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd)  }) }  fit <- nlmixr(one.cmt, theo_sd, est=\"focei\")  head(vpcSim(fit, pred=TRUE))  } #>   #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress parHistData in nlmixr2 object, save 4856 #>   #>   #>   sim.id id time     ipred        sim  tad nlmixrRowNums rxLambda rxYj rxLow #> 1      1  1 0.00  0.000000  0.9532212 0.00             2        1    2     0 #> 2      1  1 0.25 10.023191 10.1820670 0.25             3        1    2     0 #> 3      1  1 0.57 11.209259 11.4075894 0.57             4        1    2     0 #> 4      1  1 1.12 10.704906 10.3122321 1.12             5        1    2     0 #> 5      1  1 2.02  9.729745 10.6855880 2.02             6        1    2     0 #> 6      1  1 3.82  8.034879  8.4970388 3.82             7        1    2     0 #>   rxHi     pred #> 1    1 0.000000 #> 2    1 3.270856 #> 3    1 5.839073 #> 4    1 7.868363 #> 5    1 8.501092 #> 6    1 7.615773  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/news/index.html","id":"nlmixr2-212","dir":"Changelog","previous_headings":"","what":"nlmixr2 2.1.2","title":"nlmixr2 2.1.2","text":"CRAN release: 2024-05-30 Re-export population estimation control methods.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/news/index.html","id":"nlmixr2-211","dir":"Changelog","previous_headings":"","what":"nlmixr2 2.1.1","title":"nlmixr2 2.1.1","text":"CRAN release: 2024-02-01 Work systems (like intel c++) linCmt() linear compartmental models gradients.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/news/index.html","id":"nlmixr2-210","dir":"Changelog","previous_headings":"","what":"nlmixr2 2.1.0","title":"nlmixr2 2.1.0","text":"CRAN release: 2024-01-09 Reexports etExpand(), model()<- ini()<-","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/news/index.html","id":"nlmixr2-209","dir":"Changelog","previous_headings":"","what":"nlmixr2 2.0.9","title":"nlmixr2 2.0.9","text":"CRAN release: 2023-02-21 new function nlmixr2CheckInstall() helps check installation setup correctly required compilers packages. version adds crayon imported dependency","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/news/index.html","id":"nlmixr2-208","dir":"Changelog","previous_headings":"","what":"nlmixr2 2.0.8","title":"nlmixr2 2.0.8","text":"CRAN release: 2022-10-23 release bug fix captures model name correctly called directly nlmixr::nlmixr2 instead nlmixr2est::nlmixr2 also exports new vpc functions, ie vpcTad() etc","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/news/index.html","id":"nlmixr2-207","dir":"Changelog","previous_headings":"","what":"nlmixr2 2.0.7","title":"nlmixr2 2.0.7","text":"CRAN release: 2022-06-27 nlmixr2 now re-exports logit certain models work simple library(nlmixr2) instead library(rxode2);library(nlmixr2) vpcSim() now exports new nretry option robust control vpcSim() Update documentation mention package names work nlmixr2, like xpose.nlmixr2 instead xpose.nlmixr Manual hard re-export nlmixr2est::nlmixr2 allow pkgdown document function.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/news/index.html","id":"nlmixr2-206","dir":"Changelog","previous_headings":"","what":"nlmixr2 2.0.6","title":"nlmixr2 2.0.6","text":"CRAN release: 2022-05-24 nlmixr2 umbrella package include lower level packages rxode2, nlmixr2est, nlmixr2extra, nlmixr2plot Added NEWS.md file track changes package.","code":""}]
