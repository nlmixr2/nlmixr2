[{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"GNU General Public License","title":"GNU General Public License","text":"Version 3, 29 June 2007Copyright © 2007 Free Software Foundation, Inc. <http://fsf.org/> Everyone permitted copy distribute verbatim copies license document, changing allowed.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"preamble","dir":"","previous_headings":"","what":"Preamble","title":"GNU General Public License","text":"GNU General Public License free, copyleft license software kinds works. licenses software practical works designed take away freedom share change works. contrast, GNU General Public License intended guarantee freedom share change versions program–make sure remains free software users. , Free Software Foundation, use GNU General Public License software; applies also work released way authors. can apply programs, . speak free software, referring freedom, price. General Public Licenses designed make sure freedom distribute copies free software (charge wish), receive source code can get want , can change software use pieces new free programs, know can things. protect rights, need prevent others denying rights asking surrender rights. Therefore, certain responsibilities distribute copies software, modify : responsibilities respect freedom others. example, distribute copies program, whether gratis fee, must pass recipients freedoms received. must make sure , , receive can get source code. must show terms know rights. Developers use GNU GPL protect rights two steps: (1) assert copyright software, (2) offer License giving legal permission copy, distribute /modify . developers’ authors’ protection, GPL clearly explains warranty free software. users’ authors’ sake, GPL requires modified versions marked changed, problems attributed erroneously authors previous versions. devices designed deny users access install run modified versions software inside , although manufacturer can . fundamentally incompatible aim protecting users’ freedom change software. systematic pattern abuse occurs area products individuals use, precisely unacceptable. Therefore, designed version GPL prohibit practice products. problems arise substantially domains, stand ready extend provision domains future versions GPL, needed protect freedom users. Finally, every program threatened constantly software patents. States allow patents restrict development use software general-purpose computers, , wish avoid special danger patents applied free program make effectively proprietary. prevent , GPL assures patents used render program non-free. precise terms conditions copying, distribution modification follow.","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"0-definitions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"0. Definitions","title":"GNU General Public License","text":"“License” refers version 3 GNU General Public License. “Copyright” also means copyright-like laws apply kinds works, semiconductor masks. “Program” refers copyrightable work licensed License. licensee addressed “”. “Licensees” “recipients” may individuals organizations. “modify” work means copy adapt part work fashion requiring copyright permission, making exact copy. resulting work called “modified version” earlier work work “based ” earlier work. “covered work” means either unmodified Program work based Program. “propagate” work means anything , without permission, make directly secondarily liable infringement applicable copyright law, except executing computer modifying private copy. Propagation includes copying, distribution (without modification), making available public, countries activities well. “convey” work means kind propagation enables parties make receive copies. Mere interaction user computer network, transfer copy, conveying. interactive user interface displays “Appropriate Legal Notices” extent includes convenient prominently visible feature (1) displays appropriate copyright notice, (2) tells user warranty work (except extent warranties provided), licensees may convey work License, view copy License. interface presents list user commands options, menu, prominent item list meets criterion.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"1-source-code","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"1. Source Code","title":"GNU General Public License","text":"“source code” work means preferred form work making modifications . “Object code” means non-source form work. “Standard Interface” means interface either official standard defined recognized standards body, , case interfaces specified particular programming language, one widely used among developers working language. “System Libraries” executable work include anything, work whole, () included normal form packaging Major Component, part Major Component, (b) serves enable use work Major Component, implement Standard Interface implementation available public source code form. “Major Component”, context, means major essential component (kernel, window system, ) specific operating system () executable work runs, compiler used produce work, object code interpreter used run . “Corresponding Source” work object code form means source code needed generate, install, (executable work) run object code modify work, including scripts control activities. However, include work’s System Libraries, general-purpose tools generally available free programs used unmodified performing activities part work. example, Corresponding Source includes interface definition files associated source files work, source code shared libraries dynamically linked subprograms work specifically designed require, intimate data communication control flow subprograms parts work. Corresponding Source need include anything users can regenerate automatically parts Corresponding Source. Corresponding Source work source code form work.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"2-basic-permissions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"2. Basic Permissions","title":"GNU General Public License","text":"rights granted License granted term copyright Program, irrevocable provided stated conditions met. License explicitly affirms unlimited permission run unmodified Program. output running covered work covered License output, given content, constitutes covered work. License acknowledges rights fair use equivalent, provided copyright law. may make, run propagate covered works convey, without conditions long license otherwise remains force. may convey covered works others sole purpose make modifications exclusively , provide facilities running works, provided comply terms License conveying material control copyright. thus making running covered works must exclusively behalf, direction control, terms prohibit making copies copyrighted material outside relationship . Conveying circumstances permitted solely conditions stated . Sublicensing allowed; section 10 makes unnecessary.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"3-protecting-users-legal-rights-from-anti-circumvention-law","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"3. Protecting Users’ Legal Rights From Anti-Circumvention Law","title":"GNU General Public License","text":"covered work shall deemed part effective technological measure applicable law fulfilling obligations article 11 WIPO copyright treaty adopted 20 December 1996, similar laws prohibiting restricting circumvention measures. convey covered work, waive legal power forbid circumvention technological measures extent circumvention effected exercising rights License respect covered work, disclaim intention limit operation modification work means enforcing, work’s users, third parties’ legal rights forbid circumvention technological measures.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"4-conveying-verbatim-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"4. Conveying Verbatim Copies","title":"GNU General Public License","text":"may convey verbatim copies Program’s source code receive , medium, provided conspicuously appropriately publish copy appropriate copyright notice; keep intact notices stating License non-permissive terms added accord section 7 apply code; keep intact notices absence warranty; give recipients copy License along Program. may charge price price copy convey, may offer support warranty protection fee.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"5-conveying-modified-source-versions","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"5. Conveying Modified Source Versions","title":"GNU General Public License","text":"may convey work based Program, modifications produce Program, form source code terms section 4, provided also meet conditions: ) work must carry prominent notices stating modified , giving relevant date. b) work must carry prominent notices stating released License conditions added section 7. requirement modifies requirement section 4 “keep intact notices”. c) must license entire work, whole, License anyone comes possession copy. License therefore apply, along applicable section 7 additional terms, whole work, parts, regardless packaged. License gives permission license work way, invalidate permission separately received . d) work interactive user interfaces, must display Appropriate Legal Notices; however, Program interactive interfaces display Appropriate Legal Notices, work need make . compilation covered work separate independent works, nature extensions covered work, combined form larger program, volume storage distribution medium, called “aggregate” compilation resulting copyright used limit access legal rights compilation’s users beyond individual works permit. Inclusion covered work aggregate cause License apply parts aggregate.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"6-conveying-non-source-forms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"6. Conveying Non-Source Forms","title":"GNU General Public License","text":"may convey covered work object code form terms sections 4 5, provided also convey machine-readable Corresponding Source terms License, one ways: ) Convey object code , embodied , physical product (including physical distribution medium), accompanied Corresponding Source fixed durable physical medium customarily used software interchange. b) Convey object code , embodied , physical product (including physical distribution medium), accompanied written offer, valid least three years valid long offer spare parts customer support product model, give anyone possesses object code either (1) copy Corresponding Source software product covered License, durable physical medium customarily used software interchange, price reasonable cost physically performing conveying source, (2) access copy Corresponding Source network server charge. c) Convey individual copies object code copy written offer provide Corresponding Source. alternative allowed occasionally noncommercially, received object code offer, accord subsection 6b. d) Convey object code offering access designated place (gratis charge), offer equivalent access Corresponding Source way place charge. need require recipients copy Corresponding Source along object code. place copy object code network server, Corresponding Source may different server (operated third party) supports equivalent copying facilities, provided maintain clear directions next object code saying find Corresponding Source. Regardless server hosts Corresponding Source, remain obligated ensure available long needed satisfy requirements. e) Convey object code using peer--peer transmission, provided inform peers object code Corresponding Source work offered general public charge subsection 6d. separable portion object code, whose source code excluded Corresponding Source System Library, need included conveying object code work. “User Product” either (1) “consumer product”, means tangible personal property normally used personal, family, household purposes, (2) anything designed sold incorporation dwelling. determining whether product consumer product, doubtful cases shall resolved favor coverage. particular product received particular user, “normally used” refers typical common use class product, regardless status particular user way particular user actually uses, expects expected use, product. product consumer product regardless whether product substantial commercial, industrial non-consumer uses, unless uses represent significant mode use product. “Installation Information” User Product means methods, procedures, authorization keys, information required install execute modified versions covered work User Product modified version Corresponding Source. information must suffice ensure continued functioning modified object code case prevented interfered solely modification made. convey object code work section , , specifically use , User Product, conveying occurs part transaction right possession use User Product transferred recipient perpetuity fixed term (regardless transaction characterized), Corresponding Source conveyed section must accompanied Installation Information. requirement apply neither third party retains ability install modified object code User Product (example, work installed ROM). requirement provide Installation Information include requirement continue provide support service, warranty, updates work modified installed recipient, User Product modified installed. Access network may denied modification materially adversely affects operation network violates rules protocols communication across network. Corresponding Source conveyed, Installation Information provided, accord section must format publicly documented (implementation available public source code form), must require special password key unpacking, reading copying.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"7-additional-terms","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"7. Additional Terms","title":"GNU General Public License","text":"“Additional permissions” terms supplement terms License making exceptions one conditions. Additional permissions applicable entire Program shall treated though included License, extent valid applicable law. additional permissions apply part Program, part may used separately permissions, entire Program remains governed License without regard additional permissions. convey copy covered work, may option remove additional permissions copy, part . (Additional permissions may written require removal certain cases modify work.) may place additional permissions material, added covered work, can give appropriate copyright permission. Notwithstanding provision License, material add covered work, may (authorized copyright holders material) supplement terms License terms: ) Disclaiming warranty limiting liability differently terms sections 15 16 License; b) Requiring preservation specified reasonable legal notices author attributions material Appropriate Legal Notices displayed works containing ; c) Prohibiting misrepresentation origin material, requiring modified versions material marked reasonable ways different original version; d) Limiting use publicity purposes names licensors authors material; e) Declining grant rights trademark law use trade names, trademarks, service marks; f) Requiring indemnification licensors authors material anyone conveys material (modified versions ) contractual assumptions liability recipient, liability contractual assumptions directly impose licensors authors. non-permissive additional terms considered “restrictions” within meaning section 10. Program received , part , contains notice stating governed License along term restriction, may remove term. license document contains restriction permits relicensing conveying License, may add covered work material governed terms license document, provided restriction survive relicensing conveying. add terms covered work accord section, must place, relevant source files, statement additional terms apply files, notice indicating find applicable terms. Additional terms, permissive non-permissive, may stated form separately written license, stated exceptions; requirements apply either way.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"8-termination","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"8. Termination","title":"GNU General Public License","text":"may propagate modify covered work except expressly provided License. attempt otherwise propagate modify void, automatically terminate rights License (including patent licenses granted third paragraph section 11). However, cease violation License, license particular copyright holder reinstated () provisionally, unless copyright holder explicitly finally terminates license, (b) permanently, copyright holder fails notify violation reasonable means prior 60 days cessation. Moreover, license particular copyright holder reinstated permanently copyright holder notifies violation reasonable means, first time received notice violation License (work) copyright holder, cure violation prior 30 days receipt notice. Termination rights section terminate licenses parties received copies rights License. rights terminated permanently reinstated, qualify receive new licenses material section 10.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"9-acceptance-not-required-for-having-copies","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"9. Acceptance Not Required for Having Copies","title":"GNU General Public License","text":"required accept License order receive run copy Program. Ancillary propagation covered work occurring solely consequence using peer--peer transmission receive copy likewise require acceptance. However, nothing License grants permission propagate modify covered work. actions infringe copyright accept License. Therefore, modifying propagating covered work, indicate acceptance License .","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"10-automatic-licensing-of-downstream-recipients","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"10. Automatic Licensing of Downstream Recipients","title":"GNU General Public License","text":"time convey covered work, recipient automatically receives license original licensors, run, modify propagate work, subject License. responsible enforcing compliance third parties License. “entity transaction” transaction transferring control organization, substantially assets one, subdividing organization, merging organizations. propagation covered work results entity transaction, party transaction receives copy work also receives whatever licenses work party’s predecessor interest give previous paragraph, plus right possession Corresponding Source work predecessor interest, predecessor can get reasonable efforts. may impose restrictions exercise rights granted affirmed License. example, may impose license fee, royalty, charge exercise rights granted License, may initiate litigation (including cross-claim counterclaim lawsuit) alleging patent claim infringed making, using, selling, offering sale, importing Program portion .","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"11-patents","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"11. Patents","title":"GNU General Public License","text":"“contributor” copyright holder authorizes use License Program work Program based. work thus licensed called contributor’s “contributor version”. contributor’s “essential patent claims” patent claims owned controlled contributor, whether already acquired hereafter acquired, infringed manner, permitted License, making, using, selling contributor version, include claims infringed consequence modification contributor version. purposes definition, “control” includes right grant patent sublicenses manner consistent requirements License. contributor grants non-exclusive, worldwide, royalty-free patent license contributor’s essential patent claims, make, use, sell, offer sale, import otherwise run, modify propagate contents contributor version. following three paragraphs, “patent license” express agreement commitment, however denominated, enforce patent (express permission practice patent covenant sue patent infringement). “grant” patent license party means make agreement commitment enforce patent party. convey covered work, knowingly relying patent license, Corresponding Source work available anyone copy, free charge terms License, publicly available network server readily accessible means, must either (1) cause Corresponding Source available, (2) arrange deprive benefit patent license particular work, (3) arrange, manner consistent requirements License, extend patent license downstream recipients. “Knowingly relying” means actual knowledge , patent license, conveying covered work country, recipient’s use covered work country, infringe one identifiable patents country reason believe valid. , pursuant connection single transaction arrangement, convey, propagate procuring conveyance , covered work, grant patent license parties receiving covered work authorizing use, propagate, modify convey specific copy covered work, patent license grant automatically extended recipients covered work works based . patent license “discriminatory” include within scope coverage, prohibits exercise , conditioned non-exercise one rights specifically granted License. may convey covered work party arrangement third party business distributing software, make payment third party based extent activity conveying work, third party grants, parties receive covered work , discriminatory patent license () connection copies covered work conveyed (copies made copies), (b) primarily connection specific products compilations contain covered work, unless entered arrangement, patent license granted, prior 28 March 2007. Nothing License shall construed excluding limiting implied license defenses infringement may otherwise available applicable patent law.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"12-no-surrender-of-others-freedom","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"12. No Surrender of Others’ Freedom","title":"GNU General Public License","text":"conditions imposed (whether court order, agreement otherwise) contradict conditions License, excuse conditions License. convey covered work satisfy simultaneously obligations License pertinent obligations, consequence may convey . example, agree terms obligate collect royalty conveying convey Program, way satisfy terms License refrain entirely conveying Program.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"13-use-with-the-gnu-affero-general-public-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"13. Use with the GNU Affero General Public License","title":"GNU General Public License","text":"Notwithstanding provision License, permission link combine covered work work licensed version 3 GNU Affero General Public License single combined work, convey resulting work. terms License continue apply part covered work, special requirements GNU Affero General Public License, section 13, concerning interaction network apply combination .","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"14-revised-versions-of-this-license","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"14. Revised Versions of this License","title":"GNU General Public License","text":"Free Software Foundation may publish revised /new versions GNU General Public License time time. new versions similar spirit present version, may differ detail address new problems concerns. version given distinguishing version number. Program specifies certain numbered version GNU General Public License “later version” applies , option following terms conditions either numbered version later version published Free Software Foundation. Program specify version number GNU General Public License, may choose version ever published Free Software Foundation. Program specifies proxy can decide future versions GNU General Public License can used, proxy’s public statement acceptance version permanently authorizes choose version Program. Later license versions may give additional different permissions. However, additional obligations imposed author copyright holder result choosing follow later version.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"15-disclaimer-of-warranty","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"15. Disclaimer of Warranty","title":"GNU General Public License","text":"WARRANTY PROGRAM, EXTENT PERMITTED APPLICABLE LAW. EXCEPT OTHERWISE STATED WRITING COPYRIGHT HOLDERS /PARTIES PROVIDE PROGRAM “” WITHOUT WARRANTY KIND, EITHER EXPRESSED IMPLIED, INCLUDING, LIMITED , IMPLIED WARRANTIES MERCHANTABILITY FITNESS PARTICULAR PURPOSE. ENTIRE RISK QUALITY PERFORMANCE PROGRAM . PROGRAM PROVE DEFECTIVE, ASSUME COST NECESSARY SERVICING, REPAIR CORRECTION.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"16-limitation-of-liability","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"16. Limitation of Liability","title":"GNU General Public License","text":"EVENT UNLESS REQUIRED APPLICABLE LAW AGREED WRITING COPYRIGHT HOLDER, PARTY MODIFIES /CONVEYS PROGRAM PERMITTED , LIABLE DAMAGES, INCLUDING GENERAL, SPECIAL, INCIDENTAL CONSEQUENTIAL DAMAGES ARISING USE INABILITY USE PROGRAM (INCLUDING LIMITED LOSS DATA DATA RENDERED INACCURATE LOSSES SUSTAINED THIRD PARTIES FAILURE PROGRAM OPERATE PROGRAMS), EVEN HOLDER PARTY ADVISED POSSIBILITY DAMAGES.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"17-interpretation-of-sections-15-and-16","dir":"","previous_headings":"TERMS AND CONDITIONS","what":"17. Interpretation of Sections 15 and 16","title":"GNU General Public License","text":"disclaimer warranty limitation liability provided given local legal effect according terms, reviewing courts shall apply local law closely approximates absolute waiver civil liability connection Program, unless warranty assumption liability accompanies copy Program return fee. END TERMS CONDITIONS","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/LICENSE.html","id":"how-to-apply-these-terms-to-your-new-programs","dir":"","previous_headings":"","what":"How to Apply These Terms to Your New Programs","title":"GNU General Public License","text":"develop new program, want greatest possible use public, best way achieve make free software everyone can redistribute change terms. , attach following notices program. safest attach start source file effectively state exclusion warranty; file least “copyright” line pointer full notice found. Also add information contact electronic paper mail. program terminal interaction, make output short notice like starts interactive mode: hypothetical commands show w show c show appropriate parts General Public License. course, program’s commands might different; GUI interface, use “box”. also get employer (work programmer) school, , sign “copyright disclaimer” program, necessary. information , apply follow GNU GPL, see <http://www.gnu.org/licenses/>. GNU General Public License permit incorporating program proprietary programs. program subroutine library, may consider useful permit linking proprietary applications library. want , use GNU Lesser General Public License instead License. first, please read <http://www.gnu.org/philosophy/--lgpl.html>.","code":"<one line to give the program's name and a brief idea of what it does.> Copyright (C) <year>  <name of author>  This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.  This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License for more details.  You should have received a copy of the GNU General Public License along with this program.  If not, see <http://www.gnu.org/licenses/>. <program>  Copyright (C) <year>  <name of author> This program comes with ABSOLUTELY NO WARRANTY; for details type 'show w'. This is free software, and you are welcome to redistribute it under certain conditions; type 'show c' for details."},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"adding-covariances-between-random-effects","dir":"Articles","previous_headings":"","what":"Adding Covariances between random effects","title":"Random Effect Covariances","text":"can simply add co-variances two random effects adding effects together model specification block, eta.cl+eta.v ~. statement, specify lower triangular matrix fit c(). example phenobarbitol data:","code":"## Load phenobarbitol data library(nlmixr2)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"model-specification","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Model Specification","title":"Random Effect Covariances","text":"","code":"pheno <- function() {   ini({     tcl <- log(0.008) # typical value of clearance     tv <-  log(0.6)   # typical value of volume     ## var(eta.cl)     eta.cl + eta.v ~ c(1,                         0.01, 1) ## cov(eta.cl, eta.v), var(eta.v)                       # interindividual variability on clearance and volume     add.err <- 0.1    # residual variability   })   model({     cl <- exp(tcl + eta.cl) # individual value of clearance     v <- exp(tv + eta.v)    # individual value of volume     ke <- cl / v            # elimination rate constant     d/dt(A1) = - ke * A1    # model differential equation     cp = A1 / v             # concentration in plasma     cp ~ add(add.err)       # define error model   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"fit-with-saem","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Fit with SAEM","title":"Random Effect Covariances","text":"","code":"fit <- nlmixr(pheno, pheno_sd, \"saem\",               control=list(print=0),                table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  print(fit) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 688.6792 985.5502 1003.811      -486.7751         7.570439 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance   saem table compress #> elapsed 0.003883    4e-06   0.019005 15.143  3.25    0.026 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>                          Parameter  Est.     SE %RSE    Back-transformed(95%CI) #> tcl     typical value of clearance -4.99 0.0743 1.49 0.00677 (0.00586, 0.00784) #> tv         typical value of volume 0.346 0.0538 15.5          1.41 (1.27, 1.57) #> add.err       residual variability  2.83                                   2.83 #>         BSV(CV%) Shrink(SD)% #> tcl         52.4      1.50%  #> tv          41.0      1.09%  #> add.err                      #>   #>   Covariance Type ($covMethod): linFim #>   Correlations in between subject variability (BSV) matrix: #>     cor:eta.v,eta.cl  #>           0.989   #>   #>  #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 155 × 24 #>   ID     TIME    DV EPRED  ERES   NPDE    NPD  PRED    RES    WRES IPRED  IRES #>   <fct> <dbl> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl> #> 1 1        2   17.3  18.9 -1.56 -0.422 -0.422  17.5 -0.222 -0.0297  18.5 -1.18 #> 2 1      112.  31    29.9  1.13  0.394  0.394  27.9  3.11   0.254   29.6  1.37 #> 3 2        2    9.7  10.9 -1.19 -1.01  -1.01   10.5 -0.813 -0.162   12.5 -2.77 #> # … with 152 more rows, and 12 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.cl <dbl>, eta.v <dbl>, A1 <dbl>, cl <dbl>, #> #   v <dbl>, ke <dbl>, tad <dbl>, dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"basic-goodness-of-fit-plots","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Basic Goodness of Fit Plots","title":"Random Effect Covariances","text":"individual plots great, better see actual curves; can augPred","code":"plot(fit) plot(augPred(fit))"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/addingCovariances.html","id":"two-types-of-vpcs","dir":"Articles","previous_headings":"Adding Covariances between random effects","what":"Two types of VPCs","title":"Random Effect Covariances","text":"","code":"library(ggplot2) p1 <- vpcPlot(fit, show=list(obs_dv=TRUE)); #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 p1 <- p1 + ylab(\"Concentrations\")  ## A prediction-corrected VPC p2 <- vpcPlot(fit, pred_corr = TRUE, show=list(obs_dv=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 p2 <- p2 + ylab(\"Prediction-Corrected Concentrations\")  p1 p2"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"the-broom-and-broom-mixed-packages","dir":"Articles","previous_headings":"","what":"The broom and broom.mixed packages","title":"Using broom with nlmixr2","text":"broom broom.mixed packages attempt put standard model outputs data frames. nlmixr supports tidy glance methods support augment time. Using model covariance term, Phenobarbital model, can explore different types output used tidy functions. explore , first run model:","code":"library(nlmixr2) library(broom.mixed)  pheno <- function() {   # Pheno with covariance   ini({     tcl <- log(0.008) # typical value of clearance     tv <-  log(0.6)   # typical value of volume     ## var(eta.cl)     eta.cl + eta.v ~ c(1,                         0.01, 1) ## cov(eta.cl, eta.v), var(eta.v)     # interindividual variability on clearance and volume     add.err <- 0.1    # residual variability   })   model({     cl <- exp(tcl + eta.cl) # individual value of clearance     v <- exp(tv + eta.v)    # individual value of volume     ke <- cl / v            # elimination rate constant     d/dt(A1) = - ke * A1    # model differential equation     cp = A1 / v             # concentration in plasma     cp ~ add(add.err)       # define error model   }) }  ## We will run it two ways to allow comparisons fit.s <- nlmixr(pheno, pheno_sd, \"saem\", control=list(logLik=TRUE, print=0),                 table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  fit.f <- nlmixr(pheno, pheno_sd, \"focei\",                 control=list(print=0),                  table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done #> [====|====|====|====|====|====|====|====|====|====] 0:00:00"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"glancing-at-the-goodness-of-fit-metrics","dir":"Articles","previous_headings":"","what":"Glancing at the goodness of fit metrics","title":"Using broom with nlmixr2","text":"Often fitting data, want glance fit see well fits. broom, glance give summary fit metrics goodness fit: Note nlmixr possible one fit metric (based different quadratures, FOCEi approximation etc). However, glance returns fit metrics current. wish can set objective function focei objective function (already calculated CWRES). Now glance gives gauss3_1.6 values. course can always change type objective function nlmixr uses: setting back SAEM default objective function FOCEi, glance(fit.s) values : convenience, can glance objects:","code":"glance(fit.s) setOfv(fit.s,\"gauss3_1.6\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 glance(fit.s) setOfv(fit.s,\"FOCEi\") # Setting objective function to focei glance(fit.s) glance(fit.s, type=\"FOCEi\")"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"tidying-of-overall-fit-parameters","dir":"Articles","previous_headings":"Tidying the model parameters","what":"Tidying of overall fit parameters","title":"Using broom with nlmixr2","text":"can also tidy model estimates data frame broom processing. can useful integrating 3rd parting modeling packages. consistent parameter format, tasks multiple types models can automated applied. default function tidy, applied fit object provides overall parameter information tidy dataset: Note default parameters actually estimated nlmixr, back-transformed values table printout. course, mu-referenced models, may want exponentiate terms. broom package allows apply exponentiation parameters, : Note:, accordance rest broom package, parameters exponentiated, standard errors transformed approximate standard error formula: \\(\\textrm{se}(\\exp(x)) \\approx \\exp(\\textrm{model estimate}_x)\\times \\textrm{se}_x\\). can confusing confidence intervals (described later) using actual standard error back-transforming exponentiated scale. reason default nlmixr’s broom interface exponentiate=FALSE, : want, can also use parsed back-transformation used nlmixr tables (ie fit$parFixedDf). Please note uses approximate back-transformation standard errors log-scaled back-transformed values. done : Also note, time writing default separator variables ., doesn’t work well model giving cor__eta.v.eta.cl. can easily change : gives easier way parse value: cor__eta.v..eta.cl","code":"tidy(fit.s) ## Transformation applied on every parameter tidy(fit.s, exponentiate=TRUE) tidy(fit.s, exponentiate=FALSE) ## No transformation applied ## Transformation applied to log-scaled population parameters tidy(fit.s, exponentiate=NA) options(broom.mixed.sep2=\"..\") tidy(fit.s)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"adding-a-confidence-interval-to-the-parameters","dir":"Articles","previous_headings":"Tidying the model parameters","what":"Adding a confidence interval to the parameters","title":"Using broom with nlmixr2","text":"default R method confint works nlmixr fit objects: transforms variables described . can still use exponentiate parameter control display confidence interval: However, broom also implemented way make data tidy dataset. easiest way get values nlmixr dataset use:  want confidence adaptive back-transformed scale, simply use following:","code":"confint(fit.s) confint(fit.s, exponentiate=FALSE) tidy(fit.s, conf.level=0.9) tidy(fit.s, conf.level=0.9, exponentiate=NA)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-other-model-information-with-tidy","dir":"Articles","previous_headings":"","what":"Extracting other model information with tidy","title":"Using broom with nlmixr2","text":"type information extracted can controlled effects argument.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-only-fixed-effect-parameters","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting only fixed effect parameters","title":"Using broom with nlmixr2","text":"fixed effect parameters can extracted effects=\"fixed\"","code":"tidy(fit.s, effects=\"fixed\")"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-only-random-parameters","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting only random parameters","title":"Using broom with nlmixr2","text":"random standard deviations can extracted effects=\"ran_pars\":","code":"tidy(fit.s, effects=\"ran_pars\")"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-random-values-also-called-etas","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting random values (also called ETAs)","title":"Using broom with nlmixr2","text":"random values, NONMEM ETAs, can extracted effects=\"ran_vals\" effects=\"random\" duplicate method running effects broom package supports effects=\"random\" broom.mixed package supports effects=\"ran_vals\".","code":"head(tidy(fit.s, effects=\"ran_vals\"))"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"extracting-random-coefficients","dir":"Articles","previous_headings":"Extracting other model information with tidy","what":"Extracting random coefficients","title":"Using broom with nlmixr2","text":"Random coefficients population fixed effect parameter + random effect parameter, possibly transformed correct scale. case can extract information nlmixr fit object :","code":"head(tidy(fit.s, effects=\"ran_coef\")) head(tidy(fit.s, effects=\"ran_coef\", exponentiate=NA)) head(tidy(fit.s, effects=\"ran_coef\", exponentiate=TRUE))"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"dotwhisker","dir":"Articles","previous_headings":"Example of using a tidy model estimates for other packages","what":"Dotwhisker","title":"Using broom with nlmixr2","text":"explained , standard format makes easier tidyverse packages interact model information. example piping tidy information dplyr filter effects dotwhisker package plot model parameter confidence intervals.","code":"options(broom.mixed.sep2=\": \", broom.mixed.sep2=\", \") library(ggplot2) library(dotwhisker) library(dplyr) fit.s %>%     tidy(exponentiate=NA) %>%     filter(effect==\"fixed\") %>%     dwplot()"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/broom.html","id":"huxtable","dir":"Articles","previous_headings":"Example of using a tidy model estimates for other packages","what":"Huxtable","title":"Using broom with nlmixr2","text":"allows easy creation report ready tables many formats including word. Huxtable relies broom implementation can also use huxtable compare runs: word-based table can also easily created tool: produces following word document. Happy tidying!","code":"library(huxtable) tbl <- huxreg('Phenobarbitol'=fit.s)  tbl huxreg('SAEM'=fit.s, 'FOCEi'=fit.f) library(officer) library(flextable)  ft  <- huxtable::as_flextable(tbl);      read_docx() %>%     flextable::body_add_flextable(ft)  %>%     print(target=\"pheno.docx\")"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/censoring.html","id":"censoring-support-in-nlmixr","dir":"Articles","previous_headings":"","what":"Censoring support in nlmixr","title":"Censoring in nlmixr","text":"general, censoring observation measured researcher knows something certain number. 2001, Beal introduced censoring pharmacometric community described common ways deal missing data. methods , data structure used nlmixr support : Estimate Likelihood observation censored limit. concentrations limit quantitation (left censored), can specify nlmixr two columns: DV, CENS. value censored, DV limit quantification, CENS 1. rest non-censored values, DV keeps normal value CENS 0. censored value limit quantitation (right censored), DV remains limit quantification CENS -1. expansion M3 method. cases, like PK, can also assume observations actually positive. Therefore, may want adjust likelihood take consideration fact. can accomplished nlmixr well adding LIMIT column. case left censored problem, can specify concentration LIMIT DV. works right left censored values. data columns LIMIT CENS, based Monolix method handling censored data.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/censoring.html","id":"data-output-for-censored-data-in-nlmixr","dir":"Articles","previous_headings":"","what":"Data output for censored data in nlmixr","title":"Censoring in nlmixr","text":"censored data output, often useful see predictions perform censored area. accomplish , simulated value used show prediction noise. used calculate standard residual values nlmixr. default, value simulated truncated normal distribution model assumptions censoring information specified data (though can use CDF method used npde package instead calculating npdes well). simulated value replaces original DV used calculate residuals requested. original limit information output lowerLim upperLim.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"nlmixr-model","dir":"Articles","previous_headings":"","what":"nlmixr model","title":"mavoglurant -- physiologically-based PK","text":"","code":"library(nlmixr2) library(xpose) library(xpose.nlmixr) library(ggplot2)  pbpk <- function(){   ini({     ##theta=exp(c(1.1, .3, 2, 7.6, .003, .3))     lKbBR = 1.1     lKbMU = 0.3     lKbAD = 2     lCLint = 7.6     lKbBO = 0.03     lKbRB = 0.3     eta.LClint ~ 4     add.err <- 1     prop.err <- 10   })   model({     KbBR = exp(lKbBR)     KbMU = exp(lKbMU)     KbAD = exp(lKbAD)     CLint= exp(lCLint + eta.LClint)     KbBO = exp(lKbBO)     KbRB = exp(lKbRB)      ## Regional blood flows     CO  = (187.00*WT^0.81)*60/1000;         # Cardiac output (L/h) from White et al (1968)     QHT = 4.0 *CO/100;     QBR = 12.0*CO/100;     QMU = 17.0*CO/100;     QAD = 5.0 *CO/100;     QSK = 5.0 *CO/100;     QSP = 3.0 *CO/100;     QPA = 1.0 *CO/100;     QLI = 25.5*CO/100;     QST = 1.0 *CO/100;     QGU = 14.0*CO/100;     QHA = QLI - (QSP + QPA + QST + QGU); # Hepatic artery blood flow     QBO = 5.0 *CO/100;     QKI = 19.0*CO/100;     QRB = CO - (QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI);     QLU = QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI + QRB;      ## Organs' volumes = organs' weights / organs' density     VLU = (0.76 *WT/100)/1.051;     VHT = (0.47 *WT/100)/1.030;     VBR = (2.00 *WT/100)/1.036;     VMU = (40.00*WT/100)/1.041;     VAD = (21.42*WT/100)/0.916;     VSK = (3.71 *WT/100)/1.116;     VSP = (0.26 *WT/100)/1.054;     VPA = (0.14 *WT/100)/1.045;     VLI = (2.57 *WT/100)/1.040;     VST = (0.21 *WT/100)/1.050;     VGU = (1.44 *WT/100)/1.043;     VBO = (14.29*WT/100)/1.990;     VKI = (0.44 *WT/100)/1.050;     VAB = (2.81 *WT/100)/1.040;     VVB = (5.62 *WT/100)/1.040;     VRB = (3.86 *WT/100)/1.040;      ## Fixed parameters     BP = 0.61;      # Blood:plasma partition coefficient     fup = 0.028;    # Fraction unbound in plasma     fub = fup/BP;   # Fraction unbound in blood      KbLU = exp(0.8334);     KbHT = exp(1.1205);     KbSK = exp(-.5238);     KbSP = exp(0.3224);     KbPA = exp(0.3224);     KbLI = exp(1.7604);     KbST = exp(0.3224);     KbGU = exp(1.2026);     KbKI = exp(1.3171);      ##-----------------------------------------     S15 = VVB*BP/1000;     C15 = Venous_Blood/S15      ##-----------------------------------------     d/dt(Lungs) = QLU*(Venous_Blood/VVB - Lungs/KbLU/VLU);     d/dt(Heart) = QHT*(Arterial_Blood/VAB - Heart/KbHT/VHT);     d/dt(Brain) = QBR*(Arterial_Blood/VAB - Brain/KbBR/VBR);     d/dt(Muscles) = QMU*(Arterial_Blood/VAB - Muscles/KbMU/VMU);     d/dt(Adipose) = QAD*(Arterial_Blood/VAB - Adipose/KbAD/VAD);     d/dt(Skin) = QSK*(Arterial_Blood/VAB - Skin/KbSK/VSK);     d/dt(Spleen) = QSP*(Arterial_Blood/VAB - Spleen/KbSP/VSP);     d/dt(Pancreas) = QPA*(Arterial_Blood/VAB - Pancreas/KbPA/VPA);     d/dt(Liver) = QHA*Arterial_Blood/VAB + QSP*Spleen/KbSP/VSP + QPA*Pancreas/KbPA/VPA + QST*Stomach/KbST/VST + QGU*Gut/KbGU/VGU - CLint*fub*Liver/KbLI/VLI - QLI*Liver/KbLI/VLI;     d/dt(Stomach) = QST*(Arterial_Blood/VAB - Stomach/KbST/VST);     d/dt(Gut) = QGU*(Arterial_Blood/VAB - Gut/KbGU/VGU);     d/dt(Bones) = QBO*(Arterial_Blood/VAB - Bones/KbBO/VBO);     d/dt(Kidneys) = QKI*(Arterial_Blood/VAB - Kidneys/KbKI/VKI);     d/dt(Arterial_Blood) = QLU*(Lungs/KbLU/VLU - Arterial_Blood/VAB);     d/dt(Venous_Blood) = QHT*Heart/KbHT/VHT + QBR*Brain/KbBR/VBR + QMU*Muscles/KbMU/VMU + QAD*Adipose/KbAD/VAD + QSK*Skin/KbSK/VSK + QLI*Liver/KbLI/VLI + QBO*Bones/KbBO/VBO + QKI*Kidneys/KbKI/VKI + QRB*Rest_of_Body/KbRB/VRB - QLU*Venous_Blood/VVB;     d/dt(Rest_of_Body) = QRB*(Arterial_Blood/VAB - Rest_of_Body/KbRB/VRB);      C15 ~ add(add.err) + prop(prop.err)   }) }  dat <- read.csv(\"Mavoglurant_A2121_nmpk.csv\") dat$occ = unlist(with(dat, tapply(EVID, ID, function(x) cumsum(x>0)))) dat = subset(dat, occ==1) dat = subset(dat, ID<812) ## First 20 dat = subset(dat, EVID>0 | DV>0) dat$CMT[dat$CMT == 0]  <- 1; dat$CMT[dat$EVID == 1]  <- \"Venous_Blood\" ## Compartment dosed to is Venous Blood dat$CMT[dat$EVID != 1]  <- \"C15\" ## Observing C15  gofs <- function(fit){     ################################################################################     ## Standard plots     ################################################################################     plot(fit)      xpdb <- xpose_data_nlmixr(fit) ## Convert to nlmixr object      print(dv_vs_pred(xpdb) +           ylab(\"Observed Mavoglurant Concentrations (ng/mL)\") +           xlab(\"Population Predicted Mavoglurant Concentrations (ng/mL)\"));      print(dv_vs_ipred(xpdb) +           ylab(\"Observed Mavoglurant Concentrations (ng/mL)\") +           xlab(\"Individual Predicted Mavoglurant Concentrations (ng/mL)\"));      print(res_vs_pred(xpdb) +           ylab(\"Conditional Weighted Residuals\") +           xlab(\"Population Predicted Mavoglurant Concentrations (ng/mL)\"));      print(res_vs_idv(xpdb) +           ylab(\"Conditional Weighted Residuals\") +           xlab(\"Time (h)\"));      if (!is.null(fit$saem)){         print(prm_vs_iteration(xpdb));     }      print(absval_res_vs_idv(xpdb, res = 'IWRES') +           ylab(\"Individual Weighted Residuals\") +           xlab(\"Time (h)\"))      print(absval_res_vs_pred(xpdb, res = 'IWRES') +           ylab(\"Individual Weighted Residuals\") +           xlab(\"Population Predicted Mavoglurant Concentrations (ng/mL)\"))      print(ind_plots(xpdb, nrow=3, ncol=4) +           ylab(\"Predicted and Observed Mavoglurant Concentrations (ng/mL)\") +           xlab(\"Time (h)\"))      print(res_distrib(xpdb) +           ylab(\"Density\") +           xlab(\"Conditional Weighted Residuals\"));     # Visual Predictive Checks     f1 <- vpcPlot(fit,n=500,stratify=\"DOSE\", show=list(obs_dv=T), log_y=TRUE,            bins = c(0, 2, 4, 6, 8, 10, 20, 30, 40, 50),            ylab = \"Mavoglurant Concentrations (ng/mL)\",            xlab = \"Time (hours)\")     f2 <- vpcPlot(fit,n=500, show=list(obs_dv=T), bins = c(0, 2, 4, 6, 8, 10, 20, 30, 40, 50), log_y=TRUE,                  ylab = \"Mavoglurant Concentrations (ng/mL)\", xlab = \"Time (hours)\")     plot(f1)     plot(f2) }"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"fit-addprop-saem","dir":"Articles","previous_headings":"SAEM","what":"Fit add+prop SAEM","title":"mavoglurant -- physiologically-based PK","text":"","code":"fit.addProp.S <- nlmixr(pbpk, dat, est=\"saem\", control=list(print=0),                          table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  gofs(fit.addProp.S) #>        ID          CMT                 EVID        EVI2        MDV    #>  793    : 15   Length:256         Min.   :0   Min.   :0   Min.   :0   #>  796    : 15   Class :character   1st Qu.:0   1st Qu.:0   1st Qu.:0   #>  797    : 14   Mode  :character   Median :0   Median :0   Median :0   #>  799    : 14                      Mean   :0   Mean   :0   Mean   :0   #>  803    : 14                      3rd Qu.:0   3rd Qu.:0   3rd Qu.:0   #>  806    : 14                      Max.   :0   Max.   :0   Max.   :0   #>  (Other):170                                                          #>        DV              LNDV             AMT         TIME             DOSE       #>  Min.   :  2.01   Min.   :0.6981   Min.   :0   Min.   : 0.200   Min.   :25.00   #>  1st Qu.: 29.30   1st Qu.:3.3780   1st Qu.:0   1st Qu.: 0.533   1st Qu.:25.00   #>  Median : 88.10   Median :4.4775   Median :0   Median : 2.200   Median :25.00   #>  Mean   :184.95   Mean   :4.4056   Mean   :0   Mean   : 6.471   Mean   :29.59   #>  3rd Qu.:327.50   3rd Qu.:5.7915   3rd Qu.:0   3rd Qu.: 8.200   3rd Qu.:37.50   #>  Max.   :985.00   Max.   :6.8930   Max.   :0   Max.   :48.167   Max.   :37.50   #>                                                                                 #>       OCC         RATE        AGE             SEX             RACE        #>  Min.   :1   Min.   :0   Min.   :19.00   Min.   :1.000   Min.   : 1.000   #>  1st Qu.:1   1st Qu.:0   1st Qu.:23.75   1st Qu.:1.000   1st Qu.: 1.000   #>  Median :1   Median :0   Median :31.00   Median :1.000   Median : 1.000   #>  Mean   :1   Mean   :0   Mean   :33.92   Mean   :1.219   Mean   : 5.445   #>  3rd Qu.:1   3rd Qu.:0   3rd Qu.:43.00   3rd Qu.:1.000   3rd Qu.: 2.000   #>  Max.   :1   Max.   :0   Max.   :50.00   Max.   :2.000   Max.   :88.000   #>                                                                           #>        WT               HT            EPRED               ERES           #>  Min.   : 61.90   Min.   :1.560   Min.   :  0.5143   Min.   :-523.8847   #>  1st Qu.: 68.70   1st Qu.:1.650   1st Qu.: 30.9813   1st Qu.: -24.4194   #>  Median : 77.40   Median :1.770   Median : 99.2949   Median :   0.0526   #>  Mean   : 78.67   Mean   :1.742   Mean   :198.0135   Mean   : -13.0631   #>  3rd Qu.: 86.10   3rd Qu.:1.830   3rd Qu.:335.1844   3rd Qu.:  14.1390   #>  Max.   :103.50   Max.   :1.910   Max.   :883.8847   Max.   : 347.6242   #>                                                                          #>       NPDE                NPD                 PRED               RES            #>  Min.   :-2.935199   Min.   :-2.935199   Min.   :  0.5117   Min.   :-532.1409   #>  1st Qu.:-0.717066   1st Qu.:-0.717066   1st Qu.: 30.1771   1st Qu.: -21.8163   #>  Median : 0.008356   Median : 0.008356   Median : 95.7582   Median :   0.9355   #>  Mean   : 0.001308   Mean   : 0.001308   Mean   :196.9020   Mean   : -11.9516   #>  3rd Qu.: 0.679772   3rd Qu.: 0.679772   3rd Qu.:335.7669   3rd Qu.:  14.2728   #>  Max.   : 2.474740   Max.   : 2.474740   Max.   :892.1409   Max.   : 356.1652   #>                                                                                 #>       WRES              IPRED               IRES               IWRES         #>  Min.   :-2.43491   Min.   :  0.3217   Min.   :-513.3152   Min.   :-2.4132   #>  1st Qu.:-0.67384   1st Qu.: 27.1350   1st Qu.: -15.1977   1st Qu.:-0.6303   #>  Median : 0.06236   Median : 97.0370   Median :  -0.3605   Median :-0.0285   #>  Mean   : 0.09261   Mean   :194.9558   Mean   : -10.0054   Mean   : 0.0532   #>  3rd Qu.: 0.72509   3rd Qu.:332.7572   3rd Qu.:  11.4958   3rd Qu.: 0.6855   #>  Max.   : 4.38369   Max.   :873.3152   Max.   : 338.5404   Max.   : 2.8964   #>                                                                              #>      CPRED               CRES              CWRES            ETA.LCLINT        #>  Min.   : -0.7037   Min.   :-533.258   Min.   :-2.48793   Min.   :-0.636333   #>  1st Qu.: 28.2785   1st Qu.: -21.689   1st Qu.:-0.72941   1st Qu.:-0.333454   #>  Median : 94.5632   Median :   1.583   Median : 0.08715   Median : 0.137383   #>  Mean   :196.2686   Mean   : -11.318   Mean   : 0.03609   Mean   : 0.005812   #>  3rd Qu.:336.0810   3rd Qu.:  15.221   3rd Qu.: 0.73238   3rd Qu.: 0.257907   #>  Max.   :893.2583   Max.   : 354.215   Max.   : 2.66161   Max.   : 0.451128   #>                                                                               #>      LUNGS               HEART               BRAIN             MUSCLES         #>  Min.   :0.0002528   Min.   :0.0002142   Min.   :0.002248   Min.   :0.003731   #>  1st Qu.:0.0216588   1st Qu.:0.0184007   1st Qu.:0.194603   1st Qu.:0.323622   #>  Median :0.0759579   Median :0.0658837   Median :0.738473   Median :1.248829   #>  Mean   :0.1542607   Mean   :0.1624718   Mean   :1.497554   Mean   :2.383302   #>  3rd Qu.:0.2641742   3rd Qu.:0.2490483   3rd Qu.:2.954854   3rd Qu.:4.677097   #>  Max.   :0.6738089   Max.   :0.8433921   Max.   :4.806670   Max.   :7.220636   #>                                                                                #>     ADIPOSE             SKIN               SPLEEN             PANCREAS         #>  Min.   :0.07558   Min.   :0.0003016   Min.   :5.188e-05   Min.   :2.821e-05   #>  1st Qu.:2.63980   1st Qu.:0.0259241   1st Qu.:4.449e-03   1st Qu.:2.421e-03   #>  Median :3.99597   Median :0.0930605   Median :1.572e-02   Median :8.588e-03   #>  Mean   :4.00018   Mean   :0.2291940   Mean   :3.618e-02   Mean   :2.057e-02   #>  3rd Qu.:5.35314   3rd Qu.:0.3550839   3rd Qu.:5.650e-02   3rd Qu.:3.143e-02   #>  Max.   :7.91034   Max.   :1.1496034   Max.   :2.122e-01   Max.   :1.196e-01   #>                                                                                #>      LIVER             STOMACH               GUT                BONES          #>  Min.   :0.001167   Min.   :4.219e-05   Min.   :0.0007031   Min.   :0.005892   #>  1st Qu.:0.119514   1st Qu.:3.623e-03   1st Qu.:0.0604017   1st Qu.:0.608290   #>  Median :0.427493   Median :1.292e-02   Median :0.2159981   Median :1.957449   #>  Mean   :0.998056   Mean   :3.170e-02   Mean   :0.5324453   Mean   :1.853818   #>  3rd Qu.:1.626811   3rd Qu.:4.819e-02   3rd Qu.:0.8130848   3rd Qu.:2.782872   #>  Max.   :4.272264   Max.   :1.741e-01   Max.   :2.8106661   Max.   :4.354734   #>                                                                                #>     KIDNEYS          ARTERIAL_BLOOD       VENOUS_BLOOD        REST_OF_BODY      #>  Min.   :0.0002381   Min.   :0.0004107   Min.   :0.0008207   Min.   :0.002153   #>  1st Qu.:0.0204191   1st Qu.:0.0351942   1st Qu.:0.0703057   1st Qu.:0.187551   #>  Median :0.0720261   Median :0.1236023   Median :0.2463491   Median :0.754165   #>  Mean   :0.1616563   Mean   :0.2556180   Mean   :0.4962671   Mean   :1.264640   #>  3rd Qu.:0.2570456   3rd Qu.:0.4324578   3rd Qu.:0.8536919   3rd Qu.:2.317678   #>  Max.   :0.9284196   Max.   :1.1893297   Max.   :2.1118947   Max.   :3.582505   #>                                                                                 #>       KBBR           KBMU             KBAD           CLINT           KBBO       #>  Min.   :7.48   Min.   :0.6212   Min.   :7.199   Min.   : 769   Min.   :4.684   #>  1st Qu.:7.48   1st Qu.:0.6212   1st Qu.:7.199   1st Qu.:1041   1st Qu.:4.684   #>  Median :7.48   Median :0.6212   Median :7.199   Median :1667   Median :4.684   #>  Mean   :7.48   Mean   :0.6212   Mean   :7.199   Mean   :1533   Mean   :4.684   #>  3rd Qu.:7.48   3rd Qu.:0.6212   3rd Qu.:7.199   3rd Qu.:1881   3rd Qu.:4.684   #>  Max.   :7.48   Max.   :0.6212   Max.   :7.199   Max.   :2281   Max.   :4.684   #>                                                                                 #>       KBRB             CO             QHT             QBR        #>  Min.   :3.679   Min.   :317.1   Min.   :12.69   Min.   :38.06   #>  1st Qu.:3.679   1st Qu.:345.1   1st Qu.:13.80   1st Qu.:41.41   #>  Median :3.679   Median :380.1   Median :15.20   Median :45.61   #>  Mean   :3.679   Mean   :384.5   Mean   :15.38   Mean   :46.14   #>  3rd Qu.:3.679   3rd Qu.:414.3   3rd Qu.:16.57   3rd Qu.:49.72   #>  Max.   :3.679   Max.   :480.9   Max.   :19.24   Max.   :57.71   #>                                                                  #>       QMU             QAD             QSK             QSP         #>  Min.   :53.92   Min.   :15.86   Min.   :15.86   Min.   : 9.514   #>  1st Qu.:58.66   1st Qu.:17.25   1st Qu.:17.25   1st Qu.:10.353   #>  Median :64.61   Median :19.00   Median :19.00   Median :11.402   #>  Mean   :65.36   Mean   :19.22   Mean   :19.22   Mean   :11.534   #>  3rd Qu.:70.44   3rd Qu.:20.72   3rd Qu.:20.72   3rd Qu.:12.430   #>  Max.   :81.76   Max.   :24.05   Max.   :24.05   Max.   :14.428   #>                                                                   #>       QPA             QLI              QST             QGU        #>  Min.   :3.171   Min.   : 80.87   Min.   :3.171   Min.   :44.40   #>  1st Qu.:3.451   1st Qu.: 88.00   1st Qu.:3.451   1st Qu.:48.31   #>  Median :3.801   Median : 96.92   Median :3.801   Median :53.21   #>  Mean   :3.845   Mean   : 98.04   Mean   :3.845   Mean   :53.83   #>  3rd Qu.:4.143   3rd Qu.:105.65   3rd Qu.:4.143   3rd Qu.:58.01   #>  Max.   :4.809   Max.   :122.64   Max.   :4.809   Max.   :67.33   #>                                                                   #>       QHA             QBO             QKI             QRB        #>  Min.   :20.61   Min.   :15.86   Min.   :60.26   Min.   :23.79   #>  1st Qu.:22.43   1st Qu.:17.25   1st Qu.:65.57   1st Qu.:25.88   #>  Median :24.71   Median :19.00   Median :72.21   Median :28.51   #>  Mean   :24.99   Mean   :19.22   Mean   :73.05   Mean   :28.84   #>  3rd Qu.:26.93   3rd Qu.:20.72   3rd Qu.:78.72   3rd Qu.:31.07   #>  Max.   :31.26   Max.   :24.05   Max.   :91.38   Max.   :36.07   #>                                                                  #>       QLU             VLU              VHT              VBR        #>  Min.   :317.1   Min.   :0.4476   Min.   :0.2825   Min.   :1.195   #>  1st Qu.:345.1   1st Qu.:0.4968   1st Qu.:0.3135   1st Qu.:1.326   #>  Median :380.1   Median :0.5597   Median :0.3532   Median :1.494   #>  Mean   :384.5   Mean   :0.5689   Mean   :0.3590   Mean   :1.519   #>  3rd Qu.:414.3   3rd Qu.:0.6226   3rd Qu.:0.3929   3rd Qu.:1.662   #>  Max.   :480.9   Max.   :0.7484   Max.   :0.4723   Max.   :1.998   #>                                                                    #>       VMU             VAD             VSK             VSP         #>  Min.   :23.78   Min.   :14.47   Min.   :2.058   Min.   :0.1527   #>  1st Qu.:26.40   1st Qu.:16.07   1st Qu.:2.284   1st Qu.:0.1695   #>  Median :29.74   Median :18.10   Median :2.573   Median :0.1909   #>  Mean   :30.23   Mean   :18.40   Mean   :2.615   Mean   :0.1941   #>  3rd Qu.:33.08   3rd Qu.:20.13   3rd Qu.:2.862   3rd Qu.:0.2124   #>  Max.   :39.77   Max.   :24.20   Max.   :3.441   Max.   :0.2553   #>                                                                   #>       VPA               VLI             VST              VGU         #>  Min.   :0.08293   Min.   :1.530   Min.   :0.1238   Min.   :0.8546   #>  1st Qu.:0.09204   1st Qu.:1.698   1st Qu.:0.1374   1st Qu.:0.9485   #>  Median :0.10369   Median :1.913   Median :0.1548   Median :1.0686   #>  Mean   :0.10540   Mean   :1.944   Mean   :0.1573   Mean   :1.0862   #>  3rd Qu.:0.11535   3rd Qu.:2.128   3rd Qu.:0.1722   3rd Qu.:1.1887   #>  Max.   :0.13866   Max.   :2.558   Max.   :0.2070   Max.   :1.4290   #>                                                                      #>       VBO             VKI              VAB             VVB        #>  Min.   :4.445   Min.   :0.2594   Min.   :1.672   Min.   :3.345   #>  1st Qu.:4.933   1st Qu.:0.2879   1st Qu.:1.856   1st Qu.:3.712   #>  Median :5.558   Median :0.3243   Median :2.091   Median :4.183   #>  Mean   :5.649   Mean   :0.3297   Mean   :2.126   Mean   :4.251   #>  3rd Qu.:6.183   3rd Qu.:0.3608   3rd Qu.:2.326   3rd Qu.:4.653   #>  Max.   :7.432   Max.   :0.4337   Max.   :2.796   Max.   :5.593   #>                                                                   #>       VRB             S15                TAD            DOSENUM  #>  Min.   :2.297   Min.   :0.002040   Min.   : 0.200   Min.   :1   #>  1st Qu.:2.550   1st Qu.:0.002265   1st Qu.: 0.533   1st Qu.:1   #>  Median :2.873   Median :0.002551   Median : 2.200   Median :1   #>  Mean   :2.920   Mean   :0.002593   Mean   : 6.471   Mean   :1   #>  3rd Qu.:3.196   3rd Qu.:0.002838   3rd Qu.: 8.200   3rd Qu.:1   #>  Max.   :3.841   Max.   :0.003412   Max.   :48.167   Max.   :1   #>                                                                  #>    eta.LClint        #>  Min.   :-0.636333   #>  1st Qu.:-0.333454   #>  Median : 0.137383   #>  Mean   : 0.005812   #>  3rd Qu.: 0.257907   #>  Max.   : 0.451128   #>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"change-error-to-lognormal","dir":"Articles","previous_headings":"SAEM","what":"Change error to lognormal","title":"mavoglurant -- physiologically-based PK","text":"NOTE: lognormal distribution AIC/loglik/etc normal scale. Therefore, can compare AICs fit.lnorm fit.addProp since calculated scale. case can see AIC log-normal model better AIC addProp model.","code":"fit.lnorm.S <- pbpk %>%     model({C15 ~ lnorm(lnorm.err)}) %>% # Change C15 to be log-normally distributed     ## Requires data since piping from pbpk model     nlmixr(dat,est=\"saem\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 gofs(fit.lnorm.S) #>        ID          CMT                 EVID        EVI2        MDV    #>  793    : 15   Length:256         Min.   :0   Min.   :0   Min.   :0   #>  796    : 15   Class :character   1st Qu.:0   1st Qu.:0   1st Qu.:0   #>  797    : 14   Mode  :character   Median :0   Median :0   Median :0   #>  799    : 14                      Mean   :0   Mean   :0   Mean   :0   #>  803    : 14                      3rd Qu.:0   3rd Qu.:0   3rd Qu.:0   #>  806    : 14                      Max.   :0   Max.   :0   Max.   :0   #>  (Other):170                                                          #>        DV              LNDV             AMT         TIME             DOSE       #>  Min.   :  2.01   Min.   :0.6981   Min.   :0   Min.   : 0.200   Min.   :25.00   #>  1st Qu.: 29.30   1st Qu.:3.3780   1st Qu.:0   1st Qu.: 0.533   1st Qu.:25.00   #>  Median : 88.10   Median :4.4775   Median :0   Median : 2.200   Median :25.00   #>  Mean   :184.95   Mean   :4.4056   Mean   :0   Mean   : 6.471   Mean   :29.59   #>  3rd Qu.:327.50   3rd Qu.:5.7915   3rd Qu.:0   3rd Qu.: 8.200   3rd Qu.:37.50   #>  Max.   :985.00   Max.   :6.8930   Max.   :0   Max.   :48.167   Max.   :37.50   #>                                                                                 #>       OCC         RATE        AGE             SEX             RACE        #>  Min.   :1   Min.   :0   Min.   :19.00   Min.   :1.000   Min.   : 1.000   #>  1st Qu.:1   1st Qu.:0   1st Qu.:23.75   1st Qu.:1.000   1st Qu.: 1.000   #>  Median :1   Median :0   Median :31.00   Median :1.000   Median : 1.000   #>  Mean   :1   Mean   :0   Mean   :33.92   Mean   :1.219   Mean   : 5.445   #>  3rd Qu.:1   3rd Qu.:0   3rd Qu.:43.00   3rd Qu.:1.000   3rd Qu.: 2.000   #>  Max.   :1   Max.   :0   Max.   :50.00   Max.   :2.000   Max.   :88.000   #>                                                                           #>        WT               HT            EPRED               ERES           #>  Min.   : 61.90   Min.   :1.560   Min.   :  0.6331   Min.   :-492.9075   #>  1st Qu.: 68.70   1st Qu.:1.650   1st Qu.: 30.9454   1st Qu.: -23.4824   #>  Median : 77.40   Median :1.770   Median :104.2367   Median :  -0.2906   #>  Mean   : 78.67   Mean   :1.742   Mean   :191.1033   Mean   :  -6.1529   #>  3rd Qu.: 86.10   3rd Qu.:1.830   3rd Qu.:316.2809   3rd Qu.:  16.1991   #>  Max.   :103.50   Max.   :1.910   Max.   :852.9075   Max.   : 367.0875   #>                                                                          #>       NPDE               NPD                PRED               RES            #>  Min.   :-2.93520   Min.   :-2.93520   Min.   :  0.6325   Min.   :-502.2661   #>  1st Qu.:-0.79779   1st Qu.:-0.79779   1st Qu.: 31.7104   1st Qu.: -23.3620   #>  Median : 0.01671   Median : 0.01671   Median :102.9339   Median :  -0.2013   #>  Mean   :-0.13118   Mean   :-0.13118   Mean   :191.1633   Mean   :  -6.2129   #>  3rd Qu.: 0.60276   3rd Qu.: 0.60276   3rd Qu.:317.2256   3rd Qu.:  16.5768   #>  Max.   : 2.05375   Max.   : 2.05375   Max.   :862.2661   Max.   : 377.4247   #>                                                                               #>       WRES               IPRED               IRES              IWRES          #>  Min.   :-3.052314   Min.   :  0.8702   Min.   :-493.592   Min.   :-3.02874   #>  1st Qu.:-0.717736   1st Qu.: 29.4336   1st Qu.: -21.019   1st Qu.:-0.81794   #>  Median :-0.008093   Median :110.8090   Median :  -1.010   Median :-0.07477   #>  Mean   :-0.072453   Mean   :190.0317   Mean   :  -5.081   Mean   :-0.09384   #>  3rd Qu.: 0.656429   3rd Qu.:316.2691   3rd Qu.:  12.329   3rd Qu.: 0.67939   #>  Max.   : 2.418322   Max.   :853.5924   Max.   : 363.889   Max.   : 3.34199   #>                                                                               #>      CPRED               CRES               CWRES            ETA.LCLINT      #>  Min.   :  0.6272   Min.   :-502.5950   Min.   :-3.05172   Min.   :-0.6315   #>  1st Qu.: 31.7441   1st Qu.: -23.1552   1st Qu.:-0.71823   1st Qu.:-0.2990   #>  Median :102.9636   Median :  -0.2752   Median :-0.01603   Median : 0.1066   #>  Mean   :191.6890   Mean   :  -6.7386   Mean   :-0.08126   Mean   :-0.0200   #>  3rd Qu.:317.9609   3rd Qu.:  15.8504   3rd Qu.: 0.65374   3rd Qu.: 0.2464   #>  Max.   :862.5950   Max.   : 376.1411   Max.   : 2.34353   Max.   : 0.4329   #>                                                                              #>      LUNGS               HEART               BRAIN             MUSCLES         #>  Min.   :0.0006838   Min.   :0.0005787   Min.   :0.008757   Min.   :0.009226   #>  1st Qu.:0.0233558   1st Qu.:0.0198613   1st Qu.:0.307061   1st Qu.:0.321108   #>  Median :0.0850527   Median :0.0739511   Median :1.274784   Median :1.289504   #>  Mean   :0.1506973   Mean   :0.1597971   Mean   :1.928454   Mean   :2.213161   #>  3rd Qu.:0.2566820   3rd Qu.:0.2379271   3rd Qu.:3.461631   3rd Qu.:4.343395   #>  Max.   :0.6650013   Max.   :0.8380577   Max.   :5.521798   Max.   :6.913628   #>                                                                                #>     ADIPOSE            SKIN               SPLEEN             PANCREAS         #>  Min.   :0.1759   Min.   :0.0008149   Min.   :0.0001403   Min.   :7.627e-05   #>  1st Qu.:2.5907   1st Qu.:0.0279852   1st Qu.:0.0047995   1st Qu.:2.612e-03   #>  Median :4.0840   Median :0.1045123   Median :0.0176175   Median :9.628e-03   #>  Mean   :4.0830   Mean   :0.2255123   Mean   :0.0354591   Mean   :2.019e-02   #>  3rd Qu.:5.5408   3rd Qu.:0.3390837   3rd Qu.:0.0545023   3rd Qu.:3.001e-02   #>  Max.   :8.3623   Max.   :1.1424994   Max.   :0.2104963   Max.   :1.187e-01   #>                                                                               #>      LIVER             STOMACH              GUT              BONES          #>  Min.   :0.003823   Min.   :0.000114   Min.   :0.00190   Min.   :0.004534   #>  1st Qu.:0.121450   1st Qu.:0.003910   1st Qu.:0.06519   1st Qu.:0.160199   #>  Median :0.475210   Median :0.014491   Median :0.24238   Median :0.688594   #>  Mean   :1.008375   Mean   :0.031155   Mean   :0.52357   Mean   :0.927186   #>  3rd Qu.:1.581715   3rd Qu.:0.046077   3rd Qu.:0.77697   3rd Qu.:1.612842   #>  Max.   :4.647168   Max.   :0.172947   Max.   :2.79266   Max.   :2.502575   #>                                                                             #>     KIDNEYS         ARTERIAL_BLOOD      VENOUS_BLOOD      REST_OF_BODY     #>  Min.   :0.000644   Min.   :0.001111   Min.   :0.00222   Min.   :0.01647   #>  1st Qu.:0.022025   1st Qu.:0.037954   1st Qu.:0.07581   1st Qu.:0.63290   #>  Median :0.080703   Median :0.138424   Median :0.27582   Median :2.51086   #>  Mean   :0.158330   Mean   :0.249826   Mean   :0.48471   Mean   :2.31805   #>  3rd Qu.:0.248906   3rd Qu.:0.420919   3rd Qu.:0.83107   3rd Qu.:3.62933   #>  Max.   :0.920234   Max.   :1.174850   Max.   :2.08368   Max.   :5.51603   #>                                                                            #>       KBBR            KBMU             KBAD           CLINT        #>  Min.   :10.71   Min.   :0.5713   Min.   :7.519   Min.   : 741.8   #>  1st Qu.:10.71   1st Qu.:0.5713   1st Qu.:7.519   1st Qu.:1034.6   #>  Median :10.71   Median :0.5713   Median :7.519   Median :1552.0   #>  Mean   :10.71   Mean   :0.5713   Mean   :7.519   Mean   :1430.6   #>  3rd Qu.:10.71   3rd Qu.:0.5713   3rd Qu.:7.519   3rd Qu.:1784.8   #>  Max.   :10.71   Max.   :0.5713   Max.   :7.519   Max.   :2150.8   #>                                                                    #>       KBBO            KBRB             CO             QHT        #>  Min.   :1.481   Min.   :9.906   Min.   :317.1   Min.   :12.69   #>  1st Qu.:1.481   1st Qu.:9.906   1st Qu.:345.1   1st Qu.:13.80   #>  Median :1.481   Median :9.906   Median :380.1   Median :15.20   #>  Mean   :1.481   Mean   :9.906   Mean   :384.5   Mean   :15.38   #>  3rd Qu.:1.481   3rd Qu.:9.906   3rd Qu.:414.3   3rd Qu.:16.57   #>  Max.   :1.481   Max.   :9.906   Max.   :480.9   Max.   :19.24   #>                                                                  #>       QBR             QMU             QAD             QSK        #>  Min.   :38.06   Min.   :53.92   Min.   :15.86   Min.   :15.86   #>  1st Qu.:41.41   1st Qu.:58.66   1st Qu.:17.25   1st Qu.:17.25   #>  Median :45.61   Median :64.61   Median :19.00   Median :19.00   #>  Mean   :46.14   Mean   :65.36   Mean   :19.22   Mean   :19.22   #>  3rd Qu.:49.72   3rd Qu.:70.44   3rd Qu.:20.72   3rd Qu.:20.72   #>  Max.   :57.71   Max.   :81.76   Max.   :24.05   Max.   :24.05   #>                                                                  #>       QSP              QPA             QLI              QST        #>  Min.   : 9.514   Min.   :3.171   Min.   : 80.87   Min.   :3.171   #>  1st Qu.:10.353   1st Qu.:3.451   1st Qu.: 88.00   1st Qu.:3.451   #>  Median :11.402   Median :3.801   Median : 96.92   Median :3.801   #>  Mean   :11.534   Mean   :3.845   Mean   : 98.04   Mean   :3.845   #>  3rd Qu.:12.430   3rd Qu.:4.143   3rd Qu.:105.65   3rd Qu.:4.143   #>  Max.   :14.428   Max.   :4.809   Max.   :122.64   Max.   :4.809   #>                                                                    #>       QGU             QHA             QBO             QKI        #>  Min.   :44.40   Min.   :20.61   Min.   :15.86   Min.   :60.26   #>  1st Qu.:48.31   1st Qu.:22.43   1st Qu.:17.25   1st Qu.:65.57   #>  Median :53.21   Median :24.71   Median :19.00   Median :72.21   #>  Mean   :53.83   Mean   :24.99   Mean   :19.22   Mean   :73.05   #>  3rd Qu.:58.01   3rd Qu.:26.93   3rd Qu.:20.72   3rd Qu.:78.72   #>  Max.   :67.33   Max.   :31.26   Max.   :24.05   Max.   :91.38   #>                                                                  #>       QRB             QLU             VLU              VHT         #>  Min.   :23.79   Min.   :317.1   Min.   :0.4476   Min.   :0.2825   #>  1st Qu.:25.88   1st Qu.:345.1   1st Qu.:0.4968   1st Qu.:0.3135   #>  Median :28.51   Median :380.1   Median :0.5597   Median :0.3532   #>  Mean   :28.84   Mean   :384.5   Mean   :0.5689   Mean   :0.3590   #>  3rd Qu.:31.07   3rd Qu.:414.3   3rd Qu.:0.6226   3rd Qu.:0.3929   #>  Max.   :36.07   Max.   :480.9   Max.   :0.7484   Max.   :0.4723   #>                                                                    #>       VBR             VMU             VAD             VSK        #>  Min.   :1.195   Min.   :23.78   Min.   :14.47   Min.   :2.058   #>  1st Qu.:1.326   1st Qu.:26.40   1st Qu.:16.07   1st Qu.:2.284   #>  Median :1.494   Median :29.74   Median :18.10   Median :2.573   #>  Mean   :1.519   Mean   :30.23   Mean   :18.40   Mean   :2.615   #>  3rd Qu.:1.662   3rd Qu.:33.08   3rd Qu.:20.13   3rd Qu.:2.862   #>  Max.   :1.998   Max.   :39.77   Max.   :24.20   Max.   :3.441   #>                                                                  #>       VSP              VPA               VLI             VST         #>  Min.   :0.1527   Min.   :0.08293   Min.   :1.530   Min.   :0.1238   #>  1st Qu.:0.1695   1st Qu.:0.09204   1st Qu.:1.698   1st Qu.:0.1374   #>  Median :0.1909   Median :0.10369   Median :1.913   Median :0.1548   #>  Mean   :0.1941   Mean   :0.10540   Mean   :1.944   Mean   :0.1573   #>  3rd Qu.:0.2124   3rd Qu.:0.11535   3rd Qu.:2.128   3rd Qu.:0.1722   #>  Max.   :0.2553   Max.   :0.13866   Max.   :2.558   Max.   :0.2070   #>                                                                      #>       VGU              VBO             VKI              VAB        #>  Min.   :0.8546   Min.   :4.445   Min.   :0.2594   Min.   :1.672   #>  1st Qu.:0.9485   1st Qu.:4.933   1st Qu.:0.2879   1st Qu.:1.856   #>  Median :1.0686   Median :5.558   Median :0.3243   Median :2.091   #>  Mean   :1.0862   Mean   :5.649   Mean   :0.3297   Mean   :2.126   #>  3rd Qu.:1.1887   3rd Qu.:6.183   3rd Qu.:0.3608   3rd Qu.:2.326   #>  Max.   :1.4290   Max.   :7.432   Max.   :0.4337   Max.   :2.796   #>                                                                    #>       VVB             VRB             S15                TAD         #>  Min.   :3.345   Min.   :2.297   Min.   :0.002040   Min.   : 0.200   #>  1st Qu.:3.712   1st Qu.:2.550   1st Qu.:0.002265   1st Qu.: 0.533   #>  Median :4.183   Median :2.873   Median :0.002551   Median : 2.200   #>  Mean   :4.251   Mean   :2.920   Mean   :0.002593   Mean   : 6.471   #>  3rd Qu.:4.653   3rd Qu.:3.196   3rd Qu.:0.002838   3rd Qu.: 8.200   #>  Max.   :5.593   Max.   :3.841   Max.   :0.003412   Max.   :48.167   #>                                                                      #>     DOSENUM    eta.LClint      #>  Min.   :1   Min.   :-0.6315   #>  1st Qu.:1   1st Qu.:-0.2990   #>  Median :1   Median : 0.1066   #>  Mean   :1   Mean   :-0.0200   #>  3rd Qu.:1   3rd Qu.: 0.2464   #>  Max.   :1   Max.   : 0.4329   #>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"piping-to-focei","dir":"Articles","previous_headings":"","what":"Piping to FOCEi","title":"mavoglurant -- physiologically-based PK","text":"can pipe models different estimation methods new estimation methods.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"additive-proportional","dir":"Articles","previous_headings":"Piping to FOCEi","what":"Additive + Proportional","title":"mavoglurant -- physiologically-based PK","text":"","code":"fit.addProp.F <- fit.addProp.S %>%     nlmixr(est=\"focei\",            control=list(print=0),             table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:22  #> done ## Since this was a model pipline, the data ## remains the same as the last fit.  gofs(fit.addProp.F) #>        ID          CMT                 EVID        EVI2        MDV    #>  793    : 15   Length:256         Min.   :0   Min.   :0   Min.   :0   #>  796    : 15   Class :character   1st Qu.:0   1st Qu.:0   1st Qu.:0   #>  797    : 14   Mode  :character   Median :0   Median :0   Median :0   #>  799    : 14                      Mean   :0   Mean   :0   Mean   :0   #>  803    : 14                      3rd Qu.:0   3rd Qu.:0   3rd Qu.:0   #>  806    : 14                      Max.   :0   Max.   :0   Max.   :0   #>  (Other):170                                                          #>        DV              LNDV             AMT         TIME             DOSE       #>  Min.   :  2.01   Min.   :0.6981   Min.   :0   Min.   : 0.200   Min.   :25.00   #>  1st Qu.: 29.30   1st Qu.:3.3780   1st Qu.:0   1st Qu.: 0.533   1st Qu.:25.00   #>  Median : 88.10   Median :4.4775   Median :0   Median : 2.200   Median :25.00   #>  Mean   :184.95   Mean   :4.4056   Mean   :0   Mean   : 6.471   Mean   :29.59   #>  3rd Qu.:327.50   3rd Qu.:5.7915   3rd Qu.:0   3rd Qu.: 8.200   3rd Qu.:37.50   #>  Max.   :985.00   Max.   :6.8930   Max.   :0   Max.   :48.167   Max.   :37.50   #>                                                                                 #>       OCC         RATE        AGE             SEX             RACE        #>  Min.   :1   Min.   :0   Min.   :19.00   Min.   :1.000   Min.   : 1.000   #>  1st Qu.:1   1st Qu.:0   1st Qu.:23.75   1st Qu.:1.000   1st Qu.: 1.000   #>  Median :1   Median :0   Median :31.00   Median :1.000   Median : 1.000   #>  Mean   :1   Mean   :0   Mean   :33.92   Mean   :1.219   Mean   : 5.445   #>  3rd Qu.:1   3rd Qu.:0   3rd Qu.:43.00   3rd Qu.:1.000   3rd Qu.: 2.000   #>  Max.   :1   Max.   :0   Max.   :50.00   Max.   :2.000   Max.   :88.000   #>                                                                           #>        WT               HT            EPRED              ERES           #>  Min.   : 61.90   Min.   :1.560   Min.   :  1.489   Min.   :-532.5794   #>  1st Qu.: 68.70   1st Qu.:1.650   1st Qu.: 29.771   1st Qu.: -19.7594   #>  Median : 77.40   Median :1.770   Median : 89.073   Median :  -0.7489   #>  Mean   : 78.67   Mean   :1.742   Mean   :198.065   Mean   : -13.1147   #>  3rd Qu.: 86.10   3rd Qu.:1.830   3rd Qu.:340.338   3rd Qu.:  15.3204   #>  Max.   :103.50   Max.   :1.910   Max.   :892.579   Max.   : 338.9830   #>                                                                         #>       NPDE                NPD                 PRED              RES            #>  Min.   :-2.935199   Min.   :-2.935199   Min.   :  1.392   Min.   :-541.5251   #>  1st Qu.:-0.722511   1st Qu.:-0.722511   1st Qu.: 29.402   1st Qu.: -18.2325   #>  Median : 0.041789   Median : 0.041789   Median : 87.038   Median :  -0.1431   #>  Mean   : 0.004365   Mean   : 0.004365   Mean   :197.210   Mean   : -12.2601   #>  3rd Qu.: 0.612813   3rd Qu.: 0.612813   3rd Qu.:341.337   3rd Qu.:  15.6288   #>  Max.   : 2.713052   Max.   : 2.713052   Max.   :901.525   Max.   : 349.3258   #>                                                                                #>       WRES              IPRED              IRES               IWRES           #>  Min.   :-2.19102   Min.   :  1.205   Min.   :-533.7807   Min.   :-2.185337   #>  1st Qu.:-0.68689   1st Qu.: 27.883   1st Qu.: -13.9744   1st Qu.:-0.639223   #>  Median :-0.01821   Median : 87.475   Median :  -0.0126   Median :-0.009932   #>  Mean   : 0.07768   Mean   :195.998   Mean   : -11.0474   Mean   : 0.011870   #>  3rd Qu.: 0.72365   3rd Qu.:335.116   3rd Qu.:  11.5959   3rd Qu.: 0.658331   #>  Max.   : 4.30965   Max.   :893.781   Max.   : 334.7323   Max.   : 2.559917   #>                                                                               #>      CPRED               CRES               CWRES            ETA.LCLINT        #>  Min.   :  0.4319   Min.   :-541.7612   Min.   :-2.20991   Min.   :-0.608642   #>  1st Qu.: 28.2033   1st Qu.: -17.5360   1st Qu.:-0.76559   1st Qu.:-0.288330   #>  Median : 86.3193   Median :   0.3433   Median : 0.01883   Median : 0.114270   #>  Mean   :196.8603   Mean   : -11.9099   Mean   : 0.01267   Mean   :-0.007901   #>  3rd Qu.:341.4566   3rd Qu.:  16.8438   3rd Qu.: 0.70321   3rd Qu.: 0.227756   #>  Max.   :901.7612   Max.   : 347.9082   Max.   : 2.93064   Max.   : 0.368509   #>                                                                                #>      LUNGS               HEART             BRAIN             MUSCLES        #>  Min.   :0.0009467   Min.   :0.00080   Min.   :0.008901   Min.   :0.01346   #>  1st Qu.:0.0221628   1st Qu.:0.01886   1st Qu.:0.213499   1st Qu.:0.32338   #>  Median :0.0690150   Median :0.05999   Median :0.733717   Median :1.12400   #>  Mean   :0.1550357   Mean   :0.16297   Mean   :1.572570   Mean   :2.33749   #>  3rd Qu.:0.2730784   3rd Qu.:0.25463   3rd Qu.:3.142835   3rd Qu.:4.65369   #>  Max.   :0.6818635   Max.   :0.84673   Max.   :4.946001   Max.   :7.19210   #>                                                                             #>     ADIPOSE            SKIN              SPLEEN             PANCREAS         #>  Min.   :0.3729   Min.   :0.001126   Min.   :0.0001941   Min.   :0.0001055   #>  1st Qu.:2.7391   1st Qu.:0.026580   1st Qu.:0.0045557   1st Qu.:0.0024799   #>  Median :4.6912   Median :0.084760   Median :0.0142936   Median :0.0078116   #>  Mean   :4.5100   Mean   :0.229870   Mean   :0.0363282   Mean   :0.0206468   #>  3rd Qu.:6.0315   3rd Qu.:0.363129   3rd Qu.:0.0575290   3rd Qu.:0.0320656   #>  Max.   :8.4651   Max.   :1.153985   Max.   :0.2134889   Max.   :0.1201504   #>                                                                              #>      LIVER             STOMACH               GUT               BONES         #>  Min.   :0.004854   Min.   :0.0001577   Min.   :0.002627   Min.   :0.03628   #>  1st Qu.:0.122183   1st Qu.:0.0037130   1st Qu.:0.061911   1st Qu.:1.27184   #>  Median :0.389564   Median :0.0117571   Median :0.196645   Median :2.50350   #>  Mean   :1.038448   Mean   :0.0318079   Mean   :0.534130   Mean   :2.38796   #>  3rd Qu.:1.731292   3rd Qu.:0.0492383   3rd Qu.:0.831174   3rd Qu.:3.37429   #>  Max.   :4.438733   Max.   :0.1748488   Max.   :2.822001   Max.   :5.30557   #>                                                                              #>     KIDNEYS          ARTERIAL_BLOOD      VENOUS_BLOOD       REST_OF_BODY      #>  Min.   :0.0008911   Min.   :0.001538   Min.   :0.003074   Min.   :0.006307   #>  1st Qu.:0.0209049   1st Qu.:0.036018   1st Qu.:0.071936   1st Qu.:0.151741   #>  Median :0.0654781   Median :0.112319   Median :0.223814   Median :0.533427   #>  Mean   :0.1623603   Mean   :0.256871   Mean   :0.498787   Mean   :1.076948   #>  3rd Qu.:0.2625001   3rd Qu.:0.445837   3rd Qu.:0.883869   3rd Qu.:2.091592   #>  Max.   :0.9345757   Max.   :1.201820   Max.   :2.138754   Max.   :3.248250   #>                                                                               #>       KBBR            KBMU             KBAD           CLINT      #>  Min.   :7.964   Min.   :0.6045   Min.   :10.26   Min.   : 730   #>  1st Qu.:7.964   1st Qu.:0.6045   1st Qu.:10.26   1st Qu.:1006   #>  Median :7.964   Median :0.6045   Median :10.26   Median :1504   #>  Mean   :7.964   Mean   :0.6045   Mean   :10.26   Mean   :1383   #>  3rd Qu.:7.964   3rd Qu.:0.6045   3rd Qu.:10.26   3rd Qu.:1685   #>  Max.   :7.964   Max.   :0.6045   Max.   :10.26   Max.   :1939   #>                                                                  #>       KBBO            KBRB             CO             QHT        #>  Min.   :7.597   Min.   :2.929   Min.   :317.1   Min.   :12.69   #>  1st Qu.:7.597   1st Qu.:2.929   1st Qu.:345.1   1st Qu.:13.80   #>  Median :7.597   Median :2.929   Median :380.1   Median :15.20   #>  Mean   :7.597   Mean   :2.929   Mean   :384.5   Mean   :15.38   #>  3rd Qu.:7.597   3rd Qu.:2.929   3rd Qu.:414.3   3rd Qu.:16.57   #>  Max.   :7.597   Max.   :2.929   Max.   :480.9   Max.   :19.24   #>                                                                  #>       QBR             QMU             QAD             QSK        #>  Min.   :38.06   Min.   :53.92   Min.   :15.86   Min.   :15.86   #>  1st Qu.:41.41   1st Qu.:58.66   1st Qu.:17.25   1st Qu.:17.25   #>  Median :45.61   Median :64.61   Median :19.00   Median :19.00   #>  Mean   :46.14   Mean   :65.36   Mean   :19.22   Mean   :19.22   #>  3rd Qu.:49.72   3rd Qu.:70.44   3rd Qu.:20.72   3rd Qu.:20.72   #>  Max.   :57.71   Max.   :81.76   Max.   :24.05   Max.   :24.05   #>                                                                  #>       QSP              QPA             QLI              QST        #>  Min.   : 9.514   Min.   :3.171   Min.   : 80.87   Min.   :3.171   #>  1st Qu.:10.353   1st Qu.:3.451   1st Qu.: 88.00   1st Qu.:3.451   #>  Median :11.402   Median :3.801   Median : 96.92   Median :3.801   #>  Mean   :11.534   Mean   :3.845   Mean   : 98.04   Mean   :3.845   #>  3rd Qu.:12.430   3rd Qu.:4.143   3rd Qu.:105.65   3rd Qu.:4.143   #>  Max.   :14.428   Max.   :4.809   Max.   :122.64   Max.   :4.809   #>                                                                    #>       QGU             QHA             QBO             QKI        #>  Min.   :44.40   Min.   :20.61   Min.   :15.86   Min.   :60.26   #>  1st Qu.:48.31   1st Qu.:22.43   1st Qu.:17.25   1st Qu.:65.57   #>  Median :53.21   Median :24.71   Median :19.00   Median :72.21   #>  Mean   :53.83   Mean   :24.99   Mean   :19.22   Mean   :73.05   #>  3rd Qu.:58.01   3rd Qu.:26.93   3rd Qu.:20.72   3rd Qu.:78.72   #>  Max.   :67.33   Max.   :31.26   Max.   :24.05   Max.   :91.38   #>                                                                  #>       QRB             QLU             VLU              VHT         #>  Min.   :23.79   Min.   :317.1   Min.   :0.4476   Min.   :0.2825   #>  1st Qu.:25.88   1st Qu.:345.1   1st Qu.:0.4968   1st Qu.:0.3135   #>  Median :28.51   Median :380.1   Median :0.5597   Median :0.3532   #>  Mean   :28.84   Mean   :384.5   Mean   :0.5689   Mean   :0.3590   #>  3rd Qu.:31.07   3rd Qu.:414.3   3rd Qu.:0.6226   3rd Qu.:0.3929   #>  Max.   :36.07   Max.   :480.9   Max.   :0.7484   Max.   :0.4723   #>                                                                    #>       VBR             VMU             VAD             VSK        #>  Min.   :1.195   Min.   :23.78   Min.   :14.47   Min.   :2.058   #>  1st Qu.:1.326   1st Qu.:26.40   1st Qu.:16.07   1st Qu.:2.284   #>  Median :1.494   Median :29.74   Median :18.10   Median :2.573   #>  Mean   :1.519   Mean   :30.23   Mean   :18.40   Mean   :2.615   #>  3rd Qu.:1.662   3rd Qu.:33.08   3rd Qu.:20.13   3rd Qu.:2.862   #>  Max.   :1.998   Max.   :39.77   Max.   :24.20   Max.   :3.441   #>                                                                  #>       VSP              VPA               VLI             VST         #>  Min.   :0.1527   Min.   :0.08293   Min.   :1.530   Min.   :0.1238   #>  1st Qu.:0.1695   1st Qu.:0.09204   1st Qu.:1.698   1st Qu.:0.1374   #>  Median :0.1909   Median :0.10369   Median :1.913   Median :0.1548   #>  Mean   :0.1941   Mean   :0.10540   Mean   :1.944   Mean   :0.1573   #>  3rd Qu.:0.2124   3rd Qu.:0.11535   3rd Qu.:2.128   3rd Qu.:0.1722   #>  Max.   :0.2553   Max.   :0.13866   Max.   :2.558   Max.   :0.2070   #>                                                                      #>       VGU              VBO             VKI              VAB        #>  Min.   :0.8546   Min.   :4.445   Min.   :0.2594   Min.   :1.672   #>  1st Qu.:0.9485   1st Qu.:4.933   1st Qu.:0.2879   1st Qu.:1.856   #>  Median :1.0686   Median :5.558   Median :0.3243   Median :2.091   #>  Mean   :1.0862   Mean   :5.649   Mean   :0.3297   Mean   :2.126   #>  3rd Qu.:1.1887   3rd Qu.:6.183   3rd Qu.:0.3608   3rd Qu.:2.326   #>  Max.   :1.4290   Max.   :7.432   Max.   :0.4337   Max.   :2.796   #>                                                                    #>       VVB             VRB             S15                TAD         #>  Min.   :3.345   Min.   :2.297   Min.   :0.002040   Min.   : 0.200   #>  1st Qu.:3.712   1st Qu.:2.550   1st Qu.:0.002265   1st Qu.: 0.533   #>  Median :4.183   Median :2.873   Median :0.002551   Median : 2.200   #>  Mean   :4.251   Mean   :2.920   Mean   :0.002593   Mean   : 6.471   #>  3rd Qu.:4.653   3rd Qu.:3.196   3rd Qu.:0.002838   3rd Qu.: 8.200   #>  Max.   :5.593   Max.   :3.841   Max.   :0.003412   Max.   :48.167   #>                                                                      #>     DOSENUM    eta.LClint        #>  Min.   :1   Min.   :-0.608642   #>  1st Qu.:1   1st Qu.:-0.288330   #>  Median :1   Median : 0.114270   #>  Mean   :1   Mean   :-0.007901   #>  3rd Qu.:1   3rd Qu.: 0.227756   #>  Max.   :1   Max.   : 0.368509   #>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/mavoglurant.html","id":"log-normal","dir":"Articles","previous_headings":"Piping to FOCEi","what":"Log-normal","title":"mavoglurant -- physiologically-based PK","text":"# Traditional lognormal estimates identical NOTE: estimates AIC different since calculated log scale.","code":"fit.lnorm.F <- fit.addProp.F %>%     model({C15 ~ lnorm(lnorm.err)}) %>%     nlmixr(est=\"focei\",            control=list(print=0),             table=list(cwres=TRUE, npde=TRUE)); #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:22  #> done ## In this model pipline we are changing the fit method to focei.  gofs(fit.lnorm.F); #>        ID          CMT                 EVID        EVI2        MDV    #>  793    : 15   Length:256         Min.   :0   Min.   :0   Min.   :0   #>  796    : 15   Class :character   1st Qu.:0   1st Qu.:0   1st Qu.:0   #>  797    : 14   Mode  :character   Median :0   Median :0   Median :0   #>  799    : 14                      Mean   :0   Mean   :0   Mean   :0   #>  803    : 14                      3rd Qu.:0   3rd Qu.:0   3rd Qu.:0   #>  806    : 14                      Max.   :0   Max.   :0   Max.   :0   #>  (Other):170                                                          #>        DV              LNDV             AMT         TIME             DOSE       #>  Min.   :  2.01   Min.   :0.6981   Min.   :0   Min.   : 0.200   Min.   :25.00   #>  1st Qu.: 29.30   1st Qu.:3.3780   1st Qu.:0   1st Qu.: 0.533   1st Qu.:25.00   #>  Median : 88.10   Median :4.4775   Median :0   Median : 2.200   Median :25.00   #>  Mean   :184.95   Mean   :4.4056   Mean   :0   Mean   : 6.471   Mean   :29.59   #>  3rd Qu.:327.50   3rd Qu.:5.7915   3rd Qu.:0   3rd Qu.: 8.200   3rd Qu.:37.50   #>  Max.   :985.00   Max.   :6.8930   Max.   :0   Max.   :48.167   Max.   :37.50   #>                                                                                 #>       OCC         RATE        AGE             SEX             RACE        #>  Min.   :1   Min.   :0   Min.   :19.00   Min.   :1.000   Min.   : 1.000   #>  1st Qu.:1   1st Qu.:0   1st Qu.:23.75   1st Qu.:1.000   1st Qu.: 1.000   #>  Median :1   Median :0   Median :31.00   Median :1.000   Median : 1.000   #>  Mean   :1   Mean   :0   Mean   :33.92   Mean   :1.219   Mean   : 5.445   #>  3rd Qu.:1   3rd Qu.:0   3rd Qu.:43.00   3rd Qu.:1.000   3rd Qu.: 2.000   #>  Max.   :1   Max.   :0   Max.   :50.00   Max.   :2.000   Max.   :88.000   #>                                                                           #>        WT               HT            EPRED              ERES           #>  Min.   : 61.90   Min.   :1.560   Min.   :  1.384   Min.   :-495.9996   #>  1st Qu.: 68.70   1st Qu.:1.650   1st Qu.: 28.343   1st Qu.: -16.9544   #>  Median : 77.40   Median :1.770   Median : 88.239   Median :   0.6545   #>  Mean   : 78.67   Mean   :1.742   Mean   :187.942   Mean   :  -2.9920   #>  3rd Qu.: 86.10   3rd Qu.:1.830   3rd Qu.:317.888   3rd Qu.:  22.4077   #>  Max.   :103.50   Max.   :1.910   Max.   :856.000   Max.   : 363.4580   #>                                                                         #>       NPDE               NPD                PRED              RES            #>  Min.   :-2.93520   Min.   :-2.93520   Min.   :  1.395   Min.   :-505.7560   #>  1st Qu.:-0.63582   1st Qu.:-0.63582   1st Qu.: 28.842   1st Qu.: -14.9512   #>  Median : 0.08365   Median : 0.08365   Median : 87.623   Median :   0.5988   #>  Mean   :-0.02358   Mean   :-0.02358   Mean   :187.901   Mean   :  -2.9508   #>  3rd Qu.: 0.70899   3rd Qu.: 0.70899   3rd Qu.:319.303   3rd Qu.:  21.0645   #>  Max.   : 2.21636   Max.   : 2.21636   Max.   :865.756   Max.   : 374.9286   #>                                                                              #>       WRES               IPRED              IRES               IWRES         #>  Min.   :-2.867294   Min.   :  1.532   Min.   :-493.7385   Min.   :-2.8300   #>  1st Qu.:-0.649761   1st Qu.: 26.810   1st Qu.: -10.3538   1st Qu.:-0.6106   #>  Median : 0.054529   Median : 90.884   Median :   0.9186   Median : 0.1283   #>  Mean   :-0.005792   Mean   :186.415   Mean   :  -1.4647   Mean   :-0.0192   #>  3rd Qu.: 0.710212   3rd Qu.:312.879   3rd Qu.:  16.5443   3rd Qu.: 0.6520   #>  Max.   : 2.498981   Max.   :853.739   Max.   : 360.8283   Max.   : 1.9438   #>                                                                              #>      CPRED              CRES               CWRES            ETA.LCLINT        #>  Min.   :  1.394   Min.   :-506.3691   Min.   :-2.86770   Min.   :-0.576934   #>  1st Qu.: 28.979   1st Qu.: -15.4483   1st Qu.:-0.64906   1st Qu.:-0.265299   #>  Median : 87.851   Median :   0.5639   Median : 0.06177   Median : 0.173208   #>  Mean   :188.359   Mean   :  -3.4089   Mean   :-0.01102   Mean   :-0.008434   #>  3rd Qu.:319.824   3rd Qu.:  21.0061   3rd Qu.: 0.70520   3rd Qu.: 0.241792   #>  Max.   :866.369   Max.   : 373.5313   Max.   : 2.44698   Max.   : 0.370694   #>                                                                               #>      LUNGS              HEART              BRAIN            MUSCLES        #>  Min.   :0.001204   Min.   :0.001017   Min.   :0.01336   Min.   :0.01937   #>  1st Qu.:0.021886   1st Qu.:0.018594   1st Qu.:0.25083   1st Qu.:0.36384   #>  Median :0.072523   Median :0.062959   Median :0.93279   Median :1.35901   #>  Mean   :0.147702   Mean   :0.157333   Mean   :1.72317   Mean   :2.48129   #>  3rd Qu.:0.257236   3rd Qu.:0.237247   3rd Qu.:3.34110   3rd Qu.:4.76106   #>  Max.   :0.662580   Max.   :0.837339   Max.   :5.17725   Max.   :7.41135   #>                                                                            #>     ADIPOSE            SKIN              SPLEEN             PANCREAS         #>  Min.   :0.4658   Min.   :0.001432   Min.   :0.0002468   Min.   :0.0001341   #>  1st Qu.:2.7045   1st Qu.:0.026204   1st Qu.:0.0044922   1st Qu.:0.0024450   #>  Median :4.5581   Median :0.088939   Median :0.0150139   Median :0.0082032   #>  Mean   :4.4345   Mean   :0.222047   Mean   :0.0348545   Mean   :0.0198613   #>  3rd Qu.:5.9427   3rd Qu.:0.338302   3rd Qu.:0.0540794   3rd Qu.:0.0299590   #>  Max.   :8.4011   Max.   :1.141569   Max.   :0.2101807   Max.   :0.1185490   #>                                                                              #>      LIVER             STOMACH               GUT               BONES         #>  Min.   :0.006451   Min.   :0.0002005   Min.   :0.003339   Min.   :0.04499   #>  1st Qu.:0.119347   1st Qu.:0.0036602   1st Qu.:0.061029   1st Qu.:1.19134   #>  Median :0.397975   Median :0.0123426   Median :0.206396   Median :2.44337   #>  Mean   :0.988815   Mean   :0.0306677   Mean   :0.515469   Mean   :2.30752   #>  3rd Qu.:1.600101   3rd Qu.:0.0459012   3rd Qu.:0.774527   3rd Qu.:3.26561   #>  Max.   :4.501058   Max.   :0.1727813   Max.   :2.790190   Max.   :5.07574   #>                                                                              #>     KIDNEYS         ARTERIAL_BLOOD      VENOUS_BLOOD       REST_OF_BODY      #>  Min.   :0.001133   Min.   :0.001955   Min.   :0.003908   Min.   :0.008534   #>  1st Qu.:0.020619   1st Qu.:0.035558   1st Qu.:0.071052   1st Qu.:0.160240   #>  Median :0.068784   Median :0.118019   Median :0.235202   Median :0.598338   #>  Mean   :0.155546   Mean   :0.244978   Mean   :0.474962   Mean   :1.093395   #>  3rd Qu.:0.246872   3rd Qu.:0.419803   3rd Qu.:0.832799   3rd Qu.:2.099581   #>  Max.   :0.918635   Max.   :1.171242   Max.   :2.075415   Max.   :3.267103   #>                                                                              #>       KBBR            KBMU             KBAD           CLINT        #>  Min.   :9.387   Min.   :0.6835   Min.   :10.58   Min.   : 784.5   #>  1st Qu.:9.387   1st Qu.:0.6835   1st Qu.:10.58   1st Qu.:1071.4   #>  Median :9.387   Median :0.6835   Median :10.58   Median :1661.1   #>  Mean   :9.387   Mean   :0.6835   Mean   :10.58   Mean   :1440.3   #>  3rd Qu.:9.387   3rd Qu.:0.6835   3rd Qu.:10.58   3rd Qu.:1779.0   #>  Max.   :9.387   Max.   :0.6835   Max.   :10.58   Max.   :2023.8   #>                                                                    #>       KBBO            KBRB             CO             QHT        #>  Min.   :7.498   Min.   :3.116   Min.   :317.1   Min.   :12.69   #>  1st Qu.:7.498   1st Qu.:3.116   1st Qu.:345.1   1st Qu.:13.80   #>  Median :7.498   Median :3.116   Median :380.1   Median :15.20   #>  Mean   :7.498   Mean   :3.116   Mean   :384.5   Mean   :15.38   #>  3rd Qu.:7.498   3rd Qu.:3.116   3rd Qu.:414.3   3rd Qu.:16.57   #>  Max.   :7.498   Max.   :3.116   Max.   :480.9   Max.   :19.24   #>                                                                  #>       QBR             QMU             QAD             QSK        #>  Min.   :38.06   Min.   :53.92   Min.   :15.86   Min.   :15.86   #>  1st Qu.:41.41   1st Qu.:58.66   1st Qu.:17.25   1st Qu.:17.25   #>  Median :45.61   Median :64.61   Median :19.00   Median :19.00   #>  Mean   :46.14   Mean   :65.36   Mean   :19.22   Mean   :19.22   #>  3rd Qu.:49.72   3rd Qu.:70.44   3rd Qu.:20.72   3rd Qu.:20.72   #>  Max.   :57.71   Max.   :81.76   Max.   :24.05   Max.   :24.05   #>                                                                  #>       QSP              QPA             QLI              QST        #>  Min.   : 9.514   Min.   :3.171   Min.   : 80.87   Min.   :3.171   #>  1st Qu.:10.353   1st Qu.:3.451   1st Qu.: 88.00   1st Qu.:3.451   #>  Median :11.402   Median :3.801   Median : 96.92   Median :3.801   #>  Mean   :11.534   Mean   :3.845   Mean   : 98.04   Mean   :3.845   #>  3rd Qu.:12.430   3rd Qu.:4.143   3rd Qu.:105.65   3rd Qu.:4.143   #>  Max.   :14.428   Max.   :4.809   Max.   :122.64   Max.   :4.809   #>                                                                    #>       QGU             QHA             QBO             QKI        #>  Min.   :44.40   Min.   :20.61   Min.   :15.86   Min.   :60.26   #>  1st Qu.:48.31   1st Qu.:22.43   1st Qu.:17.25   1st Qu.:65.57   #>  Median :53.21   Median :24.71   Median :19.00   Median :72.21   #>  Mean   :53.83   Mean   :24.99   Mean   :19.22   Mean   :73.05   #>  3rd Qu.:58.01   3rd Qu.:26.93   3rd Qu.:20.72   3rd Qu.:78.72   #>  Max.   :67.33   Max.   :31.26   Max.   :24.05   Max.   :91.38   #>                                                                  #>       QRB             QLU             VLU              VHT         #>  Min.   :23.79   Min.   :317.1   Min.   :0.4476   Min.   :0.2825   #>  1st Qu.:25.88   1st Qu.:345.1   1st Qu.:0.4968   1st Qu.:0.3135   #>  Median :28.51   Median :380.1   Median :0.5597   Median :0.3532   #>  Mean   :28.84   Mean   :384.5   Mean   :0.5689   Mean   :0.3590   #>  3rd Qu.:31.07   3rd Qu.:414.3   3rd Qu.:0.6226   3rd Qu.:0.3929   #>  Max.   :36.07   Max.   :480.9   Max.   :0.7484   Max.   :0.4723   #>                                                                    #>       VBR             VMU             VAD             VSK        #>  Min.   :1.195   Min.   :23.78   Min.   :14.47   Min.   :2.058   #>  1st Qu.:1.326   1st Qu.:26.40   1st Qu.:16.07   1st Qu.:2.284   #>  Median :1.494   Median :29.74   Median :18.10   Median :2.573   #>  Mean   :1.519   Mean   :30.23   Mean   :18.40   Mean   :2.615   #>  3rd Qu.:1.662   3rd Qu.:33.08   3rd Qu.:20.13   3rd Qu.:2.862   #>  Max.   :1.998   Max.   :39.77   Max.   :24.20   Max.   :3.441   #>                                                                  #>       VSP              VPA               VLI             VST         #>  Min.   :0.1527   Min.   :0.08293   Min.   :1.530   Min.   :0.1238   #>  1st Qu.:0.1695   1st Qu.:0.09204   1st Qu.:1.698   1st Qu.:0.1374   #>  Median :0.1909   Median :0.10369   Median :1.913   Median :0.1548   #>  Mean   :0.1941   Mean   :0.10540   Mean   :1.944   Mean   :0.1573   #>  3rd Qu.:0.2124   3rd Qu.:0.11535   3rd Qu.:2.128   3rd Qu.:0.1722   #>  Max.   :0.2553   Max.   :0.13866   Max.   :2.558   Max.   :0.2070   #>                                                                      #>       VGU              VBO             VKI              VAB        #>  Min.   :0.8546   Min.   :4.445   Min.   :0.2594   Min.   :1.672   #>  1st Qu.:0.9485   1st Qu.:4.933   1st Qu.:0.2879   1st Qu.:1.856   #>  Median :1.0686   Median :5.558   Median :0.3243   Median :2.091   #>  Mean   :1.0862   Mean   :5.649   Mean   :0.3297   Mean   :2.126   #>  3rd Qu.:1.1887   3rd Qu.:6.183   3rd Qu.:0.3608   3rd Qu.:2.326   #>  Max.   :1.4290   Max.   :7.432   Max.   :0.4337   Max.   :2.796   #>                                                                    #>       VVB             VRB             S15                TAD         #>  Min.   :3.345   Min.   :2.297   Min.   :0.002040   Min.   : 0.200   #>  1st Qu.:3.712   1st Qu.:2.550   1st Qu.:0.002265   1st Qu.: 0.533   #>  Median :4.183   Median :2.873   Median :0.002551   Median : 2.200   #>  Mean   :4.251   Mean   :2.920   Mean   :0.002593   Mean   : 6.471   #>  3rd Qu.:4.653   3rd Qu.:3.196   3rd Qu.:0.002838   3rd Qu.: 8.200   #>  Max.   :5.593   Max.   :3.841   Max.   :0.003412   Max.   :48.167   #>                                                                      #>     DOSENUM    eta.LClint        #>  Min.   :1   Min.   :-0.576934   #>  1st Qu.:1   1st Qu.:-0.265299   #>  Median :1   Median : 0.173208   #>  Mean   :1   Mean   :-0.008434   #>  3rd Qu.:1   3rd Qu.: 0.241792   #>  Max.   :1   Max.   : 0.370694   #> datL  <- dat datL$DV <- log(datL$DV);  pbpkL <- function() {   ini({     ##theta=exp(c(1.1, .3, 2, 7.6, .003, .3))     lKbBR = 1.1     lKbMU = 0.3     lKbAD = 2     lCLint = 7.6     lKbBO = 0.03     lKbRB = 0.3     eta.LClint ~ 4     add.err <- 1   })   model({     KbBR = exp(lKbBR)     KbMU = exp(lKbMU)     KbAD = exp(lKbAD)     CLint= exp(lCLint + eta.LClint)     KbBO = exp(lKbBO)     KbRB = exp(lKbRB)      ## Regional blood flows     CO  = (187.00*WT^0.81)*60/1000;         # Cardiac output (L/h) from White et al (1968)     QHT = 4.0 *CO/100;     QBR = 12.0*CO/100;     QMU = 17.0*CO/100;     QAD = 5.0 *CO/100;     QSK = 5.0 *CO/100;     QSP = 3.0 *CO/100;     QPA = 1.0 *CO/100;     QLI = 25.5*CO/100;     QST = 1.0 *CO/100;     QGU = 14.0*CO/100;     QHA = QLI - (QSP + QPA + QST + QGU); # Hepatic artery blood flow     QBO = 5.0 *CO/100;     QKI = 19.0*CO/100;     QRB = CO - (QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI);     QLU = QHT + QBR + QMU + QAD + QSK + QLI + QBO + QKI + QRB;      ## Organs' volumes = organs' weights / organs' density     VLU = (0.76 *WT/100)/1.051;     VHT = (0.47 *WT/100)/1.030;     VBR = (2.00 *WT/100)/1.036;     VMU = (40.00*WT/100)/1.041;     VAD = (21.42*WT/100)/0.916;     VSK = (3.71 *WT/100)/1.116;     VSP = (0.26 *WT/100)/1.054;     VPA = (0.14 *WT/100)/1.045;     VLI = (2.57 *WT/100)/1.040;     VST = (0.21 *WT/100)/1.050;     VGU = (1.44 *WT/100)/1.043;     VBO = (14.29*WT/100)/1.990;     VKI = (0.44 *WT/100)/1.050;     VAB = (2.81 *WT/100)/1.040;     VVB = (5.62 *WT/100)/1.040;     VRB = (3.86 *WT/100)/1.040;      ## Fixed parameters     BP = 0.61;      # Blood:plasma partition coefficient     fup = 0.028;    # Fraction unbound in plasma     fub = fup/BP;   # Fraction unbound in blood      KbLU = exp(0.8334);     KbHT = exp(1.1205);     KbSK = exp(-.5238);     KbSP = exp(0.3224);     KbPA = exp(0.3224);     KbLI = exp(1.7604);     KbST = exp(0.3224);     KbGU = exp(1.2026);     KbKI = exp(1.3171);      ##-----------------------------------------     S15 = VVB*BP/1000;     C15 = Venous_Blood/S15     lnC15 = log(C15);      ##-----------------------------------------     d/dt(Lungs) = QLU*(Venous_Blood/VVB - Lungs/KbLU/VLU);     d/dt(Heart) = QHT*(Arterial_Blood/VAB - Heart/KbHT/VHT);     d/dt(Brain) = QBR*(Arterial_Blood/VAB - Brain/KbBR/VBR);     d/dt(Muscles) = QMU*(Arterial_Blood/VAB - Muscles/KbMU/VMU);     d/dt(Adipose) = QAD*(Arterial_Blood/VAB - Adipose/KbAD/VAD);     d/dt(Skin) = QSK*(Arterial_Blood/VAB - Skin/KbSK/VSK);     d/dt(Spleen) = QSP*(Arterial_Blood/VAB - Spleen/KbSP/VSP);     d/dt(Pancreas) = QPA*(Arterial_Blood/VAB - Pancreas/KbPA/VPA);     d/dt(Liver) = QHA*Arterial_Blood/VAB + QSP*Spleen/KbSP/VSP + QPA*Pancreas/KbPA/VPA + QST*Stomach/KbST/VST + QGU*Gut/KbGU/VGU - CLint*fub*Liver/KbLI/VLI - QLI*Liver/KbLI/VLI;     d/dt(Stomach) = QST*(Arterial_Blood/VAB - Stomach/KbST/VST);     d/dt(Gut) = QGU*(Arterial_Blood/VAB - Gut/KbGU/VGU);     d/dt(Bones) = QBO*(Arterial_Blood/VAB - Bones/KbBO/VBO);     d/dt(Kidneys) = QKI*(Arterial_Blood/VAB - Kidneys/KbKI/VKI);     d/dt(Arterial_Blood) = QLU*(Lungs/KbLU/VLU - Arterial_Blood/VAB);     d/dt(Venous_Blood) = QHT*Heart/KbHT/VHT + QBR*Brain/KbBR/VBR +       QMU*Muscles/KbMU/VMU + QAD*Adipose/KbAD/VAD +       QSK*Skin/KbSK/VSK + QLI*Liver/KbLI/VLI + QBO*Bones/KbBO/VBO +       QKI*Kidneys/KbKI/VKI + QRB*Rest_of_Body/KbRB/VRB - QLU*Venous_Blood/VVB;     d/dt(Rest_of_Body) = QRB*(Arterial_Blood/VAB - Rest_of_Body/KbRB/VRB);      lnC15 ~ add(add.err)   }) }  fit.lnorm.trans <- pbpkL %>%     nlmixr(datL,est=\"saem\",            control=list(print=0),             table=list(npde=TRUE, cwres=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-models-via-piping","dir":"Articles","previous_headings":"","what":"Changing models via piping","title":"Modifying nlmixr2 models by piping","text":"running nlmixr vignette, Let’s start simple PK example, using single-dose theophylline dataset generously provided Dr. Robert . Upton University California, San Francisco: can try First-Order Conditional Estimation Interaction (FOCEi) method find good solution:","code":"library(nlmixr2)  one.compartment <- function() {   ini({     tka <- 0.45 # Log Ka     tcl <- 1 # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; # log V     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     d/dt(depot) = -ka * depot     d/dt(center) = ka * depot - cl / v * center     cp = center / v      cp ~ add(add.sd)   }) } fit <- nlmixr(one.compartment, theo_sd, est=\"focei\",               control=list(print=0),                table=list(npde=TRUE, cwres=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(fit) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 116.8139 373.4137 393.5933      -179.7068         73.85496 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.016409 0.475935   0.475937 0.751    0.012 5.650719 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.474  0.209 44.1       1.61 (1.07, 2.42)     68.9     0.384%  #> tcl       Log Cl  1.01 0.0943 9.32       2.75 (2.29, 3.31)     26.8      3.87%  #> tv         log V  3.46 0.0403 1.16       31.8 (29.4, 34.4)     13.9      10.3%  #> add.sd           0.696                               0.696                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 26 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.0967  0.643  1.24   1.24   0     0.74   1.06   0     0.74  #> 2 1      0.25  2.84 3.83   -0.986 -0.486 -0.486  3.29 -0.449 -0.242  3.85 -1.01  #> 3 1      0.57  6.57 6.15    0.422 -1.71  -1.71   5.87  0.705  0.287  6.79 -0.216 #> # … with 129 more rows, and 14 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-and-fixing-parameter-values-in-models","dir":"Articles","previous_headings":"","what":"Changing and fixing parameter values in models","title":"Modifying nlmixr2 models by piping","text":"Something may want change initial estimates model. simple modify model definition change , may also want change specific way; example try range starting values see system behaves (either full estimation posthoc estimation). situations can come tedious modify models hand. nlmixr provides ability : Change parameter estimates running model. (ie ini(tka=0.5)) Fix parameters arbitrary values, estimated values (ie ini(tka=fix(0.5)) ini(tka=fix)) easiest way illustrate showing examples piping changes model:","code":"## Example 1 -- Set inital estimate to 0.5 (shown w/posthoc) one.ka.0.5 <- fit %>%     ini(tka=0.5) %>%      nlmixr(est=\"posthoc\", control=list(print=0),             table=list(cwres=TRUE, npde=TRUE))  print(one.ka.0.5) ## Example 2 -- Fix tka to 0.5 and re-estimate. one.ka.0.5 <- fit %>%     ini(tka=fix(0.5)) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(one.ka.0.5) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 116.8498 371.4495 388.7463      -179.7248         11.40363 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.002655  0.27083   0.270832 0.302     0.01 0.304683 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE  %RSE Back-transformed(95%CI) BSV(CV%) #> tka       Log Ka   0.5  FIXED FIXED                    1.65     68.9 #> tcl       Log Cl  1.01  0.113  11.1       2.75 (2.21, 3.43)     26.8 #> tv         log V  3.46 0.0539  1.56       31.8 (28.6, 35.3)     13.9 #> add.sd           0.696                                0.696          #>        Shrink(SD)% #> tka        0.309%  #> tcl         3.89%  #> tv          10.2%  #> add.sd             #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 26 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.0967  0.643  1.24   1.24   0     0.74   1.06   0     0.74  #> 2 1      0.25  2.84 3.90   -1.06  -0.440 -0.440  3.36 -0.520 -0.276  3.85 -1.01  #> 3 1      0.57  6.57 6.23    0.342 -1.75  -1.75   5.96  0.611  0.248  6.79 -0.219 #> # … with 129 more rows, and 14 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> ## Example 3 -- Fix tka to model estimated value and re-estimate. one.ka.0.5 <- fit %>%     ini(tka=fix) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(one.ka.0.5) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>          OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 116.814 371.4137 388.7106      -179.7069         13.60513 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.001992 0.272515   0.272517 0.301     0.01 0.249976 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE  %RSE Back-transformed(95%CI) BSV(CV%) #> tka       Log Ka 0.474  FIXED FIXED                    1.61     68.9 #> tcl       Log Cl  1.01  0.101  9.93       2.75 (2.26, 3.35)     26.8 #> tv         log V  3.46 0.0457  1.32       31.8 (29.1, 34.8)     13.9 #> add.sd           0.696                                0.696          #>        Shrink(SD)% #> tka        0.386%  #> tcl         3.87%  #> tv          10.3%  #> add.sd             #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 26 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.0967  0.643  1.24   1.24   0     0.74   1.06   0     0.74  #> 2 1      0.25  2.84 3.83   -0.986 -0.486 -0.486  3.29 -0.449 -0.242  3.85 -1.01  #> 3 1      0.57  6.57 6.15    0.422 -1.71  -1.71   5.87  0.705  0.287  6.79 -0.216 #> # … with 129 more rows, and 14 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> ## Example 4 -- Change tka to 0.7 in orginal model function and then estimate one.ka.0.7 <- one.compartment %>%     ini(tka=0.7) %>%      nlmixr(theo_sd, est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(one.ka.0.7) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 116.8133 373.4131 393.5927      -179.7065          49.0338 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.002008 0.476576   0.476578 0.292     0.01 1.619838 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.471  0.202 42.8        1.6 (1.08, 2.38)     69.5     0.996%  #> tcl       Log Cl  1.01 0.0757 7.49       2.75 (2.37, 3.19)     26.4      3.12%  #> tv         log V  3.46 0.0543 1.57       31.9 (28.6, 35.4)     13.8      9.93%  #> add.sd           0.697                               0.697                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 26 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.0968  0.643  1.24   1.24   0     0.74   1.06   0     0.74  #> 2 1      0.25  2.84 3.82   -0.979 -0.468 -0.468  3.28 -0.438 -0.235  3.85 -1.01  #> 3 1      0.57  6.57 6.13    0.437 -1.75  -1.75   5.85  0.722  0.293  6.79 -0.215 #> # … with 129 more rows, and 14 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-model-features","dir":"Articles","previous_headings":"","what":"Changing model features","title":"Modifying nlmixr2 models by piping","text":"developing models, often add remove subject variability parameters, add covariates effects, /change residual errors. can change lines model piping fit nlmixr model specification function model","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"adding-or-removing-between-subject-variability","dir":"Articles","previous_headings":"Changing model features","what":"Adding or Removing between subject variability","title":"Modifying nlmixr2 models by piping","text":"Often developing model add remove subject variability certain model parameters. example, remove subject variability ka parameter changing line model; example remove eta prior fit prior model specification function, simply pipe model function. can re-estimate piping nlmixr function . course also add eta parameter way; can see name change examining omega matrix: Note new subject variability parameters distinguished types parameters (ie population parameters, individual covariates) name. Parameters starting ending following names assumed subject variability parameters: eta (NONMEM convention) ppv (per patient variability) psv (per subject variability) iiv (inter-individual variability) bsv (subject variability) bpv (patient variability)","code":"## Remove eta.ka on ka noEta <- fit %>%     model(ka <- exp(tka)) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(noEta) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF     AIC      BIC Log-likelihood Condition Number #> FOCEi 176.5812 431.181 448.4778      -209.5905         34.87439 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.002539 0.297813   0.297815 0.733    0.012 3.253833 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.431   0.17 39.5        1.54 (1.1, 2.15)                      #> tcl       Log Cl 0.991 0.0745 7.51        2.7 (2.33, 3.12)     30.3      7.76%  #> tv         log V  3.48 0.0485 1.39       32.4 (29.5, 35.7)     15.6      7.93%  #> add.sd            1.02                                1.02                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 25 #>   ID     TIME    DV EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.142  0.598  0.915  0.915  0     0.74   0.726  0     0.74  #> 2 1      0.25  2.84 3.24  -0.397 -0.593 -0.593  3.12 -0.277 -0.246  3.57 -0.730 #> 3 1      0.57  6.57 5.70   0.872 -0.449 -0.449  5.61  0.959  0.723  6.45  0.121 #> # … with 129 more rows, and 13 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.cl <dbl>, eta.v <dbl>, depot <dbl>, #> #   center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl> addBackKa <- noEta %>%     model({ka <- exp(tka + bsv.ka)}) %>%     ini(bsv.ka=0.1) %>%     nlmixr(est=\"focei\", control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(addBackKa) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF      AIC     BIC Log-likelihood Condition Number #> FOCEi 116.8217 373.4214 393.601      -179.7107         159.1738 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.002629 0.475704   0.475706 0.745    0.012 4.492961 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.484  0.196 40.4       1.62 (1.11, 2.38)     69.6     0.891%  #> tcl       Log Cl  1.01   0.62 61.1       2.76 (0.819, 9.3)     26.8      4.10%  #> tv         log V  3.46 0.0872 2.52       31.8 (26.8, 37.7)     14.1      10.9%  #> add.sd           0.694                               0.694                      #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 26 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.0964  0.644  1.50   1.50   0     0.74   1.07   0     0.74  #> 2 1      0.25  2.84 3.67   -0.826 -0.706 -0.706  3.32 -0.480 -0.255  3.85 -1.01  #> 3 1      0.57  6.57 5.95    0.621 -1.88  -1.88   5.91  0.663  0.267  6.79 -0.217 #> # … with 129 more rows, and 14 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.cl <dbl>, eta.v <dbl>, bsv.ka <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> addBackKa$omega #>            eta.cl      eta.v    bsv.ka #> eta.cl 0.06918013 0.00000000 0.0000000 #> eta.v  0.00000000 0.01968171 0.0000000 #> bsv.ka 0.00000000 0.00000000 0.3946166"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"adding-covariate-effects","dir":"Articles","previous_headings":"Changing model features","what":"Adding Covariate effects","title":"Modifying nlmixr2 models by piping","text":"","code":"## Note currently cov is needed as a prefix so nlmixr knows this is an ## estimated parameter not a parameter wt70 <- fit %>%    model({cl <- exp(tcl + eta.cl)*(WT/70)^covWtPow}) %>%   ini(covWtPow=fix(0.75)) %>%   ini(tka=fix(0.5)) %>%   nlmixr(est=\"focei\", control=list(print=0),          table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(wt70) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 116.2107 370.8105 388.1073      -179.4053         10.72451 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.002575 0.286897   0.286899 0.804    0.011 4.032629 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>          Parameter  Est.     SE  %RSE Back-transformed(95%CI) BSV(CV%) #> tka         Log Ka   0.5  FIXED FIXED                    1.65     68.9 #> tcl         Log Cl  1.01 0.0761   7.5        2.76 (2.38, 3.2)     26.7 #> tv           log V  3.46 0.0293 0.846         31.7 (30, 33.6)     13.8 #> add.sd             0.696                                0.696          #> covWtPow            0.75  FIXED FIXED                    0.75          #>          Shrink(SD)% #> tka          0.822%  #> tcl           6.36%  #> tv            12.1%  #> add.sd               #> covWtPow             #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 27 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.0967  0.643  1.23   1.23   0     0.74   1.06   0     0.74  #> 2 1      0.25  2.84 3.90   -1.06  -0.468 -0.468  3.36 -0.522 -0.277  3.84 -1.00  #> 3 1      0.57  6.57 6.22    0.351 -1.64  -1.64   5.95  0.617  0.251  6.79 -0.216 #> # … with 129 more rows, and 15 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>, WT <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/modelPiping.html","id":"changing-residual-errors","dir":"Articles","previous_headings":"Changing model features","what":"Changing residual errors","title":"Modifying nlmixr2 models by piping","text":"Changing residual errors also just easy, simply specifying error wish change:","code":"## Since there are 0 predictions in the data, these are changed to ## 0.0150 to show proportional error change. d <- theo_sd d$DV[d$EVID == 0 & d$DV == 0] <- 0.0150  addPropModel <- fit %>%     model({cp ~ add(add.err)+prop(prop.err)}) %>%     ini(prop.err=0.1) %>%     nlmixr(d,est=\"focei\",            control=list(print=0),            table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #> done  print(addPropModel) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 104.3506 362.9504 386.0128      -173.4752         58.88045 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.002531  0.47683   0.476832 0.971    0.011 5.077807 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>          Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) #> tka         Log Ka 0.391  0.196 50.2       1.48 (1.01, 2.17)     69.0 #> tcl         Log Cl  1.02  0.074 7.23       2.79 (2.41, 3.22)     25.8 #> tv           log V  3.47 0.0464 1.34         32 (29.2, 35.1)     12.6 #> add.err            0.273                               0.273          #> prop.err           0.134                               0.134          #>          Shrink(SD)% #> tka           2.00%  #> tcl           1.18%  #> tv            15.6%  #> add.err              #> prop.err             #>   #>   Covariance Type ($covMethod): r,s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 26 #>   ID     TIME    DV  EPRED   ERES   NPDE    NPD  PRED    RES   WRES IPRED   IRES #>   <fct> <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl> <dbl>  <dbl>  <dbl> <dbl>  <dbl> #> 1 1      0     0.74 0.0380  0.702  2.13   2.13   0     0.74   2.71   0     0.74  #> 2 1      0.25  2.84 3.59   -0.748 -0.915 -0.915  3.05 -0.212 -0.126  3.46 -0.624 #> 3 1      0.57  6.57 5.86    0.712 -0.830 -0.830  5.53  1.04   0.428  6.23  0.338 #> # … with 129 more rows, and 14 more variables: IWRES <dbl>, CPRED <dbl>, #> #   CRES <dbl>, CWRES <dbl>, eta.ka <dbl>, eta.cl <dbl>, eta.v <dbl>, #> #   depot <dbl>, center <dbl>, ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"multiple-endpoints","dir":"Articles","previous_headings":"","what":"Multiple endpoints","title":"Working with multiple endpoints","text":"Joint PK/PD models, PK/PD models fix certain components common pharmacometrics. classic example, (provided Tomoo Funaki Nick Holford) Warfarin. example, transit-compartment (depot gut central volume) PK model effect compartment PCA measurement. illustrated example model can applied data: Notice two endpoints model cp effect. modeled nlmixr using ~ “modeled ” specification. see nlmixr handle multiple compartment model, quite informative parse model print information model. case initial parsing give: middle printout, shows data must formatted (using cmt dvid data items) allow nlmixr model multiple endpoint appropriately. course interested can directly access information ui$multipleEndpoint. Notice cmt dvid items can use named variables directly either cmt dvid specification. flexible notation makes rename compartments run nlmixr model functions. thing note cp specified ODE compartment number compartments defined rxode2 part nlmixr model. cp defined compartment, related variable cp. last thing notice cmt items numbered cmt=5 cp cmt=4 effect even though specified model first cp cmt. ordering effect compartment rxode2 system. course cp related compartment central, may make sense pair cp central compartment. something want can specify compartment relate effect | operator. case change change, model updated : Notice case cmt variables numbered sequentially cp variable matches center compartment.","code":"library(nlmixr2) library(ggplot2) pk.turnover.emax <- function() {   ini({     tktr <- log(1)     tka <- log(1)     tcl <- log(0.1)     tv <- log(10)     ##     eta.ktr ~ 1     eta.ka ~ 1     eta.cl ~ 2     eta.v ~ 1     prop.err <- 0.1     pkadd.err <- 0.1     ##     temax <- logit(0.8)     #temax <- 7.5     tec50 <- log(0.5)     tkout <- log(0.05)     te0 <- log(100)     ##     eta.emax ~ .5     eta.ec50  ~ .5     eta.kout ~ .5     eta.e0 ~ .5     ##     pdadd.err <- 10   })   model({     ktr <- exp(tktr + eta.ktr)     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     ##     #poplogit = log(temax/(1-temax))     emax=expit(temax+eta.emax)     #logit=temax+eta.emax     ec50 =  exp(tec50 + eta.ec50)     kout = exp(tkout + eta.kout)     e0 = exp(te0 + eta.e0)     ##     DCP = center/v     PD=1-emax*DCP/(ec50+DCP)     ##     effect(0) = e0     kin = e0*kout     ##     d/dt(depot) = -ktr * depot     d/dt(gut) =  ktr * depot -ka * gut     d/dt(center) =  ka * gut - cl / v * center     d/dt(effect) = kin*PD -kout*effect     ##     cp = center / v     cp ~ prop(prop.err) + add(pkadd.err)     effect ~ add(pdadd.err)   }) } ui <- nlmixr(pk.turnover.emax) ui #>  ── rxode2-based free-form 4-cmt ODE model ──────────────────────────────────────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>       tktr        tka        tcl         tv   prop.err  pkadd.err      temax  #>  0.0000000  0.0000000 -2.3025851  2.3025851  0.1000000  0.1000000  1.3862944  #>      tec50      tkout        te0  pdadd.err  #> -0.6931472 -2.9957323  4.6051702 10.0000000  #>  #> Omega ($omega):  #>          eta.ktr eta.ka eta.cl eta.v eta.emax eta.ec50 eta.kout eta.e0 #> eta.ktr        1      0      0     0      0.0      0.0      0.0    0.0 #> eta.ka         0      1      0     0      0.0      0.0      0.0    0.0 #> eta.cl         0      0      2     0      0.0      0.0      0.0    0.0 #> eta.v          0      0      0     1      0.0      0.0      0.0    0.0 #> eta.emax       0      0      0     0      0.5      0.0      0.0    0.0 #> eta.ec50       0      0      0     0      0.0      0.5      0.0    0.0 #> eta.kout       0      0      0     0      0.0      0.0      0.5    0.0 #> eta.e0         0      0      0     0      0.0      0.0      0.0    0.5 #>  ── Multiple Endpoint Model ($multipleEndpoint): ──   #>     variable                   cmt                   dvid* #> 1     cp ~ …     cmt='cp' or cmt=5     dvid='cp' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2 #>   * If dvids are outside this range, all dvids are re-numered sequentially, ie 1,7, 10 becomes 1,2,3 etc #>  #>  ── μ-referencing ($muRefTable): ──   #>   theta      eta level #> 1  tktr  eta.ktr    id #> 2   tka   eta.ka    id #> 3   tcl   eta.cl    id #> 4    tv    eta.v    id #> 5 temax eta.emax    id #> 6 tec50 eta.ec50    id #> 7 tkout eta.kout    id #> 8   te0   eta.e0    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         tktr <- 0 #>         tka <- 0 #>         tcl <- -2.30258509299405 #>         tv <- 2.30258509299405 #>         prop.err <- c(0, 0.1) #>         pkadd.err <- c(0, 0.1) #>         temax <- 1.38629436111989 #>         tec50 <- -0.693147180559945 #>         tkout <- -2.99573227355399 #>         te0 <- 4.60517018598809 #>         pdadd.err <- c(0, 10) #>         eta.ktr ~ 1 #>         eta.ka ~ 1 #>         eta.cl ~ 2 #>         eta.v ~ 1 #>         eta.emax ~ 0.5 #>         eta.ec50 ~ 0.5 #>         eta.kout ~ 0.5 #>         eta.e0 ~ 0.5 #>     }) #>     model({ #>         ktr <- exp(tktr + eta.ktr) #>         ka <- exp(tka + eta.ka) #>         cl <- exp(tcl + eta.cl) #>         v <- exp(tv + eta.v) #>         emax = expit(temax + eta.emax) #>         ec50 = exp(tec50 + eta.ec50) #>         kout = exp(tkout + eta.kout) #>         e0 = exp(te0 + eta.e0) #>         DCP = center/v #>         PD = 1 - emax * DCP/(ec50 + DCP) #>         effect(0) = e0 #>         kin = e0 * kout #>         d/dt(depot) = -ktr * depot #>         d/dt(gut) = ktr * depot - ka * gut #>         d/dt(center) = ka * gut - cl/v * center #>         d/dt(effect) = kin * PD - kout * effect #>         cp = center/v #>         cp ~ prop(prop.err) + add(pkadd.err) #>         effect ~ add(pdadd.err) #>     }) #> } ui$multipleEndpoint #>     variable                   cmt                   dvid* #> 1     cp ~ …     cmt='cp' or cmt=5     dvid='cp' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2 cp ~ prop(prop.err) + add(pkadd.err) cp ~ prop(prop.err) + add(pkadd.err) | central pk.turnover.emax2 <- function() {   ini({     tktr <- log(1)     tka <- log(1)     tcl <- log(0.1)     tv <- log(10)     ##     eta.ktr ~ 1     eta.ka ~ 1     eta.cl ~ 2     eta.v ~ 1     prop.err <- 0.1     pkadd.err <- 0.1     ##     temax <- logit(0.8)     tec50 <- log(0.5)     tkout <- log(0.05)     te0 <- log(100)     ##     eta.emax ~ .5     eta.ec50  ~ .5     eta.kout ~ .5     eta.e0 ~ .5     ##     pdadd.err <- 10   })   model({     ktr <- exp(tktr + eta.ktr)     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     ##     emax=expit(temax+eta.emax)     ec50 =  exp(tec50 + eta.ec50)     kout = exp(tkout + eta.kout)     e0 = exp(te0 + eta.e0)     ##     DCP = center/v     PD=1-emax*DCP/(ec50+DCP)     ##     effect(0) = e0     kin = e0*kout     ##     d/dt(depot) = -ktr * depot     d/dt(gut) =  ktr * depot -ka * gut     d/dt(center) =  ka * gut - cl / v * center     d/dt(effect) = kin*PD -kout*effect     ##     cp = center / v     cp ~ prop(prop.err) + add(pkadd.err) | center     effect ~ add(pdadd.err)   }) } ui2 <- nlmixr(pk.turnover.emax2) ui2$multipleEndpoint #>     variable                   cmt                   dvid* #> 1     cp ~ … cmt='center' or cmt=3 dvid='center' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"dvid-vs-cmt-which-one-is-used","dir":"Articles","previous_headings":"Multiple endpoints","what":"DVID vs CMT, which one is used","title":"Working with multiple endpoints","text":"dvid cmt combined dataset, cmt data item always used event information dvid used observations. nlmixr expects cmt data item match dvid item observations either zero one dvid replace cmt information. wish use dvid items define multiple endpoints nlmixr, can set following option: cmt items used multiple endpoint models. course can turn different models wish:","code":"options(rxode2.combine.dvid=FALSE) ui2$multipleEndpoint #>     variable                   cmt #> 1     cp ~ … cmt='center' or cmt=3 #> 2 effect ~ … cmt='effect' or cmt=4 options(rxode2.combine.dvid=TRUE) ui2$multipleEndpoint #>     variable                   cmt                   dvid* #> 1     cp ~ … cmt='center' or cmt=3 dvid='center' or dvid=1 #> 2 effect ~ … cmt='effect' or cmt=4 dvid='effect' or dvid=2"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"running-a-multiple-endpoint-model","dir":"Articles","previous_headings":"Multiple endpoints","what":"Running a multiple endpoint model","title":"Working with multiple endpoints","text":"information, can use built-warfarin dataset nlmixr2: Since dvid specifies pca effect endpoint, can update model explicit making one last change: ","code":"summary(warfarin) #>        id             time             amt                dv          dvid     #>  Min.   : 1.00   Min.   :  0.00   Min.   :  0.000   Min.   :  0.00   cp :283   #>  1st Qu.: 8.00   1st Qu.: 24.00   1st Qu.:  0.000   1st Qu.:  4.50   pca:232   #>  Median :15.00   Median : 48.00   Median :  0.000   Median : 11.40             #>  Mean   :16.08   Mean   : 52.08   Mean   :  6.524   Mean   : 20.02             #>  3rd Qu.:24.00   3rd Qu.: 96.00   3rd Qu.:  0.000   3rd Qu.: 26.00             #>  Max.   :33.00   Max.   :144.00   Max.   :153.000   Max.   :100.00             #>       evid               wt              age            sex      #>  Min.   :0.00000   Min.   : 40.00   Min.   :21.00   female:101   #>  1st Qu.:0.00000   1st Qu.: 60.00   1st Qu.:23.00   male  :414   #>  Median :0.00000   Median : 70.00   Median :28.00                #>  Mean   :0.06214   Mean   : 69.27   Mean   :31.85                #>  3rd Qu.:0.00000   3rd Qu.: 78.00   3rd Qu.:36.00                #>  Max.   :1.00000   Max.   :102.00   Max.   :63.00 cp ~ prop(prop.err) + add(pkadd.err) effect ~ add(pdadd.err) cp ~ prop(prop.err) + add(pkadd.err) effect ~ add(pdadd.err)  | pca pk.turnover.emax3 <- function() {   ini({     tktr <- log(1)     tka <- log(1)     tcl <- log(0.1)     tv <- log(10)     ##     eta.ktr ~ 1     eta.ka ~ 1     eta.cl ~ 2     eta.v ~ 1     prop.err <- 0.1     pkadd.err <- 0.1     ##     temax <- logit(0.8)     tec50 <- log(0.5)     tkout <- log(0.05)     te0 <- log(100)     ##     eta.emax ~ .5     eta.ec50  ~ .5     eta.kout ~ .5     eta.e0 ~ .5     ##     pdadd.err <- 10   })   model({     ktr <- exp(tktr + eta.ktr)     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     emax = expit(temax+eta.emax)     ec50 =  exp(tec50 + eta.ec50)     kout = exp(tkout + eta.kout)     e0 = exp(te0 + eta.e0)     ##     DCP = center/v     PD=1-emax*DCP/(ec50+DCP)     ##     effect(0) = e0     kin = e0*kout     ##     d/dt(depot) = -ktr * depot     d/dt(gut) =  ktr * depot -ka * gut     d/dt(center) =  ka * gut - cl / v * center     d/dt(effect) = kin*PD -kout*effect     ##     cp = center / v     cp ~ prop(prop.err) + add(pkadd.err)     effect ~ add(pdadd.err) | pca   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"run-the-models-with-saem","dir":"Articles","previous_headings":"Multiple endpoints","what":"Run the models with SAEM","title":"Working with multiple endpoints","text":"","code":"fit.TOS <- nlmixr(pk.turnover.emax3, warfarin, \"saem\", control=list(print=0),                   table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  print(fit.TOS) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>          OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 1383.99 2309.684 2389.105      -1135.842          1688.39 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance    saem  table compress #> elapsed 0.004123    5e-06   0.075006 187.627 14.052    0.037 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>            Est.     SE  %RSE Back-transformed(95%CI) BSV(CV% or SD) Shrink(SD)% #> tktr      0.426   0.44   103      1.53 (0.646, 3.62)           103.      52.3%  #> tka       -0.19  0.223   117     0.827 (0.534, 1.28)           41.7      63.6%  #> tcl       -1.97  0.051  2.58    0.139 (0.126, 0.153)           26.6      5.33%  #> tv            2 0.0476  2.37       7.41 (6.75, 8.14)           21.4      17.9%  #> prop.err  0.124                                0.124                            #> pkadd.err 0.758                                0.758                            #> temax      2.93  0.403  13.7     0.95 (0.895, 0.976)           3.00      83.9%  #> tec50     -0.17  0.148  87.3     0.844 (0.631, 1.13)           49.2      8.67%  #> tkout      -2.9 0.0391  1.34 0.0548 (0.0507, 0.0591)           6.31      46.2%  #> te0        4.57 0.0115 0.252       96.5 (94.3, 98.7)           5.15      17.8%  #> pdadd.err  3.73                                 3.73                            #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 483 × 42 #>   ID     TIME CMT      DV EPRED  ERES   NPDE    NPD  PRED   RES   WRES IPRED #>   <fct> <dbl> <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> #> 1 1       0.5 cp      0    1.94 -1.94  0.496  0.496  1.45 -1.45 -1.07  0.517 #> 2 1       1   cp      1.9  4.51 -2.61  0.728  0.728  4.06 -2.16 -0.816 1.66  #> 3 1       2   cp      3.3  8.23 -4.93 -2.94  -2.94   8.47 -5.17 -1.45  4.40  #> # … with 480 more rows, and 30 more variables: IRES <dbl>, IWRES <dbl>, #> #   CPRED <dbl>, CRES <dbl>, CWRES <dbl>, eta.ktr <dbl>, eta.ka <dbl>, #> #   eta.cl <dbl>, eta.v <dbl>, eta.emax <dbl>, eta.ec50 <dbl>, eta.kout <dbl>, #> #   eta.e0 <dbl>, depot <dbl>, gut <dbl>, center <dbl>, effect <dbl>, #> #   ktr <dbl>, ka <dbl>, cl <dbl>, v <dbl>, emax <dbl>, ec50 <dbl>, kout <dbl>, #> #   e0 <dbl>, DCP <dbl>, PD <dbl>, kin <dbl>, tad <dbl>, dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"saem-diagnostic-plots","dir":"Articles","previous_headings":"Multiple endpoints > Run the models with SAEM","what":"SAEM Diagnostic plots","title":"Working with multiple endpoints","text":"","code":"plot(fit.TOS) v1s <- vpcPlot(fit.TOS, show=list(obs_dv=TRUE), scales=\"free_y\") +   ylab(\"Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v2s <- vpcPlot(fit.TOS, show=list(obs_dv=TRUE), pred_corr = TRUE) +   ylab(\"Prediction Corrected Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v1s v2s"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"focei-fits","dir":"Articles","previous_headings":"Multiple endpoints","what":"FOCEi fits","title":"Working with multiple endpoints","text":"","code":"## FOCEi fit/vpcs fit.TOF <- nlmixr(pk.turnover.emax3, warfarin, \"focei\", control=list(print=0),                   table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:01:21  #> done"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/multiple-endpoints.html","id":"focei-diagnostic-plots","dir":"Articles","previous_headings":"Multiple endpoints > FOCEi fits","what":"FOCEi Diagnostic Plots","title":"Working with multiple endpoints","text":"","code":"print(fit.TOF) #> ── nlmixr FOCEi (outer: nlminb) ──────────────────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 1394.134 2319.828 2399.249      -1140.914         43937.34 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup optimize covariance table compress    other #> elapsed 0.003274 81.62976   81.62977  2.05     0.01 151.3822 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>            Est.     SE     %RSE Back-transformed(95%CI) BSV(CV% or SD) #> tktr      0.125   2.22 1.77e+03     1.13 (0.0147, 87.2)           113. #> tka        0.12   2.32 1.93e+03       1.13 (0.012, 106)           116. #> tcl       -2.03  0.116     5.73    0.132 (0.105, 0.165)           28.1 #> tv         2.06  0.104     5.05       7.86 (6.41, 9.63)           22.4 #> prop.err  0.143                                   0.143                #> pkadd.err 0.179                                   0.179                #> temax      5.01   6.76      135     0.993 (0.000265, 1)           3.00 #> tec50      0.15  0.225      150       1.16 (0.747, 1.8)           50.3 #> tkout     -2.94 0.0861     2.93  0.053 (0.0448, 0.0627)           12.3 #> te0        4.57 0.0371    0.811        96.4 (89.6, 104)           7.08 #> pdadd.err  3.74                                    3.74                #>           Shrink(SD)% #> tktr           63.2%  #> tka            63.4%  #> tcl            1.96%  #> tv             8.85%  #> prop.err              #> pkadd.err             #> temax          96.8%  #> tec50          8.66%  #> tkout          27.9%  #> te0            24.0%  #> pdadd.err             #>   #>   Covariance Type ($covMethod): s #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>   Minimization message ($message):   #>     false convergence (8)  #>   In an ODE system, false convergence may mean \"useless\" evaluations were performed. #>   See https://tinyurl.com/yyrrwkce #>   It could also mean the convergence is poor, check results before accepting fit #>   You may also try a good derivative free optimization: #>     nlmixr2(...,control=list(outerOpt=\"bobyqa\")) #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 483 × 42 #>   ID     TIME CMT      DV EPRED  ERES   NPDE    NPD  PRED   RES   WRES IPRED #>   <fct> <dbl> <fct> <dbl> <dbl> <dbl>  <dbl>  <dbl> <dbl> <dbl>  <dbl> <dbl> #> 1 1       0.5 cp      0    2.14 -2.14 -0.728 -0.728  1.40 -1.40 -0.908 0.444 #> 2 1       1   cp      1.9  4.61 -2.71  1.26   1.26   3.95 -2.05 -0.579 1.46  #> 3 1       2   cp      3.3  7.70 -4.40 -2.94  -2.94   8.27 -4.97 -1.03  3.99  #> # … with 480 more rows, and 30 more variables: IRES <dbl>, IWRES <dbl>, #> #   CPRED <dbl>, CRES <dbl>, CWRES <dbl>, eta.ktr <dbl>, eta.ka <dbl>, #> #   eta.cl <dbl>, eta.v <dbl>, eta.emax <dbl>, eta.ec50 <dbl>, eta.kout <dbl>, #> #   eta.e0 <dbl>, depot <dbl>, gut <dbl>, center <dbl>, effect <dbl>, #> #   ktr <dbl>, ka <dbl>, cl <dbl>, v <dbl>, emax <dbl>, ec50 <dbl>, kout <dbl>, #> #   e0 <dbl>, DCP <dbl>, PD <dbl>, kin <dbl>, tad <dbl>, dosenum <dbl> plot(fit.TOF) v1f <- vpcPlot(fit.TOF, show=list(obs_dv=TRUE), scales=\"free_y\") +   ylab(\"Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v2f <- vpcPlot(fit.TOF, show=list(obs_dv=TRUE), pred_corr = TRUE) +   ylab(\"Prediction Corrected Warfarin Cp [mg/L] or PCA\") +   xlab(\"Time [h]\")  v1f v2f"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nimo.html","id":"nlmixr-model","dir":"Articles","previous_headings":"","what":"nlmixr model","title":"Nimotuzumab","text":"","code":"library(nlmixr2) library(xpose) library(xpose.nlmixr) library(ggplot2)  nimo <- function() {   ini({     ## Note that the UI can take expressions     ## Also note that these initial estimates should be provided on the log-scale     tcl <- log(0.001)     tv1 <- log(1.45)     tQ <- log(0.004)     tv2 <- log(44)     tkss <- log(12)     tkint <- log(0.3)     tksyn <- log(1)     tkdeg <- log(7)     ## Initial estimates should be high for SAEM ETAs     eta.cl  ~ 2     eta.v1  ~ 2     eta.kss ~ 2     ##  Also true for additive error (also ignored in SAEM)     add.err <- 10   })   model({     cl <- exp(tcl + eta.cl)     v1 <- exp(tv1 + eta.v1)     Q  <- exp(tQ)     v2 <- exp(tv2)     kss <- exp(tkss + eta.kss)     kint <- exp(tkint)     ksyn <- exp(tksyn)     kdeg <- exp(tkdeg)      k <- cl/v1     k12 <- Q/v1     k21 <- Q/v2      eff(0) <- ksyn/kdeg ##initializing compartment      ## Concentration is calculated     conc = 0.5*(central/v1-eff-kss)+0.5*sqrt((central/v1-eff-kss)**2+4*kss*central/v1)      d/dt(central)  = -(k+k12)*conc*v1+k21*peripheral-kint*eff*conc*v1/(kss+conc)     d/dt(peripheral) = k12*conc*v1-k21*peripheral  ##Free Drug second compartment amount     d/dt(eff) = ksyn - kdeg*eff - (kint-kdeg)*conc*eff/(kss+conc)      IPRED=log(conc)      IPRED ~ add(add.err)   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nimo.html","id":"fit","dir":"Articles","previous_headings":"","what":"Fit","title":"Nimotuzumab","text":"","code":"fit <- nlmixr(nimo, nimoData, est=\"saem\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> 001: -7.082156   0.240380    -5.322648   3.706002    2.535890    -1.294407   -0.102901   1.975165    1.900000    1.900000    2.150501    1.391724     #> 002: -7.318608   0.337788    -5.472643   3.604174    2.671940    -1.381532   0.004361    1.965802    1.805000    1.805000    2.042976    0.830852     #> 003: -7.004796   0.329353    -5.552719   3.663648    2.576095    -1.342266   0.094213    2.169032    1.714750    1.714750    1.940827    0.704378     #> 004: -6.831052   0.337039    -5.509392   3.581316    2.619975    -1.473308   0.193564    2.039580    1.629012    1.629012    1.843786    0.673922     #> 005: -6.988888   0.327350    -5.438457   3.546217    2.611964    -1.375401   0.032029    2.028963    1.547562    1.547562    1.751597    0.664592     #> 006: -6.877438   0.309723    -5.508254   3.692787    2.673534    -1.385796   -0.048632   1.984854    1.470184    1.470184    1.664017    0.659652     #> 007: -6.898159   0.314886    -5.496362   3.638982    2.747608    -1.255406   -0.026410   1.947620    1.407505    1.396675    1.580816    0.663774     #> 008: -6.957871   0.319272    -5.352725   3.503540    2.776519    -1.197933   0.000427    1.968390    1.337130    1.326841    1.501775    0.670739     #> 009: -6.826759   0.315714    -5.227308   3.580258    2.922322    -1.203666   -0.010643   2.177228    1.270273    1.260499    1.483524    0.661929     #> 010: -7.082397   0.308379    -5.273932   3.611745    2.874421    -1.137025   0.115752    2.203563    1.305004    1.197474    1.517557    0.656455     #> 011: -7.083805   0.294951    -5.267117   3.697103    2.937389    -1.228824   0.136825    2.298366    1.239753    1.137600    1.522041    0.661686     #> 012: -7.229129   0.369998    -5.290768   3.737127    2.879780    -1.195137   0.181972    2.281019    1.177766    1.080720    1.445939    0.660513     #> 013: -7.118783   0.316777    -5.198435   3.808386    3.007388    -1.298448   0.173969    2.200194    1.118877    1.026684    1.545758    0.659895     #> 014: -7.107046   0.296195    -5.247466   3.826552    3.068812    -1.449512   0.198110    2.171824    1.062934    0.975350    1.468470    0.664804     #> 015: -7.101186   0.342107    -5.262732   3.789245    3.006193    -1.467174   0.209708    2.105610    1.173838    0.926582    1.395047    0.661338     #> 016: -7.054116   0.293809    -5.404022   3.710325    2.800496    -1.446669   0.248707    2.016275    1.115146    0.880253    1.325294    0.661297     #> 017: -6.900522   0.299893    -5.468624   3.730384    2.913575    -1.388838   0.287952    2.001241    1.059389    0.836241    1.259030    0.662951     #> 018: -6.847400   0.259424    -5.462242   3.782073    2.941709    -1.430433   0.325918    2.151714    1.006419    0.794429    1.196078    0.674475     #> 019: -6.753272   0.299121    -5.510133   3.743449    2.954801    -1.441600   0.390829    2.220912    0.956098    0.754707    1.136274    0.665982     #> 020: -6.837756   0.315087    -5.621735   3.778400    2.916021    -1.288673   0.366226    2.244962    1.106701    0.716972    1.079461    0.667779     #> 021: -6.893220   0.306474    -5.591735   3.473458    2.872476    -1.289627   0.381579    2.338688    1.255998    0.681123    1.025488    0.670320     #> 022: -7.005703   0.363949    -5.581785   3.500052    2.745047    -1.268654   0.294263    2.201461    1.193198    0.647067    0.974213    0.668004     #> 023: -6.939491   0.324638    -5.455178   3.494135    2.667590    -1.310115   0.298623    2.255601    1.133538    0.614714    0.925503    0.653433     #> 024: -6.885500   0.269202    -5.425549   3.477327    2.519646    -1.295313   0.341746    2.453918    1.201937    0.583978    0.879227    0.657180     #> 025: -7.003679   0.329172    -5.462586   3.450449    2.399445    -1.392637   0.407089    2.493273    1.141840    0.554779    0.835266    0.657478     #> 026: -6.998503   0.308081    -5.503414   3.378182    2.240570    -1.395307   0.507344    2.538508    1.084748    0.527040    0.793503    0.652995     #> 027: -6.983049   0.251959    -5.415440   3.357185    2.331519    -1.429724   0.469920    2.487613    1.053474    0.500688    0.753828    0.653142     #> 028: -7.064152   0.281134    -5.428507   3.340922    2.360536    -1.343881   0.489512    2.441413    1.031793    0.475654    0.744672    0.656158     #> 029: -7.153328   0.259568    -5.408880   3.332953    2.419550    -1.396986   0.552957    2.412138    1.038802    0.451871    0.755118    0.654489     #> 030: -7.137799   0.269775    -5.430981   3.324828    2.505459    -1.450748   0.544276    2.356400    0.986862    0.429278    0.717362    0.654892     #> 031: -7.278104   0.306992    -5.462212   3.347481    2.481115    -1.393738   0.510631    2.404250    0.937519    0.407814    0.681494    0.653134     #> 032: -7.366002   0.296299    -5.462750   3.354325    2.493465    -1.385500   0.511527    2.445562    0.890643    0.387423    0.647419    0.659970     #> 033: -7.126602   0.319700    -5.438877   3.445812    2.471803    -1.441491   0.498690    2.510886    0.846111    0.368052    0.615049    0.662377     #> 034: -7.011533   0.319809    -5.457466   3.448620    2.549336    -1.433274   0.440205    2.477871    0.803806    0.349649    0.601210    0.661287     #> 035: -7.030069   0.328177    -5.430406   3.521252    2.568902    -1.477423   0.431840    2.497634    0.777766    0.332167    0.571150    0.669576     #> 036: -6.790538   0.306774    -5.527834   3.622364    2.476747    -1.425994   0.382638    2.494380    0.738878    0.315558    0.542592    0.668018     #> 037: -6.800334   0.270544    -5.414146   3.402385    2.582889    -1.400895   0.474395    2.576823    0.818234    0.299781    0.560308    0.659367     #> 038: -6.779983   0.198230    -5.460225   3.326120    2.459665    -1.312269   0.425136    2.498573    0.777322    0.284791    0.532293    0.662861     #> 039: -6.671886   0.254019    -5.570037   3.257240    2.441459    -1.403449   0.505908    2.453239    0.738456    0.270552    0.552395    0.655443     #> 040: -6.801421   0.264928    -5.582054   3.187304    2.426505    -1.432948   0.510497    2.418150    0.701533    0.257024    0.524775    0.661263     #> 041: -6.867235   0.280701    -5.643455   3.254848    2.508290    -1.478873   0.516456    2.354902    0.719071    0.258599    0.498537    0.658930     #> 042: -6.780870   0.297515    -5.625829   3.229796    2.525800    -1.423885   0.545876    2.247574    0.704235    0.262364    0.473610    0.656337     #> 043: -7.000980   0.308498    -5.643916   3.368084    2.518038    -1.448837   0.571972    2.253661    0.838864    0.261131    0.449929    0.660254     #> 044: -6.881316   0.361812    -5.676801   3.302498    2.485286    -1.378273   0.610588    2.406006    0.796921    0.287254    0.427433    0.659041     #> 045: -6.992270   0.311070    -5.460939   3.297823    2.493164    -1.394428   0.574134    2.346399    0.987389    0.272891    0.406061    0.657335     #> 046: -6.937286   0.255586    -5.505305   3.189254    2.469744    -1.477122   0.595653    2.387849    0.938020    0.259247    0.385758    0.657275     #> 047: -6.910055   0.278884    -5.524470   3.291595    2.395307    -1.531927   0.560231    2.426453    0.891119    0.261829    0.366470    0.657160     #> 048: -7.067394   0.288722    -5.510406   3.356396    2.365454    -1.578588   0.642720    2.429590    0.846563    0.296891    0.348147    0.655746     #> 049: -6.923328   0.270119    -5.450789   3.414379    2.366448    -1.585423   0.629513    2.466967    0.893002    0.282046    0.330739    0.658189     #> 050: -6.975794   0.288132    -5.435516   3.347858    2.392924    -1.608769   0.643707    2.417948    0.932213    0.277081    0.314202    0.648781     #> 051: -6.875901   0.353712    -5.416865   3.611819    2.462963    -1.660868   0.661059    2.438330    0.970314    0.294981    0.298492    0.652593     #> 052: -6.765307   0.271983    -5.391472   3.626409    2.527210    -1.643741   0.684367    2.440789    0.921799    0.288411    0.283568    0.655201     #> 053: -6.620037   0.310457    -5.451163   3.854368    2.628403    -1.630681   0.646037    2.405277    0.875709    0.273990    0.269389    0.661798     #> 054: -6.541914   0.322377    -5.602161   3.918050    2.661677    -1.588618   0.619825    2.408575    0.831923    0.260291    0.255920    0.656715     #> 055: -6.373490   0.295359    -5.581440   3.790033    2.702007    -1.567283   0.614160    2.346308    0.843537    0.265659    0.284322    0.657369     #> 056: -6.361577   0.312322    -5.637698   3.785505    2.787302    -1.527121   0.574659    2.272041    0.801360    0.252376    0.270106    0.659265     #> 057: -6.297834   0.286892    -5.705691   3.762464    2.794607    -1.540606   0.548523    2.251223    0.761292    0.239758    0.276525    0.662021     #> 058: -6.402065   0.258021    -5.810660   3.777895    2.758826    -1.493502   0.544410    2.192527    0.862540    0.263461    0.262699    0.656945     #> 059: -6.488559   0.275667    -5.779645   3.824903    2.822481    -1.496432   0.516002    2.169180    0.941809    0.280023    0.249564    0.661064     #> 060: -6.537952   0.322100    -5.844695   4.198486    2.774870    -1.501122   0.532435    2.161901    0.894719    0.287462    0.237086    0.663263     #> 061: -6.416021   0.343720    -5.758680   3.940205    2.650611    -1.499860   0.520846    2.224032    0.849983    0.273089    0.225231    0.664169     #> 062: -6.310170   0.299830    -5.611265   3.839088    2.686540    -1.439855   0.487623    2.288302    0.807484    0.259434    0.213970    0.663122     #> 063: -6.294908   0.311997    -5.540899   3.862490    2.707261    -1.423113   0.494748    2.327657    0.767109    0.246462    0.203271    0.660175     #> 064: -6.366629   0.316682    -5.694336   3.936071    2.652013    -1.427522   0.492013    2.282279    0.835532    0.234139    0.193108    0.670102     #> 065: -6.180801   0.364973    -5.741631   3.493918    2.689585    -1.489510   0.476151    2.215031    0.793756    0.235573    0.183452    0.667527     #> 066: -6.179648   0.348374    -5.749013   3.402021    2.762067    -1.490865   0.520905    2.185092    0.929906    0.254211    0.174280    0.661183     #> 067: -6.263086   0.327637    -5.634331   3.234640    2.755069    -1.510695   0.550426    2.217312    0.979119    0.322320    0.176250    0.662333     #> 068: -6.292892   0.362669    -5.612425   3.180375    2.701803    -1.509967   0.559493    2.262292    0.930163    0.306204    0.209163    0.659376     #> 069: -6.406907   0.311112    -5.588864   2.947345    2.659620    -1.506976   0.586969    2.254385    1.083297    0.321730    0.198705    0.665014     #> 070: -6.314687   0.246440    -5.595287   2.908022    2.630289    -1.497341   0.549582    2.261500    1.029132    0.314350    0.206450    0.657920     #> 071: -6.217709   0.265446    -5.567675   2.798543    2.600281    -1.531825   0.566408    2.206204    0.977676    0.298633    0.196128    0.659110     #> 072: -6.157095   0.238023    -5.754847   2.756068    2.610835    -1.545311   0.590166    2.188482    0.928792    0.302674    0.215475    0.656766     #> 073: -6.287617   0.255763    -5.782974   2.668018    2.562220    -1.547860   0.620664    2.168260    0.961688    0.313501    0.204701    0.659373     #> 074: -6.509203   0.260687    -5.652472   2.846293    2.500960    -1.562527   0.515292    2.121736    1.267267    0.297826    0.194466    0.668704     #> 075: -6.416412   0.278495    -5.663658   2.889233    2.531158    -1.575245   0.563700    2.156104    1.203903    0.282935    0.184743    0.660703     #> 076: -6.372197   0.258099    -5.726064   2.809855    2.497007    -1.585770   0.554655    2.130951    1.143708    0.268788    0.175506    0.656914     #> 077: -6.345672   0.278881    -5.670182   2.647593    2.595867    -1.575106   0.604909    2.152797    1.189868    0.296868    0.166730    0.657233     #> 078: -6.348930   0.262330    -5.658917   2.462042    2.552281    -1.543080   0.649866    2.176722    1.130374    0.282025    0.158394    0.658202     #> 079: -6.182329   0.305910    -5.622486   2.681155    2.576799    -1.530473   0.609340    2.235116    1.073856    0.267924    0.151881    0.666624     #> 080: -6.278351   0.247696    -5.611191   2.640099    2.540012    -1.529954   0.613512    2.216091    1.020163    0.254528    0.152491    0.665660     #> 081: -6.161229   0.308140    -5.648894   2.746375    2.584527    -1.542349   0.612081    2.185029    0.969155    0.251895    0.144867    0.658389     #> 082: -6.134250   0.290519    -5.697368   2.861817    2.573103    -1.554697   0.594581    2.126595    0.920697    0.239300    0.137623    0.654481     #> 083: -6.157780   0.293400    -5.674551   2.596083    2.552749    -1.554927   0.613874    2.102997    0.874662    0.227335    0.130742    0.649084     #> 084: -6.043718   0.270041    -5.524905   2.548757    2.544325    -1.547110   0.572517    2.204878    0.830929    0.215968    0.132570    0.649058     #> 085: -6.035218   0.203893    -5.464928   2.517038    2.519986    -1.562535   0.583354    2.289152    0.809167    0.205170    0.125942    0.659515     #> 086: -6.155169   0.188440    -5.358699   2.760529    2.498737    -1.578073   0.580119    2.283462    0.904021    0.194911    0.120566    0.652513     #> 087: -6.115400   0.156386    -5.284803   2.778030    2.502999    -1.590966   0.603655    2.235995    0.858820    0.185166    0.114538    0.654176     #> 088: -6.158905   0.168182    -5.450443   2.449863    2.516668    -1.578885   0.565575    2.174054    0.887651    0.235742    0.113189    0.672454     #> 089: -6.264660   0.164214    -5.592644   2.405672    2.533449    -1.562987   0.581745    2.165362    1.141834    0.228379    0.107530    0.663633     #> 090: -6.279971   0.227163    -5.563073   2.419175    2.545061    -1.556209   0.595420    2.181293    1.239181    0.235747    0.102153    0.659207     #> 091: -6.211909   0.182332    -5.561700   2.445815    2.572867    -1.544233   0.596836    2.182525    1.177222    0.223959    0.128134    0.653343     #> 092: -6.054699   0.227844    -5.661706   2.325238    2.516278    -1.536466   0.568745    2.156513    1.118361    0.212761    0.122333    0.654642     #> 093: -6.060565   0.272713    -5.729856   2.462729    2.511964    -1.535758   0.574684    2.156639    1.062443    0.212576    0.116217    0.657862     #> 094: -6.246009   0.287082    -5.862449   2.551871    2.478441    -1.539652   0.606569    2.199354    1.234343    0.247500    0.110406    0.654755     #> 095: -6.430293   0.274664    -5.696054   2.580877    2.460005    -1.534625   0.608098    2.271460    1.691609    0.236875    0.104886    0.658308     #> 096: -6.235785   0.261008    -5.573622   2.627211    2.484236    -1.537258   0.653057    2.253702    1.607029    0.225031    0.099641    0.659037     #> 097: -6.424872   0.273861    -5.622372   2.356470    2.528754    -1.536887   0.689467    2.268328    1.556114    0.213780    0.094659    0.654865     #> 098: -6.292736   0.285177    -5.715682   2.226018    2.579253    -1.531399   0.684539    2.272246    1.600298    0.203091    0.089926    0.662134     #> 099: -6.272271   0.291946    -5.757178   2.435993    2.512930    -1.534143   0.677665    2.285231    1.520283    0.224477    0.095242    0.661522     #> 100: -6.212044   0.249385    -5.898241   2.320787    2.509986    -1.546925   0.700892    2.320300    1.444269    0.213253    0.123807    0.664829     #> 101: -6.145608   0.204983    -5.761245   2.475931    2.517424    -1.559297   0.720140    2.349080    1.372055    0.202590    0.117616    0.663993     #> 102: -6.088134   0.202131    -5.798948   2.318193    2.482019    -1.557104   0.714314    2.330478    1.303453    0.192461    0.111736    0.656278     #> 103: -6.155875   0.197593    -5.842397   2.162408    2.429311    -1.566786   0.730617    2.305273    1.238280    0.182838    0.106149    0.656881     #> 104: -6.087011   0.207827    -5.953135   2.118611    2.511587    -1.562439   0.767974    2.280894    1.176366    0.188620    0.100841    0.666994     #> 105: -6.039989   0.251439    -5.966304   2.123777    2.549131    -1.557299   0.757149    2.254959    1.117548    0.253200    0.095799    0.666102     #> 106: -6.290345   0.268955    -5.975043   2.145418    2.573836    -1.550764   0.743828    2.239197    1.151869    0.245265    0.091009    0.659745     #> 107: -6.286730   0.287510    -5.955899   2.111745    2.594305    -1.561735   0.747215    2.250038    1.094275    0.248733    0.086459    0.659499     #> 108: -6.273823   0.297585    -6.016208   2.113022    2.595285    -1.566934   0.734420    2.258948    1.039562    0.277755    0.082136    0.660153     #> 109: -6.267443   0.316282    -6.038765   2.197108    2.609124    -1.577313   0.734572    2.255037    1.005796    0.315716    0.078029    0.661130     #> 110: -6.157332   0.269255    -6.051623   2.140537    2.550621    -1.569779   0.731601    2.273520    0.955506    0.299930    0.074935    0.659734     #> 111: -6.076713   0.269728    -5.953031   2.187567    2.523093    -1.573527   0.738749    2.270180    0.907731    0.284934    0.078932    0.655210     #> 112: -5.964195   0.169871    -5.815473   2.113463    2.501764    -1.570052   0.722121    2.274298    0.931897    0.270687    0.079653    0.658917     #> 113: -6.037903   0.193654    -5.686140   2.183916    2.521836    -1.569770   0.686944    2.272125    0.885302    0.257152    0.075670    0.656216     #> 114: -6.212603   0.207454    -5.578621   2.227185    2.468546    -1.572799   0.704449    2.289144    0.852730    0.244295    0.071886    0.659052     #> 115: -6.087506   0.159465    -5.562266   2.362240    2.467027    -1.569250   0.703103    2.295304    0.810094    0.232080    0.068292    0.659037     #> 116: -6.271836   0.207026    -5.771661   2.317987    2.466562    -1.567764   0.735192    2.279674    1.040933    0.220476    0.074169    0.661909     #> 117: -6.181938   0.247848    -5.916636   2.197798    2.461699    -1.577292   0.724590    2.285703    0.988886    0.221815    0.073582    0.656724     #> 118: -6.105514   0.259773    -6.031286   2.199732    2.433550    -1.573767   0.713413    2.310808    0.939442    0.227781    0.077772    0.662981     #> 119: -6.139682   0.230993    -5.775459   2.245673    2.475944    -1.576630   0.720349    2.319870    1.079576    0.255713    0.092191    0.660103     #> 120: -6.222458   0.265085    -5.780395   2.238269    2.407321    -1.563498   0.717967    2.312104    1.343394    0.242927    0.087581    0.662831     #> 121: -6.205576   0.292690    -5.818731   2.215492    2.353619    -1.568312   0.708781    2.332225    1.276224    0.237629    0.083202    0.658801     #> 122: -6.340574   0.248690    -5.792620   2.186040    2.336950    -1.568947   0.751458    2.336919    1.327683    0.225748    0.079042    0.664029     #> 123: -6.240619   0.286918    -5.922783   2.151440    2.385952    -1.578815   0.739304    2.315010    1.261299    0.239872    0.075090    0.665589     #> 124: -6.062197   0.188491    -5.671910   2.065987    2.407938    -1.575661   0.754348    2.354000    1.198234    0.258650    0.071335    0.655621     #> 125: -5.938171   0.133588    -5.669819   2.098894    2.394591    -1.567429   0.766950    2.346589    1.138322    0.245718    0.067769    0.647558     #> 126: -6.050836   0.159536    -5.575193   2.028379    2.321413    -1.567408   0.759598    2.356169    1.081406    0.233432    0.064380    0.646938     #> 127: -6.043550   0.162555    -5.630182   2.028261    2.279293    -1.565329   0.757574    2.375814    1.027336    0.221760    0.063550    0.652070     #> 128: -6.163815   0.156006    -5.713401   2.082449    2.292989    -1.567436   0.783207    2.368118    0.994222    0.210672    0.060373    0.652423     #> 129: -6.026360   0.134431    -5.730523   2.080405    2.279718    -1.560976   0.774327    2.367867    0.944511    0.207261    0.057354    0.646028     #> 130: -6.182462   0.182418    -5.854656   2.108885    2.282749    -1.562019   0.772143    2.336400    1.141696    0.206348    0.054486    0.651123     #> 131: -6.123334   0.226231    -5.956765   2.269243    2.261948    -1.562097   0.764782    2.345229    1.084611    0.203200    0.063076    0.646223     #> 132: -6.157793   0.253613    -5.899925   2.213909    2.231974    -1.566266   0.763625    2.348024    1.030380    0.193040    0.072373    0.646635     #> 133: -6.160282   0.176399    -5.600395   2.237008    2.202996    -1.566850   0.759821    2.343707    0.978861    0.200522    0.068755    0.643980     #> 134: -6.091373   0.214783    -5.522203   2.174087    2.204914    -1.567717   0.766791    2.351139    0.929918    0.190496    0.065317    0.639176     #> 135: -6.223544   0.196752    -5.619198   2.134648    2.148990    -1.569439   0.762407    2.354880    1.029688    0.189921    0.062051    0.638897     #> 136: -6.351980   0.222879    -5.619590   1.940290    2.136948    -1.569182   0.777299    2.362702    0.978204    0.180425    0.060331    0.638686     #> 137: -6.254703   0.238560    -5.325081   1.962909    2.156771    -1.567986   0.778301    2.386634    0.929294    0.197500    0.060935    0.642611     #> 138: -6.325032   0.223826    -5.596957   1.927149    2.119538    -1.568227   0.777141    2.401026    0.882829    0.208409    0.057888    0.645660     #> 139: -6.327387   0.252262    -5.794480   1.837559    2.130708    -1.571525   0.771579    2.385050    0.849735    0.205737    0.054994    0.648003     #> 140: -6.315469   0.252960    -5.515650   1.918284    2.087438    -1.569570   0.765491    2.393909    1.066001    0.200785    0.052244    0.650808     #> 141: -6.259260   0.196768    -5.359083   1.898649    2.102203    -1.572031   0.760099    2.389715    1.012701    0.190746    0.054229    0.650098     #> 142: -6.286116   0.207886    -5.429603   1.828356    2.113582    -1.568979   0.760490    2.398108    1.040263    0.210455    0.051517    0.644076     #> 143: -6.277863   0.144409    -5.400326   1.798129    2.124122    -1.568783   0.766750    2.390298    1.135030    0.199932    0.083070    0.640880     #> 144: -6.097191   0.152707    -5.265616   1.784166    2.067682    -1.569320   0.775770    2.387152    1.078278    0.189935    0.081843    0.640220     #> 145: -6.030562   0.169422    -5.372859   1.638945    2.042808    -1.571701   0.782241    2.388795    1.024364    0.182802    0.079024    0.646379     #> 146: -5.929208   0.183166    -5.215155   1.582296    2.124695    -1.572587   0.799206    2.384018    0.973146    0.173661    0.080349    0.649840     #> 147: -6.091094   0.148861    -5.413417   1.518910    2.117711    -1.577794   0.803974    2.390770    1.018066    0.189119    0.076332    0.651413     #> 148: -6.038322   0.163040    -5.364643   1.405403    2.060034    -1.580065   0.800919    2.394011    0.967163    0.199397    0.075860    0.643081     #> 149: -6.144971   0.162795    -5.434824   1.639964    2.046322    -1.578302   0.788771    2.397330    0.918804    0.189427    0.100187    0.642488     #> 150: -6.158308   0.153766    -5.322483   1.715597    2.019627    -1.577785   0.777469    2.393026    0.872864    0.179956    0.095178    0.642393     #> 151: -6.325919   0.162711    -5.333445   1.774397    1.980282    -1.576951   0.764681    2.393685    0.924791    0.177011    0.090419    0.640315     #> 152: -6.275873   0.140045    -5.434571   1.728362    1.946403    -1.579603   0.779750    2.395632    0.947999    0.177398    0.074118    0.640285     #> 153: -6.388154   0.204051    -5.674642   1.587373    1.920670    -1.577911   0.790669    2.395030    0.973367    0.198067    0.059956    0.633047     #> 154: -6.392683   0.185443    -5.801330   1.582848    1.964034    -1.578287   0.793954    2.392946    1.015318    0.204812    0.070121    0.631243     #> 155: -6.318437   0.228441    -5.918381   1.503735    1.936745    -1.577975   0.794713    2.391426    0.593669    0.212431    0.062457    0.635381     #> 156: -6.244482   0.191055    -5.744870   1.600130    1.955168    -1.577474   0.795110    2.391378    0.654095    0.239660    0.058790    0.636975     #> 157: -6.280873   0.176652    -5.640207   1.532814    1.973167    -1.579682   0.792470    2.391740    0.693335    0.222825    0.054457    0.642161     #> 158: -6.347095   0.192369    -5.639766   1.674537    1.995592    -1.580147   0.791439    2.396190    0.803920    0.212944    0.051899    0.642383     #> 159: -6.316945   0.133937    -5.675075   1.639609    1.976042    -1.579965   0.785751    2.394868    0.984798    0.193061    0.052124    0.642193     #> 160: -6.196957   0.133609    -5.674684   1.679991    1.981697    -1.580074   0.785797    2.393723    0.826229    0.196067    0.071522    0.636361     #> 161: -6.158592   0.155390    -5.689167   1.712191    2.025802    -1.580988   0.784514    2.392092    0.581564    0.166288    0.073511    0.634819     #> 162: -6.137448   0.154718    -5.678096   1.699526    2.025256    -1.580696   0.782306    2.393472    0.572338    0.162702    0.065574    0.636686     #> 163: -6.100945   0.148876    -5.661370   1.590237    2.003860    -1.582737   0.776825    2.392300    0.717984    0.148697    0.056941    0.645844     #> 164: -6.169722   0.144153    -5.675152   1.588790    2.007761    -1.583089   0.780865    2.393946    0.791595    0.180963    0.062668    0.639522     #> 165: -6.165415   0.136011    -5.468960   1.626551    2.036934    -1.584196   0.776216    2.391671    0.953662    0.223472    0.055287    0.653602     #> 166: -6.168184   0.169013    -5.549479   1.658533    2.018651    -1.584383   0.776294    2.390741    1.047761    0.222250    0.050838    0.653822     #> 167: -6.228627   0.220283    -5.594599   1.565492    2.028183    -1.583950   0.781883    2.391679    1.008091    0.206021    0.035260    0.641002     #> 168: -6.313146   0.222538    -5.916894   1.534677    2.032115    -1.584270   0.784079    2.390755    1.151038    0.223107    0.030725    0.645640     #> 169: -6.245363   0.215022    -5.951179   1.528584    2.022510    -1.584000   0.785383    2.389286    0.970954    0.219767    0.032126    0.647806     #> 170: -6.147276   0.130025    -5.557288   1.601452    2.020010    -1.584146   0.787341    2.386905    0.940890    0.185054    0.031372    0.650503     #> 171: -6.189950   0.113086    -5.714958   1.737105    2.031047    -1.584089   0.782702    2.386961    1.128114    0.135486    0.036217    0.647351     #> 172: -6.221322   0.102054    -5.701951   1.781948    2.055567    -1.583864   0.781344    2.387267    1.214306    0.128140    0.033982    0.652524     #> 173: -6.375344   0.146202    -5.820274   1.867366    2.078362    -1.583308   0.788934    2.388403    1.604321    0.132159    0.027481    0.653632     #> 174: -6.317145   0.145986    -5.704583   1.950026    2.081375    -1.583737   0.794455    2.389226    1.069156    0.151687    0.024780    0.645972     #> 175: -6.354248   0.193550    -5.778465   1.889422    2.079067    -1.583930   0.799495    2.388396    1.196044    0.158432    0.027334    0.655684     #> 176: -6.474609   0.164674    -5.288514   1.896971    2.095629    -1.584153   0.802286    2.389881    1.636644    0.176902    0.025370    0.642049     #> 177: -6.481511   0.194558    -5.409854   1.920877    2.108349    -1.583950   0.800018    2.388218    1.798048    0.155473    0.027795    0.651002     #> 178: -6.236869   0.174708    -5.611176   1.800213    2.116938    -1.583644   0.802930    2.386063    1.219576    0.140254    0.032773    0.649996     #> 179: -6.402773   0.160141    -5.504130   1.821194    2.150982    -1.583531   0.807279    2.384348    1.661895    0.128963    0.034756    0.648968     #> 180: -6.200352   0.201573    -5.379617   1.622757    2.098665    -1.583212   0.808068    2.384942    1.291450    0.136027    0.034760    0.648252     #> 181: -6.154629   0.134022    -5.703647   1.517957    2.097937    -1.583226   0.808596    2.384396    1.267142    0.109287    0.038464    0.653541     #> 182: -6.017586   0.152084    -5.624867   1.590407    2.115783    -1.582320   0.809266    2.382520    0.877975    0.112818    0.049803    0.646338     #> 183: -6.035195   0.155852    -5.615884   1.541263    2.122084    -1.582177   0.812211    2.383690    1.082328    0.138553    0.063931    0.643350     #> 184: -6.030149   0.160561    -5.709429   1.547401    2.114630    -1.581728   0.814090    2.381816    0.915867    0.133825    0.054102    0.644647     #> 185: -6.104584   0.163207    -5.562519   1.570250    2.105220    -1.582416   0.815267    2.381782    0.914228    0.115981    0.058587    0.651388     #> 186: -6.083656   0.135009    -5.728530   1.448787    2.091375    -1.582231   0.812878    2.382702    1.109141    0.121905    0.049311    0.642822     #> 187: -6.043931   0.169513    -5.766415   1.324844    2.099793    -1.581689   0.812464    2.383573    1.185721    0.131987    0.028303    0.653313     #> 188: -6.248159   0.200303    -5.861558   1.228064    2.095785    -1.580921   0.814914    2.382313    1.274920    0.189190    0.025971    0.655708     #> 189: -6.216796   0.232604    -6.067062   1.177817    2.121533    -1.581297   0.814820    2.380523    0.890098    0.128944    0.026408    0.657238     #> 190: -6.051454   0.196362    -5.895573   1.255496    2.123353    -1.581410   0.814494    2.380912    0.935833    0.110422    0.029227    0.663242     #> 191: -5.991635   0.211124    -5.892124   1.298279    2.106945    -1.580958   0.817877    2.382479    0.892656    0.156577    0.024955    0.655780     #> 192: -6.047691   0.215289    -5.783624   1.295377    2.101948    -1.580537   0.822596    2.383478    0.727932    0.177825    0.023867    0.652239     #> 193: -6.058464   0.208433    -5.788977   1.327596    2.102704    -1.579820   0.820865    2.383558    0.693397    0.190835    0.021649    0.648304     #> 194: -6.127456   0.199013    -5.709657   1.387952    2.107181    -1.579817   0.821016    2.384216    1.010959    0.157728    0.016798    0.643460     #> 195: -6.227061   0.196115    -5.660851   1.380943    2.065294    -1.579715   0.824801    2.383256    0.925967    0.197993    0.010805    0.639466     #> 196: -6.266126   0.189600    -5.536753   1.370643    2.057695    -1.579833   0.823964    2.384284    0.846838    0.197563    0.010803    0.647238     #> 197: -6.115913   0.236366    -5.580681   1.288545    2.072621    -1.579683   0.822335    2.384590    0.802606    0.166022    0.009784    0.655001     #> 198: -6.208735   0.238806    -5.787343   1.374681    2.085660    -1.579910   0.823466    2.385170    0.827327    0.160943    0.007928    0.655151     #> 199: -6.026800   0.172341    -5.542369   1.381131    2.078567    -1.579377   0.829612    2.386308    0.707425    0.132404    0.009525    0.657788     #> 200: -6.065896   0.195934    -5.843292   1.245720    2.077078    -1.579436   0.835513    2.386421    0.703542    0.153531    0.010915    0.654184     #> 201: -6.037815   0.179665    -5.856646   1.228126    2.079716    -1.579472   0.834502    2.386669    0.695206    0.146807    0.010431    0.652812     #> 202: -6.028586   0.181602    -5.843096   1.212655    2.070687    -1.579546   0.834535    2.386968    0.657706    0.159442    0.009587    0.649653     #> 203: -6.044318   0.180826    -5.858661   1.217956    2.062988    -1.579690   0.835442    2.387093    0.672605    0.162923    0.009638    0.648720     #> 204: -6.046978   0.181294    -5.894891   1.237035    2.059972    -1.579767   0.836940    2.386929    0.685689    0.160335    0.009125    0.649360     #> 205: -6.043055   0.182333    -5.884985   1.239171    2.058677    -1.579866   0.837564    2.386514    0.723288    0.160096    0.008652    0.648540     #> 206: -6.036032   0.181109    -5.852392   1.233912    2.057789    -1.579925   0.838107    2.386205    0.738081    0.162979    0.008352    0.648612     #> 207: -6.021484   0.174248    -5.818854   1.226714    2.058142    -1.579931   0.838259    2.386064    0.739126    0.167603    0.008222    0.649271     #> 208: -6.021153   0.178548    -5.781242   1.217706    2.058278    -1.579969   0.837869    2.385988    0.734650    0.170048    0.008390    0.648289     #> 209: -6.024589   0.179765    -5.779787   1.212574    2.058043    -1.580034   0.837517    2.385894    0.726853    0.174663    0.008344    0.647845     #> 210: -6.030079   0.175771    -5.780179   1.204973    2.058852    -1.580046   0.837288    2.385857    0.734415    0.176820    0.008288    0.648433     #> 211: -6.040055   0.177450    -5.794317   1.198500    2.057909    -1.580059   0.837219    2.385841    0.739096    0.178775    0.008551    0.648061     #> 212: -6.035596   0.178451    -5.827752   1.192430    2.057509    -1.580042   0.837034    2.385903    0.734221    0.178636    0.008799    0.648304     #> 213: -6.029890   0.179485    -5.830050   1.203492    2.056636    -1.580063   0.836721    2.385927    0.726448    0.178199    0.008916    0.648118     #> 214: -6.033296   0.179384    -5.832462   1.208809    2.055636    -1.580080   0.836647    2.386086    0.737925    0.175812    0.009218    0.648277     #> 215: -6.030611   0.179355    -5.827819   1.207980    2.054422    -1.580124   0.837061    2.386209    0.735468    0.173543    0.009301    0.648179     #> 216: -6.035382   0.179111    -5.815675   1.207442    2.053668    -1.580101   0.836748    2.386266    0.731987    0.174308    0.009478    0.647885     #> 217: -6.035829   0.176307    -5.811447   1.208206    2.053912    -1.580079   0.836504    2.386225    0.735263    0.176265    0.009634    0.647785     #> 218: -6.038716   0.175212    -5.803094   1.206385    2.053257    -1.580077   0.836465    2.386161    0.733623    0.176340    0.009662    0.647668     #> 219: -6.041517   0.175288    -5.801713   1.201899    2.052986    -1.580071   0.836203    2.386120    0.742767    0.174339    0.009691    0.647549     #> 220: -6.043059   0.176269    -5.796338   1.200782    2.052814    -1.580064   0.835774    2.386176    0.746294    0.174218    0.009577    0.647663     #> 221: -6.036313   0.173807    -5.789282   1.197929    2.052883    -1.580060   0.835830    2.386210    0.747214    0.173470    0.009509    0.647661     #> 222: -6.032821   0.173200    -5.789147   1.197023    2.053001    -1.580068   0.836058    2.386252    0.748097    0.173701    0.009505    0.647812     #> 223: -6.036244   0.174542    -5.792903   1.198885    2.051814    -1.580075   0.836298    2.386294    0.747196    0.173818    0.009628    0.647757     #> 224: -6.041139   0.175180    -5.793230   1.200699    2.050583    -1.580088   0.836439    2.386350    0.749775    0.173900    0.009679    0.648171     #> 225: -6.043020   0.175228    -5.791977   1.202539    2.049128    -1.580091   0.836605    2.386423    0.746513    0.172858    0.009645    0.648319     #> 226: -6.046010   0.176542    -5.800956   1.206747    2.049049    -1.580100   0.836478    2.386463    0.740736    0.172758    0.009670    0.648484     #> 227: -6.047372   0.177541    -5.797073   1.208294    2.048999    -1.580110   0.836630    2.386540    0.735427    0.173241    0.009569    0.648499     #> 228: -6.046613   0.179333    -5.790336   1.209323    2.048665    -1.580151   0.836746    2.386574    0.734800    0.173869    0.009545    0.648611     #> 229: -6.044694   0.178995    -5.787903   1.204573    2.048612    -1.580161   0.836807    2.386575    0.737819    0.173179    0.009451    0.648555     #> 230: -6.042447   0.179510    -5.784850   1.201315    2.048126    -1.580167   0.836830    2.386646    0.737473    0.172945    0.009373    0.648470     #> 231: -6.039397   0.178523    -5.791924   1.197328    2.047892    -1.580168   0.837007    2.386696    0.733809    0.172560    0.009365    0.648534     #> 232: -6.036427   0.178179    -5.789821   1.196629    2.048126    -1.580190   0.837114    2.386712    0.731822    0.172685    0.009345    0.648553     #> 233: -6.033091   0.177061    -5.799356   1.194444    2.048561    -1.580205   0.837205    2.386745    0.731844    0.173215    0.009316    0.648459     #> 234: -6.031825   0.177946    -5.802713   1.196768    2.049599    -1.580209   0.837133    2.386682    0.729929    0.173644    0.009350    0.648295     #> 235: -6.034125   0.178225    -5.803463   1.196937    2.050089    -1.580215   0.837158    2.386677    0.738386    0.173230    0.009321    0.648398     #> 236: -6.033578   0.178278    -5.803268   1.197542    2.050695    -1.580205   0.836972    2.386695    0.740681    0.173695    0.009310    0.648269     #> 237: -6.031523   0.177823    -5.807296   1.197821    2.051536    -1.580196   0.836803    2.386713    0.738362    0.174924    0.009297    0.648264     #> 238: -6.032938   0.178312    -5.804907   1.199093    2.052565    -1.580187   0.836730    2.386708    0.741566    0.174679    0.009273    0.648278     #> 239: -6.036625   0.178590    -5.802814   1.200676    2.053060    -1.580198   0.836685    2.386695    0.748088    0.174349    0.009254    0.648200     #> 240: -6.038614   0.178476    -5.805921   1.199476    2.052806    -1.580209   0.836699    2.386687    0.751567    0.173535    0.009186    0.648094     #> 241: -6.039377   0.179273    -5.802644   1.201012    2.053554    -1.580221   0.836574    2.386679    0.755957    0.173417    0.009161    0.648230     #> 242: -6.038992   0.178773    -5.800146   1.200837    2.053305    -1.580236   0.836671    2.386614    0.756825    0.173937    0.009164    0.648202     #> 243: -6.037900   0.177973    -5.805214   1.201441    2.053442    -1.580241   0.836707    2.386597    0.750510    0.174491    0.009193    0.648137     #> 244: -6.040853   0.178040    -5.806775   1.200190    2.053385    -1.580238   0.836878    2.386595    0.752354    0.174600    0.009297    0.648071     #> 245: -6.041440   0.177158    -5.807770   1.198658    2.053476    -1.580236   0.836873    2.386585    0.755209    0.174053    0.009363    0.648010     #> 246: -6.040935   0.176217    -5.809667   1.193594    2.053928    -1.580223   0.836785    2.386542    0.756366    0.173823    0.009379    0.648088     #> 247: -6.042686   0.176416    -5.814321   1.193132    2.054173    -1.580211   0.836709    2.386513    0.759862    0.173311    0.009408    0.648109     #> 248: -6.043405   0.176550    -5.819465   1.192699    2.054664    -1.580192   0.836713    2.386501    0.765463    0.172159    0.009460    0.648017     #> 249: -6.043893   0.177021    -5.824353   1.192617    2.055544    -1.580199   0.836803    2.386499    0.763867    0.171985    0.009560    0.648053     #> 250: -6.044945   0.177262    -5.819880   1.194029    2.056006    -1.580193   0.836721    2.386489    0.765597    0.171627    0.009683    0.647954     #> 251: -6.047887   0.177378    -5.820870   1.195264    2.056631    -1.580186   0.836656    2.386486    0.771218    0.171941    0.009698    0.648057     #> 252: -6.048612   0.177427    -5.823707   1.194988    2.057101    -1.580191   0.836783    2.386541    0.772344    0.172590    0.009635    0.647889     #> 253: -6.049066   0.177827    -5.825395   1.194089    2.057479    -1.580196   0.837006    2.386538    0.774513    0.172940    0.009634    0.647771     #> 254: -6.049048   0.178839    -5.826311   1.193668    2.057369    -1.580210   0.836932    2.386556    0.774409    0.173425    0.009584    0.647762     #> 255: -6.048001   0.179124    -5.827309   1.192610    2.057279    -1.580221   0.836922    2.386566    0.771649    0.174069    0.009614    0.647635     #> 256: -6.047107   0.178913    -5.826684   1.193528    2.057428    -1.580223   0.836962    2.386578    0.771121    0.174244    0.009592    0.647521     #> 257: -6.048364   0.179067    -5.832659   1.192514    2.057655    -1.580227   0.836982    2.386577    0.769778    0.174925    0.009565    0.647441     #> 258: -6.049405   0.178953    -5.836710   1.192253    2.057754    -1.580233   0.837061    2.386589    0.770680    0.174636    0.009540    0.647455     #> 259: -6.050180   0.179745    -5.836728   1.191039    2.057760    -1.580242   0.837214    2.386570    0.772053    0.174236    0.009477    0.647323     #> 260: -6.049428   0.179666    -5.835383   1.191068    2.057765    -1.580256   0.837334    2.386555    0.770341    0.174152    0.009441    0.647381     #> 261: -6.051605   0.179912    -5.836785   1.190800    2.057749    -1.580263   0.837337    2.386565    0.771234    0.174262    0.009441    0.647680     #> 262: -6.052710   0.180040    -5.837382   1.191502    2.057984    -1.580270   0.837338    2.386585    0.774370    0.174398    0.009459    0.647753     #> 263: -6.053974   0.180336    -5.837455   1.190250    2.057962    -1.580278   0.837275    2.386585    0.774144    0.175086    0.009458    0.647630     #> 264: -6.054064   0.180412    -5.837370   1.189923    2.057767    -1.580283   0.837224    2.386604    0.772050    0.175621    0.009481    0.647624     #> 265: -6.053364   0.180051    -5.838664   1.189542    2.057349    -1.580276   0.837090    2.386607    0.771275    0.175555    0.009413    0.647627     #> 266: -6.053209   0.179397    -5.839791   1.189392    2.057116    -1.580270   0.837089    2.386608    0.770433    0.174799    0.009360    0.647701     #> 267: -6.051532   0.178090    -5.842313   1.189751    2.056841    -1.580266   0.837161    2.386618    0.767936    0.174527    0.009323    0.647705     #> 268: -6.050828   0.177429    -5.840276   1.189344    2.056821    -1.580268   0.837191    2.386622    0.767327    0.174388    0.009331    0.647681     #> 269: -6.049406   0.177114    -5.837303   1.188262    2.056895    -1.580266   0.837178    2.386643    0.764614    0.174535    0.009306    0.647585     #> 270: -6.049433   0.177187    -5.830595   1.188201    2.056686    -1.580265   0.837200    2.386646    0.764728    0.174772    0.009310    0.647612     #> 271: -6.049443   0.177363    -5.831428   1.188125    2.056419    -1.580271   0.837225    2.386656    0.765160    0.174783    0.009325    0.647655     #> 272: -6.051996   0.178100    -5.830547   1.188394    2.056143    -1.580272   0.837242    2.386657    0.766096    0.174963    0.009286    0.647686     #> 273: -6.053571   0.178575    -5.832195   1.188197    2.056127    -1.580269   0.837184    2.386657    0.767302    0.175488    0.009238    0.647795     #> 274: -6.056184   0.179485    -5.835056   1.188628    2.055770    -1.580266   0.837159    2.386661    0.768545    0.176191    0.009206    0.647853     #> 275: -6.057057   0.179438    -5.834413   1.188943    2.055673    -1.580272   0.837111    2.386649    0.768505    0.176338    0.009184    0.647834     #> 276: -6.057962   0.178982    -5.833021   1.190094    2.055464    -1.580269   0.837097    2.386646    0.768050    0.176209    0.009204    0.647776     #> 277: -6.058703   0.178756    -5.833162   1.189989    2.055481    -1.580268   0.837103    2.386654    0.766992    0.176468    0.009223    0.647724     #> 278: -6.059102   0.178395    -5.834376   1.190078    2.055408    -1.580267   0.837177    2.386656    0.764714    0.177226    0.009204    0.647745     #> 279: -6.057286   0.177536    -5.833635   1.190416    2.055383    -1.580268   0.837201    2.386671    0.763163    0.177514    0.009195    0.647823     #> 280: -6.057668   0.177602    -5.832522   1.191050    2.055035    -1.580268   0.837163    2.386690    0.762942    0.177939    0.009196    0.648017     #> 281: -6.057448   0.177591    -5.831519   1.191456    2.054938    -1.580265   0.837136    2.386702    0.763840    0.178164    0.009177    0.647994     #> 282: -6.057426   0.177837    -5.829458   1.192467    2.054967    -1.580265   0.837145    2.386697    0.766685    0.177837    0.009146    0.648047     #> 283: -6.057274   0.177812    -5.828143   1.193473    2.055194    -1.580266   0.837172    2.386704    0.766852    0.177680    0.009163    0.648082     #> 284: -6.056543   0.177530    -5.828204   1.193807    2.055465    -1.580265   0.837165    2.386715    0.766715    0.177692    0.009141    0.648147     #> 285: -6.057796   0.177368    -5.827359   1.194291    2.055632    -1.580263   0.837151    2.386712    0.767489    0.177905    0.009125    0.648220     #> 286: -6.056816   0.176908    -5.827372   1.194164    2.055920    -1.580265   0.837189    2.386715    0.767285    0.178143    0.009144    0.648354     #> 287: -6.056175   0.176334    -5.827578   1.194194    2.056145    -1.580267   0.837262    2.386719    0.766393    0.178137    0.009158    0.648389     #> 288: -6.056441   0.176516    -5.828566   1.193477    2.056228    -1.580270   0.837354    2.386718    0.764927    0.178744    0.009165    0.648437     #> 289: -6.058400   0.176810    -5.828672   1.193913    2.056237    -1.580272   0.837374    2.386716    0.764114    0.178813    0.009161    0.648486     #> 290: -6.060409   0.177255    -5.827538   1.194646    2.056333    -1.580274   0.837377    2.386716    0.764562    0.179031    0.009147    0.648570     #> 291: -6.060679   0.177193    -5.825811   1.194235    2.056358    -1.580276   0.837342    2.386721    0.764426    0.179092    0.009117    0.648646     #> 292: -6.060304   0.176963    -5.825061   1.194517    2.056542    -1.580276   0.837317    2.386719    0.764202    0.179245    0.009085    0.648572     #> 293: -6.059629   0.176429    -5.825661   1.194346    2.056700    -1.580278   0.837306    2.386719    0.764391    0.178857    0.009066    0.648610     #> 294: -6.059987   0.176295    -5.824778   1.194817    2.056676    -1.580279   0.837332    2.386726    0.765443    0.178739    0.009074    0.648613     #> 295: -6.061109   0.176425    -5.826245   1.195581    2.056675    -1.580278   0.837325    2.386732    0.766450    0.178804    0.009101    0.648772     #> 296: -6.062310   0.176179    -5.827352   1.196032    2.056804    -1.580278   0.837293    2.386740    0.767684    0.179088    0.009115    0.648824     #> 297: -6.063260   0.176214    -5.828144   1.195971    2.056936    -1.580276   0.837302    2.386736    0.767862    0.179344    0.009153    0.648854     #> 298: -6.063789   0.176357    -5.827673   1.196394    2.056891    -1.580278   0.837327    2.386728    0.768145    0.179817    0.009125    0.648987     #> 299: -6.064205   0.176159    -5.827665   1.196184    2.057022    -1.580280   0.837328    2.386725    0.767278    0.180212    0.009118    0.648982     #> 300: -6.063257   0.175864    -5.827706   1.195928    2.057239    -1.580281   0.837306    2.386723    0.767917    0.179755    0.009094    0.649096     #> 301: -6.063963   0.175417    -5.827506   1.196154    2.057201    -1.580281   0.837273    2.386713    0.769572    0.179628    0.009082    0.649142     #> 302: -6.064292   0.174989    -5.827463   1.195917    2.057216    -1.580282   0.837255    2.386715    0.771041    0.179851    0.009086    0.649162     #> 303: -6.065281   0.175079    -5.827874   1.195542    2.057290    -1.580282   0.837222    2.386715    0.772002    0.180495    0.009080    0.649111     #> 304: -6.066031   0.175445    -5.827980   1.194970    2.057348    -1.580283   0.837203    2.386710    0.771087    0.180828    0.009083    0.649185     #> 305: -6.066728   0.175550    -5.828371   1.195149    2.057141    -1.580282   0.837195    2.386715    0.769650    0.181103    0.009084    0.649273     #> 306: -6.066555   0.175765    -5.827260   1.195322    2.057172    -1.580285   0.837174    2.386718    0.769288    0.180810    0.009086    0.649373     #> 307: -6.066312   0.175838    -5.826478   1.195334    2.057111    -1.580284   0.837147    2.386726    0.770957    0.180264    0.009081    0.649494     #> 308: -6.067659   0.175986    -5.826741   1.195422    2.057049    -1.580283   0.837118    2.386728    0.771725    0.180197    0.009100    0.649578     #> 309: -6.068875   0.175607    -5.826290   1.195720    2.057057    -1.580284   0.837104    2.386727    0.772746    0.180148    0.009082    0.649652     #> 310: -6.069327   0.175429    -5.827419   1.195983    2.056916    -1.580283   0.837124    2.386724    0.773253    0.180170    0.009061    0.649749     #> 311: -6.071000   0.175214    -5.827659   1.196453    2.056900    -1.580282   0.837119    2.386724    0.774159    0.180513    0.009085    0.649809     #> 312: -6.074942   0.175568    -5.827848   1.196635    2.056893    -1.580280   0.837108    2.386723    0.777990    0.180673    0.009087    0.649991     #> 313: -6.077020   0.175466    -5.828379   1.196787    2.056811    -1.580276   0.837090    2.386721    0.782056    0.180356    0.009095    0.650238     #> 314: -6.077813   0.175686    -5.828444   1.196532    2.056751    -1.580276   0.837074    2.386725    0.783074    0.180264    0.009099    0.650399     #> 315: -6.078419   0.175724    -5.828864   1.196629    2.056473    -1.580277   0.837054    2.386720    0.781925    0.180084    0.009100    0.650539     #> 316: -6.078243   0.175286    -5.829453   1.196758    2.056541    -1.580276   0.837034    2.386720    0.781681    0.180067    0.009101    0.650599     #> 317: -6.077354   0.175082    -5.829594   1.196830    2.056561    -1.580276   0.837005    2.386718    0.781178    0.179934    0.009086    0.650763     #> 318: -6.078394   0.175126    -5.830734   1.197140    2.056532    -1.580276   0.836999    2.386719    0.782015    0.180161    0.009091    0.650991     #> 319: -6.078994   0.174825    -5.830709   1.197440    2.056751    -1.580278   0.836994    2.386718    0.783338    0.180342    0.009091    0.651111     #> 320: -6.078722   0.174449    -5.831040   1.197470    2.057027    -1.580279   0.836994    2.386720    0.782489    0.180331    0.009092    0.651213     #> 321: -6.079064   0.174437    -5.831676   1.197376    2.057171    -1.580279   0.836982    2.386720    0.782364    0.180845    0.009078    0.651353     #> 322: -6.080840   0.174540    -5.832640   1.197239    2.057164    -1.580278   0.836955    2.386721    0.785828    0.180890    0.009069    0.651475     #> 323: -6.081529   0.174380    -5.834011   1.196861    2.057252    -1.580279   0.836944    2.386720    0.788400    0.181074    0.009091    0.651630     #> 324: -6.081900   0.174392    -5.835389   1.196590    2.057373    -1.580280   0.836936    2.386716    0.789000    0.181314    0.009124    0.651712     #> 325: -6.082667   0.174088    -5.837475   1.196511    2.057462    -1.580281   0.836939    2.386715    0.790673    0.181340    0.009155    0.651787     #> 326: -6.083294   0.173871    -5.839127   1.196273    2.057714    -1.580282   0.836930    2.386713    0.791467    0.181211    0.009158    0.651891     #> 327: -6.084230   0.173938    -5.840173   1.195935    2.057873    -1.580284   0.836915    2.386713    0.792885    0.181126    0.009170    0.652037     #> 328: -6.084604   0.173845    -5.841502   1.195788    2.058130    -1.580285   0.836916    2.386712    0.793185    0.180720    0.009160    0.652217     #> 329: -6.085434   0.173819    -5.842126   1.195706    2.058175    -1.580286   0.836887    2.386712    0.794439    0.180548    0.009158    0.652371     #> 330: -6.086003   0.173672    -5.843371   1.195737    2.058235    -1.580287   0.836868    2.386708    0.795014    0.180510    0.009145    0.652514     #> 331: -6.086434   0.173781    -5.844106   1.195800    2.058287    -1.580288   0.836866    2.386704    0.795323    0.180489    0.009137    0.652618     #> 332: -6.086570   0.173309    -5.845219   1.196107    2.058212    -1.580290   0.836867    2.386703    0.795779    0.180370    0.009129    0.652714     #> 333: -6.087548   0.173305    -5.846386   1.196440    2.058193    -1.580291   0.836874    2.386701    0.795284    0.180352    0.009159    0.652782     #> 334: -6.088154   0.173063    -5.846765   1.196665    2.058296    -1.580291   0.836872    2.386699    0.794973    0.180655    0.009190    0.652891     #> 335: -6.088465   0.173118    -5.847050   1.196799    2.058661    -1.580291   0.836871    2.386697    0.795671    0.180681    0.009238    0.653021     #> 336: -6.088392   0.173090    -5.847709   1.196950    2.058844    -1.580292   0.836866    2.386695    0.794775    0.180643    0.009277    0.653192     #> 337: -6.089316   0.173286    -5.848658   1.196894    2.059079    -1.580293   0.836848    2.386694    0.793864    0.180809    0.009286    0.653409     #> 338: -6.090231   0.173594    -5.849502   1.196900    2.059419    -1.580292   0.836838    2.386694    0.794475    0.181080    0.009305    0.653552     #> 339: -6.090790   0.173772    -5.850307   1.196937    2.059704    -1.580293   0.836845    2.386694    0.793953    0.181163    0.009341    0.653762     #> 340: -6.091524   0.173708    -5.850852   1.197127    2.059737    -1.580292   0.836852    2.386695    0.795821    0.181104    0.009352    0.653986     #> 341: -6.093583   0.173634    -5.852101   1.197156    2.059691    -1.580293   0.836857    2.386695    0.801092    0.180756    0.009367    0.654131     #> 342: -6.095329   0.173581    -5.853323   1.197093    2.059677    -1.580293   0.836861    2.386697    0.805043    0.180648    0.009363    0.654359     #> 343: -6.096139   0.173497    -5.854044   1.197042    2.059594    -1.580293   0.836868    2.386699    0.806763    0.180475    0.009353    0.654567     #> 344: -6.097481   0.173515    -5.854938   1.196970    2.059392    -1.580293   0.836874    2.386698    0.808511    0.180374    0.009357    0.654756     #> 345: -6.098826   0.173461    -5.855573   1.197049    2.059177    -1.580293   0.836870    2.386697    0.810282    0.180272    0.009352    0.654916     #> 346: -6.099580   0.173645    -5.856468   1.197044    2.059152    -1.580293   0.836864    2.386698    0.812035    0.180058    0.009350    0.655130     #> 347: -6.100172   0.173749    -5.857303   1.196936    2.059309    -1.580293   0.836859    2.386697    0.813129    0.180190    0.009351    0.655346     #> 348: -6.100944   0.173606    -5.857872   1.196896    2.059371    -1.580294   0.836859    2.386696    0.816074    0.180351    0.009333    0.655551     #> 349: -6.101458   0.173568    -5.858367   1.196887    2.059371    -1.580294   0.836846    2.386696    0.816761    0.180302    0.009337    0.655757     #> 350: -6.102804   0.173572    -5.859193   1.196853    2.059304    -1.580294   0.836836    2.386695    0.818264    0.180365    0.009348    0.656007     #> 351: -6.104791   0.173801    -5.859258   1.196882    2.059309    -1.580294   0.836820    2.386695    0.822139    0.180277    0.009375    0.656187     #> 352: -6.106087   0.174053    -5.859334   1.196883    2.059223    -1.580294   0.836820    2.386696    0.822448    0.180278    0.009364    0.656362     #> 353: -6.106770   0.173900    -5.859721   1.196853    2.059240    -1.580294   0.836825    2.386698    0.821934    0.180446    0.009381    0.656548     #> 354: -6.107426   0.173984    -5.860248   1.196877    2.059368    -1.580294   0.836828    2.386699    0.821918    0.180865    0.009381    0.656733     #> 355: -6.108138   0.174113    -5.860629   1.196969    2.059441    -1.580295   0.836831    2.386698    0.823038    0.180795    0.009395    0.656959     #> 356: -6.108404   0.174174    -5.861406   1.197054    2.059530    -1.580294   0.836836    2.386697    0.822943    0.180596    0.009404    0.657120     #> 357: -6.108877   0.174093    -5.861779   1.197079    2.059590    -1.580294   0.836834    2.386698    0.823159    0.180446    0.009408    0.657302     #> 358: -6.108763   0.173932    -5.862791   1.196975    2.059704    -1.580294   0.836834    2.386698    0.823043    0.180195    0.009393    0.657505     #> 359: -6.108732   0.173967    -5.863424   1.197018    2.059771    -1.580295   0.836840    2.386698    0.823419    0.180162    0.009391    0.657751     #> 360: -6.109942   0.174047    -5.863960   1.197041    2.059871    -1.580295   0.836846    2.386698    0.824655    0.180121    0.009382    0.657998     #> 361: -6.111187   0.174529    -5.864635   1.196936    2.059896    -1.580294   0.836850    2.386698    0.825532    0.180048    0.009371    0.658219     #> 362: -6.112350   0.174840    -5.865256   1.196929    2.059929    -1.580294   0.836857    2.386697    0.827003    0.179934    0.009360    0.658434     #> 363: -6.114102   0.175022    -5.865708   1.196969    2.059881    -1.580294   0.836854    2.386698    0.828675    0.179605    0.009355    0.658633     #> 364: -6.114782   0.175159    -5.866213   1.196941    2.059826    -1.580294   0.836856    2.386699    0.828047    0.179563    0.009366    0.658791     #> 365: -6.115472   0.175249    -5.867194   1.197043    2.059777    -1.580294   0.836856    2.386700    0.827486    0.179740    0.009374    0.659018     #> 366: -6.116723   0.175305    -5.868093   1.197034    2.059806    -1.580294   0.836864    2.386700    0.827939    0.179718    0.009381    0.659287     #> 367: -6.118015   0.175355    -5.868623   1.196983    2.059828    -1.580294   0.836869    2.386699    0.828761    0.179685    0.009384    0.659532     #> 368: -6.119776   0.175627    -5.869040   1.196933    2.059834    -1.580294   0.836866    2.386700    0.830846    0.179849    0.009369    0.659779     #> 369: -6.121534   0.176057    -5.869051   1.196896    2.059831    -1.580293   0.836863    2.386700    0.832659    0.179995    0.009351    0.659987     #> 370: -6.122019   0.175997    -5.869564   1.196877    2.059989    -1.580293   0.836864    2.386700    0.832322    0.180110    0.009350    0.660181     #> 371: -6.122684   0.175957    -5.869990   1.196850    2.060024    -1.580294   0.836862    2.386700    0.832180    0.180233    0.009342    0.660412     #> 372: -6.123321   0.175811    -5.870265   1.196823    2.060100    -1.580293   0.836863    2.386699    0.832969    0.180303    0.009341    0.660702     #> 373: -6.125075   0.176070    -5.870562   1.196833    2.060072    -1.580293   0.836867    2.386699    0.836367    0.180286    0.009353    0.660910     #> 374: -6.126267   0.176255    -5.871124   1.196805    2.060173    -1.580293   0.836866    2.386699    0.839078    0.180160    0.009364    0.661131     #> 375: -6.127959   0.176680    -5.871373   1.196842    2.060157    -1.580293   0.836870    2.386698    0.841202    0.180125    0.009383    0.661356     #> 376: -6.129673   0.177089    -5.872011   1.196822    2.060142    -1.580293   0.836870    2.386697    0.842788    0.180090    0.009401    0.661564     #> 377: -6.131429   0.177355    -5.872411   1.196874    2.060121    -1.580293   0.836872    2.386697    0.845215    0.179833    0.009408    0.661743     #> 378: -6.132754   0.177368    -5.872805   1.196915    2.060110    -1.580293   0.836870    2.386696    0.846563    0.179758    0.009451    0.661912     #> 379: -6.133762   0.177410    -5.873260   1.196992    2.060206    -1.580293   0.836868    2.386696    0.848371    0.179577    0.009466    0.662095     #> 380: -6.134338   0.177342    -5.873345   1.197032    2.060309    -1.580293   0.836865    2.386696    0.850785    0.179277    0.009467    0.662290     #> 381: -6.135501   0.177564    -5.873448   1.196968    2.060399    -1.580293   0.836859    2.386695    0.853946    0.179073    0.009462    0.662489     #> 382: -6.136397   0.177847    -5.873716   1.196910    2.060423    -1.580293   0.836857    2.386694    0.855726    0.179073    0.009471    0.662719     #> 383: -6.137161   0.177858    -5.874207   1.196919    2.060457    -1.580293   0.836857    2.386693    0.858043    0.179168    0.009472    0.662931     #> 384: -6.137219   0.177761    -5.874653   1.196958    2.060603    -1.580292   0.836857    2.386693    0.858753    0.179163    0.009476    0.663153     #> 385: -6.138451   0.178104    -5.874775   1.196967    2.060686    -1.580293   0.836855    2.386693    0.859541    0.179169    0.009463    0.663399     #> 386: -6.139182   0.177998    -5.875010   1.196973    2.060818    -1.580292   0.836852    2.386694    0.859719    0.179125    0.009460    0.663630     #> 387: -6.139428   0.178177    -5.875211   1.196938    2.060923    -1.580292   0.836852    2.386694    0.859764    0.179052    0.009453    0.663859     #> 388: -6.139561   0.178218    -5.875550   1.196970    2.060993    -1.580292   0.836850    2.386694    0.860798    0.178854    0.009470    0.664097     #> 389: -6.140247   0.178272    -5.876004   1.197022    2.061058    -1.580293   0.836851    2.386693    0.862558    0.178709    0.009462    0.664348     #> 390: -6.140819   0.178336    -5.876475   1.197081    2.061152    -1.580293   0.836851    2.386693    0.863234    0.178583    0.009475    0.664577     #> 391: -6.142423   0.178440    -5.876900   1.197080    2.061289    -1.580293   0.836850    2.386693    0.865048    0.178452    0.009505    0.664795     #> 392: -6.143787   0.178602    -5.877018   1.197081    2.061398    -1.580293   0.836850    2.386692    0.866582    0.178507    0.009511    0.665024     #> 393: -6.144871   0.178722    -5.877099   1.197104    2.061459    -1.580293   0.836849    2.386692    0.868765    0.178422    0.009520    0.665251     #> 394: -6.144994   0.178652    -5.877345   1.197072    2.061425    -1.580293   0.836847    2.386692    0.868791    0.178364    0.009533    0.665504     #> 395: -6.145551   0.178788    -5.877386   1.197057    2.061347    -1.580293   0.836845    2.386692    0.868717    0.178285    0.009544    0.665774     #> 396: -6.146122   0.178946    -5.877413   1.197063    2.061320    -1.580293   0.836848    2.386692    0.869142    0.178089    0.009546    0.666037     #> 397: -6.145799   0.179001    -5.877612   1.197070    2.061295    -1.580293   0.836850    2.386692    0.868917    0.177956    0.009551    0.666323     #> 398: -6.145435   0.178883    -5.877766   1.197048    2.061314    -1.580292   0.836850    2.386692    0.868514    0.177910    0.009539    0.666586     #> 399: -6.145462   0.178975    -5.877899   1.197007    2.061444    -1.580293   0.836851    2.386693    0.868424    0.177735    0.009539    0.666833     #> 400: -6.145058   0.179045    -5.877900   1.196988    2.061540    -1.580292   0.836848    2.386692    0.868677    0.177788    0.009542    0.667075     #> 401: -6.145929   0.179370    -5.877934   1.196991    2.061566    -1.580292   0.836848    2.386692    0.870083    0.177713    0.009543    0.667305     #> 402: -6.146705   0.179472    -5.878118   1.197008    2.061634    -1.580292   0.836847    2.386692    0.870916    0.177513    0.009546    0.667512     #> 403: -6.147052   0.179507    -5.878108   1.196991    2.061536    -1.580292   0.836848    2.386692    0.871450    0.177380    0.009542    0.667749     #> 404: -6.147439   0.179502    -5.878152   1.196961    2.061486    -1.580292   0.836849    2.386692    0.870963    0.177192    0.009540    0.668005     #> 405: -6.148872   0.179571    -5.878141   1.196958    2.061559    -1.580292   0.836849    2.386692    0.872419    0.176999    0.009533    0.668235     #> 406: -6.149616   0.179602    -5.878109   1.196963    2.061706    -1.580292   0.836849    2.386692    0.873656    0.176962    0.009529    0.668445     #> 407: -6.150745   0.179548    -5.878181   1.197021    2.061733    -1.580291   0.836848    2.386692    0.875736    0.177017    0.009511    0.668696     #> 408: -6.152057   0.179614    -5.878206   1.197060    2.061787    -1.580291   0.836847    2.386692    0.876787    0.177122    0.009493    0.668959     #> 409: -6.152907   0.179679    -5.878269   1.197066    2.061828    -1.580291   0.836847    2.386692    0.877639    0.177037    0.009510    0.669191     #> 410: -6.153211   0.179743    -5.878329   1.197069    2.061731    -1.580291   0.836847    2.386693    0.877610    0.176870    0.009518    0.669482     #> 411: -6.154053   0.179854    -5.878413   1.197053    2.061627    -1.580291   0.836845    2.386693    0.877629    0.176622    0.009508    0.669717     #> 412: -6.154495   0.179887    -5.878600   1.197058    2.061530    -1.580291   0.836845    2.386693    0.877304    0.176533    0.009495    0.669959     #> 413: -6.155504   0.180021    -5.878722   1.197081    2.061466    -1.580291   0.836844    2.386693    0.878849    0.176532    0.009507    0.670183     #> 414: -6.156257   0.180234    -5.878737   1.197091    2.061474    -1.580291   0.836845    2.386693    0.880300    0.176613    0.009525    0.670395     #> 415: -6.157630   0.180359    -5.878791   1.197106    2.061513    -1.580291   0.836845    2.386692    0.881421    0.176836    0.009533    0.670575     #> 416: -6.158151   0.180682    -5.878840   1.197115    2.061490    -1.580291   0.836846    2.386692    0.881584    0.177025    0.009531    0.670785     #> 417: -6.159223   0.180914    -5.878827   1.197114    2.061459    -1.580291   0.836847    2.386693    0.881917    0.176890    0.009543    0.671019     #> 418: -6.160714   0.181202    -5.879019   1.197139    2.061475    -1.580291   0.836846    2.386693    0.883315    0.177017    0.009521    0.671212     #> 419: -6.162107   0.181335    -5.879189   1.197155    2.061568    -1.580291   0.836846    2.386693    0.884814    0.176974    0.009514    0.671446     #> 420: -6.163023   0.181595    -5.879221   1.197141    2.061631    -1.580291   0.836846    2.386693    0.885840    0.176835    0.009501    0.671652     #> 421: -6.163378   0.181839    -5.879217   1.197128    2.061777    -1.580291   0.836847    2.386693    0.885780    0.176739    0.009503    0.671901     #> 422: -6.163771   0.182005    -5.879175   1.197152    2.061916    -1.580291   0.836847    2.386693    0.885581    0.176690    0.009504    0.672121     #> 423: -6.164718   0.182121    -5.879384   1.197165    2.061966    -1.580291   0.836848    2.386692    0.886795    0.176612    0.009506    0.672339     #> 424: -6.164925   0.181878    -5.879565   1.197185    2.061924    -1.580291   0.836850    2.386693    0.887431    0.176430    0.009510    0.672570     #> 425: -6.165348   0.181904    -5.879662   1.197232    2.061947    -1.580291   0.836850    2.386693    0.888161    0.176160    0.009502    0.672801     #> 426: -6.165820   0.182066    -5.879694   1.197257    2.061949    -1.580291   0.836851    2.386693    0.888357    0.176192    0.009488    0.673030     #> 427: -6.166490   0.182272    -5.879682   1.197287    2.062022    -1.580291   0.836849    2.386692    0.888447    0.176075    0.009485    0.673340     #> 428: -6.167066   0.182693    -5.879685   1.197295    2.062091    -1.580291   0.836847    2.386692    0.889431    0.175840    0.009487    0.673586     #> 429: -6.167569   0.182839    -5.879752   1.197279    2.062132    -1.580291   0.836846    2.386692    0.889514    0.175718    0.009492    0.673774     #> 430: -6.168188   0.182904    -5.879848   1.197276    2.062090    -1.580291   0.836847    2.386692    0.889279    0.175665    0.009502    0.673962     #> 431: -6.169256   0.183025    -5.879826   1.197262    2.062136    -1.580291   0.836847    2.386692    0.889977    0.175652    0.009508    0.674146     #> 432: -6.169799   0.183043    -5.879832   1.197251    2.062179    -1.580291   0.836848    2.386692    0.890746    0.175726    0.009519    0.674342     #> 433: -6.171019   0.183080    -5.879886   1.197253    2.062111    -1.580291   0.836847    2.386692    0.892795    0.175585    0.009525    0.674527     #> 434: -6.171730   0.182909    -5.880017   1.197256    2.062039    -1.580291   0.836847    2.386692    0.894755    0.175482    0.009526    0.674720     #> 435: -6.172819   0.182984    -5.879975   1.197276    2.062015    -1.580291   0.836848    2.386692    0.896099    0.175325    0.009517    0.674922     #> 436: -6.173393   0.183071    -5.880058   1.197257    2.062058    -1.580291   0.836847    2.386692    0.896909    0.175101    0.009517    0.675102     #> 437: -6.174209   0.183222    -5.880144   1.197266    2.062064    -1.580291   0.836847    2.386692    0.897442    0.174937    0.009530    0.675302     #> 438: -6.175162   0.183554    -5.880142   1.197250    2.062152    -1.580291   0.836847    2.386692    0.898984    0.174830    0.009532    0.675500     #> 439: -6.175614   0.183697    -5.880175   1.197256    2.062320    -1.580291   0.836846    2.386692    0.898876    0.174789    0.009551    0.675659     #> 440: -6.176162   0.184060    -5.880090   1.197247    2.062343    -1.580291   0.836846    2.386693    0.899166    0.174724    0.009562    0.675842     #> 441: -6.176646   0.184162    -5.880063   1.197232    2.062358    -1.580291   0.836846    2.386693    0.898976    0.174798    0.009565    0.676046     #> 442: -6.177091   0.184350    -5.880082   1.197219    2.062396    -1.580291   0.836846    2.386693    0.898716    0.174735    0.009560    0.676243     #> 443: -6.177304   0.184469    -5.880130   1.197223    2.062376    -1.580291   0.836846    2.386693    0.898474    0.174740    0.009544    0.676433     #> 444: -6.177979   0.184653    -5.880119   1.197244    2.062441    -1.580291   0.836846    2.386693    0.899919    0.174669    0.009524    0.676598     #> 445: -6.179327   0.184709    -5.880164   1.197258    2.062410    -1.580291   0.836845    2.386693    0.901296    0.174705    0.009513    0.676764     #> 446: -6.180538   0.184884    -5.880229   1.197261    2.062440    -1.580291   0.836845    2.386693    0.902108    0.174730    0.009505    0.676955     #> 447: -6.181524   0.185152    -5.880232   1.197242    2.062434    -1.580291   0.836846    2.386693    0.902555    0.174573    0.009507    0.677146     #> 448: -6.181977   0.185336    -5.880225   1.197245    2.062467    -1.580291   0.836846    2.386693    0.903022    0.174478    0.009499    0.677310     #> 449: -6.182526   0.185462    -5.880183   1.197244    2.062539    -1.580291   0.836846    2.386693    0.904547    0.174330    0.009505    0.677510     #> 450: -6.182784   0.185534    -5.880244   1.197254    2.062657    -1.580291   0.836846    2.386693    0.904591    0.174204    0.009517    0.677681     #> 451: -6.182754   0.185583    -5.880271   1.197261    2.062817    -1.580291   0.836847    2.386693    0.904089    0.174101    0.009532    0.677868     #> 452: -6.183551   0.185804    -5.880360   1.197260    2.062911    -1.580291   0.836847    2.386693    0.903807    0.174118    0.009544    0.678058     #> 453: -6.184528   0.186019    -5.880356   1.197251    2.062976    -1.580291   0.836847    2.386693    0.904310    0.174051    0.009537    0.678243     #> 454: -6.185329   0.186176    -5.880404   1.197271    2.063050    -1.580291   0.836847    2.386693    0.903861    0.174140    0.009526    0.678400     #> 455: -6.186111   0.186385    -5.880416   1.197267    2.063051    -1.580291   0.836847    2.386693    0.904025    0.174133    0.009511    0.678582     #> 456: -6.186933   0.186661    -5.880432   1.197261    2.063071    -1.580291   0.836847    2.386693    0.904163    0.174035    0.009504    0.678751     #> 457: -6.187594   0.186814    -5.880443   1.197264    2.063124    -1.580291   0.836847    2.386693    0.904756    0.174213    0.009499    0.678916     #> 458: -6.187833   0.186925    -5.880423   1.197271    2.063245    -1.580291   0.836848    2.386693    0.905474    0.174193    0.009489    0.679067     #> 459: -6.188186   0.187009    -5.880417   1.197279    2.063305    -1.580291   0.836848    2.386693    0.906362    0.174159    0.009473    0.679239     #> 460: -6.188835   0.187154    -5.880444   1.197274    2.063328    -1.580291   0.836848    2.386693    0.906750    0.174187    0.009461    0.679387     #> 461: -6.188948   0.187371    -5.880464   1.197265    2.063374    -1.580291   0.836850    2.386693    0.906941    0.174048    0.009462    0.679561     #> 462: -6.189564   0.187509    -5.880440   1.197270    2.063329    -1.580291   0.836849    2.386693    0.907676    0.173916    0.009469    0.679725     #> 463: -6.190448   0.187587    -5.880441   1.197271    2.063329    -1.580291   0.836850    2.386693    0.908502    0.173872    0.009466    0.679868     #> 464: -6.191483   0.187701    -5.880423   1.197266    2.063374    -1.580291   0.836850    2.386693    0.910099    0.173762    0.009477    0.680031     #> 465: -6.191756   0.187716    -5.880443   1.197268    2.063375    -1.580291   0.836850    2.386693    0.910741    0.173583    0.009484    0.680203     #> 466: -6.192128   0.187945    -5.880462   1.197272    2.063466    -1.580291   0.836851    2.386693    0.910617    0.173468    0.009496    0.680363     #> 467: -6.191922   0.187986    -5.880462   1.197265    2.063485    -1.580291   0.836850    2.386694    0.911220    0.173283    0.009502    0.680564     #> 468: -6.192252   0.188121    -5.880465   1.197268    2.063575    -1.580291   0.836851    2.386693    0.912097    0.173186    0.009509    0.680744     #> 469: -6.192807   0.188083    -5.880455   1.197263    2.063700    -1.580291   0.836851    2.386693    0.913243    0.172981    0.009521    0.680925     #> 470: -6.193546   0.188353    -5.880434   1.197273    2.063757    -1.580291   0.836851    2.386693    0.914142    0.172986    0.009528    0.681071     #> 471: -6.194452   0.188554    -5.880468   1.197277    2.063826    -1.580291   0.836851    2.386693    0.914835    0.172966    0.009525    0.681231     #> 472: -6.194954   0.188785    -5.880463   1.197277    2.063924    -1.580291   0.836850    2.386693    0.915274    0.172895    0.009533    0.681370     #> 473: -6.195435   0.188911    -5.880493   1.197276    2.063962    -1.580291   0.836851    2.386693    0.915866    0.172796    0.009543    0.681511     #> 474: -6.195670   0.189023    -5.880503   1.197272    2.063964    -1.580291   0.836851    2.386693    0.916550    0.172677    0.009551    0.681684     #> 475: -6.195548   0.189017    -5.880527   1.197284    2.064029    -1.580291   0.836851    2.386693    0.916422    0.172827    0.009558    0.681829     #> 476: -6.195939   0.189132    -5.880514   1.197285    2.064093    -1.580291   0.836851    2.386693    0.916113    0.173001    0.009559    0.681970     #> 477: -6.196285   0.189300    -5.880506   1.197286    2.064137    -1.580291   0.836851    2.386693    0.916195    0.173037    0.009554    0.682134     #> 478: -6.196794   0.189424    -5.880502   1.197295    2.064253    -1.580291   0.836851    2.386693    0.916532    0.173020    0.009558    0.682283     #> 479: -6.197305   0.189458    -5.880503   1.197302    2.064222    -1.580291   0.836851    2.386693    0.916986    0.172824    0.009552    0.682427     #> 480: -6.197515   0.189553    -5.880513   1.197302    2.064361    -1.580291   0.836852    2.386693    0.917864    0.172647    0.009570    0.682563     #> 481: -6.197319   0.189526    -5.880549   1.197303    2.064397    -1.580291   0.836852    2.386693    0.917497    0.172473    0.009572    0.682717     #> 482: -6.197479   0.189246    -5.880568   1.197303    2.064415    -1.580291   0.836851    2.386693    0.917853    0.172456    0.009571    0.682878     #> 483: -6.198094   0.189202    -5.880576   1.197300    2.064436    -1.580291   0.836851    2.386693    0.918094    0.172321    0.009579    0.683033     #> 484: -6.198382   0.189400    -5.880546   1.197304    2.064482    -1.580291   0.836851    2.386693    0.918337    0.172155    0.009588    0.683176     #> 485: -6.199007   0.189562    -5.880550   1.197308    2.064467    -1.580291   0.836852    2.386693    0.918739    0.172011    0.009588    0.683330     #> 486: -6.199466   0.189584    -5.880568   1.197314    2.064401    -1.580291   0.836852    2.386693    0.918423    0.171895    0.009587    0.683461     #> 487: -6.200135   0.189629    -5.880574   1.197317    2.064334    -1.580291   0.836852    2.386693    0.918636    0.171781    0.009595    0.683593     #> 488: -6.200577   0.189829    -5.880561   1.197316    2.064251    -1.580291   0.836852    2.386693    0.919075    0.171611    0.009605    0.683714     #> 489: -6.201068   0.190060    -5.880585   1.197313    2.064314    -1.580291   0.836852    2.386693    0.920265    0.171515    0.009605    0.683839     #> 490: -6.201465   0.190254    -5.880614   1.197319    2.064358    -1.580291   0.836852    2.386693    0.920794    0.171382    0.009615    0.683986     #> 491: -6.202337   0.190338    -5.880630   1.197318    2.064367    -1.580291   0.836852    2.386693    0.922308    0.171253    0.009623    0.684113     #> 492: -6.202564   0.190382    -5.880622   1.197314    2.064366    -1.580291   0.836852    2.386693    0.921999    0.171198    0.009645    0.684249     #> 493: -6.203172   0.190543    -5.880638   1.197317    2.064325    -1.580291   0.836853    2.386693    0.922254    0.171084    0.009656    0.684387     #> 494: -6.203512   0.190569    -5.880659   1.197320    2.064366    -1.580291   0.836853    2.386693    0.922135    0.171025    0.009664    0.684514     #> 495: -6.204128   0.190650    -5.880655   1.197325    2.064434    -1.580291   0.836853    2.386693    0.923104    0.171044    0.009664    0.684658     #> 496: -6.204598   0.190819    -5.880648   1.197317    2.064495    -1.580291   0.836853    2.386693    0.923249    0.171073    0.009657    0.684797     #> 497: -6.204884   0.190909    -5.880661   1.197316    2.064589    -1.580291   0.836853    2.386693    0.923414    0.171080    0.009651    0.684930     #> 498: -6.205137   0.190943    -5.880657   1.197310    2.064630    -1.580291   0.836853    2.386693    0.923029    0.170945    0.009653    0.685066     #> 499: -6.205292   0.191066    -5.880633   1.197302    2.064681    -1.580291   0.836853    2.386693    0.922783    0.170733    0.009649    0.685234     #> 500: -6.205790   0.191033    -5.880628   1.197297    2.064696    -1.580291   0.836853    2.386693    0.923242    0.170624    0.009641    0.685365     #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/nimo.html","id":"goodness-of-fit-plots","dir":"Articles","previous_headings":"","what":"Goodness of fit Plots","title":"Nimotuzumab","text":"","code":"## Add cwres/npde after fit fit  <- fit %>% addCwres() %>% addNpde() #> [====|====|====|====|====|====|====|====|====|====] 0:00:02  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:04  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:01  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:01  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  plot(fit) ## Standard nlmixr plots ################################################################################ ## Xpose plots; Need to print otherwise running a script won't ## show xpose plots ################################################################################ xpdb <- xpose_data_nlmixr(fit) ## first convert to nlmixr object #>        ID           TIME              AMT         RATE         DV          #>  1      : 28   Min.   :   0.48   Min.   :0   Min.   :0   Min.   :-0.2319   #>  5      : 28   1st Qu.: 169.02   1st Qu.:0   1st Qu.:0   1st Qu.: 3.2848   #>  7      : 28   Median : 837.80   Median :0   Median :0   Median : 4.0197   #>  8      : 28   Mean   : 837.85   Mean   :0   Mean   :0   Mean   : 4.2188   #>  2      : 27   3rd Qu.:1344.69   3rd Qu.:0   3rd Qu.:0   3rd Qu.: 5.3016   #>  3      : 27   Max.   :2252.34   Max.   :0   Max.   :0   Max.   : 8.0973   #>  (Other):155                                                               #>       TAD              OCC              MDV         EVID        WGT        #>  Min.   :  0.00   Min.   : 1.000   Min.   :0   Min.   :0   Min.   :53.00   #>  1st Qu.:  0.60   1st Qu.: 2.000   1st Qu.:0   1st Qu.:0   1st Qu.:59.00   #>  Median : 96.31   Median : 5.000   Median :0   Median :0   Median :65.00   #>  Mean   :114.27   Mean   : 5.321   Mean   :0   Mean   :0   Mean   :65.03   #>  3rd Qu.:168.14   3rd Qu.: 9.000   3rd Qu.:0   3rd Qu.:0   3rd Qu.:71.00   #>  Max.   :623.03   Max.   :10.000   Max.   :0   Max.   :0   Max.   :75.00   #>                                                                            #>       BSA             AGE             HGT             DOS        #>  Min.   :1.500   Min.   :34.00   Min.   :145.0   Min.   : 50.0   #>  1st Qu.:1.560   1st Qu.:42.00   1st Qu.:153.0   1st Qu.: 50.0   #>  Median :1.600   Median :45.00   Median :157.0   Median :200.0   #>  Mean   :1.637   Mean   :49.55   Mean   :155.4   Mean   :186.9   #>  3rd Qu.:1.730   3rd Qu.:59.00   3rd Qu.:160.0   3rd Qu.:200.0   #>  Max.   :1.800   Max.   :64.00   Max.   :162.0   Max.   :400.0   #>                                                                  #>       PRED            RES               IPRED             IRES          #>  Min.   :1.575   Min.   :-3.78853   Min.   :0.7366   Min.   :-2.48821   #>  1st Qu.:3.540   1st Qu.:-0.60308   1st Qu.:3.2714   1st Qu.:-0.42777   #>  Median :4.294   Median : 0.03732   Median :4.2834   Median : 0.02403   #>  Mean   :4.295   Mean   :-0.07623   Mean   :4.2366   Mean   :-0.01783   #>  3rd Qu.:5.213   3rd Qu.: 0.50777   3rd Qu.:5.0927   3rd Qu.: 0.43955   #>  Max.   :6.345   Max.   : 1.79710   Max.   :6.7995   Max.   : 1.90157   #>                                                                         #>      IWRES              ETA.CL             ETA.V1             ETA.KSS          #>  Min.   :-3.63049   Min.   :-0.94578   Min.   :-0.579774   Min.   :-0.038563   #>  1st Qu.:-0.62415   1st Qu.:-0.79105   1st Qu.:-0.097603   1st Qu.:-0.021951   #>  Median : 0.03506   Median :-0.43457   Median :-0.088156   Median : 0.013319   #>  Mean   :-0.02601   Mean   :-0.09681   Mean   : 0.004423   Mean   : 0.004266   #>  3rd Qu.: 0.64134   3rd Qu.: 0.31317   3rd Qu.: 0.250051   3rd Qu.: 0.033573   #>  Max.   : 2.77454   Max.   : 1.89999   Max.   : 0.742166   Max.   : 0.045985   #>                                                                                #>   IPRED.STATE        CENTRAL          PERIPHERAL             EFF         #>  Min.   :0.7366   Min.   :  2.379   Min.   :   0.0067   Min.   :0.2665   #>  1st Qu.:3.2714   1st Qu.: 38.849   1st Qu.:  33.4444   1st Qu.:0.8485   #>  Median :4.2834   Median : 99.459   Median :  81.8242   Median :1.3100   #>  Mean   :4.2366   Mean   :151.189   Mean   : 188.7635   Mean   :1.8337   #>  3rd Qu.:5.0927   3rd Qu.:192.029   3rd Qu.: 249.4742   3rd Qu.:2.5040   #>  Max.   :6.7995   Max.   :673.295   Max.   :1234.1818   Max.   :7.5016   #>                                                                          #>        CL                  V1               Q                  V2        #>  Min.   :0.0007836   Min.   :0.6779   Min.   :0.002793   Min.   :3.311   #>  1st Qu.:0.0009148   1st Qu.:1.0979   1st Qu.:0.002793   1st Qu.:3.311   #>  Median :0.0013066   Median :1.1084   Median :0.002793   Median :3.311   #>  Mean   :0.0027877   Mean   :1.2969   Mean   :0.002793   Mean   :3.311   #>  3rd Qu.:0.0027597   3rd Qu.:1.5544   3rd Qu.:0.002793   3rd Qu.:3.311   #>  Max.   :0.0134900   Max.   :2.5426   Max.   :0.002793   Max.   :3.311   #>                                                                          #>       KSS             KINT             KSYN            KDEG       #>  Min.   :7.585   Min.   :0.2059   Min.   :2.309   Min.   :10.88   #>  1st Qu.:7.712   1st Qu.:0.2059   1st Qu.:2.309   1st Qu.:10.88   #>  Median :7.989   Median :0.2059   Median :2.309   Median :10.88   #>  Mean   :7.920   Mean   :0.2059   Mean   :2.309   Mean   :10.88   #>  3rd Qu.:8.152   3rd Qu.:0.2059   3rd Qu.:2.309   3rd Qu.:10.88   #>  Max.   :8.254   Max.   :0.2059   Max.   :2.309   Max.   :10.88   #>                                                                   #>        K                  K12                K21                 CONC         #>  Min.   :0.0006286   Min.   :0.001098   Min.   :0.0008435   Min.   :  2.089   #>  1st Qu.:0.0007936   1st Qu.:0.001797   1st Qu.:0.0008435   1st Qu.: 26.349   #>  Median :0.0010572   Median :0.002520   Median :0.0008435   Median : 72.488   #>  Mean   :0.0023268   Mean   :0.002443   Mean   :0.0008435   Mean   :139.822   #>  3rd Qu.:0.0017525   3rd Qu.:0.002544   3rd Qu.:0.0008435   3rd Qu.:162.824   #>  Max.   :0.0121571   Max.   :0.004120   Max.   :0.0008435   Max.   :897.433   #>                                                                               #>     DOSENUM            WRES              CPRED            CRES          #>  Min.   : 1.000   Min.   :-4.71598   Min.   :1.621   Min.   :-5.42969   #>  1st Qu.: 2.000   1st Qu.:-0.74609   1st Qu.:3.633   1st Qu.:-0.71569   #>  Median : 5.000   Median : 0.04229   Median :4.456   Median :-0.05629   #>  Mean   : 5.321   Mean   :-0.09183   Mean   :4.400   Mean   :-0.18118   #>  3rd Qu.: 9.000   3rd Qu.: 0.64245   3rd Qu.:5.330   3rd Qu.: 0.46526   #>  Max.   :10.000   Max.   : 2.27240   Max.   :6.362   Max.   : 1.77846   #>                                                                         #>      CWRES             EPRED            ERES               NPDE          #>  Min.   :-3.5241   Min.   :1.324   Min.   :-3.63859   Min.   :-2.93520   #>  1st Qu.:-0.8241   1st Qu.:3.339   1st Qu.:-0.48221   1st Qu.:-0.58284   #>  Median :-0.0728   Median :4.067   Median : 0.19066   Median : 0.09204   #>  Mean   :-0.1187   Mean   :4.168   Mean   : 0.05068   Mean   : 0.04898   #>  3rd Qu.: 0.5917   3rd Qu.:5.022   3rd Qu.: 0.64555   3rd Qu.: 0.70630   #>  Max.   : 2.2907   Max.   :6.296   Max.   : 1.88685   Max.   : 2.93520   #>                                                                          #>       NPD               eta.cl             eta.v1             eta.kss          #>  Min.   :-2.93520   Min.   :-0.94578   Min.   :-0.579774   Min.   :-0.038563   #>  1st Qu.:-0.58284   1st Qu.:-0.79105   1st Qu.:-0.097603   1st Qu.:-0.021951   #>  Median : 0.09204   Median :-0.43457   Median :-0.088156   Median : 0.013319   #>  Mean   : 0.04898   Mean   :-0.09681   Mean   : 0.004423   Mean   : 0.004266   #>  3rd Qu.: 0.70630   3rd Qu.: 0.31317   3rd Qu.: 0.250051   3rd Qu.: 0.033573   #>  Max.   : 2.93520   Max.   : 1.89999   Max.   : 0.742166   Max.   : 0.045985   #>   print(dv_vs_pred(xpdb) +       ylab(\"Observed Nimotuzumab Concentrations (ug/mL)\") +       xlab(\"Population Predicted Nimotuzumab Concentrations (ug/mL)\")) print(dv_vs_ipred(xpdb) +       ylab(\"Observed Nimotuzumab Concentrations (ug/mL)\") +       xlab(\"Individual Predicted Nimotuzumab Concentrations (ug/mL)\")) print(res_vs_pred(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Population Predicted Nimotuzumab Concentrations (ug/mL)\")) print(res_vs_idv(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Time (h)\")) print(prm_vs_iteration(xpdb)) print(absval_res_vs_idv(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_pred(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Population Predicted Nimotuzumab Concentrations (ug/mL)\")) print(ind_plots(xpdb, nrow=3, ncol=4) +       ylab(\"Predicted and Observed Nimotuzumab concentrations (ug/mL)\") +       xlab(\"Time (h)\")) print(res_distrib(xpdb) +      ylab(\"Density\") +      xlab(\"Conditional Weighted Residuals\")) ################################################################################ ##Visual Predictive Checks ################################################################################ vpcPlot(fit,n=500,stratify=c(\"DOS\"), show=list(obs_dv=T),        bins = c(-0.5,0,25,75,100,200,400,600,750,900,1100,1200,1400,1600,1900,2150,2300),        ylab = \"Nimotuzumab Concentrations (ug/mL)\", xlab = \"Time (h)\") vpcPlot(fit,n=500, show=list(obs_dv=T),        bins = c(-0.5,0,25,75,100,200,400,600,750,900,1100,1200,1400,1600,1900,2150,2300),        ylab = \"Nimotuzumab Concentrations (ug/mL)\", xlab = \"Time (h)\")"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"running-pk-models-with-nlmixr","dir":"Articles","previous_headings":"","what":"Running PK models with nlmixr","title":"Running PK models with nlmixr","text":"nlmixr uses unified interface specifying running models. Let’s start simple PK example, using single-dose theophylline dataset generously provided Dr. Robert . Upton University California, San Francisco:  can try fitting simple one-compartment PK model small dataset. write model follows: can now run model… can alternatively express model ordinary differential equations (ODEs): can try Stochastic Approximation EM (SAEM) method model: wanted , even apply traditional R method nlme method model: example delivers complete model fit fit object, including parameter history, set fixed effect estimates, random effects included subjects. Now back saem fit; Let’s look fit using nlmixr’s built-diagnostics…  Default trace plots can generated using:  little work, can get nicer set iteration trace plots (“wriggly worms”)…  … random-effects histograms…","code":"## Load libraries library(ggplot2) library(nlmixr2) str(theo_sd) #> 'data.frame':    144 obs. of  7 variables: #>  $ ID  : int  1 1 1 1 1 1 1 1 1 1 ... #>  $ TIME: num  0 0 0.25 0.57 1.12 2.02 3.82 5.1 7.03 9.05 ... #>  $ DV  : num  0 0.74 2.84 6.57 10.5 9.66 8.58 8.36 7.47 6.89 ... #>  $ AMT : num  320 0 0 0 0 ... #>  $ EVID: int  101 0 0 0 0 0 0 0 0 0 ... #>  $ CMT : int  1 2 2 2 2 2 2 2 2 2 ... #>  $ WT  : num  79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 79.6 ...  ggplot(theo_sd, aes(TIME, DV)) + geom_line(aes(group=ID), col=\"red\") +   scale_x_continuous(\"Time (h)\") + scale_y_continuous(\"Concentration\") +   labs(title=\"Theophylline single-dose\", subtitle=\"Concentration vs. time by individual\") one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  f <- nlmixr(one.cmt) fit <- nlmixr(one.cmt, theo_sd, est=\"saem\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> 001: 0.230468    0.967106    3.472284    0.570000    0.285000    0.095000    2.119404     #> 002: 0.365061    0.977768    3.529459    0.541500    0.270750    0.090250    1.335010     #> 003: 0.488244    0.914696    3.485558    0.514425    0.257212    0.085737    0.971244     #> 004: 0.438850    0.947190    3.483972    0.488704    0.244352    0.081451    0.843163     #> 005: 0.482898    0.950774    3.474136    0.464269    0.232134    0.077378    0.788258     #> 006: 0.491956    0.979240    3.471970    0.441055    0.220528    0.073509    0.717832     #> 007: 0.477660    1.002787    3.459961    0.426912    0.209501    0.069834    0.712079     #> 008: 0.439053    0.998458    3.458297    0.405567    0.199026    0.066342    0.714371     #> 009: 0.411363    0.977477    3.457951    0.385288    0.189075    0.063025    0.721845     #> 010: 0.410745    0.991449    3.447397    0.423738    0.179621    0.059874    0.709302     #> 011: 0.433425    1.017318    3.439573    0.402551    0.170640    0.056880    0.709544     #> 012: 0.436210    1.023334    3.439642    0.382424    0.162108    0.054036    0.696856     #> 013: 0.395511    1.040280    3.423171    0.363302    0.154003    0.051334    0.704853     #> 014: 0.406702    1.019553    3.438667    0.462663    0.146302    0.048767    0.702510     #> 015: 0.441774    1.021351    3.449479    0.439530    0.138987    0.046329    0.696202     #> 016: 0.455462    1.022198    3.452278    0.427200    0.132038    0.044013    0.711570     #> 017: 0.472252    0.998514    3.463348    0.432845    0.125436    0.041812    0.689144     #> 018: 0.471319    0.971010    3.454274    0.430114    0.119164    0.039721    0.707209     #> 019: 0.458576    1.005315    3.452192    0.421337    0.113206    0.037735    0.690100     #> 020: 0.468646    1.015931    3.449081    0.441522    0.107546    0.035849    0.701883     #> 021: 0.452466    1.006322    3.458239    0.419446    0.102168    0.034056    0.679647     #> 022: 0.438308    1.009664    3.460557    0.413391    0.097060    0.032353    0.679015     #> 023: 0.510514    1.001668    3.469531    0.432360    0.092207    0.030736    0.685036     #> 024: 0.488804    1.008133    3.469132    0.410742    0.087597    0.029199    0.678318     #> 025: 0.457257    1.004513    3.462259    0.390205    0.088964    0.027739    0.688890     #> 026: 0.418515    1.021308    3.442260    0.395086    0.084516    0.026352    0.689694     #> 027: 0.410099    1.042304    3.440233    0.375332    0.080290    0.025034    0.714666     #> 028: 0.467038    1.018129    3.447801    0.356565    0.076276    0.023783    0.674690     #> 029: 0.463736    1.019110    3.448272    0.351415    0.074236    0.022594    0.694448     #> 030: 0.482326    1.019097    3.448937    0.338589    0.074328    0.021464    0.703639     #> 031: 0.406919    1.008205    3.457994    0.321659    0.084870    0.020391    0.695163     #> 032: 0.427413    0.995468    3.467270    0.351586    0.080627    0.019371    0.698334     #> 033: 0.448557    1.001091    3.459605    0.381416    0.076595    0.018403    0.709970     #> 034: 0.483523    1.004791    3.458162    0.409641    0.072765    0.017482    0.696753     #> 035: 0.449963    1.000874    3.457562    0.389159    0.069127    0.016608    0.692048     #> 036: 0.452123    1.019246    3.449407    0.369701    0.069020    0.015778    0.698087     #> 037: 0.444334    1.020306    3.455621    0.367631    0.071301    0.019531    0.694994     #> 038: 0.502808    1.017756    3.446457    0.469930    0.077320    0.018554    0.703918     #> 039: 0.495188    0.981662    3.472586    0.446434    0.073454    0.023720    0.680990     #> 040: 0.477122    0.993009    3.476328    0.424112    0.069782    0.025984    0.684220     #> 041: 0.464630    0.989523    3.471589    0.402907    0.066293    0.024685    0.695821     #> 042: 0.472446    1.011679    3.460224    0.382761    0.074773    0.023451    0.678899     #> 043: 0.441071    1.027501    3.443336    0.363623    0.075549    0.022278    0.683510     #> 044: 0.439318    1.024450    3.445627    0.367552    0.071772    0.021164    0.696969     #> 045: 0.421270    1.044224    3.431280    0.393234    0.068183    0.020106    0.689607     #> 046: 0.413104    1.025536    3.439096    0.421594    0.077875    0.019101    0.692971     #> 047: 0.440146    1.032519    3.439820    0.426829    0.073982    0.018146    0.679106     #> 048: 0.460299    1.019704    3.445974    0.486263    0.072551    0.019575    0.688015     #> 049: 0.452257    1.010108    3.444878    0.461950    0.075216    0.018596    0.697326     #> 050: 0.485693    0.983792    3.444184    0.443890    0.082112    0.017755    0.709381     #> 051: 0.482704    1.003619    3.440220    0.461387    0.088997    0.018999    0.717668     #> 052: 0.520657    0.999435    3.461485    0.507427    0.084547    0.018049    0.691367     #> 053: 0.505186    1.009511    3.454679    0.498655    0.080320    0.017147    0.682522     #> 054: 0.472429    1.014735    3.455972    0.473722    0.076304    0.016289    0.696186     #> 055: 0.445610    1.010291    3.448186    0.450036    0.076995    0.015475    0.687510     #> 056: 0.455620    0.997197    3.450255    0.430994    0.073145    0.017978    0.698088     #> 057: 0.471675    0.996068    3.460098    0.409444    0.069488    0.017783    0.707231     #> 058: 0.511111    0.988364    3.459539    0.390597    0.068911    0.016894    0.695903     #> 059: 0.529860    0.960088    3.477509    0.440143    0.084812    0.016049    0.719638     #> 060: 0.525818    0.970568    3.478616    0.472130    0.080571    0.017227    0.739127     #> 061: 0.547614    0.986915    3.482793    0.498850    0.084561    0.017490    0.730382     #> 062: 0.495698    0.996072    3.481928    0.473908    0.087347    0.019653    0.723209     #> 063: 0.501003    0.984391    3.474964    0.450212    0.086770    0.021122    0.706695     #> 064: 0.498034    0.986271    3.471933    0.459443    0.085615    0.020066    0.707529     #> 065: 0.499875    0.987857    3.455804    0.484007    0.090231    0.019063    0.697022     #> 066: 0.485484    1.009395    3.470799    0.459807    0.096489    0.018110    0.682362     #> 067: 0.479913    0.986889    3.452552    0.436817    0.091665    0.017204    0.687019     #> 068: 0.426112    1.006950    3.454842    0.414976    0.087081    0.016344    0.716870     #> 069: 0.437249    1.007140    3.447936    0.410799    0.082727    0.015527    0.709888     #> 070: 0.452327    1.006997    3.460579    0.492851    0.078591    0.015588    0.714715     #> 071: 0.431163    1.030261    3.435885    0.468208    0.076970    0.018061    0.733692     #> 072: 0.455340    0.978733    3.455587    0.444798    0.074900    0.017158    0.701508     #> 073: 0.479673    1.010461    3.468721    0.422558    0.074940    0.016300    0.698294     #> 074: 0.479509    1.000638    3.459797    0.401430    0.071193    0.015485    0.679977     #> 075: 0.502097    0.981074    3.482020    0.424200    0.077789    0.018668    0.683477     #> 076: 0.524998    1.003146    3.490121    0.402990    0.073900    0.019163    0.698916     #> 077: 0.521620    0.968760    3.488303    0.411574    0.070205    0.019944    0.720650     #> 078: 0.510816    0.986501    3.484504    0.429301    0.075607    0.022080    0.691739     #> 079: 0.509684    0.994673    3.475462    0.434610    0.071826    0.025444    0.722487     #> 080: 0.522955    0.992803    3.479542    0.459337    0.068235    0.026462    0.710547     #> 081: 0.551904    0.999539    3.480434    0.436370    0.064823    0.027166    0.691172     #> 082: 0.536944    0.976360    3.488058    0.418047    0.061582    0.025808    0.700613     #> 083: 0.511034    0.991379    3.475734    0.426649    0.058503    0.024517    0.689374     #> 084: 0.483520    0.982246    3.467780    0.405317    0.063005    0.023291    0.689821     #> 085: 0.494338    1.002826    3.481592    0.385051    0.063062    0.022127    0.696735     #> 086: 0.473939    1.005779    3.466880    0.365798    0.073687    0.021021    0.684338     #> 087: 0.432317    1.017362    3.446387    0.347508    0.072717    0.019970    0.684591     #> 088: 0.357346    1.009554    3.444386    0.356469    0.073903    0.018971    0.710861     #> 089: 0.430732    1.012432    3.442183    0.341584    0.070532    0.018023    0.723051     #> 090: 0.398066    1.026840    3.429095    0.370334    0.067006    0.017121    0.717445     #> 091: 0.405676    1.030258    3.416560    0.403255    0.074206    0.018289    0.711024     #> 092: 0.464270    1.038816    3.440692    0.419839    0.092213    0.021406    0.707104     #> 093: 0.385266    1.021811    3.441752    0.398847    0.087602    0.020336    0.698292     #> 094: 0.414354    1.019108    3.437977    0.387077    0.097138    0.019319    0.713017     #> 095: 0.426120    1.044612    3.438804    0.460093    0.092281    0.018353    0.702559     #> 096: 0.413483    1.020727    3.435710    0.472540    0.087667    0.018294    0.697439     #> 097: 0.443871    1.027860    3.452246    0.448913    0.083284    0.018124    0.702690     #> 098: 0.476620    1.019392    3.461024    0.426467    0.079120    0.017218    0.701159     #> 099: 0.460455    0.985372    3.452619    0.458040    0.075164    0.016357    0.690280     #> 100: 0.432972    0.996458    3.452660    0.435138    0.071406    0.016317    0.688678     #> 101: 0.398026    1.010974    3.432077    0.413381    0.074715    0.016993    0.671984     #> 102: 0.415175    1.017551    3.428677    0.392712    0.070979    0.018549    0.699325     #> 103: 0.447148    1.016567    3.444587    0.400642    0.068879    0.019248    0.677229     #> 104: 0.430764    1.015488    3.449001    0.430624    0.065435    0.018285    0.706976     #> 105: 0.418686    0.993034    3.446091    0.409093    0.080780    0.017371    0.707939     #> 106: 0.473473    0.984588    3.455713    0.401773    0.081171    0.016502    0.699830     #> 107: 0.512811    1.005378    3.460356    0.446493    0.088515    0.015677    0.692082     #> 108: 0.479376    0.989320    3.459930    0.424169    0.084089    0.014893    0.713331     #> 109: 0.447957    0.999670    3.466966    0.402960    0.086634    0.016019    0.699059     #> 110: 0.474956    1.012387    3.450655    0.382812    0.082302    0.016690    0.705680     #> 111: 0.456322    1.006942    3.458667    0.363672    0.078951    0.015967    0.694188     #> 112: 0.469196    0.996208    3.448077    0.364906    0.076959    0.016943    0.697999     #> 113: 0.432741    1.042543    3.448420    0.370766    0.076820    0.016096    0.692496     #> 114: 0.421504    1.042248    3.446229    0.352228    0.095296    0.015291    0.681348     #> 115: 0.454553    1.015458    3.439877    0.346885    0.092033    0.016923    0.691933     #> 116: 0.453551    1.002740    3.447709    0.398423    0.087432    0.019009    0.694589     #> 117: 0.428389    1.038636    3.449094    0.385063    0.085904    0.018058    0.692295     #> 118: 0.448527    1.022390    3.448314    0.365810    0.084062    0.017155    0.693317     #> 119: 0.478259    1.005239    3.455774    0.399940    0.079859    0.021638    0.697952     #> 120: 0.447831    0.983665    3.465144    0.401221    0.075866    0.020556    0.687207     #> 121: 0.456399    1.013450    3.458710    0.381160    0.072073    0.019923    0.682918     #> 122: 0.461463    0.984002    3.449963    0.397833    0.068469    0.019679    0.684659     #> 123: 0.512784    1.019818    3.450736    0.428905    0.071507    0.019613    0.680721     #> 124: 0.490964    1.033232    3.449947    0.460297    0.067932    0.022492    0.687506     #> 125: 0.477445    1.029610    3.447912    0.437282    0.071437    0.021368    0.685470     #> 126: 0.432315    1.044595    3.435040    0.435173    0.078214    0.020299    0.689107     #> 127: 0.454453    1.039149    3.433706    0.413414    0.081738    0.019284    0.704229     #> 128: 0.410795    1.026715    3.440446    0.463744    0.077651    0.022883    0.715151     #> 129: 0.425000    1.035058    3.449435    0.498499    0.076211    0.021739    0.685180     #> 130: 0.526933    1.026353    3.456965    0.507860    0.074505    0.020652    0.669956     #> 131: 0.450757    1.017908    3.440112    0.482467    0.070938    0.019619    0.685656     #> 132: 0.429903    1.012243    3.428235    0.458344    0.073397    0.018638    0.714468     #> 133: 0.416524    1.008892    3.440107    0.435427    0.072617    0.017706    0.696093     #> 134: 0.449129    0.993571    3.460167    0.413655    0.074932    0.019697    0.702219     #> 135: 0.456197    0.999493    3.459888    0.392973    0.079587    0.019150    0.699326     #> 136: 0.483307    0.986631    3.465982    0.373324    0.075607    0.018238    0.693118     #> 137: 0.487840    0.994189    3.461497    0.378349    0.071827    0.017326    0.706732     #> 138: 0.469815    1.009396    3.457152    0.409749    0.068235    0.017255    0.694569     #> 139: 0.483826    1.013344    3.466656    0.490845    0.069676    0.021267    0.684721     #> 140: 0.490635    1.009787    3.470209    0.466303    0.069332    0.020204    0.704319     #> 141: 0.482557    0.982333    3.466333    0.442988    0.072691    0.021208    0.684403     #> 142: 0.475194    0.988805    3.464409    0.420839    0.074609    0.020148    0.690410     #> 143: 0.456921    1.014707    3.459251    0.418612    0.070878    0.020753    0.689970     #> 144: 0.488121    1.025842    3.457217    0.397682    0.067572    0.019716    0.672328     #> 145: 0.446276    1.030100    3.440286    0.407562    0.069310    0.019312    0.666905     #> 146: 0.425182    1.031176    3.451817    0.424670    0.066323    0.018869    0.680325     #> 147: 0.440620    1.012294    3.437879    0.403437    0.069522    0.017926    0.671808     #> 148: 0.402849    1.028302    3.451521    0.386286    0.066046    0.017562    0.678216     #> 149: 0.438023    1.013395    3.453749    0.370538    0.071534    0.019462    0.676195     #> 150: 0.446027    1.011472    3.440918    0.389034    0.069467    0.018489    0.689406     #> 151: 0.381619    1.035817    3.430785    0.369582    0.065993    0.018861    0.682931     #> 152: 0.409373    1.037692    3.436272    0.387809    0.073597    0.020492    0.678485     #> 153: 0.420822    1.024590    3.453221    0.395399    0.065072    0.022545    0.683923     #> 154: 0.476015    1.033954    3.459722    0.391008    0.073309    0.021631    0.682046     #> 155: 0.467844    1.012284    3.459682    0.449481    0.062729    0.024196    0.679664     #> 156: 0.488168    1.015093    3.463936    0.417569    0.077773    0.024419    0.704846     #> 157: 0.444864    1.007887    3.466910    0.349947    0.062152    0.025944    0.702978     #> 158: 0.459298    1.026103    3.454181    0.370084    0.058101    0.026140    0.686122     #> 159: 0.413319    1.024692    3.457701    0.363563    0.052330    0.023785    0.713010     #> 160: 0.484296    0.995007    3.473379    0.510596    0.062097    0.019279    0.709827     #> 161: 0.465992    0.989974    3.465053    0.374810    0.047457    0.023035    0.715279     #> 162: 0.405172    1.021056    3.451228    0.432429    0.051166    0.023270    0.707262     #> 163: 0.466775    1.004812    3.449372    0.472269    0.045830    0.021707    0.690476     #> 164: 0.452002    1.014910    3.454041    0.413032    0.046392    0.024268    0.689275     #> 165: 0.463775    1.021148    3.449767    0.395413    0.048254    0.021355    0.694189     #> 166: 0.471614    1.037494    3.460314    0.392830    0.043953    0.022644    0.701398     #> 167: 0.490737    1.033709    3.470984    0.318618    0.052763    0.025191    0.703989     #> 168: 0.464466    1.032230    3.464276    0.354964    0.057867    0.025292    0.698384     #> 169: 0.477937    1.050172    3.450105    0.329370    0.068703    0.019499    0.719401     #> 170: 0.464104    1.022714    3.452394    0.349544    0.052513    0.020716    0.720754     #> 171: 0.433308    1.025091    3.444597    0.338767    0.060523    0.021209    0.687912     #> 172: 0.448415    1.035131    3.449658    0.338344    0.063306    0.022296    0.681040     #> 173: 0.408655    1.032489    3.434183    0.315282    0.063539    0.028711    0.686192     #> 174: 0.440677    1.039608    3.450040    0.303819    0.054353    0.028223    0.693918     #> 175: 0.451265    1.033776    3.451864    0.330528    0.061174    0.027878    0.696315     #> 176: 0.429069    1.036383    3.464567    0.325198    0.060759    0.021092    0.691679     #> 177: 0.481460    1.024199    3.470977    0.408080    0.067727    0.025409    0.676567     #> 178: 0.458491    1.012677    3.459816    0.349308    0.074238    0.019512    0.667452     #> 179: 0.487849    1.023010    3.455910    0.373259    0.091711    0.016135    0.698753     #> 180: 0.442721    1.031666    3.461495    0.296137    0.077541    0.016287    0.710304     #> 181: 0.447153    1.015493    3.438008    0.332542    0.077727    0.017800    0.697853     #> 182: 0.413569    1.028028    3.436182    0.317714    0.086255    0.017076    0.703615     #> 183: 0.426136    1.036928    3.435038    0.363089    0.074402    0.017904    0.697732     #> 184: 0.436210    1.018567    3.439481    0.407825    0.075907    0.016598    0.684031     #> 185: 0.391244    1.032435    3.433154    0.370329    0.073471    0.018116    0.689369     #> 186: 0.389866    1.050023    3.434048    0.379029    0.071905    0.020053    0.689096     #> 187: 0.447114    1.015948    3.444971    0.407345    0.052055    0.021969    0.672518     #> 188: 0.432454    1.028754    3.447832    0.421504    0.065655    0.018457    0.681172     #> 189: 0.464011    1.026916    3.461449    0.419493    0.061956    0.020338    0.688364     #> 190: 0.458350    1.009449    3.470294    0.328394    0.063898    0.020134    0.689268     #> 191: 0.450376    1.032191    3.455409    0.368561    0.059642    0.019936    0.664576     #> 192: 0.437509    1.028584    3.452043    0.342407    0.068231    0.017259    0.680355     #> 193: 0.461342    1.029951    3.453265    0.338789    0.065837    0.019413    0.680283     #> 194: 0.406980    1.023905    3.438539    0.405257    0.063817    0.013722    0.694172     #> 195: 0.406065    1.027902    3.432038    0.401982    0.057171    0.013905    0.700394     #> 196: 0.413409    1.007829    3.443423    0.423902    0.079266    0.014485    0.693071     #> 197: 0.413398    1.019066    3.462620    0.363963    0.068321    0.017691    0.709439     #> 198: 0.483818    0.994331    3.459552    0.469487    0.077371    0.016624    0.685123     #> 199: 0.465578    0.988493    3.453070    0.460078    0.074678    0.016713    0.690418     #> 200: 0.443081    0.998880    3.450086    0.409772    0.079072    0.021458    0.719103     #> 201: 0.423203    0.996478    3.453265    0.390021    0.076282    0.021232    0.711977     #> 202: 0.418909    1.004909    3.449791    0.404674    0.074929    0.021174    0.715029     #> 203: 0.434592    1.004341    3.448718    0.413927    0.075159    0.021836    0.710656     #> 204: 0.440283    1.000787    3.449390    0.421578    0.073447    0.021621    0.709962     #> 205: 0.439210    1.007171    3.448398    0.420478    0.075876    0.021970    0.708410     #> 206: 0.442687    1.013659    3.447792    0.435644    0.075417    0.021853    0.707227     #> 207: 0.438994    1.015948    3.445521    0.436924    0.073494    0.021754    0.707019     #> 208: 0.438464    1.017547    3.445938    0.426909    0.071766    0.021829    0.704986     #> 209: 0.442277    1.016433    3.445376    0.428065    0.070794    0.021701    0.703121     #> 210: 0.446202    1.015341    3.446608    0.428390    0.069994    0.021567    0.701096     #> 211: 0.450883    1.016061    3.447826    0.429501    0.069682    0.021329    0.699402     #> 212: 0.455189    1.014887    3.448622    0.428541    0.069062    0.020891    0.700093     #> 213: 0.455715    1.011547    3.449715    0.424051    0.068988    0.020667    0.701594     #> 214: 0.461727    1.009979    3.451348    0.425415    0.069621    0.020518    0.701856     #> 215: 0.463352    1.009374    3.452956    0.422835    0.070053    0.020490    0.702389     #> 216: 0.468712    1.006977    3.454258    0.428081    0.070245    0.020410    0.703181     #> 217: 0.469854    1.007121    3.455437    0.429773    0.070306    0.020481    0.702822     #> 218: 0.471113    1.007403    3.455463    0.430813    0.070314    0.020399    0.703050     #> 219: 0.470254    1.006889    3.455085    0.430131    0.069941    0.020291    0.702700     #> 220: 0.467697    1.007090    3.454610    0.426322    0.069806    0.020298    0.702729     #> 221: 0.465600    1.007112    3.454437    0.421572    0.069569    0.020290    0.702637     #> 222: 0.465229    1.007293    3.454008    0.422555    0.069614    0.020270    0.702789     #> 223: 0.466522    1.007162    3.454305    0.423575    0.069493    0.020348    0.701909     #> 224: 0.468327    1.007545    3.454677    0.424714    0.069611    0.020407    0.701191     #> 225: 0.467926    1.006316    3.455055    0.423069    0.069686    0.020418    0.701180     #> 226: 0.469666    1.004998    3.455441    0.423478    0.069835    0.020476    0.700943     #> 227: 0.470265    1.004145    3.456000    0.422654    0.070233    0.020470    0.700925     #> 228: 0.469507    1.004697    3.455674    0.421133    0.069975    0.020529    0.700854     #> 229: 0.468432    1.005123    3.455245    0.421269    0.069815    0.020705    0.700657     #> 230: 0.468350    1.005259    3.454788    0.419970    0.069774    0.020922    0.700130     #> 231: 0.468715    1.005657    3.455000    0.417715    0.069461    0.021110    0.699636     #> 232: 0.467895    1.005646    3.455147    0.417504    0.069276    0.021100    0.699033     #> 233: 0.468091    1.004515    3.455520    0.418842    0.068968    0.021081    0.698978     #> 234: 0.468414    1.004059    3.455747    0.417526    0.068320    0.021216    0.699049     #> 235: 0.468279    1.003378    3.455701    0.416145    0.067871    0.021271    0.698996     #> 236: 0.468056    1.003618    3.455788    0.415053    0.067597    0.021313    0.698851     #> 237: 0.468578    1.003290    3.456152    0.415493    0.067660    0.021324    0.698944     #> 238: 0.468837    1.003732    3.456211    0.415772    0.067610    0.021301    0.699378     #> 239: 0.468318    1.004255    3.455979    0.415731    0.067635    0.021378    0.699480     #> 240: 0.468128    1.004077    3.456092    0.416280    0.067734    0.021425    0.699170     #> 241: 0.468702    1.003314    3.456248    0.417225    0.067912    0.021430    0.699206     #> 242: 0.469601    1.002846    3.456509    0.416662    0.068102    0.021410    0.699355     #> 243: 0.469451    1.003583    3.456317    0.415836    0.068506    0.021368    0.699120     #> 244: 0.468339    1.004052    3.456376    0.414159    0.068687    0.021195    0.699377     #> 245: 0.468406    1.003940    3.456639    0.412072    0.068690    0.021106    0.699916     #> 246: 0.468955    1.003908    3.456844    0.411468    0.068824    0.021094    0.699988     #> 247: 0.468502    1.003778    3.456984    0.411074    0.069011    0.021103    0.700008     #> 248: 0.467911    1.003908    3.456959    0.410532    0.069030    0.021079    0.700077     #> 249: 0.466548    1.004183    3.456736    0.408987    0.068888    0.021025    0.700220     #> 250: 0.467069    1.004675    3.456726    0.408811    0.068966    0.021066    0.700192     #> 251: 0.467479    1.004989    3.456989    0.409071    0.069236    0.021031    0.700294     #> 252: 0.468094    1.005212    3.457117    0.411447    0.069056    0.021074    0.700145     #> 253: 0.468135    1.005724    3.457140    0.412062    0.068890    0.021062    0.700423     #> 254: 0.467923    1.006293    3.457135    0.412588    0.068841    0.021035    0.700604     #> 255: 0.467450    1.006845    3.457149    0.411710    0.068943    0.021104    0.700551     #> 256: 0.467444    1.006782    3.457077    0.412169    0.069020    0.021118    0.700230     #> 257: 0.467283    1.006296    3.457030    0.412195    0.068842    0.021048    0.700111     #> 258: 0.466989    1.005917    3.457065    0.412607    0.068844    0.021044    0.699908     #> 259: 0.466852    1.005663    3.457034    0.412049    0.068849    0.021037    0.699964     #> 260: 0.466523    1.005985    3.457013    0.411661    0.068811    0.021076    0.699746     #> 261: 0.466517    1.006094    3.457073    0.410289    0.068872    0.021117    0.699644     #> 262: 0.466041    1.006503    3.456956    0.409674    0.069032    0.021079    0.699410     #> 263: 0.465630    1.006709    3.456891    0.408768    0.069019    0.021106    0.699518     #> 264: 0.465637    1.006970    3.456832    0.409037    0.069196    0.021059    0.699686     #> 265: 0.465900    1.006943    3.456892    0.409468    0.069551    0.021000    0.699845     #> 266: 0.466034    1.006727    3.456955    0.411085    0.069533    0.020972    0.699848     #> 267: 0.466335    1.006933    3.457030    0.413906    0.069598    0.020904    0.699931     #> 268: 0.466654    1.006848    3.457005    0.415354    0.069574    0.020845    0.699991     #> 269: 0.467321    1.006499    3.457094    0.415784    0.069598    0.020829    0.699962     #> 270: 0.467953    1.006632    3.457046    0.417063    0.069609    0.020777    0.699538     #> 271: 0.468489    1.006681    3.457081    0.417596    0.069485    0.020769    0.699252     #> 272: 0.468805    1.006384    3.457133    0.417482    0.069574    0.020738    0.699441     #> 273: 0.468523    1.006401    3.457071    0.416770    0.069846    0.020673    0.699313     #> 274: 0.468248    1.006872    3.457115    0.415303    0.070027    0.020610    0.699301     #> 275: 0.468334    1.006995    3.457096    0.414531    0.070192    0.020558    0.699104     #> 276: 0.467868    1.007209    3.457050    0.414569    0.070348    0.020488    0.699037     #> 277: 0.467449    1.007384    3.457157    0.413925    0.070373    0.020445    0.699334     #> 278: 0.467008    1.007307    3.457142    0.414500    0.070403    0.020383    0.699684     #> 279: 0.466840    1.007061    3.457140    0.415317    0.070361    0.020308    0.699984     #> 280: 0.466784    1.007132    3.457275    0.415399    0.070473    0.020259    0.699850     #> 281: 0.466963    1.007397    3.457345    0.416024    0.070559    0.020235    0.699742     #> 282: 0.467201    1.007533    3.457225    0.417427    0.070652    0.020165    0.699607     #> 283: 0.467021    1.007704    3.457211    0.418363    0.070628    0.020086    0.699915     #> 284: 0.466731    1.007754    3.457101    0.419370    0.070641    0.019997    0.699645     #> 285: 0.466369    1.008015    3.456936    0.419452    0.070675    0.019938    0.699438     #> 286: 0.466110    1.008239    3.456797    0.418878    0.070717    0.019857    0.699242     #> 287: 0.465751    1.008603    3.456624    0.418934    0.070858    0.019795    0.699186     #> 288: 0.465503    1.008703    3.456581    0.417926    0.070887    0.019780    0.699313     #> 289: 0.465273    1.008565    3.456532    0.416729    0.070856    0.019794    0.699357     #> 290: 0.465441    1.008619    3.456462    0.416346    0.070980    0.019805    0.699452     #> 291: 0.465211    1.009019    3.456423    0.416168    0.071135    0.019831    0.699290     #> 292: 0.464762    1.009258    3.456256    0.415460    0.071337    0.019812    0.699179     #> 293: 0.464536    1.009247    3.456064    0.414866    0.071317    0.019786    0.699208     #> 294: 0.463901    1.009460    3.455841    0.414386    0.071297    0.019769    0.699152     #> 295: 0.463543    1.009259    3.455720    0.414053    0.071331    0.019782    0.698957     #> 296: 0.463244    1.009353    3.455634    0.413318    0.071423    0.019804    0.698882     #> 297: 0.463208    1.009462    3.455585    0.413359    0.071432    0.019863    0.698779     #> 298: 0.463272    1.009320    3.455640    0.413102    0.071519    0.019837    0.698661     #> 299: 0.463402    1.009222    3.455661    0.413444    0.071587    0.019770    0.698596     #> 300: 0.463333    1.009146    3.455682    0.413584    0.071526    0.019726    0.698645     #> 301: 0.463429    1.009011    3.455607    0.413177    0.071549    0.019679    0.698806     #> 302: 0.463760    1.009180    3.455645    0.413021    0.071581    0.019673    0.698604     #> 303: 0.463969    1.009223    3.455706    0.412899    0.071626    0.019683    0.698373     #> 304: 0.464069    1.009334    3.455641    0.413735    0.071610    0.019693    0.698252     #> 305: 0.463998    1.009217    3.455634    0.414153    0.071652    0.019703    0.698203     #> 306: 0.463902    1.009139    3.455552    0.414002    0.071687    0.019713    0.698232     #> 307: 0.463711    1.009111    3.455445    0.413144    0.071823    0.019687    0.698384     #> 308: 0.463618    1.009110    3.455342    0.413419    0.071830    0.019654    0.698507     #> 309: 0.463411    1.009008    3.455283    0.413520    0.071863    0.019637    0.698660     #> 310: 0.463385    1.008976    3.455100    0.413579    0.071916    0.019595    0.698972     #> 311: 0.463196    1.008930    3.455073    0.413492    0.072059    0.019555    0.699045     #> 312: 0.462973    1.008896    3.454981    0.413925    0.072155    0.019523    0.699070     #> 313: 0.462546    1.008757    3.454840    0.413970    0.072121    0.019485    0.699223     #> 314: 0.462198    1.008660    3.454831    0.413951    0.072097    0.019490    0.699297     #> 315: 0.461983    1.008748    3.454761    0.413969    0.072070    0.019460    0.699154     #> 316: 0.461903    1.008996    3.454709    0.414369    0.072047    0.019427    0.699107     #> 317: 0.461820    1.009067    3.454735    0.413745    0.072071    0.019415    0.699088     #> 318: 0.461829    1.009206    3.454674    0.413212    0.072075    0.019384    0.699049     #> 319: 0.461681    1.009155    3.454690    0.412543    0.072124    0.019368    0.699209     #> 320: 0.461278    1.009126    3.454560    0.412432    0.072128    0.019336    0.699316     #> 321: 0.460786    1.009257    3.454408    0.412948    0.072047    0.019305    0.699245     #> 322: 0.460739    1.009340    3.454256    0.413439    0.072008    0.019285    0.699174     #> 323: 0.460579    1.009335    3.454205    0.413503    0.072064    0.019267    0.699023     #> 324: 0.460436    1.009565    3.454128    0.413920    0.072118    0.019266    0.698840     #> 325: 0.460287    1.009736    3.453977    0.414183    0.072158    0.019272    0.698685     #> 326: 0.460012    1.009796    3.453783    0.414198    0.072210    0.019273    0.698584     #> 327: 0.460226    1.009888    3.453684    0.414943    0.072173    0.019289    0.698501     #> 328: 0.460233    1.010086    3.453608    0.415510    0.072090    0.019295    0.698458     #> 329: 0.460541    1.010220    3.453618    0.415887    0.072095    0.019303    0.698406     #> 330: 0.460163    1.010297    3.453537    0.415861    0.072044    0.019299    0.698394     #> 331: 0.459958    1.010384    3.453533    0.415719    0.072096    0.019284    0.698249     #> 332: 0.460112    1.010496    3.453579    0.416361    0.072065    0.019259    0.698322     #> 333: 0.459983    1.010568    3.453440    0.417171    0.072132    0.019249    0.698275     #> 334: 0.459583    1.010537    3.453270    0.417432    0.072195    0.019251    0.698171     #> 335: 0.459388    1.010697    3.453082    0.418189    0.072202    0.019231    0.698061     #> 336: 0.458744    1.011070    3.452838    0.418504    0.072283    0.019247    0.698109     #> 337: 0.458395    1.011567    3.452584    0.419230    0.072480    0.019254    0.698167     #> 338: 0.458174    1.011776    3.452499    0.419672    0.072643    0.019283    0.698134     #> 339: 0.457895    1.011965    3.452380    0.420004    0.072641    0.019300    0.698087     #> 340: 0.457663    1.011928    3.452308    0.420197    0.072748    0.019329    0.697984     #> 341: 0.457671    1.011954    3.452259    0.420443    0.072823    0.019352    0.697975     #> 342: 0.457357    1.011899    3.452170    0.420008    0.072794    0.019354    0.698043     #> 343: 0.457096    1.011946    3.452070    0.419593    0.072830    0.019340    0.697923     #> 344: 0.456966    1.011914    3.452047    0.419510    0.072780    0.019336    0.697842     #> 345: 0.456796    1.011882    3.452042    0.419286    0.072661    0.019345    0.697841     #> 346: 0.456497    1.011998    3.451911    0.419085    0.072585    0.019327    0.697732     #> 347: 0.456294    1.012036    3.451770    0.419152    0.072611    0.019319    0.697728     #> 348: 0.455951    1.012214    3.451617    0.419330    0.072533    0.019307    0.697817     #> 349: 0.455756    1.012222    3.451572    0.419495    0.072489    0.019279    0.697805     #> 350: 0.455453    1.012204    3.451412    0.419678    0.072499    0.019261    0.697782     #> 351: 0.455220    1.012404    3.451242    0.419810    0.072531    0.019248    0.697831     #> 352: 0.454816    1.012539    3.451179    0.419849    0.072525    0.019257    0.698071     #> 353: 0.454939    1.012686    3.451173    0.419968    0.072561    0.019248    0.698125     #> 354: 0.454940    1.012650    3.451127    0.420153    0.072610    0.019220    0.698175     #> 355: 0.454957    1.012561    3.451076    0.420247    0.072645    0.019205    0.698098     #> 356: 0.454709    1.012423    3.451117    0.419778    0.072656    0.019210    0.698173     #> 357: 0.454795    1.012534    3.451147    0.419639    0.072683    0.019170    0.698207     #> 358: 0.454882    1.012612    3.451212    0.419479    0.072745    0.019144    0.698160     #> 359: 0.454764    1.012668    3.451203    0.419186    0.072799    0.019104    0.698126     #> 360: 0.454469    1.012697    3.451058    0.419194    0.072776    0.019067    0.698074     #> 361: 0.454263    1.012778    3.450980    0.418807    0.072737    0.019050    0.698006     #> 362: 0.454179    1.012839    3.450894    0.418632    0.072667    0.019034    0.697779     #> 363: 0.454129    1.012842    3.450828    0.418607    0.072610    0.019030    0.697537     #> 364: 0.454334    1.012871    3.450818    0.418889    0.072524    0.019055    0.697480     #> 365: 0.454097    1.012868    3.450832    0.419002    0.072440    0.019088    0.697494     #> 366: 0.453774    1.012950    3.450746    0.418459    0.072376    0.019097    0.697600     #> 367: 0.453714    1.012916    3.450764    0.418140    0.072393    0.019086    0.697613     #> 368: 0.453845    1.012908    3.450771    0.418118    0.072343    0.019076    0.697496     #> 369: 0.454005    1.012932    3.450726    0.418386    0.072309    0.019066    0.697528     #> 370: 0.453910    1.012986    3.450690    0.418119    0.072285    0.019086    0.697610     #> 371: 0.453739    1.013151    3.450563    0.417707    0.072298    0.019084    0.697523     #> 372: 0.453414    1.013398    3.450433    0.417384    0.072317    0.019076    0.697464     #> 373: 0.453061    1.013706    3.450297    0.417252    0.072295    0.019068    0.697441     #> 374: 0.452799    1.013784    3.450194    0.417078    0.072328    0.019055    0.697296     #> 375: 0.452481    1.013825    3.450164    0.416885    0.072307    0.019064    0.697266     #> 376: 0.452497    1.013985    3.450163    0.416669    0.072338    0.019069    0.697160     #> 377: 0.452533    1.014008    3.450202    0.416353    0.072358    0.019076    0.697091     #> 378: 0.452314    1.014002    3.450152    0.416411    0.072351    0.019065    0.697140     #> 379: 0.452090    1.013893    3.450085    0.416646    0.072357    0.019035    0.697077     #> 380: 0.451987    1.013863    3.450044    0.416621    0.072400    0.019011    0.697012     #> 381: 0.451762    1.013867    3.450033    0.416617    0.072409    0.019019    0.696949     #> 382: 0.451598    1.013844    3.449988    0.416573    0.072343    0.019015    0.696900     #> 383: 0.451554    1.013717    3.450037    0.416413    0.072257    0.019040    0.696810     #> 384: 0.451444    1.013595    3.450072    0.415923    0.072192    0.019050    0.696806     #> 385: 0.451513    1.013607    3.450077    0.415993    0.072139    0.019078    0.696774     #> 386: 0.451629    1.013728    3.450126    0.416164    0.072185    0.019113    0.696730     #> 387: 0.451792    1.013743    3.450242    0.415959    0.072141    0.019149    0.696675     #> 388: 0.451963    1.013802    3.450322    0.416308    0.072096    0.019180    0.696541     #> 389: 0.452000    1.013637    3.450325    0.416328    0.072102    0.019194    0.696516     #> 390: 0.451756    1.013686    3.450295    0.416375    0.072083    0.019195    0.696438     #> 391: 0.451905    1.013669    3.450253    0.416581    0.072042    0.019202    0.696339     #> 392: 0.451981    1.013692    3.450297    0.417034    0.072000    0.019200    0.696406     #> 393: 0.452035    1.013606    3.450227    0.417395    0.071969    0.019180    0.696404     #> 394: 0.452107    1.013623    3.450146    0.417532    0.071897    0.019170    0.696421     #> 395: 0.452224    1.013658    3.450125    0.417272    0.071842    0.019174    0.696436     #> 396: 0.452263    1.013706    3.450142    0.417436    0.071820    0.019174    0.696435     #> 397: 0.452437    1.013602    3.450247    0.417416    0.071781    0.019193    0.696388     #> 398: 0.452762    1.013548    3.450339    0.417373    0.071781    0.019199    0.696425     #> 399: 0.453053    1.013465    3.450488    0.417447    0.071754    0.019217    0.696412     #> 400: 0.453147    1.013479    3.450571    0.417233    0.071680    0.019224    0.696376     #> 401: 0.453119    1.013477    3.450574    0.416914    0.071636    0.019230    0.696472     #> 402: 0.453150    1.013501    3.450615    0.416663    0.071609    0.019251    0.696581     #> 403: 0.453410    1.013490    3.450637    0.416646    0.071633    0.019252    0.696607     #> 404: 0.453612    1.013519    3.450636    0.416599    0.071659    0.019248    0.696545     #> 405: 0.453638    1.013519    3.450686    0.416423    0.071710    0.019239    0.696540     #> 406: 0.453596    1.013522    3.450701    0.416226    0.071687    0.019246    0.696573     #> 407: 0.453597    1.013523    3.450721    0.416183    0.071708    0.019261    0.696479     #> 408: 0.453756    1.013579    3.450751    0.416054    0.071762    0.019263    0.696508     #> 409: 0.453681    1.013653    3.450674    0.415936    0.071721    0.019270    0.696471     #> 410: 0.453552    1.013696    3.450591    0.415961    0.071677    0.019291    0.696470     #> 411: 0.453475    1.013627    3.450544    0.415848    0.071707    0.019296    0.696467     #> 412: 0.453447    1.013773    3.450496    0.415443    0.071652    0.019305    0.696532     #> 413: 0.453278    1.013894    3.450440    0.415032    0.071614    0.019322    0.696592     #> 414: 0.453089    1.014023    3.450443    0.415168    0.071566    0.019344    0.696499     #> 415: 0.453100    1.014022    3.450433    0.415217    0.071512    0.019369    0.696440     #> 416: 0.453070    1.014071    3.450399    0.415122    0.071461    0.019371    0.696407     #> 417: 0.453173    1.014102    3.450374    0.415319    0.071476    0.019374    0.696302     #> 418: 0.453131    1.014122    3.450389    0.415150    0.071482    0.019382    0.696174     #> 419: 0.453159    1.014175    3.450407    0.415209    0.071483    0.019391    0.696100     #> 420: 0.453360    1.014141    3.450471    0.415069    0.071548    0.019367    0.696001     #> 421: 0.453259    1.014119    3.450503    0.414869    0.071550    0.019356    0.695938     #> 422: 0.453440    1.014008    3.450511    0.414959    0.071543    0.019344    0.695900     #> 423: 0.453403    1.013929    3.450511    0.414850    0.071577    0.019341    0.695881     #> 424: 0.453212    1.013929    3.450442    0.414904    0.071607    0.019338    0.695809     #> 425: 0.453190    1.013981    3.450340    0.415093    0.071598    0.019350    0.695737     #> 426: 0.453168    1.014134    3.450278    0.415191    0.071598    0.019353    0.695669     #> 427: 0.452964    1.014218    3.450230    0.415263    0.071633    0.019342    0.695627     #> 428: 0.452839    1.014266    3.450243    0.415152    0.071616    0.019358    0.695571     #> 429: 0.452835    1.014313    3.450233    0.415186    0.071584    0.019356    0.695578     #> 430: 0.452612    1.014447    3.450195    0.414955    0.071619    0.019357    0.695647     #> 431: 0.452516    1.014403    3.450186    0.414658    0.071640    0.019336    0.695638     #> 432: 0.452415    1.014481    3.450170    0.414493    0.071673    0.019330    0.695571     #> 433: 0.452433    1.014548    3.450209    0.414531    0.071715    0.019332    0.695594     #> 434: 0.452365    1.014429    3.450235    0.414593    0.071764    0.019326    0.695566     #> 435: 0.452431    1.014404    3.450200    0.414533    0.071766    0.019326    0.695532     #> 436: 0.452442    1.014391    3.450227    0.414612    0.071811    0.019311    0.695578     #> 437: 0.452520    1.014398    3.450200    0.414671    0.071843    0.019295    0.695597     #> 438: 0.452438    1.014512    3.450162    0.414635    0.071878    0.019270    0.695571     #> 439: 0.452496    1.014603    3.450161    0.414785    0.071894    0.019251    0.695485     #> 440: 0.452438    1.014638    3.450185    0.414581    0.071855    0.019229    0.695481     #> 441: 0.452555    1.014635    3.450213    0.414685    0.071842    0.019214    0.695420     #> 442: 0.452499    1.014693    3.450235    0.414604    0.071824    0.019213    0.695374     #> 443: 0.452589    1.014804    3.450193    0.414796    0.071835    0.019191    0.695366     #> 444: 0.452526    1.014861    3.450100    0.414925    0.071876    0.019168    0.695367     #> 445: 0.452482    1.014934    3.450020    0.415205    0.071933    0.019147    0.695320     #> 446: 0.452325    1.014983    3.449940    0.415350    0.071957    0.019134    0.695324     #> 447: 0.452354    1.015043    3.449932    0.415306    0.071957    0.019115    0.695344     #> 448: 0.452337    1.015031    3.449956    0.414942    0.071948    0.019107    0.695309     #> 449: 0.452340    1.015074    3.450095    0.414475    0.071893    0.019129    0.695351     #> 450: 0.452357    1.015040    3.450162    0.414091    0.071845    0.019144    0.695377     #> 451: 0.452509    1.015005    3.450207    0.414082    0.071776    0.019165    0.695334     #> 452: 0.452704    1.015033    3.450266    0.414092    0.071730    0.019163    0.695287     #> 453: 0.452703    1.015032    3.450238    0.413840    0.071710    0.019154    0.695188     #> 454: 0.452571    1.015142    3.450221    0.413732    0.071695    0.019150    0.695114     #> 455: 0.452672    1.015182    3.450198    0.413850    0.071632    0.019141    0.695044     #> 456: 0.452701    1.015165    3.450195    0.414069    0.071617    0.019145    0.694995     #> 457: 0.452736    1.015124    3.450215    0.414295    0.071572    0.019150    0.694899     #> 458: 0.452765    1.015193    3.450234    0.414473    0.071521    0.019155    0.694819     #> 459: 0.452612    1.015277    3.450200    0.414424    0.071450    0.019148    0.694808     #> 460: 0.452411    1.015342    3.450134    0.414161    0.071417    0.019157    0.694843     #> 461: 0.452279    1.015435    3.450106    0.414044    0.071382    0.019161    0.694880     #> 462: 0.452119    1.015560    3.450077    0.413892    0.071349    0.019161    0.694871     #> 463: 0.452156    1.015628    3.450075    0.413709    0.071333    0.019159    0.694918     #> 464: 0.452168    1.015723    3.450029    0.413616    0.071346    0.019149    0.694879     #> 465: 0.452154    1.015602    3.450050    0.413439    0.071323    0.019137    0.694854     #> 466: 0.452169    1.015595    3.450038    0.413093    0.071322    0.019133    0.694874     #> 467: 0.451973    1.015591    3.450084    0.412766    0.071305    0.019127    0.694834     #> 468: 0.452031    1.015621    3.450123    0.412597    0.071300    0.019116    0.694856     #> 469: 0.452100    1.015752    3.450140    0.412803    0.071345    0.019102    0.694874     #> 470: 0.452032    1.015849    3.450110    0.412876    0.071407    0.019086    0.694873     #> 471: 0.451983    1.015894    3.450079    0.412730    0.071451    0.019071    0.694966     #> 472: 0.451987    1.015858    3.450097    0.412653    0.071481    0.019057    0.695036     #> 473: 0.451903    1.015885    3.450105    0.412468    0.071463    0.019037    0.695063     #> 474: 0.451938    1.015856    3.450086    0.412437    0.071440    0.019038    0.695122     #> 475: 0.452028    1.015973    3.450073    0.412341    0.071428    0.019028    0.695146     #> 476: 0.452085    1.015983    3.450076    0.412430    0.071390    0.019023    0.695146     #> 477: 0.452018    1.015946    3.450133    0.412300    0.071374    0.019031    0.695098     #> 478: 0.451965    1.015880    3.450157    0.412233    0.071374    0.019034    0.695113     #> 479: 0.452075    1.015902    3.450133    0.412403    0.071401    0.019038    0.695175     #> 480: 0.452003    1.015928    3.450140    0.412184    0.071448    0.019025    0.695262     #> 481: 0.451967    1.015994    3.450145    0.411918    0.071433    0.019017    0.695311     #> 482: 0.452043    1.016014    3.450147    0.411931    0.071396    0.019012    0.695337     #> 483: 0.452039    1.016014    3.450140    0.412061    0.071400    0.019008    0.695313     #> 484: 0.451998    1.015934    3.450138    0.412326    0.071366    0.019007    0.695290     #> 485: 0.452070    1.015991    3.450144    0.412467    0.071346    0.019017    0.695247     #> 486: 0.452120    1.016007    3.450157    0.412287    0.071363    0.019012    0.695216     #> 487: 0.452319    1.016037    3.450210    0.412281    0.071381    0.019001    0.695178     #> 488: 0.452344    1.016015    3.450235    0.412143    0.071400    0.018991    0.695170     #> 489: 0.452554    1.015971    3.450269    0.412148    0.071388    0.018999    0.695152     #> 490: 0.452774    1.016005    3.450342    0.412387    0.071390    0.018999    0.695120     #> 491: 0.452875    1.016039    3.450400    0.412179    0.071397    0.018999    0.695079     #> 492: 0.452947    1.016093    3.450453    0.412000    0.071405    0.019005    0.695118     #> 493: 0.452943    1.016042    3.450490    0.411781    0.071391    0.019018    0.695093     #> 494: 0.453013    1.016015    3.450505    0.411566    0.071362    0.019030    0.695112     #> 495: 0.453135    1.015995    3.450531    0.411610    0.071325    0.019039    0.695067     #> 496: 0.453240    1.016031    3.450511    0.411623    0.071350    0.019051    0.695034     #> 497: 0.453210    1.015991    3.450511    0.411816    0.071314    0.019061    0.695009     #> 498: 0.453235    1.015962    3.450483    0.411889    0.071271    0.019067    0.694955     #> 499: 0.453330    1.015991    3.450466    0.412126    0.071282    0.019062    0.694855     #> 500: 0.453359    1.015978    3.450426    0.412210    0.071308    0.019053    0.694810     #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  print(fit) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem table compress    other #> elapsed 0.002457   0.009011 1.157 0.028    0.023 2.024532 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 16 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # … with 129 more rows, and 4 more variables: cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> one.compartment <- function() {   ini({     tka <- 0.45 # Log Ka     tcl <- 1 # Log Cl     tv <- 3.45    # Log V     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     d/dt(depot) = -ka * depot     d/dt(center) = ka * depot - cl / v * center     cp = center / v     cp ~ add(add.sd)   }) } fit2 <- nlmixr(one.compartment, theo_sd,  est=\"saem\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> 001: 0.228842    0.967748    3.473706    0.570000    0.285000    0.095000    2.127104     #> 002: 0.362350    0.982086    3.531830    0.541500    0.270750    0.090250    1.343354     #> 003: 0.486377    0.918092    3.487192    0.514425    0.257212    0.085737    0.970654     #> 004: 0.448033    0.941625    3.484309    0.488704    0.244352    0.081451    0.833068     #> 005: 0.484364    0.959146    3.475359    0.464269    0.232134    0.077378    0.775843     #> 006: 0.498647    0.968668    3.475246    0.441055    0.220528    0.073509    0.711073     #> 007: 0.457698    0.995279    3.463439    0.425109    0.209501    0.069834    0.712488     #> 008: 0.447271    0.991129    3.466635    0.403854    0.199026    0.066342    0.718001     #> 009: 0.418756    0.975501    3.461547    0.383661    0.189075    0.063025    0.721799     #> 010: 0.434908    0.979752    3.452082    0.430459    0.179621    0.059874    0.700046     #> 011: 0.453682    0.997626    3.454771    0.408936    0.170640    0.056880    0.700755     #> 012: 0.442069    1.010409    3.445827    0.388490    0.162108    0.054036    0.680295     #> 013: 0.394082    1.045357    3.424316    0.369065    0.154003    0.051334    0.691555     #> 014: 0.418912    1.020405    3.437972    0.454508    0.146302    0.048767    0.707247     #> 015: 0.450647    1.020208    3.446836    0.431783    0.138987    0.046329    0.699230     #> 016: 0.455156    1.011207    3.452418    0.420907    0.132038    0.044013    0.709817     #> 017: 0.454209    1.011550    3.455826    0.416368    0.125436    0.041812    0.682493     #> 018: 0.481963    0.982805    3.452119    0.445080    0.119164    0.039721    0.708557     #> 019: 0.433916    0.992401    3.450532    0.422826    0.113206    0.037735    0.700975     #> 020: 0.452742    1.004083    3.447202    0.403662    0.107546    0.035849    0.702001     #> 021: 0.440352    1.007914    3.455756    0.388535    0.102168    0.034056    0.688374     #> 022: 0.462514    1.013834    3.459868    0.446907    0.097060    0.032353    0.672307     #> 023: 0.510433    1.018080    3.464768    0.453508    0.092207    0.030736    0.683116     #> 024: 0.505023    1.022779    3.465907    0.430832    0.087597    0.029199    0.674035     #> 025: 0.463270    0.996693    3.460755    0.409291    0.086079    0.027739    0.692014     #> 026: 0.418262    1.029322    3.434456    0.418259    0.081775    0.026352    0.681431     #> 027: 0.412561    1.036120    3.435697    0.397346    0.077686    0.025034    0.702894     #> 028: 0.459226    1.018053    3.442891    0.377479    0.073802    0.023783    0.673631     #> 029: 0.441300    1.024849    3.436863    0.358605    0.070112    0.022594    0.692878     #> 030: 0.450634    1.019543    3.444037    0.368944    0.067204    0.021464    0.694510     #> 031: 0.404865    1.006885    3.451975    0.350497    0.076784    0.020391    0.691190     #> 032: 0.429158    0.986366    3.460689    0.393870    0.072945    0.020516    0.685700     #> 033: 0.441694    1.015131    3.447680    0.433176    0.069297    0.019490    0.701208     #> 034: 0.459691    1.025187    3.448459    0.423784    0.065833    0.018515    0.700650     #> 035: 0.448490    0.993987    3.451082    0.402595    0.063673    0.017590    0.690347     #> 036: 0.440475    1.010294    3.448794    0.382465    0.065840    0.016710    0.698097     #> 037: 0.440800    1.016281    3.457230    0.373107    0.070740    0.019511    0.697999     #> 038: 0.501426    1.008802    3.447568    0.454382    0.075237    0.018536    0.695994     #> 039: 0.503105    0.985233    3.464689    0.481892    0.071475    0.024470    0.680558     #> 040: 0.490999    0.990494    3.476163    0.457797    0.067902    0.027228    0.688251     #> 041: 0.427559    0.990051    3.456903    0.434907    0.064506    0.025867    0.704861     #> 042: 0.469610    1.008789    3.452902    0.423650    0.065575    0.024573    0.667630     #> 043: 0.429632    1.029260    3.434061    0.402467    0.064093    0.023345    0.674441     #> 044: 0.426791    1.033423    3.442291    0.382344    0.060889    0.023715    0.689780     #> 045: 0.439166    1.039680    3.444678    0.409196    0.058473    0.026513    0.666704     #> 046: 0.449732    1.021747    3.452184    0.388737    0.076523    0.025187    0.670696     #> 047: 0.448682    1.022402    3.447422    0.385782    0.072697    0.023928    0.678809     #> 048: 0.462412    1.014597    3.452977    0.453127    0.069062    0.024029    0.689036     #> 049: 0.453678    1.015421    3.447899    0.430471    0.065609    0.023736    0.699366     #> 050: 0.444388    0.984329    3.442143    0.408948    0.073960    0.022550    0.711403     #> 051: 0.479956    1.027312    3.436790    0.419293    0.072544    0.021422    0.706821     #> 052: 0.508123    1.016265    3.457646    0.473098    0.068917    0.020351    0.699726     #> 053: 0.500808    1.016328    3.450532    0.463831    0.065471    0.019333    0.710769     #> 054: 0.451186    0.998085    3.455309    0.440639    0.062198    0.019237    0.720393     #> 055: 0.439421    1.001841    3.454720    0.418607    0.068369    0.019615    0.693577     #> 056: 0.444055    0.995894    3.452197    0.402833    0.064950    0.021325    0.689743     #> 057: 0.465416    1.003333    3.456503    0.397692    0.062490    0.020259    0.698737     #> 058: 0.494344    1.001565    3.452259    0.432842    0.064623    0.019246    0.701581     #> 059: 0.492572    0.970673    3.462142    0.452865    0.091520    0.018284    0.701132     #> 060: 0.496908    0.983368    3.460151    0.497663    0.086944    0.017938    0.724766     #> 061: 0.526079    1.002996    3.462006    0.561871    0.087731    0.018286    0.727232     #> 062: 0.462843    1.019394    3.460337    0.533777    0.087660    0.021289    0.726495     #> 063: 0.474541    1.004908    3.452840    0.507088    0.084115    0.020224    0.697833     #> 064: 0.467203    1.002140    3.459668    0.481734    0.084776    0.019213    0.693698     #> 065: 0.483757    0.987828    3.446348    0.491686    0.083718    0.020116    0.685104     #> 066: 0.472414    1.036279    3.453456    0.467102    0.087915    0.019365    0.681788     #> 067: 0.460663    1.002433    3.441331    0.443747    0.083520    0.021658    0.680079     #> 068: 0.425001    1.006484    3.450377    0.421559    0.079344    0.020575    0.716611     #> 069: 0.412044    1.012679    3.441327    0.400481    0.075376    0.022344    0.713220     #> 070: 0.432289    1.001084    3.453546    0.466003    0.079717    0.021227    0.712484     #> 071: 0.421864    1.008974    3.439370    0.442703    0.084266    0.020165    0.725818     #> 072: 0.458654    0.982493    3.454867    0.420568    0.102673    0.019157    0.713630     #> 073: 0.503323    0.989296    3.475063    0.399539    0.097540    0.018199    0.718928     #> 074: 0.493499    0.983319    3.477763    0.379562    0.092663    0.017289    0.709900     #> 075: 0.531045    0.971036    3.497359    0.391356    0.088030    0.022725    0.695760     #> 076: 0.564427    0.996869    3.505542    0.386519    0.083628    0.021589    0.707267     #> 077: 0.556551    0.967085    3.494549    0.397391    0.079447    0.020510    0.713332     #> 078: 0.543627    0.982419    3.499697    0.377521    0.075474    0.019801    0.705810     #> 079: 0.545656    0.964761    3.487952    0.427271    0.071701    0.024303    0.732369     #> 080: 0.517135    0.971570    3.488798    0.449238    0.068116    0.024623    0.728873     #> 081: 0.493794    0.994109    3.470857    0.426776    0.064710    0.023392    0.717783     #> 082: 0.469165    0.982102    3.466079    0.416999    0.061474    0.026739    0.702364     #> 083: 0.426242    1.010776    3.455274    0.396149    0.058401    0.025402    0.703063     #> 084: 0.426289    1.022361    3.448272    0.378808    0.055481    0.024717    0.688961     #> 085: 0.450292    1.025667    3.462772    0.395353    0.053204    0.023827    0.701245     #> 086: 0.445043    1.016989    3.451573    0.394319    0.063578    0.023438    0.679443     #> 087: 0.417278    1.016006    3.436987    0.374603    0.060399    0.022266    0.687619     #> 088: 0.397899    1.014641    3.451820    0.362924    0.063356    0.021799    0.691511     #> 089: 0.424903    1.025656    3.436587    0.376961    0.062951    0.020709    0.715617     #> 090: 0.427781    1.027416    3.433489    0.421959    0.062056    0.019673    0.700108     #> 091: 0.416970    1.023989    3.421604    0.496573    0.066034    0.021466    0.688105     #> 092: 0.438154    1.053726    3.432245    0.536456    0.075187    0.023526    0.698181     #> 093: 0.406316    1.043127    3.430645    0.511037    0.073855    0.022349    0.707216     #> 094: 0.418521    1.035183    3.429699    0.485485    0.082814    0.021232    0.707900     #> 095: 0.413319    1.032049    3.442526    0.476562    0.078958    0.020170    0.704314     #> 096: 0.430042    1.022584    3.446836    0.458792    0.075010    0.019162    0.685928     #> 097: 0.455539    1.022434    3.453577    0.435853    0.071260    0.018898    0.678804     #> 098: 0.464357    1.027099    3.455949    0.414060    0.067697    0.017953    0.685588     #> 099: 0.471048    1.000363    3.454110    0.488532    0.064312    0.018852    0.678556     #> 100: 0.428363    1.005284    3.447649    0.464105    0.062570    0.020844    0.670701     #> 101: 0.414993    1.010080    3.434915    0.440900    0.072676    0.019802    0.673130     #> 102: 0.404156    1.018800    3.425588    0.418855    0.069042    0.021601    0.687776     #> 103: 0.473708    1.000818    3.453444    0.397912    0.065590    0.022888    0.672080     #> 104: 0.454973    1.004054    3.469311    0.380735    0.062310    0.021743    0.709958     #> 105: 0.447574    0.993913    3.462344    0.381349    0.074277    0.020656    0.707492     #> 106: 0.479700    0.981919    3.473923    0.362282    0.080368    0.019623    0.697093     #> 107: 0.510656    0.984056    3.462674    0.425964    0.080584    0.018642    0.700005     #> 108: 0.471853    0.987806    3.469474    0.404666    0.076555    0.018190    0.718298     #> 109: 0.457792    0.996784    3.473497    0.384432    0.074792    0.017604    0.696221     #> 110: 0.470372    0.997815    3.454129    0.410154    0.071303    0.016724    0.690925     #> 111: 0.483124    1.017138    3.460620    0.390152    0.090307    0.015888    0.673898     #> 112: 0.477637    0.994079    3.446168    0.449771    0.085792    0.015093    0.676947     #> 113: 0.442038    1.037499    3.450326    0.468448    0.083272    0.014339    0.677096     #> 114: 0.438324    1.037347    3.449152    0.445026    0.094095    0.014751    0.674526     #> 115: 0.451708    1.005043    3.451142    0.422774    0.093739    0.014014    0.683948     #> 116: 0.469935    1.012553    3.456284    0.401636    0.089052    0.013313    0.700378     #> 117: 0.443566    1.038590    3.452866    0.381554    0.092193    0.012647    0.695686     #> 118: 0.466284    1.018714    3.456025    0.379026    0.092601    0.013799    0.693663     #> 119: 0.484809    1.014321    3.460758    0.421073    0.100370    0.019623    0.703244     #> 120: 0.431725    0.987327    3.452330    0.469017    0.095351    0.020853    0.695314     #> 121: 0.469978    1.036757    3.449845    0.445567    0.090584    0.020463    0.692292     #> 122: 0.472483    0.998021    3.456579    0.428548    0.086055    0.020548    0.683278     #> 123: 0.477245    1.036545    3.443222    0.445535    0.081752    0.021550    0.684115     #> 124: 0.459105    1.052316    3.434295    0.486192    0.077664    0.021582    0.673732     #> 125: 0.456589    1.065326    3.428847    0.461883    0.073781    0.020503    0.680516     #> 126: 0.426539    1.070033    3.421021    0.471782    0.074840    0.021287    0.689804     #> 127: 0.461142    1.027349    3.423929    0.507609    0.078424    0.020223    0.709164     #> 128: 0.419983    1.024484    3.432829    0.499379    0.076619    0.023525    0.731110     #> 129: 0.458295    1.019525    3.447583    0.523792    0.080610    0.022349    0.705573     #> 130: 0.493377    1.019201    3.442300    0.501402    0.076579    0.021232    0.690288     #> 131: 0.453207    1.014472    3.430575    0.519050    0.077196    0.020170    0.703552     #> 132: 0.387296    1.025007    3.423363    0.493098    0.085546    0.019162    0.715117     #> 133: 0.399943    1.014010    3.429520    0.468443    0.081269    0.018203    0.719537     #> 134: 0.417952    1.010580    3.446170    0.445021    0.077205    0.018927    0.710689     #> 135: 0.448867    1.003881    3.452976    0.422769    0.073345    0.019474    0.699042     #> 136: 0.470960    1.001507    3.456161    0.403145    0.069678    0.018811    0.691957     #> 137: 0.505660    0.997319    3.460032    0.442887    0.066194    0.017871    0.716582     #> 138: 0.471891    1.011649    3.451857    0.429482    0.062884    0.016977    0.691340     #> 139: 0.453600    1.027530    3.455545    0.431592    0.071296    0.017614    0.678474     #> 140: 0.459588    1.026772    3.463126    0.427335    0.067731    0.018355    0.691931     #> 141: 0.467884    0.996592    3.465776    0.408400    0.075091    0.018650    0.671208     #> 142: 0.478653    0.996013    3.463912    0.387980    0.077437    0.019856    0.691304     #> 143: 0.459373    1.007115    3.467301    0.418266    0.073566    0.022438    0.701390     #> 144: 0.475921    1.001781    3.463115    0.409669    0.069887    0.021316    0.696689     #> 145: 0.447320    1.023742    3.446758    0.430404    0.073868    0.020251    0.684300     #> 146: 0.419888    1.025914    3.453435    0.417595    0.070174    0.019238    0.689187     #> 147: 0.433559    1.013026    3.448293    0.396715    0.066666    0.018276    0.671437     #> 148: 0.432246    1.017985    3.457482    0.376880    0.063332    0.019142    0.677371     #> 149: 0.434927    1.012078    3.450116    0.367109    0.071213    0.020185    0.666521     #> 150: 0.472154    1.000161    3.443522    0.366735    0.068532    0.019176    0.696530     #> 151: 0.417225    1.029907    3.446144    0.348398    0.065105    0.021936    0.694149     #> 152: 0.437309    1.009241    3.456539    0.346186    0.071217    0.019736    0.689387     #> 153: 0.443395    1.022581    3.466777    0.397588    0.073158    0.021481    0.691285     #> 154: 0.474917    1.034869    3.469549    0.384631    0.082353    0.022046    0.700042     #> 155: 0.456013    1.012703    3.456577    0.431421    0.064152    0.026511    0.680906     #> 156: 0.454706    1.017265    3.451133    0.391892    0.083677    0.029577    0.713418     #> 157: 0.440423    1.006251    3.459825    0.379368    0.069966    0.029140    0.721839     #> 158: 0.461332    1.010092    3.458838    0.371172    0.064348    0.028952    0.697920     #> 159: 0.420172    1.024889    3.457826    0.366155    0.046180    0.024741    0.701854     #> 160: 0.468361    0.992548    3.466193    0.422483    0.049199    0.021472    0.708589     #> 161: 0.435283    0.993633    3.462297    0.366975    0.036102    0.024519    0.695306     #> 162: 0.447637    1.021387    3.452806    0.435773    0.039989    0.026882    0.697772     #> 163: 0.487679    1.001479    3.452050    0.467727    0.036301    0.025011    0.708619     #> 164: 0.477198    0.993084    3.464745    0.457223    0.032008    0.027746    0.698953     #> 165: 0.510767    1.004602    3.469572    0.431430    0.036191    0.024236    0.700815     #> 166: 0.514969    1.012029    3.469917    0.467541    0.035244    0.026244    0.708088     #> 167: 0.483093    1.030498    3.478251    0.391579    0.044500    0.028964    0.715958     #> 168: 0.476695    1.044163    3.461697    0.391016    0.047952    0.028058    0.713814     #> 169: 0.455210    1.048358    3.450162    0.317200    0.059288    0.022488    0.714497     #> 170: 0.464261    1.010898    3.451968    0.346285    0.055272    0.020893    0.703286     #> 171: 0.427155    1.025296    3.443761    0.374028    0.063015    0.023165    0.676551     #> 172: 0.449634    1.028013    3.454746    0.373912    0.065742    0.021873    0.671573     #> 173: 0.438657    1.027427    3.439073    0.355670    0.063678    0.027703    0.672649     #> 174: 0.464586    1.038234    3.449573    0.342182    0.059087    0.024955    0.685672     #> 175: 0.463025    1.030466    3.443942    0.383031    0.066814    0.025817    0.689070     #> 176: 0.405488    1.027909    3.445625    0.379338    0.067695    0.021303    0.689735     #> 177: 0.462833    1.027539    3.457987    0.461603    0.063537    0.027514    0.687671     #> 178: 0.467025    1.006962    3.464062    0.403778    0.073660    0.024324    0.684524     #> 179: 0.496932    1.004448    3.462414    0.417742    0.078314    0.018646    0.721322     #> 180: 0.463149    1.017811    3.463960    0.330499    0.068745    0.017739    0.718234     #> 181: 0.477670    1.007491    3.437048    0.385523    0.069170    0.018535    0.704542     #> 182: 0.397833    1.011764    3.437660    0.336525    0.089613    0.017695    0.709685     #> 183: 0.419367    1.014077    3.443633    0.340013    0.080113    0.016836    0.708055     #> 184: 0.420481    1.031817    3.429914    0.415921    0.076441    0.017952    0.686781     #> 185: 0.400967    1.041108    3.427780    0.388581    0.068234    0.017933    0.690540     #> 186: 0.378778    1.055151    3.422427    0.378144    0.080762    0.019126    0.706354     #> 187: 0.425880    1.032040    3.433015    0.386902    0.064352    0.022355    0.683440     #> 188: 0.437508    1.041014    3.442045    0.433319    0.076531    0.019254    0.686629     #> 189: 0.432002    1.038562    3.450294    0.397264    0.075914    0.016951    0.695285     #> 190: 0.445815    1.019800    3.461053    0.335951    0.071572    0.016751    0.680011     #> 191: 0.447265    1.018364    3.451614    0.337992    0.070611    0.014477    0.677923     #> 192: 0.435311    1.013246    3.455020    0.329174    0.065525    0.013824    0.695070     #> 193: 0.464839    1.023138    3.458074    0.366851    0.075380    0.015470    0.687945     #> 194: 0.441785    1.026898    3.450363    0.432452    0.067260    0.010374    0.713523     #> 195: 0.425105    1.033093    3.439440    0.405262    0.063488    0.010978    0.705746     #> 196: 0.422841    1.021345    3.447846    0.394242    0.082240    0.012945    0.704502     #> 197: 0.410073    1.030040    3.456494    0.340189    0.071165    0.014565    0.713122     #> 198: 0.478152    0.997299    3.454618    0.466456    0.075104    0.014848    0.690571     #> 199: 0.436293    0.991874    3.449431    0.385652    0.075366    0.012163    0.690439     #> 200: 0.430289    1.000417    3.446106    0.355353    0.082673    0.014124    0.696866     #> 201: 0.415496    0.999750    3.446594    0.350232    0.085844    0.014600    0.692466     #> 202: 0.414157    1.007318    3.446043    0.361919    0.083537    0.014781    0.698776     #> 203: 0.433595    1.003881    3.445349    0.388043    0.085278    0.015417    0.696839     #> 204: 0.432527    1.001590    3.446215    0.398346    0.085602    0.014866    0.696996     #> 205: 0.432321    1.008565    3.446476    0.391779    0.088866    0.014995    0.697692     #> 206: 0.435995    1.013248    3.447589    0.400399    0.088255    0.014782    0.700773     #> 207: 0.435104    1.013702    3.447412    0.394436    0.086120    0.014553    0.701283     #> 208: 0.436052    1.013140    3.447984    0.386236    0.083793    0.014433    0.699110     #> 209: 0.439855    1.011896    3.447962    0.393088    0.082855    0.014368    0.697245     #> 210: 0.440082    1.011131    3.448565    0.393385    0.081029    0.014553    0.696387     #> 211: 0.444027    1.011130    3.449731    0.395760    0.080210    0.014578    0.694048     #> 212: 0.449299    1.009178    3.450572    0.397742    0.079928    0.014453    0.692908     #> 213: 0.452305    1.006786    3.451804    0.399364    0.079715    0.014430    0.693309     #> 214: 0.457482    1.006188    3.453259    0.400910    0.080345    0.014470    0.692454     #> 215: 0.459291    1.006285    3.454349    0.400041    0.080579    0.014533    0.691854     #> 216: 0.464460    1.004518    3.455035    0.408659    0.080391    0.014395    0.693468     #> 217: 0.468540    1.004904    3.455730    0.411368    0.079849    0.014399    0.692882     #> 218: 0.470901    1.005149    3.455541    0.413920    0.079520    0.014462    0.693009     #> 219: 0.470705    1.004617    3.455113    0.415730    0.078474    0.014514    0.693564     #> 220: 0.469352    1.004806    3.455146    0.413799    0.078231    0.014623    0.693658     #> 221: 0.468602    1.004272    3.455468    0.411215    0.077367    0.014713    0.693692     #> 222: 0.469562    1.004509    3.455566    0.413622    0.077012    0.014889    0.693379     #> 223: 0.470659    1.004144    3.455916    0.415670    0.076045    0.015158    0.693128     #> 224: 0.472749    1.004784    3.456302    0.418784    0.075733    0.015357    0.692715     #> 225: 0.473587    1.003741    3.456862    0.419552    0.074976    0.015589    0.692958     #> 226: 0.475351    1.003018    3.457158    0.422049    0.074845    0.015773    0.692958     #> 227: 0.475309    1.002694    3.457731    0.422819    0.074870    0.016001    0.692834     #> 228: 0.474366    1.003506    3.457428    0.422058    0.074615    0.016225    0.693063     #> 229: 0.473885    1.003500    3.457254    0.422541    0.074150    0.016494    0.692669     #> 230: 0.473558    1.003364    3.456997    0.420966    0.074101    0.016735    0.692718     #> 231: 0.473475    1.003641    3.457254    0.418194    0.073689    0.016989    0.693011     #> 232: 0.472287    1.003676    3.457171    0.417845    0.073521    0.017005    0.692755     #> 233: 0.471782    1.002758    3.457307    0.418840    0.073255    0.017057    0.692670     #> 234: 0.471536    1.002693    3.457258    0.417464    0.072957    0.017242    0.692712     #> 235: 0.470543    1.002586    3.456719    0.416255    0.072671    0.017235    0.693130     #> 236: 0.470434    1.003059    3.456267    0.415288    0.072570    0.017344    0.693566     #> 237: 0.470704    1.002891    3.456323    0.415119    0.072655    0.017382    0.694142     #> 238: 0.471261    1.003002    3.456345    0.415060    0.072796    0.017378    0.694940     #> 239: 0.470845    1.003442    3.456175    0.415478    0.072820    0.017398    0.695093     #> 240: 0.470776    1.003473    3.456242    0.414648    0.072856    0.017457    0.694775     #> 241: 0.471064    1.002889    3.456395    0.415247    0.072908    0.017479    0.694766     #> 242: 0.471538    1.002742    3.456322    0.414339    0.073092    0.017500    0.694873     #> 243: 0.471677    1.003285    3.456370    0.413440    0.073490    0.017535    0.694952     #> 244: 0.470938    1.003522    3.456606    0.411814    0.073673    0.017471    0.695240     #> 245: 0.471524    1.003287    3.457030    0.409998    0.073643    0.017445    0.695611     #> 246: 0.472295    1.003455    3.457195    0.409679    0.073694    0.017481    0.695516     #> 247: 0.471486    1.003243    3.457433    0.409033    0.073579    0.017565    0.695478     #> 248: 0.471294    1.003531    3.457525    0.408954    0.073362    0.017626    0.695144     #> 249: 0.470437    1.003768    3.457535    0.408191    0.073269    0.017692    0.695326     #> 250: 0.470779    1.004311    3.457629    0.408453    0.073278    0.017783    0.695432     #> 251: 0.471254    1.004986    3.457868    0.409228    0.073303    0.017821    0.695437     #> 252: 0.471989    1.005168    3.458252    0.410524    0.073057    0.017917    0.695327     #> 253: 0.471455    1.005467    3.458210    0.411860    0.072831    0.017976    0.695538     #> 254: 0.471586    1.006197    3.458226    0.412504    0.072836    0.018011    0.695600     #> 255: 0.470994    1.006787    3.458157    0.411812    0.072825    0.018063    0.695500     #> 256: 0.470776    1.007028    3.458133    0.412174    0.072818    0.018174    0.695380     #> 257: 0.470089    1.006677    3.458076    0.411823    0.072565    0.018167    0.695226     #> 258: 0.469630    1.006610    3.457856    0.412986    0.072499    0.018173    0.694898     #> 259: 0.469437    1.006603    3.457803    0.413201    0.072547    0.018157    0.694692     #> 260: 0.469261    1.006990    3.457872    0.412777    0.072528    0.018108    0.694679     #> 261: 0.469394    1.006848    3.457914    0.412211    0.072583    0.018117    0.694612     #> 262: 0.468411    1.007158    3.457767    0.411764    0.072965    0.018060    0.694761     #> 263: 0.467741    1.007429    3.457569    0.411556    0.073001    0.018110    0.694726     #> 264: 0.466819    1.007895    3.457318    0.412485    0.073120    0.018091    0.694789     #> 265: 0.466361    1.008140    3.457127    0.412974    0.073434    0.018071    0.694917     #> 266: 0.466070    1.008214    3.456910    0.414447    0.073403    0.018107    0.694919     #> 267: 0.465822    1.008400    3.456938    0.416545    0.073439    0.018074    0.694867     #> 268: 0.465947    1.008358    3.456804    0.417638    0.073377    0.018045    0.694941     #> 269: 0.466531    1.008164    3.456817    0.418445    0.073285    0.018048    0.695088     #> 270: 0.466329    1.008345    3.456550    0.419823    0.073253    0.018008    0.694912     #> 271: 0.466011    1.008494    3.456393    0.420196    0.073354    0.018015    0.694977     #> 272: 0.465890    1.008284    3.456306    0.419691    0.073529    0.018021    0.695342     #> 273: 0.465694    1.008409    3.456419    0.418796    0.073791    0.018029    0.695499     #> 274: 0.465431    1.008695    3.456478    0.417052    0.074042    0.017974    0.695732     #> 275: 0.465497    1.008824    3.456505    0.416264    0.074243    0.017960    0.695666     #> 276: 0.465253    1.009088    3.456489    0.416465    0.074445    0.017937    0.695524     #> 277: 0.464812    1.009309    3.456544    0.416038    0.074383    0.017960    0.695442     #> 278: 0.464622    1.009426    3.456571    0.416468    0.074260    0.017932    0.695504     #> 279: 0.464698    1.009389    3.456566    0.417479    0.074062    0.017936    0.695647     #> 280: 0.464653    1.009535    3.456571    0.417356    0.074014    0.017947    0.695619     #> 281: 0.464577    1.009855    3.456597    0.417708    0.074044    0.017979    0.695458     #> 282: 0.464764    1.009951    3.456576    0.418493    0.074148    0.017930    0.695473     #> 283: 0.464700    1.009884    3.456474    0.419588    0.074102    0.017873    0.695820     #> 284: 0.464470    1.009860    3.456289    0.420664    0.074027    0.017814    0.695859     #> 285: 0.464211    1.010014    3.456106    0.420766    0.074001    0.017773    0.695672     #> 286: 0.463706    1.010398    3.455874    0.420656    0.074056    0.017737    0.695398     #> 287: 0.462992    1.010831    3.455536    0.420380    0.074151    0.017706    0.695338     #> 288: 0.462607    1.010924    3.455346    0.419761    0.074100    0.017728    0.695360     #> 289: 0.462364    1.010843    3.455238    0.419004    0.074011    0.017760    0.695327     #> 290: 0.462241    1.010794    3.455159    0.418965    0.074047    0.017766    0.695388     #> 291: 0.462308    1.011065    3.455232    0.419651    0.074111    0.017790    0.695203     #> 292: 0.462406    1.011125    3.455214    0.420387    0.074215    0.017768    0.695153     #> 293: 0.462404    1.011022    3.455165    0.420559    0.074209    0.017741    0.695276     #> 294: 0.462255    1.011045    3.455051    0.420711    0.074232    0.017733    0.695092     #> 295: 0.462108    1.010757    3.454993    0.420681    0.074280    0.017737    0.694915     #> 296: 0.461849    1.010721    3.454942    0.419736    0.074346    0.017751    0.694932     #> 297: 0.461940    1.010722    3.454925    0.419785    0.074356    0.017803    0.694762     #> 298: 0.462273    1.010642    3.454917    0.420009    0.074401    0.017800    0.694591     #> 299: 0.462524    1.010580    3.454927    0.420679    0.074397    0.017765    0.694445     #> 300: 0.462613    1.010557    3.454980    0.421146    0.074327    0.017760    0.694369     #> 301: 0.462799    1.010372    3.454978    0.420831    0.074307    0.017736    0.694252     #> 302: 0.463201    1.010427    3.455038    0.421019    0.074220    0.017761    0.694023     #> 303: 0.463542    1.010464    3.455084    0.421034    0.074168    0.017785    0.693782     #> 304: 0.463459    1.010650    3.454979    0.421460    0.074055    0.017798    0.693784     #> 305: 0.463344    1.010604    3.454938    0.421499    0.074078    0.017832    0.693690     #> 306: 0.462893    1.010607    3.454783    0.420990    0.074072    0.017860    0.693579     #> 307: 0.462604    1.010709    3.454637    0.420256    0.074137    0.017858    0.693767     #> 308: 0.462094    1.010657    3.454484    0.420151    0.074104    0.017838    0.693810     #> 309: 0.461905    1.010454    3.454444    0.420119    0.074120    0.017835    0.694054     #> 310: 0.461982    1.010406    3.454361    0.419773    0.074188    0.017798    0.694392     #> 311: 0.461863    1.010385    3.454341    0.419418    0.074361    0.017767    0.694462     #> 312: 0.461731    1.010323    3.454287    0.419432    0.074504    0.017757    0.694397     #> 313: 0.461578    1.010054    3.454224    0.419294    0.074554    0.017730    0.694602     #> 314: 0.461472    1.009831    3.454281    0.418947    0.074583    0.017736    0.694707     #> 315: 0.461564    1.009808    3.454275    0.418903    0.074620    0.017720    0.694688     #> 316: 0.461610    1.009803    3.454278    0.419110    0.074589    0.017708    0.694751     #> 317: 0.461407    1.009815    3.454296    0.418310    0.074625    0.017704    0.694827     #> 318: 0.461425    1.009816    3.454291    0.417728    0.074538    0.017701    0.694809     #> 319: 0.461447    1.009780    3.454305    0.416985    0.074535    0.017706    0.694954     #> 320: 0.460977    1.009741    3.454125    0.416916    0.074534    0.017706    0.695132     #> 321: 0.460463    1.009766    3.453889    0.417098    0.074414    0.017703    0.695296     #> 322: 0.460274    1.009834    3.453686    0.417636    0.074393    0.017697    0.695346     #> 323: 0.460169    1.009909    3.453561    0.417937    0.074439    0.017703    0.695294     #> 324: 0.459832    1.010189    3.453443    0.418030    0.074487    0.017699    0.695126     #> 325: 0.459672    1.010464    3.453289    0.418107    0.074494    0.017714    0.695020     #> 326: 0.459292    1.010580    3.453152    0.418113    0.074489    0.017735    0.694900     #> 327: 0.459425    1.010702    3.453063    0.418777    0.074478    0.017758    0.694844     #> 328: 0.459460    1.010903    3.453020    0.419086    0.074514    0.017760    0.694745     #> 329: 0.459560    1.011035    3.452977    0.419191    0.074506    0.017776    0.694632     #> 330: 0.459373    1.011045    3.452950    0.419292    0.074461    0.017789    0.694752     #> 331: 0.459190    1.011033    3.452948    0.418889    0.074486    0.017791    0.694681     #> 332: 0.459279    1.011114    3.452992    0.419107    0.074450    0.017776    0.694729     #> 333: 0.459117    1.011233    3.452882    0.419564    0.074435    0.017760    0.694796     #> 334: 0.458943    1.011196    3.452769    0.419646    0.074438    0.017765    0.694733     #> 335: 0.458781    1.011200    3.452639    0.420029    0.074492    0.017753    0.694634     #> 336: 0.458075    1.011438    3.452434    0.420128    0.074578    0.017767    0.694727     #> 337: 0.457693    1.011868    3.452202    0.420595    0.074795    0.017771    0.694741     #> 338: 0.457399    1.012054    3.452144    0.420859    0.074918    0.017776    0.694620     #> 339: 0.456983    1.012238    3.452006    0.420649    0.074892    0.017759    0.694535     #> 340: 0.456717    1.012188    3.451967    0.420540    0.074907    0.017761    0.694453     #> 341: 0.456741    1.012183    3.451934    0.420362    0.075006    0.017748    0.694485     #> 342: 0.456454    1.012075    3.451935    0.419803    0.074981    0.017731    0.694462     #> 343: 0.456296    1.012147    3.451860    0.419169    0.074966    0.017713    0.694376     #> 344: 0.456251    1.012138    3.451809    0.419192    0.074887    0.017709    0.694384     #> 345: 0.456161    1.012122    3.451799    0.418933    0.074763    0.017726    0.694426     #> 346: 0.455877    1.012225    3.451712    0.418697    0.074720    0.017714    0.694360     #> 347: 0.455671    1.012171    3.451582    0.418438    0.074740    0.017714    0.694434     #> 348: 0.455319    1.012242    3.451443    0.418248    0.074673    0.017707    0.694624     #> 349: 0.454927    1.012270    3.451314    0.418036    0.074600    0.017685    0.694749     #> 350: 0.454485    1.012341    3.451073    0.417897    0.074546    0.017663    0.694795     #> 351: 0.454215    1.012576    3.450856    0.417954    0.074498    0.017657    0.694855     #> 352: 0.453835    1.012735    3.450773    0.417928    0.074477    0.017658    0.695071     #> 353: 0.453876    1.012925    3.450748    0.417972    0.074487    0.017653    0.695100     #> 354: 0.454016    1.012999    3.450667    0.418210    0.074509    0.017639    0.695093     #> 355: 0.454136    1.012992    3.450592    0.418188    0.074519    0.017640    0.695029     #> 356: 0.453978    1.012903    3.450590    0.417802    0.074519    0.017655    0.695197     #> 357: 0.453821    1.012994    3.450541    0.417893    0.074541    0.017632    0.695243     #> 358: 0.453656    1.013102    3.450537    0.417789    0.074554    0.017619    0.695232     #> 359: 0.453350    1.013224    3.450480    0.417639    0.074531    0.017608    0.695275     #> 360: 0.453019    1.013268    3.450297    0.417821    0.074505    0.017603    0.695171     #> 361: 0.452795    1.013340    3.450202    0.417659    0.074510    0.017606    0.695047     #> 362: 0.452695    1.013379    3.450064    0.417747    0.074448    0.017612    0.694919     #> 363: 0.452703    1.013316    3.449994    0.418018    0.074378    0.017627    0.694763     #> 364: 0.452982    1.013316    3.449988    0.418570    0.074316    0.017671    0.694685     #> 365: 0.452887    1.013261    3.450020    0.418628    0.074228    0.017715    0.694684     #> 366: 0.452725    1.013314    3.449989    0.418042    0.074193    0.017728    0.694805     #> 367: 0.452734    1.013272    3.450003    0.417642    0.074247    0.017728    0.694845     #> 368: 0.452856    1.013297    3.449992    0.417617    0.074195    0.017734    0.694773     #> 369: 0.452984    1.013310    3.449988    0.418036    0.074181    0.017737    0.694833     #> 370: 0.453051    1.013399    3.449963    0.418192    0.074143    0.017766    0.694836     #> 371: 0.452848    1.013635    3.449820    0.418179    0.074127    0.017782    0.694807     #> 372: 0.452482    1.013864    3.449654    0.418191    0.074147    0.017779    0.694834     #> 373: 0.451963    1.014140    3.449439    0.418134    0.074125    0.017777    0.694879     #> 374: 0.451822    1.014246    3.449323    0.418099    0.074124    0.017756    0.694792     #> 375: 0.451655    1.014240    3.449314    0.417914    0.074089    0.017751    0.694767     #> 376: 0.451544    1.014293    3.449327    0.417673    0.074122    0.017756    0.694696     #> 377: 0.451453    1.014254    3.449350    0.417607    0.074125    0.017769    0.694541     #> 378: 0.451348    1.014220    3.449301    0.417756    0.074059    0.017768    0.694526     #> 379: 0.451279    1.014135    3.449261    0.418088    0.074047    0.017747    0.694488     #> 380: 0.451318    1.014119    3.449257    0.418122    0.074074    0.017734    0.694443     #> 381: 0.451292    1.014143    3.449243    0.418179    0.074085    0.017732    0.694429     #> 382: 0.451324    1.014205    3.449232    0.418035    0.074022    0.017718    0.694336     #> 383: 0.451429    1.014191    3.449263    0.417861    0.073947    0.017738    0.694215     #> 384: 0.451344    1.014115    3.449272    0.417510    0.073884    0.017762    0.694190     #> 385: 0.451399    1.014025    3.449277    0.417601    0.073790    0.017790    0.694117     #> 386: 0.451566    1.014118    3.449346    0.417735    0.073791    0.017841    0.694106     #> 387: 0.451763    1.014269    3.449412    0.417661    0.073739    0.017865    0.694046     #> 388: 0.451962    1.014284    3.449450    0.417833    0.073775    0.017890    0.693978     #> 389: 0.451973    1.014217    3.449436    0.417764    0.073885    0.017899    0.694013     #> 390: 0.451892    1.014279    3.449373    0.417734    0.073923    0.017907    0.693963     #> 391: 0.451993    1.014288    3.449346    0.417878    0.073921    0.017890    0.693928     #> 392: 0.452030    1.014272    3.449388    0.418293    0.073908    0.017868    0.694023     #> 393: 0.451956    1.014242    3.449339    0.418670    0.073914    0.017842    0.694085     #> 394: 0.451876    1.014276    3.449238    0.418807    0.073860    0.017815    0.694085     #> 395: 0.451875    1.014321    3.449190    0.418632    0.073798    0.017807    0.694116     #> 396: 0.452008    1.014273    3.449225    0.419046    0.073737    0.017797    0.694080     #> 397: 0.452244    1.014088    3.449313    0.419276    0.073679    0.017806    0.694015     #> 398: 0.452559    1.014005    3.449409    0.419329    0.073669    0.017807    0.694028     #> 399: 0.452826    1.013960    3.449551    0.419218    0.073672    0.017814    0.694026     #> 400: 0.452956    1.013924    3.449613    0.419050    0.073650    0.017819    0.694030     #> 401: 0.452934    1.013947    3.449612    0.418844    0.073658    0.017818    0.694201     #> 402: 0.452819    1.014084    3.449648    0.418648    0.073640    0.017828    0.694269     #> 403: 0.452976    1.014072    3.449674    0.418659    0.073683    0.017824    0.694295     #> 404: 0.453165    1.014042    3.449654    0.418659    0.073706    0.017819    0.694277     #> 405: 0.453080    1.014021    3.449649    0.418625    0.073732    0.017821    0.694231     #> 406: 0.453037    1.014053    3.449642    0.418501    0.073722    0.017841    0.694264     #> 407: 0.453004    1.014080    3.449681    0.418465    0.073734    0.017854    0.694163     #> 408: 0.453214    1.014169    3.449746    0.418314    0.073773    0.017850    0.694170     #> 409: 0.453251    1.014120    3.449728    0.417918    0.073739    0.017844    0.694215     #> 410: 0.453286    1.014118    3.449679    0.417959    0.073683    0.017865    0.694226     #> 411: 0.453312    1.014055    3.449648    0.418075    0.073705    0.017872    0.694237     #> 412: 0.453315    1.014145    3.449646    0.417552    0.073613    0.017885    0.694375     #> 413: 0.453196    1.014223    3.449636    0.417035    0.073573    0.017907    0.694416     #> 414: 0.453037    1.014369    3.449645    0.417342    0.073564    0.017930    0.694362     #> 415: 0.453121    1.014362    3.449653    0.417280    0.073545    0.017937    0.694303     #> 416: 0.453021    1.014427    3.449635    0.417000    0.073523    0.017936    0.694288     #> 417: 0.453061    1.014443    3.449609    0.417077    0.073548    0.017939    0.694168     #> 418: 0.453035    1.014456    3.449632    0.416865    0.073551    0.017942    0.694054     #> 419: 0.453133    1.014510    3.449653    0.416964    0.073547    0.017951    0.693980     #> 420: 0.453315    1.014482    3.449748    0.416706    0.073605    0.017935    0.693880     #> 421: 0.453262    1.014429    3.449779    0.416438    0.073597    0.017923    0.693807     #> 422: 0.453419    1.014315    3.449795    0.416404    0.073628    0.017910    0.693753     #> 423: 0.453472    1.014287    3.449796    0.416298    0.073676    0.017903    0.693757     #> 424: 0.453320    1.014291    3.449719    0.416185    0.073688    0.017899    0.693701     #> 425: 0.453369    1.014376    3.449630    0.416354    0.073728    0.017894    0.693685     #> 426: 0.453453    1.014526    3.449579    0.416471    0.073795    0.017887    0.693614     #> 427: 0.453369    1.014608    3.449579    0.416455    0.073863    0.017884    0.693581     #> 428: 0.453349    1.014623    3.449602    0.416335    0.073883    0.017891    0.693501     #> 429: 0.453449    1.014630    3.449653    0.416376    0.073842    0.017895    0.693501     #> 430: 0.453340    1.014786    3.449663    0.416207    0.073876    0.017895    0.693519     #> 431: 0.453250    1.014804    3.449661    0.415978    0.073850    0.017886    0.693486     #> 432: 0.453083    1.014954    3.449620    0.415781    0.073850    0.017893    0.693431     #> 433: 0.453082    1.015060    3.449667    0.415737    0.073832    0.017912    0.693438     #> 434: 0.452988    1.014998    3.449694    0.415613    0.073804    0.017918    0.693411     #> 435: 0.453048    1.014943    3.449723    0.415467    0.073769    0.017914    0.693387     #> 436: 0.453071    1.014881    3.449797    0.415202    0.073823    0.017907    0.693412     #> 437: 0.453078    1.014841    3.449822    0.414814    0.073854    0.017895    0.693428     #> 438: 0.452921    1.014899    3.449796    0.414522    0.073862    0.017879    0.693350     #> 439: 0.452929    1.014953    3.449817    0.414344    0.073834    0.017876    0.693281     #> 440: 0.452816    1.014978    3.449868    0.413914    0.073794    0.017871    0.693309     #> 441: 0.452996    1.014922    3.449939    0.413920    0.073769    0.017866    0.693256     #> 442: 0.453024    1.014952    3.449977    0.413669    0.073762    0.017871    0.693257     #> 443: 0.453080    1.014991    3.449936    0.413631    0.073769    0.017851    0.693256     #> 444: 0.452972    1.015058    3.449822    0.413513    0.073821    0.017832    0.693240     #> 445: 0.452851    1.015142    3.449718    0.413874    0.073915    0.017811    0.693290     #> 446: 0.452650    1.015238    3.449645    0.414112    0.073990    0.017789    0.693339     #> 447: 0.452695    1.015339    3.449638    0.414225    0.074041    0.017766    0.693340     #> 448: 0.452739    1.015363    3.449668    0.414032    0.074071    0.017748    0.693285     #> 449: 0.452841    1.015436    3.449771    0.413784    0.074039    0.017760    0.693282     #> 450: 0.452910    1.015372    3.449842    0.413630    0.074004    0.017766    0.693298     #> 451: 0.453091    1.015315    3.449883    0.413937    0.073942    0.017788    0.693249     #> 452: 0.453254    1.015306    3.449915    0.414056    0.073895    0.017788    0.693230     #> 453: 0.453241    1.015312    3.449879    0.413983    0.073883    0.017777    0.693160     #> 454: 0.453143    1.015393    3.449856    0.414011    0.073882    0.017770    0.693068     #> 455: 0.453147    1.015412    3.449829    0.414034    0.073808    0.017762    0.693019     #> 456: 0.453092    1.015444    3.449786    0.414004    0.073784    0.017762    0.692962     #> 457: 0.453011    1.015406    3.449776    0.414139    0.073728    0.017768    0.692886     #> 458: 0.453018    1.015479    3.449780    0.414228    0.073649    0.017775    0.692812     #> 459: 0.452811    1.015569    3.449746    0.414043    0.073596    0.017770    0.692837     #> 460: 0.452617    1.015618    3.449673    0.413810    0.073581    0.017776    0.692817     #> 461: 0.452536    1.015680    3.449649    0.413718    0.073571    0.017772    0.692794     #> 462: 0.452410    1.015761    3.449630    0.413497    0.073567    0.017761    0.692801     #> 463: 0.452410    1.015843    3.449637    0.413191    0.073555    0.017764    0.692881     #> 464: 0.452335    1.015938    3.449583    0.413007    0.073581    0.017751    0.692879     #> 465: 0.452315    1.015853    3.449605    0.412772    0.073564    0.017732    0.692899     #> 466: 0.452254    1.015859    3.449592    0.412382    0.073586    0.017722    0.692940     #> 467: 0.452027    1.015752    3.449621    0.412064    0.073600    0.017710    0.692956     #> 468: 0.452171    1.015717    3.449718    0.411901    0.073633    0.017705    0.692988     #> 469: 0.452384    1.015792    3.449780    0.412087    0.073644    0.017700    0.692985     #> 470: 0.452406    1.015851    3.449767    0.412182    0.073691    0.017688    0.693005     #> 471: 0.452343    1.015781    3.449755    0.412102    0.073710    0.017677    0.693082     #> 472: 0.452300    1.015720    3.449774    0.412063    0.073725    0.017666    0.693181     #> 473: 0.452186    1.015706    3.449776    0.411847    0.073758    0.017654    0.693207     #> 474: 0.452171    1.015703    3.449774    0.411849    0.073755    0.017660    0.693300     #> 475: 0.452197    1.015844    3.449779    0.411768    0.073770    0.017659    0.693318     #> 476: 0.452188    1.015867    3.449768    0.411942    0.073752    0.017644    0.693303     #> 477: 0.452123    1.015853    3.449807    0.411931    0.073742    0.017639    0.693247     #> 478: 0.452057    1.015866    3.449831    0.411898    0.073755    0.017630    0.693248     #> 479: 0.452110    1.015910    3.449821    0.412009    0.073836    0.017626    0.693281     #> 480: 0.452082    1.015948    3.449853    0.411796    0.073889    0.017618    0.693300     #> 481: 0.452104    1.015934    3.449865    0.411555    0.073869    0.017617    0.693285     #> 482: 0.452194    1.015911    3.449872    0.411394    0.073842    0.017615    0.693291     #> 483: 0.452198    1.015858    3.449865    0.411552    0.073859    0.017608    0.693226     #> 484: 0.452145    1.015744    3.449853    0.411839    0.073873    0.017608    0.693213     #> 485: 0.452227    1.015818    3.449854    0.412112    0.073847    0.017616    0.693190     #> 486: 0.452313    1.015887    3.449865    0.411974    0.073857    0.017608    0.693169     #> 487: 0.452561    1.015909    3.449931    0.412090    0.073844    0.017614    0.693174     #> 488: 0.452699    1.015892    3.449983    0.412226    0.073863    0.017619    0.693139     #> 489: 0.452909    1.015813    3.450022    0.412374    0.073819    0.017646    0.693100     #> 490: 0.453162    1.015836    3.450077    0.412771    0.073778    0.017657    0.693028     #> 491: 0.453240    1.015910    3.450127    0.412653    0.073766    0.017663    0.692966     #> 492: 0.453273    1.015901    3.450160    0.412558    0.073743    0.017666    0.692977     #> 493: 0.453260    1.015837    3.450189    0.412548    0.073719    0.017676    0.692968     #> 494: 0.453435    1.015801    3.450213    0.412512    0.073686    0.017691    0.692950     #> 495: 0.453614    1.015789    3.450250    0.412633    0.073637    0.017700    0.692892     #> 496: 0.453737    1.015827    3.450228    0.412614    0.073678    0.017704    0.692919     #> 497: 0.453697    1.015798    3.450203    0.412747    0.073642    0.017701    0.692928     #> 498: 0.453605    1.015820    3.450143    0.412689    0.073603    0.017699    0.692923     #> 499: 0.453690    1.015838    3.450116    0.412936    0.073597    0.017692    0.692869     #> 500: 0.453789    1.015781    3.450094    0.413054    0.073613    0.017685    0.692815     #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 print(fit2) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem table compress    other #> elapsed 0.002448   0.011006 8.272 0.029    0.024 1.478546 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.454  0.196 43.1       1.57 (1.07, 2.31)     71.5   -0.0203%  #> tcl       Log Cl  1.02 0.0853  8.4       2.76 (2.34, 3.26)     27.6      3.46%  #> tv         Log V  3.45 0.0454 1.32       31.5 (28.8, 34.4)     13.4      9.89%  #> add.sd           0.693                               0.693                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 19 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    cp #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.103 -0.491 -0.0820  0    #> 2 1      0.25  2.84  3.27 -0.426  3.87 -1.03  -1.48   0.103 -0.491 -0.0820  3.87 #> 3 1      0.57  6.57  5.85  0.723  6.82 -0.246 -0.356  0.103 -0.491 -0.0820  6.82 #> # … with 129 more rows, and 7 more variables: depot <dbl>, center <dbl>, #> #   ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl> fitN <- nlmixr(one.compartment, theo_sd, list(pnlsTol=0.5), est=\"nlme\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> **Iteration 1 #> LME step: Loglik: -183.2083, nlminb iterations: 1 #> reStruct  parameters: #>       ID1       ID2       ID3  #> 0.2195819 0.9924330 1.6502972  #>  Beginning PNLS step: ..  completed fit_nlme() step. #> PNLS step: RSS =  64.95306  #>  fixed effects: 0.4464074  1.033353  3.45079   #>  iterations: 3  #> Convergence crit. (must all become <= tolerance = 1e-05): #>      fixed   reStruct  #> 0.03227684 0.54047252  #>  #> **Iteration 2 #> LME step: Loglik: -180.6328, nlminb iterations: 1 #> reStruct  parameters: #>       ID1       ID2       ID3  #> 0.1425419 0.9780287 1.6452264  #>  Beginning PNLS step: ..  completed fit_nlme() step. #> PNLS step: RSS =  64.95308  #>  fixed effects: 0.4464074  1.033353  3.45079   #>  iterations: 1  #> Convergence crit. (must all become <= tolerance = 1e-05): #>        fixed     reStruct  #> 0.000000e+00 3.794674e-06  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 print(fitN) #> ── nlmixr nlme by maximum likelihood ─────────────────────────────────────────── #>  #>          OBJF      AIC      BIC Log-likelihood Condition Number #> nlme 118.6658 375.2656 395.4452      -180.6328         9.736076 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup table compress    other #> elapsed 0.002649 0.027    0.007 2.609351 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter   Est.      SE  %RSE Back-transformed(95%CI) BSV(CV%) #> tka       Log Ka 0.4464  0.1442 32.31    1.563 (1.178, 2.073)     66.6 #> tcl       Log Cl  1.033 0.08626 8.347     2.81 (2.373, 3.328)     26.7 #> tv         Log V  3.451 0.04622  1.34    31.53 (28.79, 34.51)     13.5 #> add.sd           0.6988                                0.6988          #>        Shrink(SD)% #> tka        -6.31%  #> tcl         7.24%  #> tv          7.82%  #> add.sd             #>   #>   Covariance Type ($covMethod): nlme #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 19 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    cp #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.06  0.0740 -0.478 -0.0902  0    #> 2 1      0.25  2.84  3.24 -0.404  3.78 -0.944 -1.35  0.0740 -0.478 -0.0902  3.78 #> 3 1      0.57  6.57  5.81  0.756  6.72 -0.147 -0.210 0.0740 -0.478 -0.0902  6.72 #> # … with 129 more rows, and 7 more variables: depot <dbl>, center <dbl>, #> #   ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl> plot(fit) print(fit) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem table compress    other #> elapsed 0.002457   0.009011 1.157 0.028    0.023 2.024532 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka           Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 16 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # … with 129 more rows, and 4 more variables: cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl> fit$eta #>    ID      eta.ka      eta.cl        eta.v #> 1   1  0.10731154 -0.48517165 -0.080931725 #> 2   2  0.22080418  0.14429189  0.020773136 #> 3   3  0.36598441  0.03419804  0.056788684 #> 4   4 -0.28113932 -0.01574487 -0.008637915 #> 5   5 -0.04398605 -0.15197704 -0.141377078 #> 6   6 -0.39515116  0.37444543  0.193442460 #> 7   7 -0.79434925  0.16560786  0.045569689 #> 8   8 -0.18186287  0.16995649  0.093424836 #> 9   9  1.43144889  0.03238919  0.016094182 #> 10 10 -0.73678690 -0.38980303 -0.168358818 #> 11 11  0.77831903  0.28316698  0.144328407 #> 12 12 -0.53103406 -0.11995492 -0.202969357 traceplot(fit) iter <- fit2$par.hist.stacked iter$Parameter[iter$par==\"add.sd\"] <- \"Additive error\" iter$Parameter[iter$par==\"eta.cl\"]  <- \"IIV CL/F\" iter$Parameter[iter$par==\"eta.v\"]   <- \"IIV V/F\" iter$Parameter[iter$par==\"eta.ka\"]  <- \"IIV ka\" iter$Parameter[iter$par==\"tcl\"]     <- \"log(CL/F)\" iter$Parameter[iter$par==\"tv\"]      <- \"log(V/F)\" iter$Parameter[iter$par==\"tka\"]     <- \"log(ka)\" iter$Parameter <- ordered(iter$Parameter, c(\"log(CL/F)\", \"log(V/F)\", \"log(ka)\",                                             \"IIV CL/F\", \"IIV V/F\", \"IIV ka\",                                             \"Additive error\"))  ggplot(iter, aes(iter, val)) +   geom_line(col=\"red\") +    scale_x_continuous(\"Iteration\") +   scale_y_continuous(\"Value\") +   facet_wrap(~ Parameter, scales=\"free_y\") +   labs(title=\"Theophylline single-dose\", subtitle=\"Parameter estimation iterations\") etas <- data.frame(eta = c(fit2$eta$eta.ka, fit2$eta$eta.cl, fit2$eta$eta.v),                    lab = rep(c(\"eta(ka)\", \"eta(CL/F)\", \"eta(V/F)\"), each=nrow(fit2$eta))) etas$lab <- ordered(etas$lab, c(\"eta(CL/F)\",\"eta(V/F)\",\"eta(ka)\"))  ggplot(etas, aes(eta)) +   geom_histogram(fill=\"red\", col=\"white\") +    geom_vline(xintercept=0) +   scale_x_continuous(expression(paste(eta))) +   scale_y_continuous(\"Count\") +   facet_grid(~ lab) +   coord_cartesian(xlim=c(-1.75,1.75)) +   labs(title=\"Theophylline single-dose\", subtitle=\"IIV distributions\")"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"xpose","dir":"Articles","previous_headings":"Running PK models with nlmixr","what":"xpose","title":"Running PK models with nlmixr","text":"nice. really want complete suite model diagnostic tools, like available xpose, right? Restart R, install xpose CRAN, haven’t already… Now install extension nlmixr: … convert nlmixr fit object xpose fit object.    information using xpose, see Uppsala pharmacometrics group’s comprehensive site .","code":"## install.packages(\"xpose\") library(xpose) devtools::install_github(\"nlmixr2/xpose.nlmixr\") library(xpose.nlmixr) xp <- xpose_data_nlmixr(fit2) #>        ID          TIME              DV              AMT         EVID   #>  1      :11   Min.   : 0.000   Min.   : 0.000   Min.   :0   Min.   :0   #>  2      :11   1st Qu.: 0.595   1st Qu.: 2.877   1st Qu.:0   1st Qu.:0   #>  3      :11   Median : 3.530   Median : 5.275   Median :0   Median :0   #>  4      :11   Mean   : 5.895   Mean   : 4.960   Mean   :0   Mean   :0   #>  5      :11   3rd Qu.: 9.000   3rd Qu.: 7.140   3rd Qu.:0   3rd Qu.:0   #>  6      :11   Max.   :24.650   Max.   :11.400   Max.   :0   Max.   :0   #>  (Other):66                                                             #>       CMT          WT             PRED            RES              IPRED       #>  Min.   :2   Min.   :54.60   Min.   :0.000   Min.   :-3.0456   Min.   :0.000   #>  1st Qu.:2   1st Qu.:63.58   1st Qu.:3.471   1st Qu.:-0.9546   1st Qu.:3.128   #>  Median :2   Median :70.50   Median :5.515   Median :-0.1108   Median :5.428   #>  Mean   :2   Mean   :69.58   Mean   :5.025   Mean   :-0.0642   Mean   :4.999   #>  3rd Qu.:2   3rd Qu.:74.42   3rd Qu.:7.265   3rd Qu.: 0.7469   3rd Qu.:7.075   #>  Max.   :2   Max.   :86.40   Max.   :8.583   Max.   : 4.2147   Max.   :9.804   #>                                                                                #>       IRES              IWRES              ETA.KA              ETA.CL          #>  Min.   :-2.30170   Min.   :-3.32225   Min.   :-0.798170   Min.   :-0.490712   #>  1st Qu.:-0.29296   1st Qu.:-0.42285   1st Qu.:-0.436312   1st Qu.:-0.134923   #>  Median : 0.00000   Median : 0.00000   Median :-0.109144   Median : 0.035380   #>  Mean   :-0.03871   Mean   :-0.05587   Mean   :-0.004456   Mean   : 0.002638   #>  3rd Qu.: 0.20151   3rd Qu.: 0.29085   3rd Qu.: 0.255856   3rd Qu.: 0.168102   #>  Max.   : 2.77714   Max.   : 4.00849   Max.   : 1.429816   Max.   : 0.388593   #>                                                                                #>      ETA.V                 CP            DEPOT              CENTER      #>  Min.   :-0.195522   Min.   :0.000   Min.   :  0.0000   Min.   :  0.0   #>  1st Qu.:-0.095508   1st Qu.:3.128   1st Qu.:  0.0004   1st Qu.:101.0   #>  Median : 0.016087   Median :5.428   Median :  2.5415   Median :166.9   #>  Mean   :-0.002467   Mean   :4.999   Mean   : 69.0922   Mean   :155.9   #>  3rd Qu.: 0.065787   3rd Qu.:7.075   3rd Qu.:120.2246   3rd Qu.:226.4   #>  Max.   : 0.184904   Max.   :9.804   Max.   :320.6500   Max.   :286.8   #>                                                                         #>        KA               CL              V              TAD            DOSENUM  #>  Min.   :0.7087   Min.   :1.691   Min.   :25.91   Min.   : 0.000   Min.   :1   #>  1st Qu.:1.0188   1st Qu.:2.413   1st Qu.:28.64   1st Qu.: 0.595   1st Qu.:1   #>  Median :1.4154   Median :2.861   Median :32.01   Median : 3.530   Median :1   #>  Mean   :1.9538   Mean   :2.853   Mean   :31.63   Mean   : 5.895   Mean   :1   #>  3rd Qu.:2.0372   3rd Qu.:3.267   3rd Qu.:33.65   3rd Qu.: 9.000   3rd Qu.:1   #>  Max.   :6.5772   Max.   :4.073   Max.   :37.90   Max.   :24.650   Max.   :1   #>                                                                                #>       WRES              CPRED            CRES              CWRES          #>  Min.   :-1.94205   Min.   :0.000   Min.   :-2.58246   Min.   :-2.14627   #>  1st Qu.:-0.66636   1st Qu.:3.434   1st Qu.:-0.96926   1st Qu.:-0.68995   #>  Median :-0.09749   Median :5.523   Median :-0.09416   Median :-0.07605   #>  Mean   :-0.02151   Mean   :5.049   Mean   :-0.08828   Mean   :-0.07784   #>  3rd Qu.: 0.47996   3rd Qu.:7.497   3rd Qu.: 0.74108   3rd Qu.: 0.39650   #>  Max.   : 2.37019   Max.   :9.561   Max.   : 3.83596   Max.   : 2.00705   #>                                                                           #>      eta.ka              eta.cl              eta.v           #>  Min.   :-0.798170   Min.   :-0.490712   Min.   :-0.195522   #>  1st Qu.:-0.436312   1st Qu.:-0.134923   1st Qu.:-0.095508   #>  Median :-0.109144   Median : 0.035380   Median : 0.016087   #>  Mean   :-0.004456   Mean   : 0.002638   Mean   :-0.002467   #>  3rd Qu.: 0.255856   3rd Qu.: 0.168102   3rd Qu.: 0.065787   #>  Max.   : 1.429816   Max.   : 0.388593   Max.   : 0.184904   #> dv_vs_pred(xp) dv_vs_ipred(xp) dv_vs_pred(xp) absval_res_vs_pred(xp, res=\"IWRES\")"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"the-ui","dir":"Articles","previous_headings":"","what":"The UI","title":"Running PK models with nlmixr","text":"nlmixr modeling dialect, inspired R NONMEM, can used fit models using current future estimation algorithms within nlmixr. Using widely-used tools inspiration advantage delivering model specification syntax instantly familiar majority analysts working pharmacometrics related fields.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"overall-model-structure","dir":"Articles","previous_headings":"The UI","what":"Overall model structure","title":"Running PK models with nlmixr","text":"Model specifications nlmixr written using functions containing ini model blocks. functions can called anything, must contain two components. Let’s look simple one-compartment model covariates.","code":"f <- function() {   ini({   # Initial conditions/variables     # are specified here   })   model({ # The model is specified     # here   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"the-ini-block","dir":"Articles","previous_headings":"The UI > Overall model structure","what":"The ini block","title":"Running PK models with nlmixr","text":"ini block specifies initial conditions, including initial estimates boundaries algorithms support (currently, built-nlme saem methods ). Nomenclature similar used NONMEM, Monolix similar packages. NONMEM world, ini block analogous $THETA, $OMEGA $SIGMA blocks. shown example: Simple parameter values specified using R-compatible assignment Boundaries may specified c(lower, est, upper). Like NONMEM, c(lower,est) equivalent c(lower,est,Inf) Also like NONMEM, c(est) specify lower bound, equivalent specifying parameter without using R’s c() function. parameters can named using almost R-compatible name. Please note : Residual error estimates coded population estimates (.e. using = <-, ~). Variable names start _ supported. Note R allow variable starting _ assigned without quoting . Naming variables start rx_ nlmixr_ allowed, since rxode2() nlmixr use prefixes internally certain estimation routines calculating residuals. Variable names case-sensitive, just like R. CL Cl. mixture models, multivariate normal individual deviations normal population parameters estimated (NONMEM called “ETA” parameters). Additionally, variance/covariance matrix deviations also estimated (NONMEM “OMEGA” matrix). also take initial estimates. nlmixr, specified ~ operator. typically used statistics R “modeled ”, chosen distinguish estimates population residual error parameters. Continuing prior example, can annotate estimates -subject error distribution… shown example: Simple variances specified variable name estimate separated ~. Correlated parameters specified sum variable labels lower triangular matrix covariance specified left handed side equation. also separated ~. initial estimates specified variance scale, analogy NONMEM, square roots diagonal elements correspond coefficients variation used exponential IIV implementation. Currently, comments inside lower triangular matrix allowed.","code":"f <- function() { # Note that arguments to the function are currently   # ignored by nlmixr   ini({     # Initial conditions for population parameters (sometimes     # called THETA parameters) are defined by either '<-' or '='     lCl <- 1.6      # log Cl (L/hr)          # Note that simple expressions that evaluate to a number are     # OK for defining initial conditions (like in R)     lVc = log(90)  # log V (L)          ## Also, note that a comment on a parameter is captured as a parameter label     lKa <- 1       # log Ka (1/hr)          # Bounds may be specified by c(lower, est, upper), like NONMEM:     # Residuals errors are assumed to be population parameters     prop.err <- c(0, 0.2, 1)          # IIV terms will be discussed in the next example   })      # The model block will be discussed later   model({}) } f <- function() {   ini({     lCl <- 1.6      # log Cl (L/hr)     lVc = log(90)   # log V (L)     lKa <- 1        # log Ka (1/hr)     prop.err <- c(0, 0.2, 1)          # Initial estimate for ka IIV variance     # Labels work for single parameters     eta.ka ~ 0.1    ## BSV Ka      # For correlated parameters, you specify the names of each     # correlated parameter separated by a addition operator `+`     # and the left handed side specifies the lower triangular     # matrix initial of the covariance matrix.     eta.cl + eta.vc ~ c(0.1,                         0.005, 0.1)          # Note that labels do not currently work for correlated     # parameters.  Also, do not put comments inside the lower     # triangular matrix as this will currently break the model.   })      # The model block will be discussed later   model({}) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"the-model-block","dir":"Articles","previous_headings":"The UI > Overall model structure","what":"The model block","title":"Running PK models with nlmixr","text":"model block specifies model, analogous $PK, $PRED $ERROR blocks NONMEM. initialization block defined, can define model terms variables defined ini block. can also mix rxode2() blocks model needed. current method defining nlmixr model specify parameters, required rxode2() lines. Continuing annotated example: points note: Parameters defined differential equations. Currently directly defining differential equations terms population parameters supported. differential equations, parameters error terms single block, instead multiple sections. Additionally state names, calculated variables, also start either rx_ nlmixr_ since used internally estimation routines. Errors specified using tilde, ~. Currently can use either add(parameter) additive error, prop(parameter) proportional error add(parameter1) + prop(parameter2) combined additive proportional error. can also specify norm(parameter) additive error, since follows normal distribution. routines, like saem, require parameters expressed terms Pop.Parameter + Individual.Deviation.Parameter + Covariate*Covariate.Parameter. order parameters matter. similar NONMEM’s mu-referencing, though restrictive. means saem, parameterization form Cl <- Cl*exp(eta.Cl) allowed. type parameter model determined ini block; covariates used model included ini block. variables need present modeling dataset model run.","code":"f <- function() {   ini({     lCl <- 1.6       # log Cl (L/hr)     lVc <- log(90)   # log Vc (L)     lKA <- 0.1       # log Ka (1/hr)     prop.err <- c(0, 0.2, 1)          eta.Cl ~ 0.1     # BSV Cl     eta.Vc ~ 0.1     # BSV Vc     eta.KA ~ 0.1     # BSV Ka   })   model({     # Parameters are defined in terms of the previously-defined     # parameter names:     Cl <- exp(lCl + eta.Cl)     Vc =  exp(lVc + eta.Vc)     KA <- exp(lKA + eta.KA)          # Next, the differential equations are defined:     kel <- Cl / Vc;          d/dt(depot)  = -KA*depot;     d/dt(centr)  =  KA*depot-kel*centr;          # And the concentration is then calculated     cp = centr / Vc;     # Finally, we specify that the plasma concentration follows     # a proportional error distribution (estimated by the parameter      # prop.err)     cp ~ prop(prop.err)   })  }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"running-models","dir":"Articles","previous_headings":"The UI","what":"Running models","title":"Running PK models with nlmixr","text":"Models can fitted several ways, including via [magrittr] forward-pipe operator. Options estimation routines can specified using nlmeControl nlme estimation: options specified nlme documentation. Options saem can specified using saemControl: example specifies 250 burn-iterations, 350 em iterations print progress every 50 runs.","code":"fit <- nlmixr(one.compartment) %>% saem.fit(data=theo_sd) fit2 <- nlmixr(one.compartment, data=theo_sd, est=\"saem\") fit3 <- one.compartment %>% saem.fit(data=theo_sd) fit4 <- nlmixr(one.compartment, theo_sd,est=\"nlme\",control = nlmeControl(pnlsTol = .5)) fit5 <- nlmixr(one.compartment,theo_sd,est=\"saem\",control=saemControl(n.burn=250,n.em=350,print=50))"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"model-syntax-for-solved-pk-systems","dir":"Articles","previous_headings":"The UI","what":"Model Syntax for solved PK systems","title":"Running PK models with nlmixr","text":"Solved PK systems also currently supported nlmixr ‘linCmt()’ pseudo-function. annotated example solved system : things keep mind: * Currently solved systems support either oral dosing, IV dosing IV infusion dosing allow mixing dosing types. * rxode2() allows mixing solved systems ODEs, implemented nlmixr yet. * solved systems implemented one, two three compartment models without first-order absorption. models support lag time tlag parameter. * general linear compartment model figures model parameter names. nlmixr currently knows numbered volumes, Vc/Vp, Clearances terms Cl Q/CLD. Additionally nlmixr knows elimination micro-constants (ie K12). Mixing parameters models currently supported.","code":"f <- function(){   ini({     lCl <- 1.6      #log Cl (L/hr)     lVc <- log(90)  #log Vc (L)     lKA <- 0.1      #log Ka (1/hr)     prop.err <- c(0, 0.2, 1)     eta.Cl ~ 0.1   # BSV Cl     eta.Vc ~ 0.1   # BSV Vc     eta.KA ~ 0.1   # BSV Ka   })   model({     Cl <- exp(lCl + eta.Cl)     Vc = exp(lVc + eta.Vc)     KA <- exp(lKA + eta.KA)     ## Instead of specifying the ODEs, you can use     ## the linCmt() function to use the solved system.     ##     ## This function determines the type of PK solved system     ## to use by the parameters that are defined.  In this case     ## it knows that this is a one-compartment model with first-order     ## absorption.     linCmt() ~ prop(prop.err)   }) }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/running_nlmixr.html","id":"checking-model-syntax","dir":"Articles","previous_headings":"The UI","what":"Checking model syntax","title":"Running PK models with nlmixr","text":"specifying model syntax can check nlmixr interpreting correctly using nlmixr function . Using function can get: general gives information model (type solved system/rxode2()), initial estimates well code model block.","code":"nlmixr(f) #>  ── rxode2-based solved PK 1-compartment model with first-order absorption ──────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>      lCl      lVc      lKA prop.err  #>  1.60000  4.49981  0.10000  0.20000  #>  #> Omega ($omega):  #>        eta.Cl eta.Vc eta.KA #> eta.Cl    0.1    0.0    0.0 #> eta.Vc    0.0    0.1    0.0 #> eta.KA    0.0    0.0    0.1 #>  ── μ-referencing ($muRefTable): ──   #>   theta    eta level #> 1   lCl eta.Cl    id #> 2   lVc eta.Vc    id #> 3   lKA eta.KA    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         lCl <- 1.6 #>         label(\"log Cl (L/hr)\") #>         lVc <- 4.49980967033027 #>         label(\"log Vc (L)\") #>         lKA <- 0.1 #>         label(\"log Ka (1/hr)\") #>         prop.err <- c(0, 0.2, 1) #>         label(\"BSV Ka\") #>         eta.Cl ~ 0.1 #>         eta.Vc ~ 0.1 #>         eta.KA ~ 0.1 #>     }) #>     model({ #>         Cl <- exp(lCl + eta.Cl) #>         Vc = exp(lVc + eta.Vc) #>         KA <- exp(lKA + eta.KA) #>         linCmt() ~ prop(prop.err) #>     }) #> }"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/wbc.html","id":"fit-model-using-saem","dir":"Articles","previous_headings":"","what":"Fit model using saem","title":"Friberg myelosuppression model","text":"","code":"d3 = read.csv(\"Simulated_WBC_pacl_ddmore_samePK_nlmixr.csv\", na.string = \".\")  fit.S <- nlmixr(wbc, d3, est=\"saem\", list(print=0), table=list(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:03  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  library(xpose.nlmixr)  xpdb <- xpose_data_nlmixr(fit.S) #>        ID           TIME             RATE        AMT          DV         #>  33     : 18   Min.   :   0.0   Min.   :0   Min.   :0   Min.   : 0.700   #>  12     :  6   1st Qu.:   0.0   1st Qu.:0   1st Qu.:0   1st Qu.: 3.675   #>  44     :  5   Median : 276.0   Median :0   Median :0   Median : 5.800   #>  1      :  4   Mean   : 451.7   Mean   :0   Mean   :0   Mean   : 6.428   #>  4      :  4   3rd Qu.: 480.0   3rd Qu.:0   3rd Qu.:0   3rd Qu.: 8.375   #>  5      :  4   Max.   :4580.0   Max.   :0   Max.   :0   Max.   :20.400   #>  (Other):135                                                             #>       CMT         V2I              V1I             CLI           PARFLAG  #>  Min.   :3   Min.   : 663.0   Min.   :179.0   Min.   :151.0   Min.   :0   #>  1st Qu.:3   1st Qu.: 917.2   1st Qu.:358.0   1st Qu.:262.5   1st Qu.:0   #>  Median :3   Median :1010.0   Median :410.0   Median :323.0   Median :0   #>  Mean   :3   Mean   : 999.8   Mean   :421.5   Mean   :328.9   Mean   :0   #>  3rd Qu.:3   3rd Qu.:1060.0   3rd Qu.:485.0   3rd Qu.:377.2   3rd Qu.:0   #>  Max.   :3   Max.   :1390.0   Max.   :679.0   Max.   :619.0   Max.   :0   #>                                                                           #>       EVID       EPRED             ERES              NPDE            #>  Min.   :0   Min.   : 2.113   Min.   :-7.7217   Min.   :-2.7130519   #>  1st Qu.:0   1st Qu.: 4.457   1st Qu.:-2.2585   1st Qu.:-0.6536562   #>  Median :0   Median : 7.730   Median :-0.7159   Median :-0.0334291   #>  Mean   :0   Mean   : 6.696   Mean   :-0.2672   Mean   : 0.0000195   #>  3rd Qu.:0   3rd Qu.: 8.423   3rd Qu.: 1.5209   3rd Qu.: 0.7279133   #>  Max.   :0   Max.   :11.073   Max.   :14.6532   Max.   : 2.7130519   #>                                                                      #>       NPD                  PRED             RES               WRES         #>  Min.   :-2.7130519   Min.   : 1.506   Min.   :-8.1628   Min.   :-1.6762   #>  1st Qu.:-0.6536562   1st Qu.: 3.861   1st Qu.:-1.9112   1st Qu.:-0.7231   #>  Median :-0.0334291   Median : 7.522   Median :-0.2987   Median :-0.1000   #>  Mean   : 0.0000195   Mean   : 6.320   Mean   : 0.1084   Mean   : 0.0835   #>  3rd Qu.: 0.7279133   3rd Qu.: 7.699   3rd Qu.: 1.9165   3rd Qu.: 0.7245   #>  Max.   : 2.7130519   Max.   :11.570   Max.   :15.5450   Max.   : 5.9017   #>                                                                            #>      IPRED              IRES               IWRES                CPRED        #>  Min.   : 0.6196   Min.   :-6.536908   Min.   :-2.3109441   Min.   :-4.196   #>  1st Qu.: 3.9270   1st Qu.:-0.536075   1st Qu.:-0.5471058   1st Qu.: 3.634   #>  Median : 6.1222   Median : 0.000618   Median : 0.0006606   Median : 6.111   #>  Mean   : 6.3883   Mean   : 0.040116   Mean   :-0.0869993   Mean   : 5.859   #>  3rd Qu.: 8.6636   3rd Qu.: 0.576408   3rd Qu.: 0.3617582   3rd Qu.: 7.677   #>  Max.   :15.8990   Max.   : 5.427836   Max.   : 2.0875911   Max.   :14.989   #>                                                                              #>       CRES             CWRES            ETA.CIRC0           ETA.MTT           #>  Min.   :-5.5566   Min.   :-2.70241   Min.   :-0.82137   Min.   :-0.3565698   #>  1st Qu.:-1.5183   1st Qu.:-0.86270   1st Qu.:-0.22980   1st Qu.:-0.0857153   #>  Median :-0.1647   Median :-0.06106   Median :-0.00503   Median : 0.0506072   #>  Mean   : 0.5697   Mean   :-0.14162   Mean   :-0.06248   Mean   : 0.0009022   #>  3rd Qu.: 2.0185   3rd Qu.: 0.65107   3rd Qu.: 0.22797   3rd Qu.: 0.1034825   #>  Max.   :18.6962   Max.   : 2.47053   Max.   : 0.51756   Max.   : 0.3746142   #>                                                                               #>    ETA.SLOPU           A_CENTR              A_PERIPH             A_PROL        #>  Min.   :-0.51756   Min.   :-2.000e-08   Min.   :0.0000000   Min.   : 0.7901   #>  1st Qu.:-0.22665   1st Qu.: 0.000e+00   1st Qu.:0.0000000   1st Qu.: 4.6138   #>  Median :-0.11168   Median : 0.000e+00   Median :0.0000000   Median : 7.2413   #>  Mean   :-0.04416   Mean   : 2.817e-04   Mean   :0.0008848   Mean   : 7.2321   #>  3rd Qu.: 0.09229   3rd Qu.: 0.000e+00   3rd Qu.:0.0000000   3rd Qu.: 9.6738   #>  Max.   : 0.79047   Max.   : 4.933e-02   Max.   :0.1543434   Max.   :19.1385   #>                                                                                #>      A_TR1            A_TR2             A_TR3             A_CIRC        #>  Min.   : 0.700   Min.   : 0.6446   Min.   : 0.7466   Min.   : 0.6196   #>  1st Qu.: 4.358   1st Qu.: 4.0886   1st Qu.: 3.8571   1st Qu.: 3.9270   #>  Median : 6.975   Median : 6.5607   Median : 6.2229   Median : 6.1222   #>  Mean   : 6.964   Mean   : 6.7218   Mean   : 6.5254   Mean   : 6.3883   #>  3rd Qu.: 9.381   3rd Qu.: 9.1819   3rd Qu.: 8.9956   3rd Qu.: 8.6636   #>  Max.   :18.062   Max.   :16.3480   Max.   :15.9568   Max.   :15.8990   #>                                                                         #>      CIRC0             MTT            SLOPU           GAMMA        #>  Min.   : 3.386   Min.   : 81.4   Min.   :18.21   Min.   :0.2094   #>  1st Qu.: 6.119   1st Qu.:106.7   1st Qu.:24.35   1st Qu.:0.2094   #>  Median : 7.660   Median :122.3   Median :27.32   Median :0.2094   #>  Mean   : 7.671   Mean   :118.0   Mean   :30.66   Mean   :0.2094   #>  3rd Qu.: 9.670   3rd Qu.:128.9   3rd Qu.:33.51   3rd Qu.:0.2094   #>  Max.   :12.918   Max.   :169.1   Max.   :67.34   Max.   :0.2094   #>                                                                    #>        CL              V1              V2              CONC            #>  Min.   :151.0   Min.   :179.0   Min.   : 663.0   Min.   :-1.000e-11   #>  1st Qu.:262.5   1st Qu.:358.0   1st Qu.: 917.2   1st Qu.: 0.000e+00   #>  Median :323.0   Median :410.0   Median :1010.0   Median : 0.000e+00   #>  Mean   :328.9   Mean   :421.5   Mean   : 999.8   Mean   : 4.569e-07   #>  3rd Qu.:377.2   3rd Qu.:485.0   3rd Qu.:1060.0   3rd Qu.: 1.000e-11   #>  Max.   :619.0   Max.   :679.0   Max.   :1390.0   Max.   : 7.969e-05   #>                                                                        #>       KTR              EDRUG             FDBK             TAD        #>  Min.   :0.02365   Min.   :0.9958   Min.   :0.8684   Min.   :  0.0   #>  1st Qu.:0.03102   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:  0.0   #>  Median :0.03270   Median :1.0000   Median :1.0080   Median :216.0   #>  Mean   :0.03487   Mean   :1.0000   Mean   :1.0670   Mean   :247.1   #>  3rd Qu.:0.03748   3rd Qu.:1.0000   3rd Qu.:1.1212   3rd Qu.:360.0   #>  Max.   :0.04914   Max.   :1.0000   Max.   :1.6628   Max.   :720.0   #>                                                      NA's   :1       #>     DOSENUM       eta.CIRC0           eta.MTT             eta.SLOPU        #>  Min.   :0.00   Min.   :-0.82137   Min.   :-0.3565698   Min.   :-0.51756   #>  1st Qu.:1.00   1st Qu.:-0.22980   1st Qu.:-0.0857153   1st Qu.:-0.22665   #>  Median :1.00   Median :-0.00503   Median : 0.0506072   Median :-0.11168   #>  Mean   :1.25   Mean   :-0.06248   Mean   : 0.0009022   Mean   :-0.04416   #>  3rd Qu.:1.00   3rd Qu.: 0.22797   3rd Qu.: 0.1034825   3rd Qu.: 0.09229   #>  Max.   :6.00   Max.   : 0.51756   Max.   : 0.3746142   Max.   : 0.79047   #>   plot(fit.S) print(dv_vs_pred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(dv_vs_ipred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Individual Predicted Neutrophil Count (10^9/L)\")) print(res_vs_pred(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(res_vs_idv(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Time (h)\")) print(prm_vs_iteration(xpdb)) print(absval_res_vs_idv(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_pred(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(ind_plots(xpdb, nrow=3, ncol=4) +       ylab(\"Predicted and Observed Neutrophil Count (10^9/L)\") +       xlab(\"Time (h)\")) print(res_distrib(xpdb) +       ylab(\"Density\") +       xlab(\"Conditional Weighted Residuals\")) vpcPlot(fit.S, n=500, n_bins = 10, show=list(obs_dv=T),         ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:06 vpcPlot(fit.S, n=500, bins = c(0,170,300,350,500,600,900,3000,4580),         show=list(obs_dv=T), ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:05"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/wbc.html","id":"fit-model-using-focei","dir":"Articles","previous_headings":"","what":"Fit model using FOCEi","title":"Friberg myelosuppression model","text":"","code":"fit.F <- nlmixr(wbc, d3, est=\"focei\", list(print=0), table=list(cwres=TRUE, npde=TRUE)) #> calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:31  #> done #> [====|====|====|====|====|====|====|====|====|====] 0:00:03"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/wbc.html","id":"focei-goodness-of-fit-plots","dir":"Articles","previous_headings":"Fit model using FOCEi","what":"FOCEi Goodness of fit plots","title":"Friberg myelosuppression model","text":"","code":"xpdb <- xpose_data_nlmixr(fit.F) #>        ID           TIME             RATE        AMT          DV         #>  33     : 18   Min.   :   0.0   Min.   :0   Min.   :0   Min.   : 0.700   #>  12     :  6   1st Qu.:   0.0   1st Qu.:0   1st Qu.:0   1st Qu.: 3.675   #>  44     :  5   Median : 276.0   Median :0   Median :0   Median : 5.800   #>  1      :  4   Mean   : 451.7   Mean   :0   Mean   :0   Mean   : 6.428   #>  4      :  4   3rd Qu.: 480.0   3rd Qu.:0   3rd Qu.:0   3rd Qu.: 8.375   #>  5      :  4   Max.   :4580.0   Max.   :0   Max.   :0   Max.   :20.400   #>  (Other):135                                                             #>       CMT         V2I              V1I             CLI           PARFLAG  #>  Min.   :3   Min.   : 663.0   Min.   :179.0   Min.   :151.0   Min.   :0   #>  1st Qu.:3   1st Qu.: 917.2   1st Qu.:358.0   1st Qu.:262.5   1st Qu.:0   #>  Median :3   Median :1010.0   Median :410.0   Median :323.0   Median :0   #>  Mean   :3   Mean   : 999.8   Mean   :421.5   Mean   :328.9   Mean   :0   #>  3rd Qu.:3   3rd Qu.:1060.0   3rd Qu.:485.0   3rd Qu.:377.2   3rd Qu.:0   #>  Max.   :3   Max.   :1390.0   Max.   :679.0   Max.   :619.0   Max.   :0   #>                                                                           #>       EVID       EPRED             ERES               NPDE          #>  Min.   :0   Min.   :-5.933   Min.   :-13.9504   Min.   :-0.22754   #>  1st Qu.:0   1st Qu.: 3.278   1st Qu.: -3.3752   1st Qu.:-0.04179   #>  Median :0   Median : 5.841   Median : -0.3651   Median : 0.01671   #>  Mean   :0   Mean   : 6.264   Mean   :  0.1641   Mean   : 0.02150   #>  3rd Qu.:0   3rd Qu.: 8.761   3rd Qu.:  2.8424   3rd Qu.: 0.07527   #>  Max.   :0   Max.   :22.419   Max.   : 17.0043   Max.   : 0.37634   #>                                                                     #>       NPD                PRED             RES                WRES           #>  Min.   :-0.22754   Min.   : 1.769   Min.   :-8.31049   Min.   :-0.077650   #>  1st Qu.:-0.04179   1st Qu.: 3.997   1st Qu.:-1.84761   1st Qu.:-0.032655   #>  Median : 0.01671   Median : 7.211   Median :-0.07836   Median :-0.001942   #>  Mean   : 0.02150   Mean   : 6.170   Mean   : 0.25881   Mean   : 0.005816   #>  3rd Qu.: 0.07527   3rd Qu.: 7.223   3rd Qu.: 2.13908   3rd Qu.: 0.035374   #>  Max.   : 0.37634   Max.   :11.457   Max.   :15.47635   Max.   : 0.331424   #>                                                                             #>      IPRED             IRES             IWRES               CPRED        #>  Min.   :0.5768   Min.   :-3.5124   Min.   :-0.063104   Min.   : 1.150   #>  1st Qu.:2.4919   1st Qu.: 0.4658   1st Qu.: 0.009421   1st Qu.: 3.635   #>  Median :3.8123   Median : 1.7984   Median : 0.055027   Median : 5.943   #>  Mean   :3.9290   Mean   : 2.4994   Mean   : 0.073607   Mean   : 5.644   #>  3rd Qu.:5.3495   3rd Qu.: 4.1565   3rd Qu.: 0.106029   3rd Qu.: 6.952   #>  Max.   :7.7763   Max.   :17.3333   Max.   : 0.565211   Max.   :10.659   #>                                                                          #>       CRES             CWRES            ETA.CIRC0           ETA.MTT          #>  Min.   :-5.7439   Min.   :-0.16495   Min.   :-1.00000   Min.   :-0.070770   #>  1st Qu.:-1.2207   1st Qu.:-0.03677   1st Qu.:-0.39799   1st Qu.:-0.003319   #>  Median : 0.2667   Median : 0.01087   Median :-0.39175   Median : 0.030900   #>  Mean   : 0.7847   Mean   : 0.02183   Mean   :-0.43184   Mean   : 0.037894   #>  3rd Qu.: 2.6182   3rd Qu.: 0.06451   3rd Qu.:-0.30044   3rd Qu.: 0.050633   #>  Max.   :15.8496   Max.   : 0.51613   Max.   :-0.09985   Max.   : 0.220879   #>                                                                              #>    ETA.SLOPU           A_CENTR              A_PERIPH              A_PROL       #>  Min.   :-0.04189   Min.   :-5.390e-06   Min.   :-2.500e-06   Min.   :0.3636   #>  1st Qu.: 0.11260   1st Qu.: 0.000e+00   1st Qu.: 0.000e+00   1st Qu.:2.7752   #>  Median : 0.16447   Median : 0.000e+00   Median : 0.000e+00   Median :4.9537   #>  Mean   : 0.18661   Mean   : 2.818e-04   Mean   : 8.848e-04   Mean   :4.5987   #>  3rd Qu.: 0.23089   3rd Qu.: 3.000e-08   3rd Qu.: 7.000e-08   3rd Qu.:6.0565   #>  Max.   : 0.53749   Max.   : 4.933e-02   Max.   : 1.543e-01   Max.   :9.0836   #>                                                                                #>      A_TR1           A_TR2           A_TR3            A_CIRC       #>  Min.   :0.334   Min.   :0.386   Min.   :0.4407   Min.   :0.5768   #>  1st Qu.:2.385   1st Qu.:2.291   1st Qu.:2.3185   1st Qu.:2.4919   #>  Median :4.890   Median :4.800   Median :4.2522   Median :3.8123   #>  Mean   :4.380   Mean   :4.183   Mean   :4.0284   Mean   :3.9290   #>  3rd Qu.:5.768   3rd Qu.:5.352   3rd Qu.:5.3476   3rd Qu.:5.3495   #>  Max.   :9.563   Max.   :9.484   Max.   :8.8454   Max.   :7.7763   #>                                                                    #>      CIRC0            MTT            SLOPU           GAMMA        #>  Min.   :2.653   Min.   :112.9   Min.   :27.13   Min.   :0.2391   #>  1st Qu.:4.843   1st Qu.:120.8   1st Qu.:31.67   1st Qu.:0.2391   #>  Median :4.873   Median :125.0   Median :33.35   Median :0.2391   #>  Mean   :4.766   Mean   :126.2   Mean   :34.35   Mean   :0.2391   #>  3rd Qu.:5.339   3rd Qu.:127.5   3rd Qu.:35.64   3rd Qu.:0.2391   #>  Max.   :6.525   Max.   :151.1   Max.   :48.43   Max.   :0.2391   #>                                                                   #>        CL              V1              V2              CONC            #>  Min.   :151.0   Min.   :179.0   Min.   : 663.0   Min.   :-2.340e-09   #>  1st Qu.:262.5   1st Qu.:358.0   1st Qu.: 917.2   1st Qu.: 0.000e+00   #>  Median :323.0   Median :410.0   Median :1010.0   Median : 0.000e+00   #>  Mean   :328.9   Mean   :421.5   Mean   : 999.8   Mean   : 4.571e-07   #>  3rd Qu.:377.2   3rd Qu.:485.0   3rd Qu.:1060.0   3rd Qu.: 1.000e-11   #>  Max.   :619.0   Max.   :679.0   Max.   :1390.0   Max.   : 7.969e-05   #>                                                                        #>       KTR              EDRUG             FDBK            TAD        #>  Min.   :0.02647   Min.   :0.9973   Min.   :0.885   Min.   :  0.0   #>  1st Qu.:0.03138   1st Qu.:1.0000   1st Qu.:1.000   1st Qu.:  0.0   #>  Median :0.03200   Median :1.0000   Median :1.038   Median :216.0   #>  Mean   :0.03185   Mean   :1.0000   Mean   :1.081   Mean   :247.1   #>  3rd Qu.:0.03312   3rd Qu.:1.0000   3rd Qu.:1.169   3rd Qu.:360.0   #>  Max.   :0.03543   Max.   :1.0000   Max.   :1.440   Max.   :720.0   #>                                                     NA's   :1       #>     DOSENUM       eta.CIRC0           eta.MTT            eta.SLOPU        #>  Min.   :0.00   Min.   :-1.00000   Min.   :-0.070770   Min.   :-0.04189   #>  1st Qu.:1.00   1st Qu.:-0.39799   1st Qu.:-0.003319   1st Qu.: 0.11260   #>  Median :1.00   Median :-0.39175   Median : 0.030900   Median : 0.16447   #>  Mean   :1.25   Mean   :-0.43184   Mean   : 0.037894   Mean   : 0.18661   #>  3rd Qu.:1.00   3rd Qu.:-0.30044   3rd Qu.: 0.050633   3rd Qu.: 0.23089   #>  Max.   :6.00   Max.   :-0.09985   Max.   : 0.220879   Max.   : 0.53749   #>  plot(fit.F) print(dv_vs_pred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(dv_vs_ipred(xpdb) +       ylab(\"Observed Neutrophil Count (10^9/L)\") +       xlab(\"Individual Predicted Neutrophil Count (10^9/L)\")) print(res_vs_pred(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(res_vs_idv(xpdb) +       ylab(\"Conditional Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_idv(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Time (h)\")) print(absval_res_vs_pred(xpdb, res = 'IWRES') +       ylab(\"Individual Weighted Residuals\") +       xlab(\"Population Predicted Neutrophil Count (10^9/L)\")) print(ind_plots(xpdb, nrow=3, ncol=4) +       ylab(\"Predicted and Observed Neutrophil Count (10^9/L)\") +       xlab(\"Time (h)\")) print(res_distrib(xpdb) +       ylab(\"Density\") +       xlab(\"Conditional Weighted Residuals\")) #vpc.ui(fit.S, n=500, show=list(obs_dv=T), ylab = \"Neutrophil count (10^9/L)\", xlab = \"Time (h)\") # 10 bins is slightly better than auto bin vpcPlot(fit.F, n=500, n_bins = 10, show=list(obs_dv=T),         ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:06 # specify bins vpcPlot(fit.F, n=500, bins = c(0,170,300,350,500,600,900,3000,4580),         show=list(obs_dv=T),         ylab = \"Neutrophil Count (10^9/L)\", xlab = \"Time (h)\") #> [====|====|====|====|====|====|====|====|====|====] 0:00:06"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"load-the-data","dir":"Articles","previous_headings":"","what":"Load the data","title":"xgxr and ggPMX integration with nlmixr2","text":"","code":"pkpd_data <- case1_pkpd %>%   arrange(DOSE) %>%   select(-IPRED) %>%   mutate(TRTACT_low2high = factor(TRTACT, levels = unique(TRTACT)),          TRTACT_high2low = factor(TRTACT, levels = rev(unique(TRTACT))),          DAY_label = paste(\"Day\", PROFDAY),          DAY_label = ifelse(DAY_label == \"Day 0\",\"Baseline\",DAY_label))   pk_data <- pkpd_data %>%   filter(CMT == 2)  pk_data_cycle1 <- pk_data %>%   filter(CYCLE == 1)"},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"use-xgxr-for-simplified-concentration-over-time-colored-by-dose-mean---95-ci","dir":"Articles","previous_headings":"Exploratory analysis using ggplot and xgx helper functions","what":"Use xgxr for simplified concentration over time, colored by Dose, mean +/- 95% CI","title":"xgxr and ggPMX integration with nlmixr2","text":"Often exploring data worthwhile plot dose nominal time add 95% confidence interval. typical plot can cumbersome lack nice features xgxr can help . Note following helper functions: xgx_theme_set() sets theme black white color theme best practices xgxr. xgx_geom_ci() creates Confidence Interval mean plots simple interface. xgx_scale_y_log10() creates log-scale includes minor grids immediately show viewer plot semi-log plot without carefully examining y axis. xgx_scale_x_time_units() creates appropriate scale based times observed units use. also allows convert units easily right display. xgx_annote_status() adds DRAFT annotation often considered best practice data plots draft.  plot see mean concentrations confidence intervals stratified dose","code":"xgx_theme_set() # This uses black and white theme based on xgxr best                 # practices  # flag for labeling figures as draft status <- \"DRAFT\"  time_units_dataset <- \"hours\" time_units_plot    <- \"days\" trtact_label       <- \"Dose\" dose_label         <- \"Dose (mg)\" conc_label         <- \"Concentration (ng/ml)\"  auc_label          <- \"AUCtau (h.(ng/ml))\" concnorm_label     <- \"Normalized Concentration (ng/ml)/mg\" sex_label          <- \"Sex\" w100_label         <- \"WEIGHTB>100\" pd_label           <- \"FEV1 (mL)\" cens_label         <- \"Censored\"   ggplot(data = pk_data_cycle1, aes(x     = NOMTIME,                                   y     = LIDV,                                   group = DOSE,                                   color = TRTACT_high2low)) +     xgx_geom_ci(conf_level = 0.95) + # Easy CI with xgxr     xgx_scale_y_log10() + # semi-log plots with semi-log grid minor lines     xgx_scale_x_time_units(units_dataset = time_units_dataset,                            units_plot = time_units_plot) +     # The last line creates an appropriate x scale based on time-units     # and time unit scale     labs(y = conc_label, color = trtact_label) +     xgx_annotate_status(status) #  Adds draft status to plot"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"concentration-over-time-faceted-by-dose-mean---95-ci-overlaid-on-gray-spaghetti-plots","dir":"Articles","previous_headings":"Exploratory analysis using ggplot and xgx helper functions","what":"Concentration over time, faceted by Dose, mean +/- 95% CI, overlaid on gray spaghetti plots","title":"xgxr and ggPMX integration with nlmixr2","text":"useful look mean concentrations, often useful look mean concentrations relationship actual individual profiles. Using ggplot coupled xgxr helper functions used , can easily create plots well:  appears variability seems higher higher doses higher later times.","code":"ggplot(data = pk_data_cycle1, aes(x = TIME, y = LIDV)) +   geom_line(aes(group = ID), color = \"grey50\", size = 1, alpha = 0.3) +   geom_cens(aes(cens=CENS)) +    xgx_geom_ci(aes(x = NOMTIME, color = NULL, group = NULL, shape = NULL), conf_level = 0.95) +   xgx_scale_y_log10() +   xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +   labs(y = conc_label, color = trtact_label) +   theme(legend.position = \"none\") +   facet_grid(.~TRTACT_low2high) +   xgx_annotate_status(status)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"exploring-the-dose-linearity","dir":"Articles","previous_headings":"Exploratory analysis using ggplot and xgx helper functions","what":"Exploring the dose linearity","title":"xgxr and ggPMX integration with nlmixr2","text":"common way explore dose linearity normalize dose. confidence intervals overlap, often dose linear example.  example seems dose-linear, exception censored data. can made even clear removing censored data plot:  lowest dose, censoring, one seems outlier. likely artifact censoring. ways explore data include looking normalized Cmax AUC values (skip vignette).","code":"ggplot(data = pk_data_cycle1,        aes(x = NOMTIME,            y = LIDV / as.numeric(as.character(DOSE)),            group = DOSE,            color = TRTACT_high2low)) +   xgx_geom_ci(conf_level = 0.95, alpha = 0.5, position = position_dodge(1)) +   xgx_scale_y_log10() +   xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +   labs(y = concnorm_label, color = trtact_label) +   xgx_annotate_status(status) ggplot(data = pk_data_cycle1 %>% filter(CENS == 0),        aes(x = NOMTIME,            y = LIDV / as.numeric(as.character(DOSE)),            group = DOSE,            color = TRTACT_high2low)) +   xgx_geom_ci(conf_level = 0.95, alpha = 0.5, position = position_dodge(1)) +   xgx_scale_y_log10() +   xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +   labs(y = concnorm_label, color = trtact_label) +   xgx_annotate_status(status)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"exploring-covariates-in-the-dataset","dir":"Articles","previous_headings":"","what":"Exploring Covariates in the dataset","title":"xgxr and ggPMX integration with nlmixr2","text":"Using xgx helper functions ggplot can explore effect high baseline weight. particular plot shown :  seems weight effect extreme either dose group","code":"ggplot(data = pk_data_cycle1, aes(x = NOMTIME,                                   y = LIDV,                                   group = WEIGHTB > 100,                                   color = WEIGHTB > 100)) +      xgx_geom_ci(conf_level = 0.95) +     xgx_scale_y_log10() +     xgx_scale_x_time_units(units_dataset = time_units_dataset, units_plot = time_units_plot) +     facet_grid(.~DOSE) +     labs(y = conc_label, color = w100_label) +     xgx_annotate_status(status)"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"summary-of-exploratory-analysis-findings","dir":"Articles","previous_headings":"Exploring Covariates in the dataset","what":"Summary of exploratory analysis findings","title":"xgxr and ggPMX integration with nlmixr2","text":"exploratory analysis see: - doses seem proportional - PK seems 2-compartment model - Censoring large effect PK data.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"fitting-the-data-with-nlmixr","dir":"Articles","previous_headings":"","what":"Fitting the data with nlmixr","title":"xgxr and ggPMX integration with nlmixr2","text":"First need subset PK data rename LIDV DV Next, purpose demostrtaion subset 7 patients per dose group): approach good demonstration, allows variety structural models applied quickly developing base model. full dataset can applied selected model make sure makes sense data. Next create 2 compartment model: Now parsing nlmixr model complete start compare models: Now run 3 different estimation methods, can compare results side--side Note additive proportional model additive component approach zero. comparing objective functions log-normal proportional models, proportional model lowest objective function value. (Since modeled log-normal without data transformation appropriate compare AIC/Objective function values)","code":"dat <- case1_pkpd %>%   rename(DV=LIDV) %>%   filter(CMT %in% 1:2) %>%   filter(TRTACT != \"Placebo\") doses <- unique(dat$DOSE) nid <- 7 # 7 ids per dose group dat2 <- do.call(\"rbind\",                 lapply(doses, function(x) {                   ids <- dat %>%                     filter(DOSE == x) %>%                     summarize(ids=unique(ID)) %>%                     pull()                   ids <- ids[seq(1, nid)]                   dat %>%                      filter(ID %in% ids)                 })) ## Use 2 compartment model cmt2 <- function(){   ini({     lka <- log(0.1) # log Ka     lv <- log(10) # Log Vc     lcl <- log(4) # Log Cl     lq <- log(10) # log Q     lvp <- log(20) # Log Vp      eta.ka ~ 0.01     eta.v ~ 0.1     eta.cl ~ 0.1     logn.sd = 10   })   model({     ka <- exp(lka + eta.ka)     cl <- exp(lcl + eta.cl)     v <- exp(lv + eta.v)     q <- exp(lq)     vp <- exp(lvp)     linCmt() ~ lnorm(logn.sd)   }) }  ## Check parsing cmt2m <- nlmixr(cmt2) print(cmt2m) #>  ── rxode2-based solved PK 2-compartment model with first-order absorption ──────  #>  ── Initalization: ──   #> Fixed Effects ($theta):  #>       lka        lv       lcl        lq       lvp   logn.sd  #> -2.302585  2.302585  1.386294  2.302585  2.995732 10.000000  #>  #> Omega ($omega):  #>        eta.ka eta.v eta.cl #> eta.ka   0.01   0.0    0.0 #> eta.v    0.00   0.1    0.0 #> eta.cl   0.00   0.0    0.1 #>  ── μ-referencing ($muRefTable): ──   #>   theta    eta level #> 1   lka eta.ka    id #> 2   lcl eta.cl    id #> 3    lv  eta.v    id #>  #>  ── Model (Normalized Syntax): ──  #> function() { #>     ini({ #>         lka <- -2.30258509299405 #>         label(\"log Ka\") #>         lv <- 2.30258509299405 #>         label(\"Log Vc\") #>         lcl <- 1.38629436111989 #>         label(\"Log Cl\") #>         lq <- 2.30258509299405 #>         label(\"log Q\") #>         lvp <- 2.99573227355399 #>         label(\"Log Vp\") #>         logn.sd <- c(0, 10) #>         eta.ka ~ 0.01 #>         eta.v ~ 0.1 #>         eta.cl ~ 0.1 #>     }) #>     model({ #>         ka <- exp(lka + eta.ka) #>         cl <- exp(lcl + eta.cl) #>         v <- exp(lv + eta.v) #>         q <- exp(lq) #>         vp <- exp(lvp) #>         linCmt() ~ lnorm(logn.sd) #>     }) #> } ## First try log-normal (since the variability seemed proportional to concentration) cmt2fit.logn <- nlmixr(cmt2m, dat2, \"saem\",                        control=list(print=0),                         table=tableControl(cwres=TRUE, npde=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  ## Now try proportional cmt2fit.prop <- cmt2fit.logn %>%     update(linCmt() ~ prop(prop.sd)) %>%     nlmixr(est=\"saem\", control=list(print=0),            table=tableControl(npde=TRUE, cwres=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  ## now try add+prop cmt2fit.add.prop <- cmt2fit.prop %>%     update(linCmt() ~ prop(prop.sd) + add(add.sd)) %>%     nlmixr(est=\"saem\", control=list(print=0),             table=tableControl(npde=TRUE, cwres=TRUE)) #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00  #>  #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 library(huxtable)  huxreg(\"lognormal\"=cmt2fit.logn, \"proportional\"=cmt2fit.prop, \"add+prop\"=cmt2fit.add.prop,        statistics=c(N=\"nobs\", \"logLik\", \"AIC\"))"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"model-diagnostics-with-ggpmx","dir":"Articles","previous_headings":"","what":"Model Diagnostics with ggPMX","title":"xgxr and ggPMX integration with nlmixr2","text":"creates two reports default settings, pdf word document. report can customized editing default template include project specificities (change labels, stratifications, filtering, etc.).    creates two reports default settings, pdf word document. report can customized editing default template include project specificities (change labels, stratifications, filtering, etc.).","code":"## The controller then can be piped into a specific plot ctr <- pmx_nlmixr(cmt2fit.logn, conts = c(\"WEIGHTB\"), cats=\"TRTACT\", vpc=TRUE) ctr %>% pmx_plot_npde_pred ## Modify graphical options and remove DRAFT label: ctr %>% pmx_plot_npde_time(smooth = list(color=\"blue\"), point = list(shape=4), is.draft=FALSE,                             labels = list(x = \"Time after first dose (days)\", y = \"Normalized PDE\")) ctr %>% pmx_plot_dv_ipred(scale_x_log10=TRUE, scale_y_log10=TRUE,filter=IPRED>0.001) ctr %>% pmx_plot_dv_pred(scale_x_log10=TRUE, scale_y_log10=TRUE,filter=IPRED>0.001) ctr %>% pmx_plot_abs_iwres_ipred ## For this display only show 1x1 individual plot for ID 110 for time < 12 ctr %>% pmx_plot_individual(1, filter=ID == 31 & TIME > 0 & TIME < 12,                              facets = list(nrow = 1, ncol = 1)) ctr %>% pmx_plot_iwres_dens ctr %>% pmx_plot_eta_qq ctr %>% pmx_plot_eta_box ctr %>% pmx_plot_eta_hist ctr %>% pmx_plot_eta_matrix ctr %>% pmx_plot_eta_matrix"},{"path":"https://nlmixr2.github.io/nlmixr2/articles/xgxr-nlmixr-ggpmx.html","id":"simulation-of-a-new-scenario-with-rxode2","dir":"Articles","previous_headings":"","what":"Simulation of a new scenario with rxode2","title":"xgxr and ggPMX integration with nlmixr2","text":"creating events can simply simulate new scenario. Perhaps drug development team wants explore 100 mg dose 3 times day dosing see happens PK. can simply simulate nlmixr model using new event table created rxode2(). case wish simulate variability see happens steady state: nlmixr model already includes information parameter estimates can simulate without uncertainty population parameters covariances, like done VPC. wish simulate 100 patients repeated 100 different theoretical studies simulate uncertainty fixed parameter estimates covariances can easily nlmixr2/rxode2: may examine simulated study information easily, show rxode2() printout: can also see covariance matricies simulated (note come inverse Wishart distribution): also easy enough create plot see going simulation:   complex simulations variability can also simulate dosing windows sampling windows use tool want summarize way wish.","code":"# Start a new simulation (ev <- et(amt=100, ii=8, ss=1)) ev$add.sampling(seq(0, 8, length.out=50)) print(ev) #> ────────────────────────── EventTable with 51 records ────────────────────────── #>  #>    1 dosing records (see $get.dosing(); add with add.dosing or et) #>    50 observation times (see $get.sampling(); add with add.sampling or et) #> ── First part of : ───────────────────────────────────────────────────────────── #> # A tibble: 51 × 5 #>     time   amt    ii evid             ss #>    <dbl> <dbl> <dbl> <evid>        <int> #>  1 0        NA    NA 0:Observation    NA #>  2 0       100     8 1:Dose (Add)      1 #>  3 0.163    NA    NA 0:Observation    NA #>  4 0.327    NA    NA 0:Observation    NA #>  5 0.490    NA    NA 0:Observation    NA #>  6 0.653    NA    NA 0:Observation    NA #>  7 0.816    NA    NA 0:Observation    NA #>  8 0.980    NA    NA 0:Observation    NA #>  9 1.14     NA    NA 0:Observation    NA #> 10 1.31     NA    NA 0:Observation    NA #> # … with 41 more rows set.seed(100) sim1 <- rxSolve(cmt2fit.logn, ev, nSub=100, nStud=100) print(sim1) #> ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ Solved rxode2 object ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ #> ── Parameters ($params): ─────────────────────────────────────────────────────── #> # A tibble: 10,000 × 10 #>    sim.id   lka    lv   lcl    lq   lvp logn.sd eta.ka    eta.v  eta.cl #>     <int> <dbl> <dbl> <dbl> <dbl> <dbl>   <dbl>  <dbl>    <dbl>   <dbl> #>  1      1 -1.15 0.984  2.14  2.51  4.63   0.352  0.356  0.103    0.435  #>  2      2 -1.15 0.984  2.14  2.51  4.63   0.352 -0.618 -0.00364  0.0610 #>  3      3 -1.15 0.984  2.14  2.51  4.63   0.352  0.239  0.00271  0.694  #>  4      4 -1.15 0.984  2.14  2.51  4.63   0.352 -0.525  0.261   -0.506  #>  5      5 -1.15 0.984  2.14  2.51  4.63   0.352  0.492 -1.22     0.579  #>  6      6 -1.15 0.984  2.14  2.51  4.63   0.352 -1.20   0.144    0.214  #>  7      7 -1.15 0.984  2.14  2.51  4.63   0.352 -2.10  -0.829    0.165  #>  8      8 -1.15 0.984  2.14  2.51  4.63   0.352 -0.920  0.272   -0.744  #>  9      9 -1.15 0.984  2.14  2.51  4.63   0.352  1.32  -0.136    0.269  #> 10     10 -1.15 0.984  2.14  2.51  4.63   0.352 -0.553 -0.596   -0.428  #> # … with 9,990 more rows #> ── Initial Conditions ($inits): ──────────────────────────────────────────────── #> named numeric(0) #>  #> Simulation with uncertainty in: #> • parameters ($thetaMat for changes) #> • omega matrix ($omegaList) #> • sigma matrix ($sigmaList) #>  #> ── First part of data (object): ──────────────────────────────────────────────── #> # A tibble: 500,000 × 9 #>   sim.id  time    ka    cl     v     q    vp ipredSim   sim #>    <int> <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl> <dbl> #> 1      1 0     0.451  13.2  2.97  12.3  103.    0.460 0.559 #> 2      1 0.163 0.451  13.2  2.97  12.3  103.    1.73  1.85  #> 3      1 0.327 0.451  13.2  2.97  12.3  103.    1.96  2.03  #> 4      1 0.490 0.451  13.2  2.97  12.3  103.    1.93  1.81  #> 5      1 0.653 0.451  13.2  2.97  12.3  103.    1.86  2.23  #> 6      1 0.816 0.451  13.2  2.97  12.3  103.    1.77  0.884 #> # … with 499,994 more rows #> ▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂ head(sim1$thetaMat) #>             lka         lv          lcl          lq          lvp #> [1,] 0.14624398 -0.4086970  0.148948234 -0.12286484 -0.013141442 #> [2,] 0.29754673  0.2877020 -0.140145807  0.18035533  0.053950443 #> [3,] 0.16599788  0.3947279  0.122784513  0.12342623  0.016885174 #> [4,] 0.10627425 -0.3509796  0.063974342  0.05341122  0.036445560 #> [5,] 0.07925247  0.1569209 -0.008418402  0.16874062  0.042176966 #> [6,] 0.03858317 -0.4124237 -0.078408241 -0.06939259  0.006522178 head(sim1$omegaList) #> [[1]] #>             eta.ka       eta.v      eta.cl #> eta.ka  0.75723787 -0.03941287  0.07129737 #> eta.v  -0.03941287  2.24018382 -0.14698494 #> eta.cl  0.07129737 -0.14698494  0.66321303 #>  #> [[2]] #>            eta.ka      eta.v     eta.cl #> eta.ka  0.6265270 -0.1501761  0.1045931 #> eta.v  -0.1501761  2.5019886 -0.2344552 #> eta.cl  0.1045931 -0.2344552  0.6103688 #>  #> [[3]] #>            eta.ka      eta.v     eta.cl #> eta.ka  0.6261422 -0.3484433  0.1426269 #> eta.v  -0.3484433  3.1009407 -0.2637253 #> eta.cl  0.1426269 -0.2637253  0.6613656 #>  #> [[4]] #>            eta.ka     eta.v     eta.cl #> eta.ka 0.40814990 0.1640374 0.07279401 #> eta.v  0.16403739 2.7727074 0.18381331 #> eta.cl 0.07279401 0.1838133 0.80266640 #>  #> [[5]] #>             eta.ka       eta.v     eta.cl #> eta.ka  0.60279063 -0.09658454 0.08482646 #> eta.v  -0.09658454  2.78250394 0.06074504 #> eta.cl  0.08482646  0.06074504 0.78717652 #>  #> [[6]] #>             eta.ka      eta.v      eta.cl #> eta.ka  0.48381282 -0.2021803  0.02843517 #> eta.v  -0.20218033  2.5771963 -0.26188336 #> eta.cl  0.02843517 -0.2618834  0.57036416 head(sim1$sigmaList) #> [[1]] #>              err.rxLinCmt #> err.rxLinCmt    0.9855042 #>  #> [[2]] #>              err.rxLinCmt #> err.rxLinCmt     1.050166 #>  #> [[3]] #>              err.rxLinCmt #> err.rxLinCmt     1.029402 #>  #> [[4]] #>              err.rxLinCmt #> err.rxLinCmt     1.042186 #>  #> [[5]] #>              err.rxLinCmt #> err.rxLinCmt    0.9566666 #>  #> [[6]] #>              err.rxLinCmt #> err.rxLinCmt     1.044673 conf <- confint(sim1, \"sim\")  p1 <- plot(conf) ## This returns a ggplot2 object  ## you can tweak the plot by the standard ggplot commands p1 + xlab(\"Time (hr)\") +    ylab(\"Simulated Concentrations of TID steady state\") # And put the same plot on a semi-log plot p1 + xlab(\"Time (hr)\") +    ylab(\"Simulated Concentrations of TID steady state\") +   xgx_scale_y_log10()"},{"path":"https://nlmixr2.github.io/nlmixr2/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Matthew Fidler. Author, maintainer. Yuan Xiong. Contributor. Rik Schoemaker. Contributor. Justin Wilkins. Contributor. Wenping Wang. Author. Mirjam Trame. Contributor. Teun Post. Contributor. Richard Hooijmaijers. Contributor.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Fidler M, Wang W (2022). nlmixr2: Nonlinear Mixed Effects Models Population PK/PD. R package version 2.0.6.","code":"@Manual{,   title = {nlmixr2: Nonlinear Mixed Effects Models in Population PK/PD},   author = {Matthew Fidler and Wenping Wang},   year = {2022},   note = {R package version 2.0.6}, }"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"nlmixr2","dir":"","previous_headings":"","what":"Nonlinear Mixed Effects Models in Population PK/PD","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"goal nlmixr2 support easy robust nonlinear mixed effects models R","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"can install development version nlmixr2 nlmixr2-family dependencies like : Optional supporting packages can installed like :","code":"remotes::install_github(\"nlmixr2/nlmixr2data\") remotes::install_github(\"nlmixr2/lotri\") remotes::install_github(\"nlmixr2/rxode2\") remotes::install_github(\"nlmixr2/nlmixr2est\") remotes::install_github(\"nlmixr2/nlmixr2extra\") remotes::install_github(\"nlmixr2/nlmixr2plot\") remotes::install_github(\"nlmixr2/nlmixr2\") remotes::install_github(\"ggPMXdevelopment/ggPMX\") # Goodness of fit plots remotes::install_github(\"nlmixr2/xpose.nlmixr\") # Additional goodness of fit plots remotes::install_github(\"RichardHooijmaijers/shinyMixR\") # Shiny run manager (like Piranha) remotes::install_github(\"nlmixr2/nlmixr2targets\") # Simplify work with the `targets` package"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"example","dir":"","previous_headings":"","what":"Example","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"basic example shows solve common problem:","code":"library(nlmixr2) #> Loading required package: nlmixr2data  ## The basic model consiss of an ini block that has initial estimates one.compartment <- function() {   ini({     tka <- 0.45 # Log Ka     tcl <- 1 # Log Cl     tv <- 3.45    # Log V     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   # and a model block with the error sppecification and model specification   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     d/dt(depot) = -ka * depot     d/dt(center) = ka * depot - cl / v * center     cp = center / v     cp ~ add(add.sd)   }) }  ## The fit is performed by the function nlmixr/nlmix2 specifying the model, data and estimate fit <- nlmixr2(one.compartment, theo_sd,  est=\"saem\", saemControl(print=0)) #> ℹ parameter labels from comments will be replaced by 'label()' #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 #> → optimizing duplicate expressions in saem model... #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 #> ✔ done #> rxode2 1.0.0 using 4 threads (see ?getRxThreads) #> Calculating covariance matrix #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 #> → finding duplicate expressions in saem predOnly model 1... #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 #> → optimizing duplicate expressions in saem predOnly model 1... #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 #> → finding duplicate expressions in saem predOnly model 2... #> [====|====|====|====|====|====|====|====|====|====] 0:00:00 #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 62360 #> → compress parHist in nlmixr2 object, save 9408 #> → compress saem0 in nlmixr2 object, save 23016 print(fit) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem table compress    other #> elapsed 0.002547   0.008005 2.518  0.03    0.023 1.729448 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.454  0.196 43.1       1.57 (1.07, 2.31)     71.5   -0.0203%  #> tcl       Log Cl  1.02 0.0853  8.4       2.76 (2.34, 3.26)     27.6      3.46%  #> tv         Log V  3.45 0.0454 1.32       31.5 (28.8, 34.4)     13.4      9.89%  #> add.sd           0.693                               0.693                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 19 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    cp #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.103 -0.491 -0.0820  0    #> 2 1      0.25  2.84  3.27 -0.426  3.87 -1.03  -1.48   0.103 -0.491 -0.0820  3.87 #> 3 1      0.57  6.57  5.85  0.723  6.82 -0.246 -0.356  0.103 -0.491 -0.0820  6.82 #> # … with 129 more rows, and 7 more variables: depot <dbl>, center <dbl>, #> #   ka <dbl>, cl <dbl>, v <dbl>, tad <dbl>, dosenum <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/index.html","id":"default-plots","dir":"","previous_headings":"","what":"Default plots","title":"Nonlinear Mixed Effects Models in Population PK/PD","text":"","code":"plot(fit) #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous y-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis #> Warning: Transformation introduced infinite values in continuous x-axis"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":null,"dir":"Reference","previous_headings":"","what":"Add CWRES — addCwres","title":"Add CWRES — addCwres","text":"returns new fit object CWRES attached","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add CWRES — addCwres","text":"","code":"addCwres(fit, focei = TRUE, updateObject = TRUE, envir = parent.frame(1))"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add CWRES — addCwres","text":"fit nlmixr2 fit without WRES/CWRES focei Boolean indicating focei objective function added.  foce objective function added. updateObject Boolean indicating original fit object updated. default true. envir Environment checked object update.  default global environment.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add CWRES — addCwres","text":"fit CWRES","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add CWRES — addCwres","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addCwres.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add CWRES — addCwres","text":"","code":"# \\donttest{  one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Log Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  f <- try(nlmixr2(one.cmt, theo_sd, \"saem\")) #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd #> rxode2 2.0.6 using 1 threads (see ?getRxThreads) #>   no cache: create with `rxCreateCache()` #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHist in nlmixr2 object, save 9392 #> → compress saem0 in nlmixr2 object, save 22888  print(f) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem table compress    other #> elapsed 0.002473   0.070006 1.612 0.037    0.023 2.875521 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 16 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # … with 129 more rows, and 4 more variables: cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>  # even though you may have forgotten to add the cwres, you can add it to the data.frame:  if (!inherits(f, \"try-error\")) {   f <- try(addCwres(f))   print(f) } #>   #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(η) #> → calculate ∂(R²)/∂(η) #> → finding duplicate expressions in inner model... #> → optimizing duplicate expressions in inner model... #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling inner model... #>   #> ✔ done #> → finding duplicate expressions in FD model... #> → compiling EBE model... #>   #> ✔ done #> → compiling events FD model... #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>           OBJF      AIC      BIC Log-likelihood Condition Number #> FOCEi 116.9949 373.5947 393.7743      -179.7973         18.15903 #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem table compress    other #> elapsed 0.002473   0.070006 1.612 0.037    0.023 2.875521 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 20 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # … with 129 more rows, and 8 more variables: cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>, WRES <dbl>, CPRED <dbl>, CRES <dbl>, CWRES <dbl>  # Note this also adds the FOCEi objective function # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":null,"dir":"Reference","previous_headings":"","what":"NPDE calculation for nlmixr2 — addNpde","title":"NPDE calculation for nlmixr2 — addNpde","text":"NPDE calculation nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"NPDE calculation for nlmixr2 — addNpde","text":"","code":"addNpde(   object,   updateObject = TRUE,   table = tableControl(),   ...,   envir = parent.frame(1) )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"NPDE calculation for nlmixr2 — addNpde","text":"object nlmixr2 fit object updateObject Boolean indicating original object updated.  default TRUE. table `tableControl()` list options ... Additional arguments passed nlmixr2est::addNpde(). envir Environment checked object update.  default global environment.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"NPDE calculation for nlmixr2 — addNpde","text":"New nlmixr2 fit object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"NPDE calculation for nlmixr2 — addNpde","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addNpde.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"NPDE calculation for nlmixr2 — addNpde","text":"","code":"# \\donttest{  one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Log Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  f <- nlmixr2(one.cmt, theo_sd, \"saem\") #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHist in nlmixr2 object, save 9392 #> → compress saem0 in nlmixr2 object, save 23472  # even though you may have forgotten to add the NPDE, you can add it to the data.frame:  f <- addNpde(f) #> → Add NPDE #>   #> ✔ done  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":null,"dir":"Reference","previous_headings":"","what":"Add table information to nlmixr2 fit object without tables — addTable","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"Add table information nlmixr2 fit object without tables","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"","code":"addTable(   object,   updateObject = FALSE,   data = object$dataSav,   thetaEtaParameters = object$foceiThetaEtaParameters,   table = tableControl(),   keep = NULL,   drop = NULL,   envir = parent.frame(1) )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"object nlmixr2 family objects updateObject Update object (default FALSE) data Saved data thetaEtaParameters Internal theta/eta parameters table `tableControl()` list options keep Character Vector items keep drop Character Vector items drop NULL envir Environment search updating","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"Fit table information attached","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"Matthew Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/addTable.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Add table information to nlmixr2 fit object without tables — addTable","text":"","code":"# \\donttest{  one.cmt <- function() {   ini({     ## You may label each parameter with a comment     tka <- 0.45 # Log Ka     tcl <- log(c(0, 2.7, 100)) # Log Cl     ## This works with interactive models     ## You may also label the preceding line with label(\"label text\")     tv <- 3.45; label(\"log V\")     ## the label(\"Label name\") works with all models     eta.ka ~ 0.6     eta.cl ~ 0.3     eta.v ~ 0.1     add.sd <- 0.7   })   model({     ka <- exp(tka + eta.ka)     cl <- exp(tcl + eta.cl)     v <- exp(tv + eta.v)     linCmt() ~ add(add.sd)   }) }  # run without tables step f <- nlmixr2(one.cmt, theo_sd, \"saem\", control=list(calcTables=FALSE)) #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> ✔ done #>   #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 63664 #> → compress parHist in nlmixr2 object, save 9392 #> → compress saem0 in nlmixr2 object, save 24656  print(f) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem compress    other #> elapsed 0.001996   0.007005 1.334    0.022 1.225999 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink   # Now add the tables  f <- addTable(f) #> → Calculating residuals/tables #> ✔ done  print(f) #> ── nlmixr SAEM OBJF by FOCEi approximation ───────────────────────────────────── #>  #>  Gaussian/Laplacian Likelihoods: AIC() or $objf etc.  #>  FOCEi CWRES & Likelihoods: addCwres()  #>  #> ── Time (sec $time): ─────────────────────────────────────────────────────────── #>  #>            setup covariance  saem compress    other #> elapsed 0.001996   0.007005 1.334    0.022 1.225999 #>  #> ── Population Parameters ($parFixed or $parFixedDf): ─────────────────────────── #>  #>        Parameter  Est.     SE %RSE Back-transformed(95%CI) BSV(CV%) Shrink(SD)% #> tka       Log Ka 0.453  0.195 43.1       1.57 (1.07, 2.31)     71.4    -0.445%  #> tcl       Log Cl  1.02 0.0843 8.29       2.76 (2.34, 3.26)     27.2      3.88%  #> tv         log V  3.45 0.0467 1.35       31.5 (28.8, 34.5)     13.9      10.2%  #> add.sd           0.695                               0.695                      #>   #>   Covariance Type ($covMethod): linFim #>   No correlations in between subject variability (BSV) matrix #>   Full BSV covariance ($omega) or correlation ($omegaR; diagonals=SDs)  #>   Distribution stats (mean/skewness/kurtosis/p-value) available in $shrink  #>  #> ── Fit Data (object is a modified tibble): ───────────────────────────────────── #> # A tibble: 132 × 16 #>   ID     TIME    DV  PRED    RES IPRED   IRES  IWRES eta.ka eta.cl   eta.v    ka #>   <fct> <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  <dbl>  <dbl>  <dbl>   <dbl> <dbl> #> 1 1      0     0.74  0     0.74   0     0.74   1.07   0.107 -0.485 -0.0809  1.75 #> 2 1      0.25  2.84  3.26 -0.424  3.87 -1.03  -1.49   0.107 -0.485 -0.0809  1.75 #> 3 1      0.57  6.57  5.84  0.726  6.82 -0.250 -0.360  0.107 -0.485 -0.0809  1.75 #> # … with 129 more rows, and 4 more variables: cl <dbl>, v <dbl>, tad <dbl>, #> #   dosenum <dbl>  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Options for FOCEi — foceiControl","title":"Control Options for FOCEi — foceiControl","text":"Control Options FOCEi","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Options for FOCEi — foceiControl","text":"","code":"foceiControl(   sigdig = 3,   ...,   epsilon = NULL,   maxInnerIterations = 1000,   maxOuterIterations = 5000,   n1qn1nsim = NULL,   print = 1L,   printNcol = floor((getOption(\"width\") - 23)/12),   scaleTo = 1,   scaleObjective = 0,   normType = c(\"rescale2\", \"mean\", \"rescale\", \"std\", \"len\", \"constant\"),   scaleType = c(\"nlmixr2\", \"norm\", \"mult\", \"multAdd\"),   scaleCmax = 1e+05,   scaleCmin = 1e-05,   scaleC = NULL,   scaleC0 = 1e+05,   derivEps = rep(20 * sqrt(.Machine$double.eps), 2),   derivMethod = c(\"switch\", \"forward\", \"central\"),   derivSwitchTol = NULL,   covDerivMethod = c(\"central\", \"forward\"),   covMethod = c(\"r,s\", \"r\", \"s\", \"\"),   hessEps = (.Machine$double.eps)^(1/3),   eventFD = sqrt(.Machine$double.eps),   eventType = c(\"gill\", \"central\", \"forward\"),   centralDerivEps = rep(20 * sqrt(.Machine$double.eps), 2),   lbfgsLmm = 7L,   lbfgsPgtol = 0,   lbfgsFactr = NULL,   eigen = TRUE,   addPosthoc = TRUE,   diagXform = c(\"sqrt\", \"log\", \"identity\"),   sumProd = FALSE,   optExpression = TRUE,   ci = 0.95,   useColor = crayon::has_color(),   boundTol = NULL,   calcTables = TRUE,   noAbort = TRUE,   interaction = TRUE,   cholSEtol = (.Machine$double.eps)^(1/3),   cholAccept = 0.001,   resetEtaP = 0.15,   resetThetaP = 0.05,   resetThetaFinalP = 0.15,   diagOmegaBoundUpper = 5,   diagOmegaBoundLower = 100,   cholSEOpt = FALSE,   cholSECov = FALSE,   fo = FALSE,   covTryHarder = FALSE,   outerOpt = c(\"nlminb\", \"bobyqa\", \"lbfgsb3c\", \"L-BFGS-B\", \"mma\", \"lbfgsbLG\", \"slsqp\",     \"Rvmmin\"),   innerOpt = c(\"n1qn1\", \"BFGS\"),   rhobeg = 0.2,   rhoend = NULL,   npt = NULL,   rel.tol = NULL,   x.tol = NULL,   eval.max = 4000,   iter.max = 2000,   abstol = NULL,   reltol = NULL,   resetHessianAndEta = FALSE,   stateTrim = Inf,   gillK = 10L,   gillStep = 4,   gillFtol = 0,   gillRtol = sqrt(.Machine$double.eps),   gillKcov = 10L,   gillStepCov = 2,   gillFtolCov = 0,   rmatNorm = TRUE,   smatNorm = TRUE,   covGillF = TRUE,   optGillF = TRUE,   covSmall = 1e-05,   adjLik = TRUE,   gradTrim = Inf,   maxOdeRecalc = 5,   odeRecalcFactor = 10^(0.5),   gradCalcCentralSmall = 1e-04,   gradCalcCentralLarge = 10000,   etaNudge = qnorm(1 - 0.05/2)/sqrt(3),   etaNudge2 = qnorm(1 - 0.05/2) * sqrt(3/5),   nRetries = 3,   seed = 42,   resetThetaCheckPer = 0.1,   etaMat = NULL,   repeatGillMax = 3,   stickyRecalcN = 5,   gradProgressOfvTime = 10,   addProp = c(\"combined2\", \"combined1\"),   badSolveObjfAdj = 100,   compress = TRUE,   rxControl = NULL,   sigdigTable = NULL,   fallbackFD = FALSE )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Options for FOCEi — foceiControl","text":"sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) ... Additional arguments passed nlmixr2est::foceiControl(). epsilon Precision estimate n1qn1 optimization. maxInnerIterations Number iterations n1qn1 optimization. maxOuterIterations Maximum number L-BFGS-B optimization outer problem. n1qn1nsim Number function evaluations n1qn1 optimization. print Integer representing outer step printed. 0 print iterations.  1 print every function evaluation (default), 5 print every 5 evaluations. printNcol Number columns printout wrapping parameter estimates/gradient scaleTo Scale initial parameter estimate value. default 1.  zero , scaling performed. scaleObjective Scale initial objective function value.  default 0 (meaning scale) normType type parameter     normalization/scaling used get scaled initial values     nlmixr2.  used scaleType . exception rescale2, come         Feature     Scaling. rescale2 rescaling type     described     OptdesX     software manual. general, scaling formula can described : v_scaled = (v_unscaled-C_1)/C_2 data normalization approaches follow following formula v_scaled = (v_unscaled-C_1)/C_2; rescale2 scales parameters (-1 1).     relative differences parameters preserved     approach constants : C_1 = (max(unscaled values)+min(unscaled values))/2 C_2 = (max(unscaled values) - min(unscaled values))/2 rescale min-max normalization. rescales     parameters (0 1).  rescale2     relative differences preserved.  approach: C_1 = min(unscaled values) C_2 = max(unscaled values) - min(unscaled values) mean mean normalization.  rescales center     parameters around mean parameters 0     1.  approach: C_1 = mean(unscaled values) C_2 = max(unscaled values) - min(unscaled values) std standardization.  standardizes mean      standard deviation.  approach: C_1 = mean(unscaled values) C_2 = sd(unscaled values) len unit length scaling.  scales    parameters unit length.  approach use Euclidean length,    : C_1 = 0 C_2 = sqrt(v_1^2 + v_2^2 + ... + v_n^2) constant perform data normalization. C_1 = 0 C_2 = 1 scaleType scaling scheme nlmixr2.  supported types : nlmixr2  approach scaling performed following equation: v_scaled = (v_current - v_init)/scaleC[] + scaleTo scaleTo parameter specified normType, scales specified scaleC. norm approach uses simple scaling provided     normType argument. mult approach use data normalization provided normType, rather uses multiplicative scaling constant provided scaleTo argument. case: v_scaled = v_current/v_init*scaleTo multAdd approach changes scaling based parameter specified.  parameter defined exponential block (ie exp(theta)), scaled linearly, : v_scaled = (v_current-v_init) + scaleTo Otherwise parameter scaled multiplicatively. v_scaled = v_current/v_init*scaleTo scaleCmax Maximum value scaleC prevent overflow. scaleCmin Minimum value scaleC prevent underflow. scaleC scaling constant used     scaleType=nlmixr2.  specified, based     type parameter estimated.  idea keep     derivatives similar log scale similar     gradient sizes.  Hence parameters like log(exp(theta))     scaling factor 1 log(theta) scaling     factor ini_value (scale 1/value; ie     d/dt(log(ini_value)) = 1/ini_value scaleC=ini_value)  parameters exponential (ie exp(theta))    parameters specifying powers, boxCox yeoJohnson    transformations , 1. additive, proportional, lognormal error structures,    given 0.5*abs(initial_estimate) Factorials scaled abs(1/digamma(inital_estimate+1)) parameters log scale (ie log(theta)) transformed    log(abs(initial_estimate))*abs(initial_estimate) parameter scaling coefficients chose try keep    similar slopes among parameters.  follow    slopes approximately log-scale. chosen logical manner, may always    apply.  can specify parameters scaling factor    parameter wish. scaleC0 Number adjust scaling factor initial gradient zero. derivEps Forward difference tolerances,     vector relative difference absolute difference.      central/forward difference step size h calculated : h = abs(x)*derivEps[1] + derivEps[2] derivMethod indicates method calculating derivatives outer problem.  Currently supports \"switch\", \"central\" \"forward\" difference methods.  Switch starts forward differences.  switch central differences abs(delta(OFV)) <= derivSwitchTol switch back forward differences abs(delta(OFV)) > derivSwitchTol. derivSwitchTol tolerance switch forward central differences. covDerivMethod indicates method calculating derivatives calculating covariance components (Hessian S). covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual     gradient cross-product (evaluated individual empirical     Bayes estimates). \"r,s\" Uses sandwich matrix calculate  covariance, : solve(R) %*% S %*% solve(R) \"r\" Uses Hessian matrix calculate  covariance 2 %*% solve(R) \"s\" Uses cross-product matrix calculate  covariance 4 %*% solve(S) \"\" calculate covariance step. hessEps double value representing epsilon Hessian calculation. eventFD Finite difference step forward central difference estimation event-based gradients eventType Event gradient type dosing events; Can \"gill\", \"central\" \"forward\" centralDerivEps Central difference tolerances.      numeric vector relative difference absolute difference.     central/forward difference step size h calculated : h = abs(x)*derivEps[1] + derivEps[2] lbfgsLmm integer giving number BFGS updates retained \"L-BFGS-B\" method, defaults 7. lbfgsPgtol double precision variable. entry pgtol >= 0 specified user.  iteration     stop : max(\\| proj g_i \\| = 1, ..., n) <= lbfgsPgtol pg_i ith component projected gradient. exit pgtol unchanged.  defaults zero,     check suppressed. lbfgsFactr Controls convergence \"L-BFGS-B\" method.  Convergence occurs reduction objective within factor machine tolerance. Default 1e10, gives tolerance 2e-6, approximately 4 sigdigs.  can check exact tolerance multiplying value .Machine$double.eps eigen boolean indicating eigenvectors calculated include condition number calculation. addPosthoc Boolean indicating posthoc parameters added table output. diagXform transformation used diagonal     chol(solve(omega)). matrix values     parameters estimated FOCEi. possibilities : sqrt Estimates sqrt diagonal elements chol(solve(omega)).  default method. log Estimates log diagonal elements chol(solve(omega)) identity Estimates diagonal elements without transformations sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. optExpression Optimize rxode2 expression speed calculation. default turned . ci Confidence level tables.  default 0.95 95% confidence. useColor Boolean indicating focei can use ASCII color codes boundTol Tolerance boundary issues. calcTables boolean determine foceiFit calculate tables. default TRUE noAbort Boolean indicate abort FOCEi evaluation runs troubles.  (default TRUE) interaction Boolean indicate FOCEi used (TRUE) instead FOCE (FALSE) cholSEtol tolerance Generalized Cholesky Decomposition.  Defaults suggested (.Machine$double.eps)^(1/3) cholAccept Tolerance accept Generalized Cholesky Decomposition R S matrix. resetEtaP represents p-value reseting individual ETA 0 optimization (instead saved value).  two test statistics used z-test either chol(omega^-1) %*% eta eta/sd(allEtas).  p-value 0 indicates ETAs never reset.  p-value 1 indicates ETAs always reset. resetThetaP represents p-value reseting population mu-referenced THETA parameters based ETA drift optimization, resetting optimization.  p-value 0 indicates THETAs never reset.  p-value 1 indicates THETAs always reset allowed.  theta reset checked beginning nearing local minima.  percent change objective function theta reset check initiated controlled resetThetaCheckPer. resetThetaFinalP represents p-value reseting population mu-referenced THETA parameters based ETA drift optimization, resetting optimization one final time. diagOmegaBoundUpper represents upper bound diagonal omega matrix.  upper bound given diag(omega)*diagOmegaBoundUpper.  diagOmegaBoundUpper 1, upper bound Omega. diagOmegaBoundLower represents lower bound diagonal omega matrix.  lower bound given diag(omega)/diagOmegaBoundUpper.  diagOmegaBoundLower 1, lower bound Omega. cholSEOpt Boolean indicating generalized Cholesky used optimizing. cholSECov Boolean indicating generalized Cholesky used calculating Covariance Matrix. fo boolean indicating FO approximation routine. covTryHarder R matrix non-positive definite corrected non-positive definite try estimating Hessian unscaled parameter space. outerOpt optimization method outer problem innerOpt optimization method inner problem (implemented yet.) rhobeg Beginning change parameters bobyqa algorithm (trust region).  default 0.2 20 parameters parameters scaled 1. rhobeg rhoend must set initial final values trust region radius, must positive 0 < rhoend < rhobeg. Typically rhobeg one tenth greatest expected change variable.  Note also smallest difference abs(upper-lower) greater equal rhobeg*2. case rhobeg adjusted. (bobyqa) rhoend smallest value trust region radius allowed. defined, 10^(-sigdig-1) used. (bobyqa) npt number points used approximate objective function via quadratic approximation bobyqa. value npt must interval [n+2,(n+1)(n+2)/2] n number parameters par. Choices exceed 2*n+1 recommended. defined, set 2*n + 1. (bobyqa) rel.tol Relative tolerance nlminb stops (nlmimb). x.tol X tolerance nlmixr2 optimizer eval.max Number maximum evaluations objective function (nlmimb) iter.max Maximum number iterations allowed (nlmimb) abstol Absolute tolerance nlmixr2 optimizer (BFGS) reltol tolerance nlmixr2 (BFGS) resetHessianAndEta boolean representing individual Hessian reset ETAs reset using option resetEtaP. stateTrim Trim state amounts/concentrations value. gillK total number possible steps determine optimal forward/central difference step size per parameter (Gill 1983 method).  0, optimal step size determined.  Otherwise optimal step size determined. gillStep looking optimal forward difference step size, step size increase initial estimate .  iteration new step size = (prior step size)*gillStep gillFtol gillFtol gradient error tolerance acceptable issuing warning/error gradient estimates. gillRtol relative tolerance used Gill 1983 determination optimal step size. gillKcov total number possible steps determine optimal forward/central difference step size per parameter (Gill 1983 method) covariance step.  0, optimal step size determined.  Otherwise optimal step size determined. gillStepCov looking optimal forward difference step size, step size increase initial estimate .  iteration covariance step equal new step size = (prior step size)*gillStepCov gillFtolCov gillFtol gradient error tolerance acceptable issuing warning/error gradient estimates covariance step. rmatNorm parameter normalize gradient step size parameter value calculation R matrix smatNorm parameter normalize gradient step size parameter value calculation S matrix covGillF Use Gill calculated optimal Forward difference step size instead central difference step size central difference gradient calculation. optGillF Use Gill calculated optimal Forward difference step size instead central difference step size central differences optimization. covSmall covSmall small number compare covariance numbers rejecting estimate covariance final estimate (comparing sandwich vs R/S matrix estimates covariance).  number controls small variance covariance matrix rejected. adjLik nlmixr2, objective function matches NONMEM's objective function, removes 2*pi constant likelihood calculation. TRUE, likelihood function adjusted 2*pi factor.  adjusted number closely matches likelihood approximations nlme, SAS approximations.  Regardless turned objective function matches NONMEM's objective function. gradTrim parameter adjust gradient |gradient| large. maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced gradCalcCentralSmall small number represents value |grad| < gradCalcCentralSmall forward differences switch central differences. gradCalcCentralLarge large number represents value |grad| > gradCalcCentralLarge forward differences switch central differences. etaNudge default initial ETA estimates start zero; Sometimes optimize appropriately.  value non-zero, n1qn1 optimization perform appropriately, reset Hessian, nudge ETA value; ETA still move, nudge ETA value. default value qnorm(1-0.05/2)*1/sqrt(3), first Gauss Quadrature numbers times 0.95% normal region. successful try second eta nudge number ().  +-etaNudge2 successful, assign zero optimize longer etaNudge2 second eta nudge.  default qnorm(1-0.05/2)*sqrt(3/5), n=3 quadrature point (excluding zero) times 0.95% normal region nRetries FOCEi fit current parameter estimates, randomly sample new parameter estimates restart problem.  similar 'PsN' resampling. seed object specifying random number generator initialized resetThetaCheckPer represents objective function % percentage resetThetaP checked. etaMat Eta matrix initial estimates final estimates ETAs. repeatGillMax tolerances reduced calculating initial Gill differences, Gill difference repeated maximum number times defined parameter. stickyRecalcN number bad ODE solves reducing atol/rtol rest problem. gradProgressOfvTime time single objective function evaluation (seconds) start progress bars gradient evaluations addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: y = f + (+ b*f^c)*err combined2 error model can described following equation: y = f + sqrt(^2 + b^2*(f^c)^2)*err : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) badSolveObjfAdj objective function adjustment ODE system solved.  based individual bad solve. compress object compressed items rxControl `rxode2` ODE solving options fitting, created `rxControl()` sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. fallbackFD Fallback finite differences sensitivity equations solve.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Options for FOCEi — foceiControl","text":"control object changes options FOCEi   family estimation methods","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Control Options for FOCEi — foceiControl","text":"Note uses R's L-BFGS-B optim outer problem BFGS n1qn1 allows restoring prior individual Hessian (faster optimization speed). However inner problem scaled.  Since eta estimates start near zero, scaling parameters make sense. process scaling can fix ill conditioning unscaled problem.  covariance step performed unscaled problem, condition number matrix may reflective scaled problem's condition-number.","code":""},{"path":[]},{"path":"https://nlmixr2.github.io/nlmixr2/reference/foceiControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control Options for FOCEi — foceiControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":null,"dir":"Reference","previous_headings":"","what":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"nlmixr2 R package fitting population pharmacokinetic (PK) pharmacokinetic-pharmacodynamic (PKPD) models.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"","code":"nlmixr2(   object,   data,   est = NULL,   control = list(),   table = tableControl(),   ...,   save = NULL,   envir = parent.frame() )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"object Fitted object function specifying model. data nlmixr data est estimation method (methods shown `nlmixr2AllEst()`). Methods can added tools control estimation control object.  expected different type estimation method table output table control object (like `tableControl()`) ... Additional arguments passed nlmixr2est::nlmixr2(). save Boolean save nlmixr2 object rds file working directory.  NULL, uses option \"nlmixr2.save\" envir Environment nlmixr object/function evaluated running estimation routine.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"Either nlmixr2 model nlmixr2 fit object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"nlmixr2 generalized function allows common access nlmixr2 estimation routines.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"nlmixr-modeling-mini-language","dir":"Reference","previous_headings":"","what":"nlmixr modeling mini-language","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"Rationale nlmixr estimation routines way specifying models.  Often models specified ways intuitive one estimation routine, make sense another estimation routine.  Sometimes, legacy estimation routines like nlme syntax outside control nlmixr package. unique syntax routine makes routines easier maintain expand, allows interfacing existing packages outside nlmixr (like nlme).  However, model definition language common estimation methods, output object uniform, make easier switch estimation routines facilitate interfacing output external packages like Xpose. nlmixr mini-modeling language, attempts address issue incorporating common language.  language inspired R NONMEM, since languages familiar many pharmacometricians. Initial Estimates boundaries population parameters nlmixr models contained R function two blocks: ini model.  R function can named anything, meant called directly R.  fact try likely get error Error: find function \"ini\". ini model block meant hold initial estimates model, boundaries parameters estimation routines support boundaries (note nlmixr's saem nlme currently support parameter boundaries). explain initial estimates specified start annotated example: shown examples: Simple parameter values specified R-compatible assignment Boundaries specified c(lower, est, upper). Like NONMEM, c(lower,est) equivalent c(lower,est,Inf) Also like NONMEM, c(est) specify lower bound, equivalent   specifying parameter  without R's `c` function. initial estimates specified variance scale, analogy      NONMEM, square roots diagonal elements correspond coefficients      variation used exponential IIV implementation parameters can named almost R compatible name.  Please note : Residual error estimates coded population estimates (.e. using    '=' '<-' statement, '~'). Naming variables start \"_\" supported.  Note R     allow variable starting \"_\" assigned without quoting . Naming variables start \"rx_\" \"nlmixr_\"   supported since rxode2 nlmixr2 use prefixes   internally certain estimation routines calculating residuals. Variable names case sensitive, just like R. \"CL\"    \"Cl\". Initial Estimates subject error distribution (NONMEM's  $OMEGA) mixture models, multivariate normal individual deviations population parameters estimated (NONMEM called eta parameters).  Additionally variance/covariance matrix deviations also estimated (NONMEM OMEGA matrix).  also initial estimates.  nlmixr specified `~` operator typically used R \"modeled \", chosen distinguish estimates population residual error parameters. Continuing prior example, can annotate estimates subject error distribution shown examples: Simple variances specified variable name     estimate separated `~`. Correlated parameters specified sum variable    labels lower triangular matrix covariance    specified left handed side equation. also    separated `~`. Currently model syntax allow comments inside lower triangular matrix. Model Syntax ODE based models (NONMEM's $PK, $PRED, $DES $ERROR) initialization block defined, can define model terms defined variables ini block.  can also mix RxODE blocks model. current method defining nlmixr model specify parameters, possibly RxODE lines: Continuing describing syntax annotated example: points note: Parameters often defined differential equations. differential equations, parameters error terms single      block, instead multiple sections. State names, calculated variables start either \"rx_\"      \"nlmixr_\" since used internally estimation routines. Errors specified using `~`.  Currently can use either add(parameter)      additive error,  prop(parameter) proportional error add(parameter1) + prop(parameter2)      additive plus proportional error.  can also specify norm(parameter) additive error,      since follows normal distribution. routines, like saem require  parameters terms Pop.Parameter + Individual.Deviation.Parameter + Covariate*Covariate.Parameter.      order parameters matter.  similar NONMEM's mu-referencing, though      quite restrictive. type parameter model determined initial block;  Covariates used      model missing ini block.  variables need present modeling      dataset model run. Model Syntax solved PK systems Solved PK systems also currently supported nlmixr `linCmt()` pseudo-function.  annotated example solved system : ##' things keep mind: RxODE allows mixing solved systems ODEs,     implemented nlmixr yet. solved systems implemented one, two three compartment     models without first-order absorption.  models support     lag time tlag parameter. general linear compartment model figures model parameter names.     nlmixr currently knows numbered volumes, Vc/Vp, Clearances terms Cl     Q/CLD.  Additionally nlmixr knows elimination micro-constants (ie K12).  Mixing     parameters models currently supported. Checking model syntax specifying model syntax can check nlmixr interpreting correctly using nlmixr function . Using function can get: general gives information model (type solved system/RxODE), initial estimates well code model block. Using model syntax estimating model model function created, can use dataset estimate parameters model given dataset. dataset RxODE compatible events IDs.  Monolix NONMEM use similar standard nlmixr can support. data converted appropriate format, can use nlmixr function run appropriate code. method estimate model : Currently nlme saem implemented.  example, run model saem, following: options saem controlled saemControl. may wish make sure minimization complete case saem.  can traceplot shows iteration history divided burn-EM phases.  case, burn seems reasonable; may wish increase number iterations EM phase estimation. Overall probably semi-reasonable solution. nlmixr output objects addition unifying modeling language sent estimation routines, outputs currently unified structure. can see fit object typing object name: example shows typical printout nlmixr fit object.  elements fit : type fit (nlme, saem, etc) Metrics goodness fit (AIC, BIC,    logLik). align comparison methods, FOCEi likelihood objective calculated           regardless method used used goodness fit metrics. FOCEi likelihood compared NONMEM's objective function gives          values (based data Wang 2007) Also note saem calculate objective function,             FOCEi used objective function fit. Even though objective functions calculated manner, caution          used comparing fits various estimation routines. next item timing steps fit. can also accessed (fit.s$time). mnemonic, access item shown printout.         true almost items printout. timing fit, parameter estimates displayed (can accessed    fit.s$par.fixed) items rounded R printing, estimate without rounding still accessible `$` syntax.        example, `$Untransformed` gives untransformed parameter values. Untransformed parameter takes log-space parameters back-transforms normal parameters.  CIs        listed back-transformed parameter space. Proportional Errors converted Omega block (accessed fit.s$omega) table fit data. Please note: nlmixr fit object actually data frame.  Saving Rdata object loading        without nlmixr just show data .  worry; fit information vanished,        can bring back simply loading nlmixr, accessing data. Special access fit information (like $omega) needs nlmixr extract information. use $ access information, order precedence : Fit data overall data.frame Information parsed nlmixr model (via $uif) Parameter history available (via $par.hist $par.hist.stacked) Fixed effects table (via $par.fixed) Individual differences typical population parameters (via $eta) Fit information list information generated post-hoc            residual calculation. Fit information environment post-hoc residual calculated Fit information data options interacted specified model            (estimation options solved system infusion IV bolus). printout may displays data data.table object tbl        object, data objects, rather derived data frame. Since object data.frame, can treat like one. addition properties fit object, additional may helpful modeler: $theta gives fixed effects parameter estimates (NONMEM     thetas). can also accessed fixed.effects     function. Note residual variability treated fixed effect parameter     included list. $eta gives random effects parameter estimates, NONMEM     etas.  can also accessed using random.effects     function.","code":"f <- function(){ ## Note the arguments to the function are currently                  ## ignored by nlmixr     ini({         ## Initial conditions for population parameters (sometimes         ## called theta parameters) are defined by either `<-` or '='         lCl <- 1.6      #log Cl (L/hr)         ## Note that simple expressions that evaluate to a number are         ## OK for defining initial conditions (like in R)         lVc = log(90)  #log V (L)         ## Also a comment on a parameter is captured as a parameter label         lKa <- 1 #log Ka (1/hr)         ## Bounds may be specified by c(lower, est, upper), like NONMEM:         ## Residuals errors are assumed to be population parameters         prop.err <- c(0, 0.2, 1)     })     ## The model block will be discussed later     model({}) } f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc = log(90)  #log V (L)         lKa <- 1 #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         ## Initial estimate for ka IIV variance         ## Labels work for single parameters         eta.ka ~ 0.1 # BSV Ka          ## For correlated parameters, you specify the names of each         ## correlated parameter separated by a addition operator `+`         ## and the left handed side specifies the lower triangular         ## matrix initial of the covariance matrix.         eta.cl + eta.vc ~ c(0.1,                             0.005, 0.1)         ## Note that labels do not currently work for correlated         ## parameters.  Also do not put comments inside the lower         ## triangular matrix as this will currently break the model.     })     ## The model block will be discussed later     model({}) } f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc <- log(90)   #log Vc (L)         lKA <- 0.1      #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         eta.Cl ~ 0.1 ## BSV Cl         eta.Vc ~ 0.1 ## BSV Vc         eta.KA ~ 0.1 ## BSV Ka     })     model({         ## First parameters are defined in terms of the initial estimates         ## parameter names.         Cl <- exp(lCl + eta.Cl)         Vc = exp(lVc + eta.Vc)         KA <- exp(lKA + eta.KA)         ## After the differential equations are defined         kel <- Cl / Vc;         d/dt(depot)    = -KA*depot;         d/dt(centr)  =  KA*depot-kel*centr;         ## And the concentration is then calculated         cp = centr / Vc;         ## Last, nlmixr is told that the plasma concentration follows         ## a proportional error (estimated by the parameter prop.err)         cp ~ prop(prop.err)     }) } f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc <- log(90)   #log Vc (L)         lKA <- 0.1      #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         eta.Cl ~ 0.1 ## BSV Cl         eta.Vc ~ 0.1 ## BSV Vc         eta.KA ~ 0.1 ## BSV Ka     })     model({         Cl <- exp(lCl + eta.Cl)         Vc = exp(lVc + eta.Vc)         KA <- exp(lKA + eta.KA)         ## Instead of specifying the ODEs, you can use         ## the linCmt() function to use the solved system.         ##         ## This function determines the type of PK solved system         ## to use by the parameters that are defined.  In this case         ## it knows that this is a one-compartment model with first-order         ## absorption.         linCmt() ~ prop(prop.err)     }) } > nlmixr(f) ## 1-compartment model with first-order absorption in terms of Cl ## Initialization: ################################################################################ Fixed Effects ($theta):     lCl     lVc     lKA 1.60000 4.49981 0.10000  Omega ($omega):      [,1] [,2] [,3] [1,]  0.1  0.0  0.0 [2,]  0.0  0.1  0.0 [3,]  0.0  0.0  0.1  ## Model: ################################################################################ Cl <- exp(lCl + eta.Cl) Vc = exp(lVc + eta.Vc) KA <- exp(lKA + eta.KA) ## Instead of specifying the ODEs, you can use ## the linCmt() function to use the solved system. ## ## This function determines the type of PK solved system ## to use by the parameters that are defined.  In this case ## it knows that this is a one-compartment model with first-order ## absorption. linCmt() ~ prop(prop.err) fit <- nlmixr(model.function, dataset, est=\"est\", control=estControl(options)) > f <- function(){     ini({         lCl <- 1.6      #log Cl (L/hr)         lVc <- log(90)   #log Vc (L)         lKA <- 0.1      #log Ka (1/hr)         prop.err <- c(0, 0.2, 1)         eta.Cl ~ 0.1 ## BSV Cl         eta.Vc ~ 0.1 ## BSV Vc         eta.KA ~ 0.1 ## BSV Ka     })     model({         ## First parameters are defined in terms of the initial estimates         ## parameter names.         Cl <- exp(lCl + eta.Cl)         Vc = exp(lVc + eta.Vc)         KA <- exp(lKA + eta.KA)         ## After the differential equations are defined         kel <- Cl / Vc;         d/dt(depot)    = -KA*depot;         d/dt(centr)  =  KA*depot-kel*centr;         ## And the concentration is then calculated         cp = centr / Vc;         ## Last, nlmixr is told that the plasma concentration follows         ## a proportional error (estimated by the parameter prop.err)         cp ~ prop(prop.err)     }) } > fit.s <- nlmixr(f,d,est=\"saem\",control=saemControl(n.burn=50,n.em=100,print=50)); Compiling RxODE differential equations...done. c:/Rtools/mingw_64/bin/g++  -I\"c:/R/R-34~1.1/include\" -DNDEBUG     -I\"d:/Compiler/gcc-4.9.3/local330/include\"  -Ic:/nlmixr/inst/include -Ic:/R/R-34~1.1/library/STANHE~1/include -Ic:/R/R-34~1.1/library/Rcpp/include -Ic:/R/R-34~1.1/library/RCPPAR~1/include -Ic:/R/R-34~1.1/library/RCPPEI~1/include -Ic:/R/R-34~1.1/library/BH/include   -O2 -Wall  -mtune=core2 -c saem3090757b4bd1x64.cpp -o saem3090757b4bd1x64.o In file included from c:/R/R-34~1.1/library/RCPPAR~1/include/armadillo:52:0,                  from c:/R/R-34~1.1/library/RCPPAR~1/include/RcppArmadilloForward.h:46,                  from c:/R/R-34~1.1/library/RCPPAR~1/include/RcppArmadillo.h:31,                  from saem3090757b4bd1x64.cpp:1: c:/R/R-34~1.1/library/RCPPAR~1/include/armadillo_bits/compiler_setup.hpp:474:96: note: #pragma message: WARNING: use of OpenMP disabled; this compiler doesn't support OpenMP 3.0+    #pragma message (\"WARNING: use of OpenMP disabled; this compiler doesn't support OpenMP 3.0+\")                                                                                                 ^ c:/Rtools/mingw_64/bin/g++ -shared -s -static-libgcc -o saem3090757b4bd1x64.dll tmp.def saem3090757b4bd1x64.o c:/nlmixr/R/rx_855815def56a50f0e7a80e48811d947c_x64.dll -Lc:/R/R-34~1.1/bin/x64 -lRblas -Lc:/R/R-34~1.1/bin/x64 -lRlapack -lgfortran -lm -lquadmath -Ld:/Compiler/gcc-4.9.3/local330/lib/x64 -Ld:/Compiler/gcc-4.9.3/local330/lib -Lc:/R/R-34~1.1/bin/x64 -lR done. 1:    1.8174   4.6328   0.0553   0.0950   0.0950   0.0950   0.6357 50:    1.3900   4.2039   0.0001   0.0679   0.0784   0.1082   0.1992 100:    1.3894   4.2054   0.0107   0.0686   0.0777   0.1111   0.1981 150:    1.3885   4.2041   0.0089   0.0683   0.0778   0.1117   0.1980 Using sympy via SnakeCharmR ## Calculate ETA-based prediction and error derivatives: Calculate Jacobian...................done. Calculate sensitivities....... done. ## Calculate d(f)/d(eta) ## ... ## done ## ... ## done The model-based sensitivities have been calculated Calculating Table Variables... done > fit.s  -- nlmixr SAEM fit (ODE); OBJF calculated from FOCEi approximation -------------       OBJF      AIC      BIC Log-likelihood Condition Number   62337.09 62351.09 62399.01      -31168.55          82.6086   -- Time (sec; fit.s$time): -----------------------------------------------------            saem setup Likelihood Calculation covariance table  elapsed 430.25 31.64                   1.19          0  3.44   -- Parameters (fit.s$par.fixed): -----------------------------------------------               Parameter Estimate     SE    lCl      log Cl (L/hr)     1.39 0.0240  1.73       4.01 (3.83, 4.20)    26.6  lVc         log Vc (L)     4.20 0.0256 0.608       67.0 (63.7, 70.4)    28.5  lKA      log Ka (1/hr)  0.00924 0.0323  349.      1.01 (0.947, 1.08)    34.3  prop.err      prop.err    0.198                             19.8           Shrink(SD)  lCl          0.248  lVc           1.09  lKA           4.19  prop.err      1.81     No correlations in between subject variability (BSV) matrix    Full BSV covariance (fit.s$omega) or correlation (fit.s$omega.R; diagonals=SDs)    Distribution stats (mean/skewness/kurtosis/p-value) available in fit.s$shrink   -- Fit Data (object fit.s is a modified data.frame): ---------------------------  # A tibble: 6,947 x 22    ID     TIME    DV  PRED    RES    WRES IPRED  IRES  IWRES CPRED   CRES  * <fct> <dbl> <dbl> <dbl>  <dbl>   <dbl> <dbl> <dbl>  <dbl> <dbl>  <dbl>  1 1      0.25  205.  198.   6.60  0.0741  189.  16.2  0.434  198.   6.78  2 1      0.5   311.  349. -38.7  -0.261   330. -19.0 -0.291  349. -38.3  3 1      0.75  389.  464. -74.5  -0.398   434. -45.2 -0.526  463. -73.9  # ... with 6,944 more rows, and 11 more variables: CWRES <dbl>, eta.Cl <dbl>,  #   eta.Vc <dbl>, eta.KA <dbl>, depot <dbl>, centr <dbl>, Cl <dbl>, Vc <dbl>,  #   KA <dbl>, kel <dbl>, cp <dbl>"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"nlmixr2 fits population PK and PKPD non-linear mixed effects models. — nlmixr2","text":"","code":"# \\donttest{  one.cmt <- function() {  ini({    ## You may label each parameter with a comment    tka <- 0.45 # Ka    tcl <- log(c(0, 2.7, 100)) # Log Cl    ## This works with interactive models    ## You may also label the preceding line with label(\"label text\")    tv <- 3.45; label(\"log V\")    ## the label(\"Label name\") works with all models    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7    prop.sd <- 0.01  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd) + prop(prop.sd)  }) }  fitF <- nlmixr(one.cmt, theo_sd, \"focei\") #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of full model... #> ✔ done #> → calculate jacobian #> → calculate ∂(f)/∂(η) #> → calculate ∂(R²)/∂(η) #> → finding duplicate expressions in inner model... #> → optimizing duplicate expressions in inner model... #> → finding duplicate expressions in EBE model... #> → optimizing duplicate expressions in EBE model... #> → compiling inner model... #>   #> ✔ done #> → finding duplicate expressions in FD model... #> → optimizing duplicate expressions in FD model... #> → compiling EBE model... #>   #> ✔ done #> → compiling events FD model... #>   #> ✔ done #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress parHist in nlmixr2 object, save 2936 #> Warning: gradient problems with initial estimate and covariance; see $scaleInfo #> Warning: last objective function was not at minimum, possible problems in optimization #> Warning: ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.)) #> Warning: initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  fitS <- nlmixr(one.cmt, theo_sd, \"saem\") #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #>   #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem model... #> ✔ done #> params:\ttka\ttcl\ttv\tV(eta.ka)\tV(eta.cl)\tV(eta.v)\tadd.sd\tprop.sd #> Calculating covariance matrix #> → loading into symengine environment... #> → pruning branches (`if`/`else`) of saem model... #> ✔ done #> → finding duplicate expressions in saem predOnly model 0... #> → finding duplicate expressions in saem predOnly model 1... #> → finding duplicate expressions in saem predOnly model 2... #> → optimizing duplicate expressions in saem predOnly model 2... #> ✔ done #>   #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress phiM in nlmixr2 object, save 64632 #> → compress parHist in nlmixr2 object, save 10472  # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2NlmeControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Values for nlme Fit with extra options for nlmixr — nlmixr2NlmeControl","title":"Control Values for nlme Fit with extra options for nlmixr — nlmixr2NlmeControl","text":"values supplied function call replace defaults list possible arguments returned.  returned list used ‘control’ argument ‘nlme’ function.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2NlmeControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Values for nlme Fit with extra options for nlmixr — nlmixr2NlmeControl","text":"","code":"nlmixr2NlmeControl(   maxIter = 100,   pnlsMaxIter = 100,   msMaxIter = 100,   minScale = 0.001,   tolerance = 1e-05,   niterEM = 25,   pnlsTol = 0.001,   msTol = 1e-06,   returnObject = FALSE,   msVerbose = FALSE,   msWarnNoConv = TRUE,   gradHess = TRUE,   apVar = TRUE,   .relStep = .Machine$double.eps^(1/3),   minAbsParApVar = 0.05,   opt = c(\"nlminb\", \"nlm\"),   natural = TRUE,   sigma = NULL,   optExpression = TRUE,   sumProd = FALSE,   rxControl = NULL,   method = c(\"ML\", \"REML\"),   random = NULL,   fixed = NULL,   weights = NULL,   verbose = TRUE,   returnNlme = FALSE,   addProp = c(\"combined2\", \"combined1\"),   calcTables = TRUE,   compress = TRUE,   adjObf = TRUE,   ci = 0.95,   sigdig = 4,   sigdigTable = NULL,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2NlmeControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Values for nlme Fit with extra options for nlmixr — nlmixr2NlmeControl","text":"maxIter maximum number iterations nlme    optimization algorithm.  Default 50. pnlsMaxIter maximum number iterations    PNLS optimization step inside nlme    optimization.  Default 7. msMaxIter maximum number iterations nlminb    (iter.max) nlm (iterlim,    10-th step) optimization step inside nlme    optimization.  Default 50 (may small e.g.    overparametrized cases). minScale minimum factor shrink default step size    attempt decrease sum squares PNLS step.    Default 0.001. tolerance tolerance convergence criterion    nlme algorithm.  Default 1e-6. niterEM number iterations EM algorithm used refine    initial estimates random effects variance-covariance    coefficients.  Default 25. pnlsTol tolerance convergence criterion PNLS    step.  Default 1e-3. msTol tolerance convergence criterion nlm,    passed gradtol argument function (see    documentation nlm).  Default 1e-7. returnObject logical value indicating whether fitted    object returned maximum number iterations    reached without convergence algorithm.  Default    FALSE. msVerbose logical value passed trace    nlminb(.., control= list(trace = *, ..))    argument print.level nlm().  Default    FALSE. msWarnNoConv logical indicating warning    signalled whenever minimization (opt)    LME step converge; defaults TRUE. gradHess logical value indicating whether numerical gradient    vectors Hessian matrices log-likelihood function    used nlm optimization. option available    correlation structure (corStruct) variance    function structure (varFunc) \"varying\" parameters    pdMat classes used random effects structure    pdSymm (general positive-definite), pdDiag (diagonal),    pdIdent (multiple identity),     pdCompSymm (compound symmetry).  Default TRUE. apVar logical value indicating whether approximate    covariance matrix variance-covariance parameters    calculated.  Default TRUE. .relStep relative step numerical derivatives    calculations.  Default .Machine$double.eps^(1/3). minAbsParApVar numeric value - minimum absolute parameter value    approximate variance calculation.  default 0.05. opt optimizer used, either \"nlminb\" (   default) \"nlm\". natural logical value indicating whether pdNatural    parametrization used general positive-definite matrices    (pdSymm) reStruct, approximate covariance    matrix estimators calculated.  Default TRUE. sigma optionally positive number fix residual error .    NULL, default, 0, sigma estimated. optExpression Optimize rxode2 expression speed calculation. default turned . sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. rxControl `rxode2` ODE solving options fitting, created `rxControl()` method character string.  \"REML\" model fit    maximizing restricted log-likelihood.  \"ML\"    log-likelihood maximized.  Defaults \"ML\". random optionally, following: () two-sided formula    form r1+...+rn~x1+...+xm | g1/.../gQ,    r1,...,rn naming parameters included right    hand side model, x1+...+xm specifying    random-effects model    parameters g1/.../gQ grouping structure    (Q may equal 1, case /    required). random effects formula repeated     levels grouping, case multiple levels    grouping; (ii) two-sided formula form    r1+...+rn~x1+..+xm, list two-sided formulas form    r1~x1+...+xm, possibly different random-effects models    different parameters, pdMat object two-sided    formula, list two-sided formulas (.e. non-NULL value    formula(random)), list pdMat objects two-sided    formulas, lists two-sided formulas. case, grouping    structure formula given groups, derived    data used fit nonlinear mixed-effects model,    inherit class  groupedData,; (iii) named list    formulas, lists formulas, pdMat objects (ii),    grouping factors names. order nesting    assumed order order elements    list; (iv) reStruct object. See documentation    pdClasses description available pdMat    classes. Defaults fixed,     resulting fixed effects also random effects. fixed two-sided linear formula form    f1+...+fn~x1+...+xm, list two-sided formulas form    f1~x1+...+xm, possibly different models different    parameters. f1,...,fn names parameters included    right hand side model x1+...+xm    expressions define linear models parameters (left    hand side formula contains several parameters,    assumed follow linear model, described right hand    side expression).    1 right hand side formula(s) indicates single    fixed effects corresponding parameter(s). weights optional varFunc object one-sided formula    describing within-group heteroscedasticity structure. given    formula, used argument varFixed,    corresponding fixed variance weights. See documentation    varClasses description available varFunc    classes. Defaults NULL, corresponding homoscedastic    within-group errors. verbose optional logical value. TRUE information    evolution iterative algorithm printed. Default    FALSE. returnNlme Returns nlme object instead nlmixr object (default FALSE).  nlme specific options `random`, `fixed`, `sens`, nlme object returned addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: y = f + (+ b*f^c)*err combined2 error model can described following equation: y = f + sqrt(^2 + b^2*(f^c)^2)*err : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) calcTables boolean determine foceiFit calculate tables. default TRUE compress object compressed items adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE ci Confidence level tables.  default 0.95 95% confidence. sigdig Optimization significant digits. controls: tolerance inner outer optimization 10^-sigdig tolerance ODE solvers  0.5*10^(-sigdig-2); sensitivity equations  steady-state solutions default 0.5*10^(-sigdig-1.5)  (sensitivity changes applicable liblsoda) tolerance boundary check 5 * 10 ^ (-sigdig + 1) sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ... Additional arguments passed nlmixr2est::nlmixr2NlmeControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/nlmixr2NlmeControl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Control Values for nlme Fit with extra options for nlmixr — nlmixr2NlmeControl","text":"","code":"nlmixr2est::nlmeControl() #> $maxIter #> [1] 100 #>  #> $pnlsMaxIter #> [1] 100 #>  #> $msMaxIter #> [1] 100 #>  #> $minScale #> [1] 0.001 #>  #> $tolerance #> [1] 1e-05 #>  #> $niterEM #> [1] 25 #>  #> $pnlsTol #> [1] 0.001 #>  #> $msTol #> [1] 1e-06 #>  #> $returnObject #> [1] FALSE #>  #> $msVerbose #> [1] FALSE #>  #> $msWarnNoConv #> [1] TRUE #>  #> $gradHess #> [1] TRUE #>  #> $apVar #> [1] TRUE #>  #> $.relStep #> [1] 6.055454e-06 #>  #> $minAbsParApVar #> [1] 0.05 #>  #> $opt #> [1] \"nlminb\" #>  #> $natural #> [1] TRUE #>  #> $sigma #> [1] 0 #>  #> $optExpression #> [1] TRUE #>  #> $sumProd #> [1] FALSE #>  #> $rxControl #> $scale #> NULL #>  #> $method #> liblsoda  #>        2  #>  #> $atol #> [1] 1e-04 #>  #> $rtol #> [1] 1e-04 #>  #> $maxsteps #> [1] 70000 #>  #> $hmin #> [1] 0 #>  #> $hmax #> [1] NA #>  #> $hini #> [1] 0 #>  #> $maxordn #> [1] 12 #>  #> $maxords #> [1] 5 #>  #> $covsInterpolation #> locf  #>    1  #>  #> $addCov #> [1] TRUE #>  #> $returnType #> rxSolve  #>       0  #>  #> $sigma #> NULL #>  #> $sigmaDf #> NULL #>  #> $nCoresRV #> [1] 1 #>  #> $sigmaIsChol #> [1] FALSE #>  #> $sigmaSeparation #> [1] \"auto\" #>  #> $sigmaXform #> identity  #>        4  #>  #> $nDisplayProgress #> [1] 10000 #>  #> $amountUnits #> [1] NA #>  #> $timeUnits #> [1] \"hours\" #>  #> $addDosing #> [1] FALSE #>  #> $stateTrim #> [1] Inf #>  #> $updateObject #> [1] FALSE #>  #> $omega #> NULL #>  #> $omegaDf #> NULL #>  #> $omegaIsChol #> [1] FALSE #>  #> $omegaSeparation #> [1] \"auto\" #>  #> $omegaXform #> variance  #>        6  #>  #> $nSub #> [1] 1 #>  #> $thetaMat #> NULL #>  #> $thetaDf #> NULL #>  #> $thetaIsChol #> [1] FALSE #>  #> $nStud #> [1] 1 #>  #> $dfSub #> [1] 0 #>  #> $dfObs #> [1] 0 #>  #> $seed #> NULL #>  #> $nsim #> NULL #>  #> $minSS #> [1] 10 #>  #> $maxSS #> [1] 1000 #>  #> $strictSS #> [1] 1 #>  #> $infSSstep #> [1] 12 #>  #> $istateReset #> [1] TRUE #>  #> $subsetNonmem #> [1] TRUE #>  #> $hmaxSd #> [1] 0 #>  #> $maxAtolRtolFactor #> [1] 0.1 #>  #> $from #> NULL #>  #> $to #> NULL #>  #> $by #> NULL #>  #> $length.out #> NULL #>  #> $iCov #> NULL #>  #> $keep #> NULL #>  #> $keepF #> character(0) #>  #> $drop #> NULL #>  #> $warnDrop #> [1] TRUE #>  #> $omegaLower #> [1] -Inf #>  #> $omegaUpper #> [1] Inf #>  #> $sigmaLower #> [1] -Inf #>  #> $sigmaUpper #> [1] Inf #>  #> $thetaLower #> [1] -Inf #>  #> $thetaUpper #> [1] Inf #>  #> $indLinPhiM #> [1] 0 #>  #> $indLinPhiTol #> [1] 1e-07 #>  #> $indLinMatExpType #> expokit  #>       2  #>  #> $indLinMatExpOrder #> [1] 6 #>  #> $idFactor #> [1] TRUE #>  #> $mxhnil #> [1] 0 #>  #> $hmxi #> [1] 0 #>  #> $warnIdSort #> [1] TRUE #>  #> $ssAtol #> [1] 1e-08 #>  #> $ssRtol #> [1] 1e-06 #>  #> $safeZero #> [1] 1 #>  #> $sumType #> pairwise  #>        1  #>  #> $prodType #> long double  #>           1  #>  #> $sensType #> advan  #>     4  #>  #> $linDiff #>    tlag       f    rate     dur   tlag2      f2   rate2    dur2  #> 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05  #>  #> $linDiffCentral #>  tlag     f  rate   dur tlag2    f2 rate2  dur2  #>  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  #>  #> $resample #> NULL #>  #> $resampleID #> [1] TRUE #>  #> $maxwhile #> [1] 100000 #>  #> $cores #> [1] 0 #>  #> $atolSens #> [1] 1e-08 #>  #> $rtolSens #> [1] 1e-06 #>  #> $ssAtolSens #> [1] 1e-08 #>  #> $ssRtolSens #> [1] 1e-06 #>  #> $simVariability #> [1] NA #>  #> attr(,\"class\") #> [1] \"rxControl\" #>  #> $method #> [1] \"ML\" #>  #> $verbose #> [1] TRUE #>  #> $returnNlme #> [1] FALSE #>  #> $addProp #> [1] \"combined2\" #>  #> $calcTables #> [1] TRUE #>  #> $compress #> [1] TRUE #>  #> $random #> NULL #>  #> $fixed #> NULL #>  #> $weights #> NULL #>  #> $ci #> [1] 0.95 #>  #> $sigdig #> [1] 4 #>  #> $sigdigTable #> [1] 4 #>  #> $genRxControl #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"nlmeControl\" nlmixr2NlmeControl() #> $maxIter #> [1] 100 #>  #> $pnlsMaxIter #> [1] 100 #>  #> $msMaxIter #> [1] 100 #>  #> $minScale #> [1] 0.001 #>  #> $tolerance #> [1] 1e-05 #>  #> $niterEM #> [1] 25 #>  #> $pnlsTol #> [1] 0.001 #>  #> $msTol #> [1] 1e-06 #>  #> $returnObject #> [1] FALSE #>  #> $msVerbose #> [1] FALSE #>  #> $msWarnNoConv #> [1] TRUE #>  #> $gradHess #> [1] TRUE #>  #> $apVar #> [1] TRUE #>  #> $.relStep #> [1] 6.055454e-06 #>  #> $minAbsParApVar #> [1] 0.05 #>  #> $opt #> [1] \"nlminb\" #>  #> $natural #> [1] TRUE #>  #> $sigma #> [1] 0 #>  #> $optExpression #> [1] TRUE #>  #> $sumProd #> [1] FALSE #>  #> $rxControl #> $scale #> NULL #>  #> $method #> liblsoda  #>        2  #>  #> $atol #> [1] 1e-04 #>  #> $rtol #> [1] 1e-04 #>  #> $maxsteps #> [1] 70000 #>  #> $hmin #> [1] 0 #>  #> $hmax #> [1] NA #>  #> $hini #> [1] 0 #>  #> $maxordn #> [1] 12 #>  #> $maxords #> [1] 5 #>  #> $covsInterpolation #> locf  #>    1  #>  #> $addCov #> [1] TRUE #>  #> $returnType #> rxSolve  #>       0  #>  #> $sigma #> NULL #>  #> $sigmaDf #> NULL #>  #> $nCoresRV #> [1] 1 #>  #> $sigmaIsChol #> [1] FALSE #>  #> $sigmaSeparation #> [1] \"auto\" #>  #> $sigmaXform #> identity  #>        4  #>  #> $nDisplayProgress #> [1] 10000 #>  #> $amountUnits #> [1] NA #>  #> $timeUnits #> [1] \"hours\" #>  #> $addDosing #> [1] FALSE #>  #> $stateTrim #> [1] Inf #>  #> $updateObject #> [1] FALSE #>  #> $omega #> NULL #>  #> $omegaDf #> NULL #>  #> $omegaIsChol #> [1] FALSE #>  #> $omegaSeparation #> [1] \"auto\" #>  #> $omegaXform #> variance  #>        6  #>  #> $nSub #> [1] 1 #>  #> $thetaMat #> NULL #>  #> $thetaDf #> NULL #>  #> $thetaIsChol #> [1] FALSE #>  #> $nStud #> [1] 1 #>  #> $dfSub #> [1] 0 #>  #> $dfObs #> [1] 0 #>  #> $seed #> NULL #>  #> $nsim #> NULL #>  #> $minSS #> [1] 10 #>  #> $maxSS #> [1] 1000 #>  #> $strictSS #> [1] 1 #>  #> $infSSstep #> [1] 12 #>  #> $istateReset #> [1] TRUE #>  #> $subsetNonmem #> [1] TRUE #>  #> $hmaxSd #> [1] 0 #>  #> $maxAtolRtolFactor #> [1] 0.1 #>  #> $from #> NULL #>  #> $to #> NULL #>  #> $by #> NULL #>  #> $length.out #> NULL #>  #> $iCov #> NULL #>  #> $keep #> NULL #>  #> $keepF #> character(0) #>  #> $drop #> NULL #>  #> $warnDrop #> [1] TRUE #>  #> $omegaLower #> [1] -Inf #>  #> $omegaUpper #> [1] Inf #>  #> $sigmaLower #> [1] -Inf #>  #> $sigmaUpper #> [1] Inf #>  #> $thetaLower #> [1] -Inf #>  #> $thetaUpper #> [1] Inf #>  #> $indLinPhiM #> [1] 0 #>  #> $indLinPhiTol #> [1] 1e-07 #>  #> $indLinMatExpType #> expokit  #>       2  #>  #> $indLinMatExpOrder #> [1] 6 #>  #> $idFactor #> [1] TRUE #>  #> $mxhnil #> [1] 0 #>  #> $hmxi #> [1] 0 #>  #> $warnIdSort #> [1] TRUE #>  #> $ssAtol #> [1] 1e-08 #>  #> $ssRtol #> [1] 1e-06 #>  #> $safeZero #> [1] 1 #>  #> $sumType #> pairwise  #>        1  #>  #> $prodType #> long double  #>           1  #>  #> $sensType #> advan  #>     4  #>  #> $linDiff #>    tlag       f    rate     dur   tlag2      f2   rate2    dur2  #> 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05 1.5e-05  #>  #> $linDiffCentral #>  tlag     f  rate   dur tlag2    f2 rate2  dur2  #>  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  #>  #> $resample #> NULL #>  #> $resampleID #> [1] TRUE #>  #> $maxwhile #> [1] 100000 #>  #> $cores #> [1] 0 #>  #> $atolSens #> [1] 1e-08 #>  #> $rtolSens #> [1] 1e-06 #>  #> $ssAtolSens #> [1] 1e-08 #>  #> $ssRtolSens #> [1] 1e-06 #>  #> $simVariability #> [1] NA #>  #> attr(,\"class\") #> [1] \"rxControl\" #>  #> $method #> [1] \"ML\" #>  #> $verbose #> [1] TRUE #>  #> $returnNlme #> [1] FALSE #>  #> $addProp #> [1] \"combined2\" #>  #> $calcTables #> [1] TRUE #>  #> $compress #> [1] TRUE #>  #> $random #> NULL #>  #> $fixed #> NULL #>  #> $weights #> NULL #>  #> $ci #> [1] 0.95 #>  #> $sigdig #> [1] 4 #>  #> $sigdigTable #> [1] 4 #>  #> $genRxControl #> [1] TRUE #>  #> attr(,\"class\") #> [1] \"nlmeControl\""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/reexports.html","id":null,"dir":"Reference","previous_headings":"","what":"Objects exported from other packages — reexports","title":"Objects exported from other packages — reexports","text":"objects imported packages. Follow links see documentation. magrittr %>% nlmixr2est .nlmixrNlmeFun, ACF, VarCorr, augPred, fixed.effects, fixef, getData, getVarCov, groupedData, nlme, nlmeControl, nlmixr, pdBlocked, pdCompSymm, pdConstruct, pdDiag, pdFactor, pdIdent, pdLogChol, pdMat, pdMatrix, pdNatural, pdSymm, random.effects, ranef, reStruct, varComb, varConstPower, varExp, varFixed, varFunc, varIdent, varPower, varWeights rxode2 RxODE, add.dosing, add.sampling, et, eventTable, expit, geom_amt, geom_cens, ini, lotri, model, probit, probitInv, rxCat, rxClean, rxControl, rxParam, rxParams, rxSolve, rxode, rxode2, stat_amt, stat_cens","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Control Options for SAEM — saemControl","title":"Control Options for SAEM — saemControl","text":"Control Options SAEM","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Control Options for SAEM — saemControl","text":"","code":"saemControl(   seed = 99,   nBurn = 200,   nEm = 300,   nmc = 3,   nu = c(2, 2, 2),   print = 1,   trace = 0,   covMethod = c(\"linFim\", \"fim\", \"r,s\", \"r\", \"s\", \"\"),   calcTables = TRUE,   logLik = FALSE,   nnodesGq = 3,   nsdGq = 1.6,   optExpression = TRUE,   adjObf = TRUE,   sumProd = FALSE,   addProp = c(\"combined2\", \"combined1\"),   tol = 1e-06,   itmax = 30,   type = c(\"nelder-mead\", \"newuoa\"),   powRange = 10,   lambdaRange = 3,   odeRecalcFactor = 10^(0.5),   maxOdeRecalc = 5L,   perSa = 0.75,   perNoCor = 0.75,   perFixOmega = 0.1,   perFixResid = 0.1,   compress = TRUE,   rxControl = NULL,   sigdig = NULL,   sigdigTable = NULL,   ci = 0.95,   muRefCov = TRUE,   ... )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Control Options for SAEM — saemControl","text":"seed Random Seed SAEM step.  (Needs set reproducibility.)  default 99. nBurn Number iterations first phase, ie  MCMC/Stochastic Approximation steps. equivalent Monolix's K_0 K_b. nEm Number iterations Expectation-Maximization (EM) Step. equivalent Monolix's K_1. nmc Number Markov Chains. default 3.  increase number chains numerical integration MC method accurate cost computation.  Monolix equivalent L. nu vector 3 integers. represent     numbers transitions three different kernels used     Hasting-Metropolis algorithm.  default value c(2,2,2),     representing 40 transition initially (value     multiplied 20). first value represents initial number multi-variate     Gibbs samples taken normal distribution. second value represents number uni-variate, multi-     dimensional random walk Gibbs samples taken. third value represents number bootstrap/reshuffling     uni-dimensional random samples taken. print number iterations completed anything printed console.  default, 1. trace integer indicating want trace(1) SAEM algorithm process.  Useful debugging, typical fitting. covMethod Method calculating covariance.      discussion, R Hessian matrix objective     function. S matrix sum individual's     gradient cross-product (evaluated individual empirical     Bayes estimates). \"linFim\" Use Linearized Fisher Information Matrix calculate covariance. \"fim\" Use SAEM-calculated Fisher Information Matrix calculate covariance. \"r,s\" Uses sandwich matrix calculate covariance, : \\(R^-1 \\times S \\times R^-1\\) \"r\" Uses Hessian matrix calculate covariance \\(2\\times R^-1\\) \"s\" Uses crossproduct matrix calculate covariance \\(4\\times S^-1\\) \"\" calculate covariance step. calcTables boolean determine foceiFit calculate tables. default TRUE logLik boolean indicating log-likelihood calculate Gaussian quadrature. nnodesGq number nodes use Gaussian quadrature computing likelihood method (defaults 1, equivalent Laplaclian likelihood) nsdGq span (SD) integrate computing likelihood Gaussian quadrature. Defaults 3 (eg 3 times SD) optExpression Optimize rxode2 expression speed calculation. default turned . adjObf boolean indicate objective function adjusted closer NONMEM's default objective function.  default TRUE sumProd boolean indicating model change multiplication high precision multiplication sums high precision sums using PreciseSums package.  default FALSE. addProp specifies type additive plus proportional   errors, one standard deviations add (combined1)   type variances add (combined2). combined1 error type can described following equation: y = f + (+ b*f^c)*err combined2 error model can described following equation: y = f + sqrt(^2 + b^2*(f^c)^2)*err : - y represents observed value - f represents predicted value -  additive standard deviation - b proportional/power standard deviation - c power exponent (proportional case c=1) tol tolerance regression models used complex residual errors (ie add+prop etc) itmax maximum number iterations regression models used complex residual errors.  number iterations itmax*number parameters type indicates type optimization residuals; Can one c(\"nelder-mead\", \"newuoa\") powRange indicates range powers can take residual errors;  default 10 indicating range c(-10, 10) lambdaRange indicates range Box-Cox Yeo-Johnson parameters constrained ;  default 3 indicating range c(-3,3) odeRecalcFactor ODE recalculation factor ODE solving goes bad, factor rtol/atol reduced maxOdeRecalc Maximum number times reduce ODE tolerances try resolve system bad ODE solve. perSa percent time `nBurn` iterations phase runs runs simulated annealing. perNoCor percentage MCMC phase SAEM algorithm variance/covariance matrix correlations.  Byt defualt 0.75 75 Monte-carlo iteration perFixOmega percentage `nBurn` phase omega values unfixed allow better exploration likelihood surface.  time, omegas fixed optimization. perFixResid percentage `nBurn` phase residual components unfixed allow better exploration likelihood surface. compress object compressed items rxControl `rxode2` ODE solving options fitting, created `rxControl()` sigdig Specifies \"significant digits\" ode solving requests.  specified controls relative absolute tolerances ODE solvers.  default tolerance 0.5*10^(-sigdig-2) regular ODEs. sensitivity equations steady-state solutions default 0.5*10^(-sigdig-1.5) (sensitivity changes applicable liblsoda).  default unspecified (NULL) uses standard atol/rtol. sigdigTable Significant digits final output table. specified, matches significant digits `sigdig` optimization algorithm.  `sigdig` NULL, use 3. ci Confidence level tables.  default 0.95 95% confidence. muRefCov controls mu-referenced covariates `saem` handled differently non mu-referenced covariates.  `TRUE`, mu-referenced covariates special handling.  `FALSE` mu-referenced covariates treated input parameter. ... Additional arguments passed nlmixr2est::saemControl().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Control Options for SAEM — saemControl","text":"List options used nlmixr2 fit     SAEM.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/saemControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Control Options for SAEM — saemControl","text":"Wenping Wang & Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":null,"dir":"Reference","previous_headings":"","what":"Set/get Objective function type for a nlmixr2 object — setOfv","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"Set/get Objective function type nlmixr2 object","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"","code":"setOfv(x, type)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"x nlmixr2 fit object type Type objective function use AIC, BIC, $objective","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"Nothing","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/setOfv.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Set/get Objective function type for a nlmixr2 object — setOfv","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":null,"dir":"Reference","previous_headings":"","what":"Output table/data.frame options — tableControl","title":"Output table/data.frame options — tableControl","text":"Output table/data.frame options","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Output table/data.frame options — tableControl","text":"","code":"tableControl(   npde = NULL,   cwres = NULL,   nsim = 300,   ties = TRUE,   censMethod = c(\"truncated-normal\", \"cdf\", \"ipred\", \"pred\", \"epred\", \"omit\"),   seed = 1009,   cholSEtol = (.Machine$double.eps)^(1/3),   state = TRUE,   lhs = TRUE,   eta = TRUE,   covariates = TRUE,   addDosing = FALSE,   subsetNonmem = TRUE,   cores = NULL,   keep = NULL,   drop = NULL )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Output table/data.frame options — tableControl","text":"npde TRUE, request npde regardless algorithm used. cwres TRUE, request CWRES FOCEi likelihood regardless algorithm used. nsim represents number simulations.  rxode2, supply single subject event tables (created [eventTable()]) ties `TRUE` jitter prediction-discrepancy points discourage ties cdf. censMethod Handle censoring method: - `\"truncated-normal\"` Simulates truncated normal distribution assumption model censoring. - `\"cdf\"` Use cdf-method censoring npde use residuals (`cwres` etc) - `\"omit\"` omit residuals censoring seed object specifying random number generator initialized cholSEtol tolerance `rxode2::choleSE` function state Boolean indicating `state` values included (default `TRUE`) lhs Boolean indicating remaining `lhs` values included (default `TRUE`) eta Boolean indicating `eta` values included (default `TRUE`) covariates Boolean indicating covariates included (default `TRUE`) addDosing Boolean indicating solve add rxode2 EVID related columns.  also include dosing information estimates doses.  default, rxode2 includes estimates observations. (default FALSE). addDosing NULL, include EVID=0 solve exclude model-times EVID=2. addDosing NA classic rxode2 EVID events returned. addDosing TRUE add event information NONMEM-style format; subsetNonmem=FALSE rxode2 also include extra event types (EVID) ending infusion modeled times: EVID=-1 modeled rate infusions turned (matches rate=-1) EVID=-2 modeled duration infusions turned (matches rate=-2) EVID=-10 specified rate infusions turned (matches rate>0) EVID=-20 specified dur infusions turned (matches dur>0) EVID=101,102,103,... Modeled time 101 first model time, 102 second etc. subsetNonmem subset NONMEM compatible EVIDs .  default TRUE. cores Number cores used parallel ODE solving.  equivalent calling setRxThreads() keep keep sent table drop dropped variables sent table","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Output table/data.frame options — tableControl","text":"list table options nlmixr2","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Output table/data.frame options — tableControl","text":"ever want add CWRES/FOCEi objective function can use addCwres ever want add NPDE/EPRED columns can use addNpde","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/tableControl.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Output table/data.frame options — tableControl","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":null,"dir":"Reference","previous_headings":"","what":"Produce trace-plot for fit if applicable — traceplot","title":"Produce trace-plot for fit if applicable — traceplot","text":"Produce trace-plot fit applicable","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Produce trace-plot for fit if applicable — traceplot","text":"","code":"traceplot(x, ...)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Produce trace-plot for fit if applicable — traceplot","text":"x fit object ... Additional arguments passed nlmixr2plot::traceplot().","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Produce trace-plot for fit if applicable — traceplot","text":"Fit traceplot nothing.","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/traceplot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"Produce trace-plot for fit if applicable — traceplot","text":"Rik Schoemaker, Wenping Wang & Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":null,"dir":"Reference","previous_headings":"","what":"VPC based on ui model — vpcPlot","title":"VPC based on ui model — vpcPlot","text":"VPC based ui model","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VPC based on ui model — vpcPlot","text":"","code":"vpcPlot(   fit,   data = NULL,   n = 300,   bins = \"jenks\",   n_bins = \"auto\",   bin_mid = \"mean\",   show = NULL,   stratify = NULL,   pred_corr = FALSE,   pred_corr_lower_bnd = 0,   pi = c(0.05, 0.95),   ci = c(0.05, 0.95),   uloq = NULL,   lloq = NULL,   log_y = FALSE,   log_y_min = 0.001,   xlab = NULL,   ylab = NULL,   title = NULL,   smooth = TRUE,   vpc_theme = NULL,   facet = \"wrap\",   scales = \"fixed\",   labeller = NULL,   vpcdb = FALSE,   verbose = FALSE,   ...,   seed = 1009 )"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VPC based on ui model — vpcPlot","text":"fit nlmixr2 fit object data data use augment VPC fit.  default fitted data, (can retrieved getData), can changed specifying argument. n Number VPC simulations.  default 100 bins either \"density\", \"time\", \"data\", \"none\", one approaches available classInterval() \"jenks\" (default) \"pretty\", numeric vector specifying bin separators. n_bins using \"auto\" binning method, number bins aim bin_mid either \"mean\" mean timepoints (default) \"middle\" use average bin boundaries. show show VPC (obs_dv, obs_ci, pi, pi_as_area, pi_ci, obs_median, sim_median, sim_median_ci) stratify character vector stratification variables. 1 2 stratification variables can supplied. pred_corr perform prediction-correction? pred_corr_lower_bnd lower bound prediction-correction pi simulated prediction interval plot. Default c(0.05, 0.95), ci confidence interval plot. Default (0.05, 0.95) uloq Number NULL indicating upper limit quantification. Default NULL. lloq Number NULL indicating lower limit quantification. Default NULL. log_y Boolean indicting whether y-axis shown logarithmic. Default FALSE. log_y_min minimal value using log_y argument. Default 1e-3. xlab label x axis ylab label y axis title title smooth \"smooth\" VPC (connect bin midpoints) show bins rectangular boxes. Default TRUE. vpc_theme theme used VPC. Expects list class vpc_theme created function vpc_theme() facet either \"wrap\", \"columns\", \"rows\" scales either \"fixed\" (default), \"free_y\", \"free_x\" \"free\" labeller ggplot2 labeller function passed underlying ggplot object vpcdb Boolean whether return underlying vpcdb rather plot verbose show debugging information (TRUE FALSE) ... Additional arguments passed nlmixr2plot::vpcPlot(). seed object specifying random number generator initialized","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VPC based on ui model — vpcPlot","text":"Simulated dataset (invisibly)","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"VPC based on ui model — vpcPlot","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcPlot.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VPC based on ui model — vpcPlot","text":"","code":"# \\donttest{ one.cmt <- function() {  ini({    ## You may label each parameter with a comment    tka <- 0.45 # Log Ka    tcl <- log(c(0, 2.7, 100)) # Log Cl    ## This works with interactive models    ## You may also label the preceding line with label(\"label text\")    tv <- 3.45; label(\"log V\")    ## the label(\"Label name\") works with all models    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd)  }) }  fit <- nlmixr2est::nlmixr(one.cmt, nlmixr2data::theo_sd, est=\"focei\") #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress parHist in nlmixr2 object, save 2072 #> Warning: gradient problems with initial estimate and covariance; see $scaleInfo #> Warning: last objective function was not at minimum, possible problems in optimization #> Warning: ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.)) #> Warning: initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  vpcPlot(fit) #>     # }"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":null,"dir":"Reference","previous_headings":"","what":"VPC simulation — vpcSim","title":"VPC simulation — vpcSim","text":"VPC simulation","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"VPC simulation — vpcSim","text":"","code":"vpcSim(object, ..., keep = NULL, n = 300, pred = FALSE, seed = 1009)"},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"VPC simulation — vpcSim","text":"object nlmixr2 fit object ... Additional arguments passed nlmixr2est::vpcSim(). keep Keep character vector n Number simulations pred predictions added simulation seed Seed set VPC simulation","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"VPC simulation — vpcSim","text":"data frame VPC simulation","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"VPC simulation — vpcSim","text":"Matthew L. Fidler","code":""},{"path":"https://nlmixr2.github.io/nlmixr2/reference/vpcSim.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"VPC simulation — vpcSim","text":"","code":"# \\donttest{ one.cmt <- function() {  ini({    ## You may label each parameter with a comment    tka <- 0.45 # Log Ka    tcl <- log(c(0, 2.7, 100)) # Log Cl    ## This works with interactive models    ## You may also label the preceding line with label(\"label text\")    tv <- 3.45; label(\"log V\")    ## the label(\"Label name\") works with all models    eta.ka ~ 0.6    eta.cl ~ 0.3    eta.v ~ 0.1    add.sd <- 0.7  })  model({    ka <- exp(tka + eta.ka)    cl <- exp(tcl + eta.cl)    v <- exp(tv + eta.v)    linCmt() ~ add(add.sd)  }) }  fit <- nlmixr(one.cmt, theo_sd, est=\"focei\") #>   #>   #>   #> ℹ parameter labels from comments will be replaced by 'label()' #> → Calculating residuals/tables #> ✔ done #> → compress origData in nlmixr2 object, save 5952 #> → compress parHist in nlmixr2 object, save 2072 #> Warning: gradient problems with initial estimate and covariance; see $scaleInfo #> Warning: last objective function was not at minimum, possible problems in optimization #> Warning: ETAs were reset to zero during optimization; (Can control by foceiControl(resetEtaP=.)) #> Warning: initial ETAs were nudged; (can control by foceiControl(etaNudge=., etaNudge2=))  head(vpcSim(fit, pred=TRUE)) #>   #>   sim.id id time    ipred        sim rxLambda rxYj rxLow rxHi     pred #> 1      1  1 0.00 0.000000 -0.6283886        1    2     0    1 0.000000 #> 2      1  1 0.25 3.019619  2.6545739        1    2     0    1 3.262732 #> 3      1  1 0.57 5.628867  6.6265894        1    2     0    1 5.830087 #> 4      1  1 1.12 8.039087  8.7118336        1    2     0    1 7.865576 #> 5      1  1 2.02 9.211883  8.9025113        1    2     0    1 8.506533 #> 6      1  1 3.82 8.607713  7.9094706        1    2     0    1 7.622375  # }"}]
